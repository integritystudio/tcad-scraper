# DETAILS.md

ğŸ” **Powered by [Detailer](https://detailer.ginylil.com)** - Context-aware codebase analysis



---

## 1. Project Overview

### Purpose & Domain
**tcad-scraper** is a comprehensive property data scraping and search system designed to extract, process, and serve detailed real estate property information primarily from Travis County Appraisal District (TCAD) sources. It addresses the problem of aggregating and structuring property tax and valuation data for use in analytics, search, and monitoring applications.

### Target Users & Use Cases
- **End Users:** Real estate professionals, investors, analysts, and developers seeking detailed property information.
- **Use Cases:**
  - Property search with rich filtering and sorting.
  - Automated scraping and data refresh of property tax and valuation data.
  - Monitoring and analytics of property data trends.
  - Integration with AI-powered natural language search.
  - Operational monitoring and queue management for scraping jobs.

### Core Business Logic & Domain Models
- **Property Data Model:** Includes property identifiers, owner info, addresses, valuations, exemptions, and metadata.
- **Scrape Jobs:** Background tasks representing scraping operations with statuses and results.
- **Search Terms & Monitoring:** Management of search terms, including zero-result and high-performing terms.
- **AI Integration:** Natural language query parsing via Claude AI for enhanced search capabilities.

---

## 2. Architecture and Structure

### High-Level Architecture
- **Frontend:** React-based UI with components for property search, filtering, analytics, and data presentation.
- **Backend API:** Node.js/Express server written in TypeScript, exposing RESTful endpoints for property data, scraping jobs, monitoring, and health checks.
- **Scraper:** Headless browser automation (Playwright) and fallback DOM scraping for data acquisition.
- **Queue System:** Redis-backed BullMQ queues manage scraping jobs asynchronously.
- **Scheduler:** Cron-based scheduled jobs trigger periodic scraping and cleanup.
- **Data Layer:** PostgreSQL database accessed via Prisma ORM, storing property data, scrape jobs, and monitoring info.
- **Monitoring:** Prometheus and Grafana for metrics collection and visualization.
- **Security:** JWT and API key authentication, CSP headers, and XController pattern for secure data embedding.
- **DevOps:** Dockerized deployment, Doppler for secrets management, CI/CD pipelines via GitHub Actions.

### Complete Repository Structure
```
.
â”œâ”€â”€ .claude/
â”‚   â””â”€â”€ agents/
â”‚       â””â”€â”€ webscraper-research-agent.md
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ README.md
â”‚       â”œâ”€â”€ ci.yml
â”‚       â”œâ”€â”€ deploy.yml
â”‚       â”œâ”€â”€ pr-checks.yml
â”‚       â””â”€â”€ security.yml
â”œâ”€â”€ bullmq-exporter/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ index.js
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ dev/
â”‚   â”œâ”€â”€ active/
â”‚   â”‚   â”œâ”€â”€ analytics-implementation-context.md
â”‚   â”‚   â”œâ”€â”€ analytics-implementation-tasks.md
â”‚   â”‚   â”œâ”€â”€ ci-cd-implementation-context.md
â”‚   â”‚   â”œâ”€â”€ ci-cd-implementation-tasks.md
â”‚   â”‚   â”œâ”€â”€ test-coverage-improvement-context.md
â”‚   â”‚   â””â”€â”€ test-coverage-improvement-tasks.md
â”‚   â”œâ”€â”€ HANDOFF-2025-11-08.md
â”‚   â”œâ”€â”€ HANDOFF.md
â”‚   â”œâ”€â”€ QUICK-START-SESSION-4.md
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ SESSION-3-SUMMARY.md
â”‚   â”œâ”€â”€ SESSION_SUMMARY.md
â”‚   â””â”€â”€ repo-summary.json
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ ANALYTICS.md
â”‚   â”œâ”€â”€ API.md
â”‚   â”œâ”€â”€ API_TOKEN_IMPLEMENTATION.md
â”‚   â”œâ”€â”€ API_TOKEN_VERIFICATION.md
â”‚   â”œâ”€â”€ BRANCH-PROTECTION.md
â”‚   â”œâ”€â”€ CHANGELOG.md
â”‚   â”œâ”€â”€ CI-CD.md
â”‚   â”œâ”€â”€ CLAUDE.md
â”‚   â”œâ”€â”€ CODEBASE_ANALYSIS.md
â”‚   â”œâ”€â”€ ENQUEUE_FIXES_SUMMARY.md
â”‚   â””â”€â”€ ... (11 more files)
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ grafana/
â”‚   â”‚   â”œâ”€â”€ dashboards/
â”‚   â”‚   â”‚   â”œâ”€â”€ code-complexity.json
â”‚   â”‚   â”‚   â””â”€â”€ tcad-overview.json
â”‚   â”‚   â””â”€â”€ provisioning/
â”‚   â”‚       â”œâ”€â”€ dashboards/
â”‚   â”‚       â””â”€â”€ datasources/
â”‚   â”œâ”€â”€ prometheus/
â”‚   â”‚   â”œâ”€â”€ prometheus.rules.yml
â”‚   â”‚   â””â”€â”€ prometheus.yml
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ CNAME
â”‚   â””â”€â”€ favicon.svg
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ setup-branch-protection.sh
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ .github/
â”‚   â”‚   â”œâ”€â”€ workflows/
â”‚   â”‚   â”œâ”€â”€ changelog-config.json
â”‚   â”‚   â””â”€â”€ dependabot.yml
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ high-performing-terms.json
â”‚   â”‚   â”œâ”€â”€ search-term-map.json
â”‚   â”‚   â”œâ”€â”€ search-term-results.csv
â”‚   â”‚   â”œâ”€â”€ zero-result-analysis.json
â”‚   â”‚   â””â”€â”€ zero-result-terms.json
â”‚   â”œâ”€â”€ docs/
â”‚   â”‚   â”œâ”€â”€ TEST-COVERAGE-SESSION-2025-11-08.md
â”‚   â”‚   â”œâ”€â”€ TEST-DATABASE-SETUP.md
â”‚   â”‚   â””â”€â”€ TEST-SEPARATION-STRATEGY.md
â”‚   â”œâ”€â”€ fallbackBrowserSearch/
â”‚   â”‚   â”œâ”€â”€ scraper-with-db.ts
â”‚   â”‚   â”œâ”€â”€ tcad-scraper.cjs
â”‚   â”‚   â”œâ”€â”€ test-manual-search.ts
â”‚   â”‚   â””â”€â”€ test-search-types.ts
â”‚   â”œâ”€â”€ one-off-enqueues/
â”‚   â”‚   â”œâ”€â”€ add-business-batch-3.ts
â”‚   â”‚   â”œâ”€â”€ add-business-terms.ts
â”‚   â”‚   â””â”€â”€ add-terms-and-dedupe.ts
â”‚   â”œâ”€â”€ .env.example
â”‚   â”œâ”€â”€ .eslintrc.json
â”‚   â”œâ”€â”€ BATCH_UPSERT_OPTIMIZATION.md
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ ENQUEUE_SCRIPTS_README.md
â”‚   â””â”€â”€ ... (4 more directories, 20 more files)
â”œâ”€â”€ shared/
â”‚   â””â”€â”€ types/
â”‚       â”œâ”€â”€ SCHEMA-DOCUMENTATION.md
â”‚       â”œâ”€â”€ index.ts
â”‚       â”œâ”€â”€ json-ld.utils.ts
â”‚       â””â”€â”€ property.types.ts
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”‚   â””â”€â”€ PropertySearch/
â”‚   â”‚   â”‚       â”œâ”€â”€ ExampleQueries.tsx
â”‚   â”‚   â”‚       â”œâ”€â”€ PropertyCard.tsx
â”‚   â”‚   â”‚       â”œâ”€â”€ PropertySearchContainer.tsx
â”‚   â”‚   â”‚       â”œâ”€â”€ SearchBox.tsx
â”‚   â”‚   â”‚       â”œâ”€â”€ SearchResults.tsx
â”‚   â”‚   â”‚       â””â”€â”€ index.ts
â”‚   â”‚   â”œâ”€â”€ ui/
â”‚   â”‚   â”‚   â”œâ”€â”€ Badge/
â”‚   â”‚   â”‚   â”œâ”€â”€ Button/
â”‚   â”‚   â”‚   â”œâ”€â”€ Card/
â”‚   â”‚   â”‚   â”œâ”€â”€ Icon/
â”‚   â”‚   â”‚   â”œâ”€â”€ Input/
â”‚   â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚   â”œâ”€â”€ Analytics.css
â”‚   â”‚   â”œâ”€â”€ Analytics.tsx
â”‚   â”‚   â”œâ”€â”€ Charts.css
â”‚   â”‚   â”œâ”€â”€ Charts.tsx
â”‚   â”‚   â”œâ”€â”€ ErrorBoundary.tsx
â”‚   â”‚   â”œâ”€â”€ Filters.css
â”‚   â”‚   â”œâ”€â”€ Filters.tsx
â”‚   â”‚   â”œâ”€â”€ PropertySearch.css
â”‚   â”‚   â”œâ”€â”€ PropertySearch.tsx
â”‚   â”‚   â”œâ”€â”€ PropertyTable.css
â”‚   â”‚   â”œâ”€â”€ PropertyTable.tsx
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ ScrapeManager.css
â”‚   â”‚   â””â”€â”€ ScrapeManager.tsx
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”œâ”€â”€ index.ts
â”‚   â”‚   â”œâ”€â”€ useAnalytics.ts
â”‚   â”‚   â”œâ”€â”€ useDebounce.ts
â”‚   â”‚   â”œâ”€â”€ useFormatting.ts
â”‚   â”‚   â”œâ”€â”€ usePagination.ts
â”‚   â”‚   â””â”€â”€ usePropertySearch.ts
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ __tests__/
â”‚   â”‚   â”œâ”€â”€ analytics.ts
â”‚   â”‚   â”œâ”€â”€ api-config.ts
â”‚   â”‚   â”œâ”€â”€ logger.ts
â”‚   â”‚   â””â”€â”€ xcontroller.client.ts
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â””â”€â”€ api.service.ts
â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ constants.ts
â”‚   â”‚   â”œâ”€â”€ formatters.ts
â”‚   â”‚   â”œâ”€â”€ helpers.ts
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”œâ”€â”€ App.css
â”‚   â”œâ”€â”€ App.tsx
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ database.ts
â”‚   â”œâ”€â”€ main.tsx
â”‚   â”œâ”€â”€ query-db.ts
â”‚   â”œâ”€â”€ test-api-direct.ts
â”‚   â””â”€â”€ vite-env.d.ts
â”œâ”€â”€ .env.example
â”œâ”€â”€ .env.monitoring.example
â”œâ”€â”€ .eslintrc.json
â”œâ”€â”€ .gitattributes
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .mcp.json
â”œâ”€â”€ .repomixignore
â”œâ”€â”€ ANALYSIS_SUMMARY.md
â”œâ”€â”€ ARCHITECTURE.md
â”œâ”€â”€ CNAME
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ MONITORING_DEPLOYMENT.md
â”œâ”€â”€ MONITORING_SETUP_SUMMARY.md
â”œâ”€â”€ QUICK_START_MONITORING.md
â”œâ”€â”€ README.md
â”œâ”€â”€ SESSION_CONTEXT.md
â”œâ”€â”€ batch-migrate-client.py
â”œâ”€â”€ bullmq-dashboard.json
â”œâ”€â”€ docker-compose.monitoring.yml
â”œâ”€â”€ docker-compose.override.yml
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ index.html
â”œâ”€â”€ index.js
â”œâ”€â”€ jest.client.config.js
â”œâ”€â”€ jest.config.cjs
â”œâ”€â”€ jest.setup.js
â”œâ”€â”€ monitor-queue.sh
â”œâ”€â”€ package-lock.json
â”œâ”€â”€ package.json
â”œâ”€â”€ refresh-tcad-token.sh
â”œâ”€â”€ refresh-token.js
â”œâ”€â”€ repomix-output.xml
â”œâ”€â”€ repomix.config.json
â”œâ”€â”€ search-terms-summary.sh
â”œâ”€â”€ setup-tcad.sh
â”œâ”€â”€ start.sh
â”œâ”€â”€ tcad-cli.cjs
â”œâ”€â”€ tcad.package
â”œâ”€â”€ test-database.ts
â”œâ”€â”€ tsconfig.app.json
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ view-queue-logs.sh
â””â”€â”€ vite.config.ts
```

---

## 3. Technical Implementation Details

### Backend Server (`server/src/index.ts` and related)
- Express.js server with layered middleware:
  - Security (Helmet, CSP via XController pattern)
  - Authentication (API key, JWT)
  - Metrics collection (Prometheus)
  - Error handling
- Routes organized under `server/src/routes/`:
  - `property.routes.ts` handles property-related API endpoints.
  - `app.routes.ts` serves frontend and SPA fallback.
- Background job processing with BullMQ queues (`server/src/queues/scraper.queue.ts`).
- Scheduled jobs via `node-cron` in `server/src/schedulers/scrape-scheduler.ts`.
- Token refresh automation via `server/src/services/token-refresh.service.ts`.
- Database access via Prisma ORM (`server/src/lib/prisma.ts`).
- Fallback scraping via DOM with Playwright (`server/src/lib/fallback/dom-scraper.ts`).
- AI integration with Claude API (`server/src/lib/claude.service.ts`).

### Frontend (`src/`)
- React 18 with TypeScript.
- Feature-based component architecture under `src/components/features/PropertySearch/`.
- UI components under `src/components/ui/` (Button, Badge, Card, Icon, Input).
- Custom hooks for analytics, formatting, pagination, and property search (`src/hooks/`).
- Styling via CSS Modules.
- Analytics integration with Google Analytics 4 and Meta Pixel (`src/lib/analytics.ts`).
- API client abstraction in `src/services/api.service.ts`.
- Data models and validation schemas in `src/types/` and `shared/types/`.

### Queue & Job Management
- BullMQ queues with Redis backend.
- Job enqueueing scripts in `server/one-off-enqueues/` and `server/src/scripts/`.
- CLI tools for queue management and analysis under `server/scripts-archive/` and `server/src/cli/`.
- Deduplication and cleanup utilities in `server/src/utils/deduplication.ts`.

### Monitoring & Observability
- Prometheus metrics exposed via `/metrics`.
- Grafana dashboards configured under `monitoring/grafana/`.
- Health endpoints under `/health/*`.
- Logging with Pino and Winston.
- Sentry integration for error tracking.

---

## 4. Development Patterns and Standards

- **TypeScript Strict Typing:**  
  Strong use of interfaces and types for domain models, API contracts, and component props.
- **Test Stratification:**  
  Separate Jest configs for unit (`jest.config.js`) and integration tests (`jest.integration.config.js`).
- **Mocking & Isolation:**  
  Tests mock external dependencies (Redis, Prisma, Playwright) for deterministic behavior.
- **Middleware Pattern:**  
  Express middleware for auth, validation, error handling, and metrics.
- **Component-Based UI:**  
  React functional components with hooks and CSS Modules.
- **Command Pattern:**  
  CLI tools and scripts encapsulate discrete operational tasks.
- **Repository Pattern:**  
  Prisma ORM abstracts database access.
- **Service Pattern:**  
  Services encapsulate external API interactions and token management.
- **Scheduler Pattern:**  
  Cron jobs for periodic scraping and cleanup.
- **Security Best Practices:**  
  CSP headers, nonce generation, JWT and API key auth, XSS prevention.
- **Configuration Management:**  
  Environment variables managed via Doppler; `.env` files for local dev.
- **Error Handling:**  
  Centralized error middleware; Sentry for error reporting.
- **Logging:**  
  Structured logging with Pino and Winston.
- **Performance Optimization:**  
  Batch upsert in database; queue deduplication; caching with Redis.

---

## 5. Integration and Dependencies

### External Libraries & Services
- **Node.js ecosystem:** Express, BullMQ, Prisma, Playwright, Jest, Axios.
- **Redis:** For caching and queue backend.
- **PostgreSQL:** Primary data store.
- **Prometheus & Grafana:** Metrics and monitoring.
- **Sentry:** Error tracking.
- **Claude AI:** Natural language query parsing.
- **Doppler:** Secrets management.
- **Docker:** Containerization and orchestration.
- **GitHub Actions:** CI/CD pipelines.

### Internal Modules & Contracts
- Modular codebase with clear separation:
  - `lib/` for utilities and services.
  - `routes/` for API endpoints.
  - `queues/` for job management.
  - `schedulers/` for cron jobs.
  - `services/` for business logic.
  - `components/` and `hooks/` for frontend UI.
- Shared types in `shared/types/` and `src/types/`.
- API contracts defined via TypeScript interfaces and Zod schemas.

---

## 6. Usage and Operational Guidance

### Setup & Deployment
- Use `Dockerfile` and `docker-compose.yml` for containerized deployment.
- Secrets managed via Doppler; `.env.example` provided for local dev.
- Run `setup-tcad.sh` and `start.sh` scripts for environment setup and service startup.
- Database migrations managed via Prisma CLI (`npx prisma migrate`).
- Redis and PostgreSQL must be running and accessible.

### Running the Server
- Start backend server with `npm run dev` or `npm start` inside `server/`.
- Frontend served via Vite (`npm run dev` in root or `src/`).
- API available under `/api/` routes.
- Health endpoints under `/health/*` for monitoring.

### Queue Management
- Use CLI scripts under `server/src/cli/` or `server/one-off-enqueues/` to enqueue scraping jobs.
- Monitor queues via Bull Board dashboard and Prometheus/Grafana.
- Deduplicate and clean queues with provided utilities (`deduplication.ts`).

### Testing
- Run unit tests with `npm run test` (unit) and `npm run test:integration` (integration).
- Tests located under `server/src/__tests__`, `server/src/lib/__tests__`, and frontend test files.
- Coverage reports generated separately for unit and integration tests.

### Monitoring & Logging
- Metrics exposed at `/metrics` for Prometheus scraping.
- Grafana dashboards configured for system health, queue status, and code complexity.
- Logs managed via Pino and Winston; Sentry captures errors.
- Use `monitor-queue.sh` and `view-queue-logs.sh` for operational log inspection.

### Security & Configuration
- API key and JWT authentication enforced.
- CSP headers and nonce middleware protect against XSS.
- Environment variables control feature flags and secrets.
- Token refresh service automates API token lifecycle.

---

## Actionable Insights for Developers and AI Agents

- **To understand data flow:**  
  Follow the scraping job lifecycle from enqueueing (`server/src/queues/scraper.queue.ts`), processing (worker scripts), to data persistence (`server/src/lib/prisma.ts`).

- **To extend scraping:**  
  Modify or add scraping logic in `server/src/lib/tcad-scraper.ts` and fallback in `server/src/lib/fallback/dom-scraper.ts`.

- **To add API endpoints:**  
  Define routes in `server/src/routes/`, implement controllers in `server/src/controllers/`, and validate inputs with middleware.

- **To debug or monitor:**  
  Use Prometheus metrics, Grafana dashboards, and Bull Board UI. Logs are structured and centralized.

- **To run tests:**  
  Use Jest configs for unit and integration tests. Mock external dependencies for isolated testing.

- **To manage secrets:**  
  Use Doppler CLI and environment variables; avoid hardcoding secrets.

- **To deploy:**  
  Use Docker and docker-compose with provided configs. Ensure environment variables and secrets are set.

- **To maintain code quality:**  
  Follow ESLint rules, use provided code complexity metrics, and adhere to documented coding standards.

---

# End of DETAILS.md for tcad-scraper