This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
migrations/
  20251028203525_init/
    migration.sql
  20251107200405_add_search_term_analytics/
    migration.sql
  migration_lock.toml
schema.prisma
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="migrations/20251028203525_init/migration.sql">
-- CreateTable
CREATE TABLE "properties" (
    "id" TEXT NOT NULL,
    "property_id" TEXT NOT NULL,
    "name" TEXT NOT NULL,
    "prop_type" TEXT NOT NULL,
    "city" TEXT,
    "property_address" TEXT NOT NULL,
    "assessed_value" DOUBLE PRECISION,
    "appraised_value" DOUBLE PRECISION NOT NULL,
    "geo_id" TEXT,
    "description" TEXT,
    "search_term" TEXT,
    "scraped_at" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
    "created_at" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
    "updated_at" TIMESTAMP(3) NOT NULL,

    CONSTRAINT "properties_pkey" PRIMARY KEY ("id")
);

-- CreateTable
CREATE TABLE "scrape_jobs" (
    "id" TEXT NOT NULL,
    "search_term" TEXT NOT NULL,
    "status" TEXT NOT NULL,
    "result_count" INTEGER,
    "error" TEXT,
    "started_at" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
    "completed_at" TIMESTAMP(3),

    CONSTRAINT "scrape_jobs_pkey" PRIMARY KEY ("id")
);

-- CreateTable
CREATE TABLE "monitored_searches" (
    "id" TEXT NOT NULL,
    "search_term" TEXT NOT NULL,
    "active" BOOLEAN NOT NULL DEFAULT true,
    "frequency" TEXT NOT NULL DEFAULT 'daily',
    "last_run" TIMESTAMP(3),
    "created_at" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
    "updated_at" TIMESTAMP(3) NOT NULL,

    CONSTRAINT "monitored_searches_pkey" PRIMARY KEY ("id")
);

-- CreateIndex
CREATE UNIQUE INDEX "properties_property_id_key" ON "properties"("property_id");

-- CreateIndex
CREATE INDEX "properties_search_term_scraped_at_idx" ON "properties"("search_term", "scraped_at");

-- CreateIndex
CREATE INDEX "properties_property_id_idx" ON "properties"("property_id");

-- CreateIndex
CREATE INDEX "properties_city_idx" ON "properties"("city");

-- CreateIndex
CREATE INDEX "properties_prop_type_idx" ON "properties"("prop_type");

-- CreateIndex
CREATE INDEX "properties_appraised_value_idx" ON "properties"("appraised_value");

-- CreateIndex
CREATE INDEX "scrape_jobs_status_started_at_idx" ON "scrape_jobs"("status", "started_at");

-- CreateIndex
CREATE INDEX "scrape_jobs_search_term_idx" ON "scrape_jobs"("search_term");

-- CreateIndex
CREATE UNIQUE INDEX "monitored_searches_search_term_key" ON "monitored_searches"("search_term");
</file>

<file path="migrations/20251107200405_add_search_term_analytics/migration.sql">
-- CreateTable
CREATE TABLE "search_term_analytics" (
    "id" TEXT NOT NULL,
    "search_term" TEXT NOT NULL,
    "term_length" INTEGER NOT NULL,
    "total_searches" INTEGER NOT NULL DEFAULT 0,
    "successful_searches" INTEGER NOT NULL DEFAULT 0,
    "failed_searches" INTEGER NOT NULL DEFAULT 0,
    "total_results" INTEGER NOT NULL DEFAULT 0,
    "avg_results_per_search" DOUBLE PRECISION NOT NULL DEFAULT 0,
    "max_results" INTEGER NOT NULL DEFAULT 0,
    "min_results" INTEGER,
    "last_searched" TIMESTAMP(3) NOT NULL,
    "success_rate" DOUBLE PRECISION NOT NULL DEFAULT 0,
    "efficiency" DOUBLE PRECISION NOT NULL DEFAULT 0,
    "created_at" TIMESTAMP(3) NOT NULL DEFAULT CURRENT_TIMESTAMP,
    "updated_at" TIMESTAMP(3) NOT NULL,

    CONSTRAINT "search_term_analytics_pkey" PRIMARY KEY ("id")
);

-- CreateIndex
CREATE INDEX "search_term_analytics_efficiency_idx" ON "search_term_analytics"("efficiency");

-- CreateIndex
CREATE INDEX "search_term_analytics_avg_results_per_search_idx" ON "search_term_analytics"("avg_results_per_search");

-- CreateIndex
CREATE INDEX "search_term_analytics_term_length_idx" ON "search_term_analytics"("term_length");

-- CreateIndex
CREATE INDEX "search_term_analytics_last_searched_idx" ON "search_term_analytics"("last_searched");

-- CreateIndex
CREATE UNIQUE INDEX "search_term_analytics_search_term_key" ON "search_term_analytics"("search_term");
</file>

<file path="migrations/migration_lock.toml">
# Please do not edit this file manually
# It should be added in your version-control system (i.e. Git)
provider = "postgresql"
</file>

<file path="schema.prisma">
generator client {
  provider = "prisma-client-js"
}

datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
}

model Property {
  id              String   @id @default(uuid())
  propertyId      String   @map("property_id") @unique
  name            String
  propType        String   @map("prop_type")
  city            String?
  propertyAddress String   @map("property_address")
  assessedValue   Float?   @map("assessed_value")
  appraisedValue  Float    @map("appraised_value")
  geoId           String?  @map("geo_id")
  description     String?  @db.Text
  searchTerm      String?  @map("search_term")
  scrapedAt       DateTime @default(now()) @map("scraped_at")
  createdAt       DateTime @default(now()) @map("created_at")
  updatedAt       DateTime @updatedAt @map("updated_at")

  @@index([searchTerm, scrapedAt])
  @@index([propertyId])
  @@index([city])
  @@index([propType])
  @@index([appraisedValue])
  @@map("properties")
}

model ScrapeJob {
  id          String    @id @default(uuid())
  searchTerm  String    @map("search_term")
  status      String    // pending, processing, completed, failed
  resultCount Int?      @map("result_count")
  error       String?   @db.Text
  startedAt   DateTime  @default(now()) @map("started_at")
  completedAt DateTime? @map("completed_at")

  @@index([status, startedAt])
  @@index([searchTerm])
  @@map("scrape_jobs")
}

model MonitoredSearch {
  id         String   @id @default(uuid())
  searchTerm String   @map("search_term") @unique
  active     Boolean  @default(true)
  frequency  String   @default("daily") // daily, weekly, monthly
  lastRun    DateTime? @map("last_run")
  createdAt  DateTime @default(now()) @map("created_at")
  updatedAt  DateTime @updatedAt @map("updated_at")

  @@map("monitored_searches")
}

model SearchTermAnalytics {
  id                String   @id @default(uuid())
  searchTerm        String   @map("search_term")
  termLength        Int      @map("term_length")
  totalSearches     Int      @default(0) @map("total_searches")
  successfulSearches Int     @default(0) @map("successful_searches")
  failedSearches    Int      @default(0) @map("failed_searches")
  totalResults      Int      @default(0) @map("total_results")
  avgResultsPerSearch Float  @default(0) @map("avg_results_per_search")
  maxResults        Int      @default(0) @map("max_results")
  minResults        Int?     @map("min_results")
  lastSearched      DateTime @map("last_searched")
  successRate       Float    @default(0) @map("success_rate")
  efficiency        Float    @default(0) // Results per search weighted by success rate
  createdAt         DateTime @default(now()) @map("created_at")
  updatedAt         DateTime @updatedAt @map("updated_at")

  @@unique([searchTerm])
  @@index([efficiency])
  @@index([avgResultsPerSearch])
  @@index([termLength])
  @@index([lastSearched])
  @@map("search_term_analytics")
}
</file>

</files>
