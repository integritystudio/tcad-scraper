This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
README_ENHANCED.md
scraper-with-db.ts
tcad-scraper.cjs
test-manual-search.ts
test-search-types.ts
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="README_ENHANCED.md">
# fallbackBrowserSearch

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "SoftwareSourceCode",
  "name": "fallbackBrowserSearch",
  "description": "Directory containing 3 code files with 0 classes and 3 functions",
  "programmingLanguage": [
    {
      "@type": "ComputerLanguage",
      "name": "Typescript"
    }
  ],
  "featureList": [
    "3 function definitions"
  ]
}
</script>

## Overview

This directory contains 3 code file(s) with extracted schemas.

## Files and Schemas

### `scraper-with-db.ts` (typescript)

**Functions:**
- `async scrapePropertyTaxInformation()` - Line 7

### `test-manual-search.ts` (typescript)

**Functions:**
- `async testManualSearch()` - Line 2

### `test-search-types.ts` (typescript)

**Functions:**
- `async testSearchTypes()` - Line 2

---
*Generated by Enhanced Schema Generator with schema.org markup*
</file>

<file path="scraper-with-db.ts">
import puppeteer from 'puppeteer';
import * as cheerio from 'cheerio';
import { insertProperties, getPropertyCount, closePool, Property } from './src/database.js';

const width = 1440;
const height = 900;

async function scrapePropertyTaxInformation() {
  const browser = await puppeteer.launch({
    headless: true,
    ignoreHTTPSErrors: true,
    args: [`--window-size=${width},${height}`, '--no-sandbox', '--disable-setuid-sandbox']
  });
  const page = await browser.newPage();
  const url = 'https://stage.travis.prodigycad.com/property-search';
  const searchInput = 'dede';

  try {
    console.log('üîç Starting scrape...');

    // Navigate to the TCAD website
    await page.goto(url, {waitUntil: "networkidle0"});

    // Input search term
    await page.type('input[type="text"]', searchInput);

    // Submit the search form
    await page.keyboard.press('Enter');

    // Wait for results to load
    await page.waitForSelector('[role="gridcell"]');

    // Parse result rows with Cheerio
    const info: Property[] = [];
    const htmlContent = await page.content();
    const $ = cheerio.load(htmlContent);

    // Find all rows that contain gridcells (data rows, not header rows)
    const rows = $('[role="row"]').filter((i, row) => {
      return $(row).find('[role="gridcell"]').length > 0;
    });

    console.log(`üìã Found ${rows.length} data rows`);

    // Extract property information using available col-ids
    rows.each((index, row) => {
      const propertyData = {
        name: $(row).find('[col-id="displayName"]').text().trim(), // Owner name
        propType: $(row).find('[col-id="propType"]').text().trim(),
        city: '', // Not available in this view
        propertyAddress: '', // Not available in this view
        assessedValue: '', // Not available in this view
        propertyID: $(row).find('[col-id="pid"]').text().trim(),
        appraisedValue: '', // Not available in this view
        description: $(row).find('[col-id="refID1"]').text().trim(), // Using refID1 as description
        geoID: $(row).find('[col-id="geoID"]').text().trim(),
      };

      info.push(propertyData);
    });

    // Filter out empty results - use propertyID since address is not available in this view
    const validProperties = info.filter(elem => elem.propertyID !== '');
    console.log(`‚úì Found ${validProperties.length} valid properties`);

    // Save to database
    if (validProperties.length > 0) {
      console.log('üíæ Saving to database...');
      await insertProperties(validProperties);

      const totalCount = await getPropertyCount();
      console.log(`‚úì Database now contains ${totalCount} total properties`);
    }

    console.log('\nüìä Sample of scraped data:');
    console.log(validProperties.slice(0, 3));

  } catch (error) {
    console.error('‚ùå Error:', error);
  } finally {
    await browser.close();
    await closePool();
    console.log('‚úì Done!');
  }
}

// Call the scraping function
scrapePropertyTaxInformation();
</file>

<file path="tcad-scraper.cjs">
const { Queue, Worker } = require('bullmq');
const puppeteer = require('puppeteer');
const cheerio = require('cheerio');

// Redis connection configuration
const connection = {
  host: process.env.REDIS_HOST,
  port: process.env.REDIS_PORT,
};

// Queue for scraping jobs
const scrapingQueue = new Queue('tcad-scraping', { connection });

// Configuration
const CONFIG = {
  TCAD_URL: 'https://stage.travis.prodigycad.com/property-search',
  CONCURRENT_WORKERS: parseInt(process.env.CONCURRENT_WORKERS),
  BATCH_SIZE: parseInt(process.env.BATCH_SIZE),
  RETRY_ATTEMPTS: 3,
  TIMEOUT: 60000, // 60 seconds
};

/**
 * Scrape property data for a single search term
 */
async function scrapeProperty(searchTerm) {
  let browser;
  
  try {
    // Launch browser
    browser = await puppeteer.launch({
      headless: 'new',
      args: [
        '--no-sandbox',
        '--disable-setuid-sandbox',
        '--disable-dev-shm-usage',
      ],
    });

    const page = await browser.newPage();
    await page.setViewport({ width: 1280, height: 800 });

    console.log(`üîç Searching for: ${searchTerm}`);

    // Navigate to TCAD search page
    await page.goto(CONFIG.TCAD_URL, {
      waitUntil: 'networkidle2',
      timeout: CONFIG.TIMEOUT,
    });

    // Wait for search input and enter search term
    await page.waitForSelector('input[type="text"]', { timeout: 10000 });
    await page.type('input[type="text"]', searchTerm);

    // Click search button
    await page.click('button[type="submit"]');

    // Wait for results grid to load
    await page.waitForSelector('.ag-root', { timeout: 15000 });

    // Give extra time for all data to load
    await page.waitForTimeout(2000);

    // Get page HTML and parse with Cheerio
    const html = await page.content();
    const $ = cheerio.load(html);

    // Extract property data from results table
    const properties = [];
    $('.ag-row').each((index, element) => {
      const cells = $(element).find('.ag-cell');
      
      // Extract data from each cell
      const property = {
        searchTerm,
        ownerName: $(cells[0]).text().trim(),
        propertyType: $(cells[1]).text().trim(),
        city: $(cells[2]).text().trim(),
        propertyAddress: $(cells[3]).text().trim(),
        assessedValue: $(cells[4]).text().trim(),
        propertyId: $(cells[5]).text().trim(),
        appraisedValue: $(cells[6]).text().trim(),
        geographicId: $(cells[7]).text().trim(),
        legalDescription: $(cells[8]).text().trim(),
        scrapedAt: new Date().toISOString(),
      };

      // Only add if we have meaningful data
      if (property.ownerName || property.propertyAddress) {
        properties.push(property);
      }
    });

    console.log(`‚úÖ Found ${properties.length} properties for "${searchTerm}"`);

    return {
      success: true,
      searchTerm,
      count: properties.length,
      properties,
    };

  } catch (error) {
    console.error(`‚ùå Error scraping "${searchTerm}":`, error.message);
    
    return {
      success: false,
      searchTerm,
      error: error.message,
      count: 0,
      properties: [],
    };

  } finally {
    if (browser) {
      await browser.close();
    }
  }
}

/**
 * Worker to process scraping jobs
 */
const worker = new Worker(
  'tcad-scraping',
  async (job) => {
    const { searchTerms, batchId } = job.data;

    console.log(`\nüì¶ Processing batch ${batchId} with ${searchTerms.length} search terms`);
    console.log(`Terms: ${searchTerms.join(', ')}`);

    const results = [];
    let successCount = 0;
    let failureCount = 0;

    // Process each search term sequentially to avoid overwhelming the server
    for (const searchTerm of searchTerms) {
      try {
        // Update progress
        await job.updateProgress({
          current: results.length + 1,
          total: searchTerms.length,
          currentTerm: searchTerm,
        });

        const result = await scrapeProperty(searchTerm);
        results.push(result);

        if (result.success) {
          successCount++;
        } else {
          failureCount++;
        }

        // Small delay between searches to be respectful
        await new Promise(resolve => setTimeout(resolve, 1000));

      } catch (error) {
        console.error(`Error processing "${searchTerm}":`, error);
        failureCount++;
        results.push({
          success: false,
          searchTerm,
          error: error.message,
          properties: [],
        });
      }
    }

    const summary = {
      batchId,
      totalSearches: searchTerms.length,
      successCount,
      failureCount,
      totalProperties: results.reduce((sum, r) => sum + r.count, 0),
      completedAt: new Date().toISOString(),
    };

    console.log(`\n‚úÖ Batch ${batchId} completed:`);
    console.log(`   - Successful: ${successCount}`);
    console.log(`   - Failed: ${failureCount}`);
    console.log(`   - Total properties: ${summary.totalProperties}`);

    return {
      summary,
      results,
    };
  },
  {
    connection,
    concurrency: CONFIG.CONCURRENT_WORKERS,
    limiter: {
      max: 10, // Max 10 jobs
      duration: 60000, // per minute
    },
  }
);

// Worker event listeners
worker.on('completed', (job) => {
  console.log(`\nüéâ Job ${job.id} completed successfully`);
});

worker.on('failed', (job, err) => {
  console.error(`\n‚ùå Job ${job.id} failed:`, err.message);
});

worker.on('progress', (job, progress) => {
  console.log(`üìä Job ${job.id} progress: ${progress.current}/${progress.total} - ${progress.currentTerm}`);
});

/**
 * Add a batch of search terms to the queue
 */
async function addBatch(searchTerms, options = {}) {
  // Split into batches if needed
  const batches = [];
  for (let i = 0; i < searchTerms.length; i += CONFIG.BATCH_SIZE) {
    batches.push(searchTerms.slice(i, i + CONFIG.BATCH_SIZE));
  }

  console.log(`\nüì§ Adding ${batches.length} batch(es) with ${searchTerms.length} total search terms`);

  const jobs = [];
  for (let i = 0; i < batches.length; i++) {
    const batchId = `batch-${Date.now()}-${i}`;
    
    const job = await scrapingQueue.add(
      'scrape-batch',
      {
        batchId,
        searchTerms: batches[i],
      },
      {
        attempts: CONFIG.RETRY_ATTEMPTS,
        backoff: {
          type: 'exponential',
          delay: 5000,
        },
        removeOnComplete: false, // Keep completed jobs for history
        removeOnFail: false, // Keep failed jobs for debugging
        ...options,
      }
    );

    jobs.push(job);
    console.log(`   ‚úì Added batch ${i + 1}/${batches.length} (Job ID: ${job.id})`);
  }

  return jobs;
}

/**
 * Get queue statistics
 */
async function getQueueStats() {
  const [waiting, active, completed, failed, delayed] = await Promise.all([
    scrapingQueue.getWaitingCount(),
    scrapingQueue.getActiveCount(),
    scrapingQueue.getCompletedCount(),
    scrapingQueue.getFailedCount(),
    scrapingQueue.getDelayedCount(),
  ]);

  return {
    waiting,
    active,
    completed,
    failed,
    delayed,
    total: waiting + active + completed + failed + delayed,
  };
}

/**
 * Example: Load search terms from file and add to queue
 */
async function processSearchTermsFromFile(filePath) {
  const fs = require('fs').promises;
  
  try {
    const content = await fs.readFile(filePath, 'utf-8');
    const searchTerms = content
      .split('\n')
      .map(term => term.trim())
      .filter(term => term.length > 0);

    console.log(`üìÑ Loaded ${searchTerms.length} search terms from ${filePath}`);
    
    return await addBatch(searchTerms);

  } catch (error) {
    console.error(`Error reading file ${filePath}:`, error.message);
    throw error;
  }
}

// Graceful shutdown
process.on('SIGTERM', async () => {
  console.log('\nüõë Shutting down gracefully...');
  await worker.close();
  await scrapingQueue.close();
  process.exit(0);
});

process.on('SIGINT', async () => {
  console.log('\nüõë Shutting down gracefully...');
  await worker.close();
  await scrapingQueue.close();
  process.exit(0);
});

// Export functions for use in other modules
module.exports = {
  addBatch,
  processSearchTermsFromFile,
  getQueueStats,
  scrapingQueue,
  worker,
};

// If run directly, start the worker
if (require.main === module) {
  console.log('üöÄ TCAD Scraper Worker Started');
  console.log(`   - Concurrent workers: ${CONFIG.CONCURRENT_WORKERS}`);
  console.log(`   - Batch size: ${CONFIG.BATCH_SIZE}`);
  console.log(`   - Redis: ${connection.host}:${connection.port}`);
  console.log('\nüëÇ Listening for jobs...');
  console.log('   Prometheus: http://localhost:9090');
  console.log('   Metrics at: http://localhost:3000/metrics\n');
}
</file>

<file path="test-manual-search.ts">
import { chromium } from 'playwright';

async function testManualSearch() {
  console.log('Starting manual test...');
  const browser = await chromium.launch({ headless: false }); // Run in headed mode to see what's happening
  const context = await browser.newContext();
  const page = await context.newPage();

  try {
    console.log('Navigating to TCAD...');
    await page.goto('https://travis.prodigycad.com/property-search', {
      waitUntil: 'networkidle',
      timeout: 30000,
    });

    console.log('Waiting for React...');
    await page.waitForFunction(() => {
      const root = document.getElementById('root');
      return root && root.children.length > 0;
    }, { timeout: 15000 });

    await page.waitForTimeout(2000);

    // Check current year
    const yearInputs = await page.$$('.MuiSelect-nativeInput');
    const currentYear = yearInputs.length > 0 ? await yearInputs[yearInputs.length - 1].inputValue() : 'unknown';
    console.log(`Current year value: ${currentYear}`);

    // Try to click year dropdown and see what options are available
    await page.locator('text=' + currentYear).last().click();
    await page.waitForTimeout(1000);

    // Get all available year options
    const yearOptions = await page.evaluate(() => {
      const options = Array.from(document.querySelectorAll('[role="option"]'));
      return options.map(el => el.textContent?.trim());
    });
    console.log('Available year options:', yearOptions);

    // Select 2024 if available
    if (yearOptions.includes('2024')) {
      await page.locator('text=2024').click();
      console.log('Selected 2024');
      await page.waitForTimeout(2000);
    }

    // Try a simple search
    console.log('Searching for "Austin"...');
    await page.type('#searchInput', 'Austin', { delay: 100 });
    await page.press('#searchInput', 'Enter');

    // Wait for results
    await page.waitForFunction(
      () => {
        const hasGridCells = document.querySelector('[role="gridcell"]') !== null;
        const hasNoResults = document.querySelector('.ag-overlay-no-rows-center') !== null;
        return hasGridCells || hasNoResults;
      },
      { timeout: 20000 }
    );

    const hasResults = await page.evaluate(() => {
      return document.querySelector('[role="gridcell"]') !== null;
    });

    console.log(`Search results: ${hasResults ? 'FOUND RESULTS' : 'NO RESULTS'}`);

    if (hasResults) {
      const rowCount = await page.evaluate(() => {
        return document.querySelectorAll('.ag-row').length;
      });
      console.log(`Found ${rowCount} rows`);
    }

    console.log('\\nWaiting 30 seconds for manual inspection...');
    await page.waitForTimeout(30000);

  } catch (error) {
    console.error('Error:', error);
  } finally {
    await browser.close();
  }
}

testManualSearch();
</file>

<file path="test-search-types.ts">
import { chromium } from 'playwright';

async function testSearchTypes() {
  const browser = await chromium.launch({ headless: true });
  const context = await browser.newContext();
  const page = await context.newPage();

  const searchTerms = [
    { term: 'Austin', type: 'City' },
    { term: 'Lamar', type: 'Street' },
    { term: 'Congress', type: 'Street' },
    { term: 'Round Rock', type: 'City' },
  ];

  try {
    await page.goto('https://travis.prodigycad.com/property-search', {
      waitUntil: 'networkidle',
      timeout: 30000,
    });

    await page.waitForFunction(() => {
      const root = document.getElementById('root');
      return root && root.children.length > 0;
    }, { timeout: 15000 });

    console.log('\n=== Testing Different Search Terms ===\n');

    for (const { term, type } of searchTerms) {
      await page.fill('#searchInput', '');
      await page.waitForTimeout(1000);

      await page.type('#searchInput', term, { delay: 50 });
      await page.press('#searchInput', 'Enter');
      await page.waitForTimeout(4000);

      const rowCount = await page.evaluate(() => {
        return document.querySelectorAll('.ag-row').length;
      });

      console.log(`${type.padEnd(10)} "${term.padEnd(15)}" -> ${rowCount > 0 ? rowCount + ' results' : 'NO RESULTS'}`);
    }

  } catch (error) {
    console.error('Error:', error);
  } finally {
    await browser.close();
  }
}

testSearchTypes();
</file>

</files>
