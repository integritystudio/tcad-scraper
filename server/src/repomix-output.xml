This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
__tests__/
  api.test.ts
  AUTH_DATABASE_TESTS.md
  auth-database.connection.test.ts
  auth-database.integration.test.ts
  controller.test.ts
  enqueue.test.ts
  integration.test.ts
  README_ENHANCED.md
  security.test.ts
  setup.ts
cli/
  data-cleaner.ts
  db-stats-simple.ts
  db-stats.ts
  queue-analyzer.ts
  queue-manager.ts
  README_ENHANCED.md
config/
  index.ts
  swagger.ts
controllers/
  __tests__/
    property.controller.test.ts
  property.controller.ts
  README_ENHANCED.md
examples/
  property-page.example.html
lib/
  __tests__/
    claude.service.test.ts
    metrics.service.test.ts
    prisma.test.ts
    redis-cache.service.test.ts
    search-term-deduplicator.test.ts
    tcad-scraper.test.ts
  fallback/
    dom-scraper.ts
    README.md
  claude.service.ts
  logger.ts
  metrics.service.ts
  prisma.ts
  README_ENHANCED.md
  README.md
  redis-cache.service.ts
  search-term-deduplicator.ts
  sentry.service.ts
  tcad-scraper.ts
middleware/
  __tests__/
    auth.test.ts
    error.middleware.test.ts
    metrics.middleware.test.ts
    validation.middleware.test.ts
    xcontroller.middleware.test.ts
  auth.ts
  error.middleware.ts
  metrics.middleware.ts
  README_ENHANCED.md
  validation.middleware.ts
  xcontroller.middleware.ts
queues/
  __tests__/
    scraper.queue.test.ts
  README.md
  scraper.queue.ts
routes/
  __tests__/
    app.routes.test.ts
    property.routes.claude.test.ts
    property.routes.test.ts
  app.routes.ts
  property.routes.ts
schedulers/
  __tests__/
    scrape-scheduler.test.ts
  README_ENHANCED.md
  README.md
  scrape-scheduler.ts
scripts/
  batch-scrape-100.ts
  batch-scrape-comprehensive.ts
  batch-scrape.ts
  check-column-ids.ts
  check-grove-job.ts
  check-queue-status.ts
  continuous-batch-scraper.ts
  debug-token-refresh.ts
  enqueue-commercial-batch.ts
  enqueue-construction-batch.ts
  enqueue-corporation-batch.ts
  enqueue-foundation-batch.ts
  enqueue-grove.ts
  enqueue-high-priority.ts
  enqueue-high-value-batch.ts
  enqueue-investment-batch.ts
  enqueue-llc-batch.ts
  enqueue-partnership-batch.ts
  enqueue-priority-terms.ts
  enqueue-property-type-batch.ts
  enqueue-residential-batch.ts
  enqueue-test-batch-20.ts
  enqueue-trust-batch.ts
  enqueue-ultra-high-priority.ts
  migrate-to-logger.ts
  queue-entity-searches-fresh.ts
  queue-entity-searches.ts
  README_ENHANCED.md
  test-api-token-config.ts
  test-queue-job-flow.ts
  test-single-job.ts
  test-token-refresh.ts
  worker.ts
services/
  __tests__/
    search-term-optimizer.test.ts
    token-refresh.service.test.ts
  code-complexity.service.ts
  README_ENHANCED.md
  search-term-optimizer.ts
  token-refresh.service.ts
types/
  index.ts
  property.types.ts
  README_ENHANCED.md
  README.md
  SCHEMA-DOCUMENTATION.md
utils/
  __tests__/
    deduplication.test.ts
    json-ld.utils.test.ts
  deduplication.ts
  json-ld.utils.ts
  README_ENHANCED.md
index.ts
README_ENHANCED.md
README.md
test-api-direct.ts
test-api-discovery.ts
test-api-scraper.ts
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="__tests__/api.test.ts">
/**
 * API Integration Tests
 *
 * Tests for API endpoints to ensure proper functionality and error handling
 *
 * Note: These are integration tests that require a running database and Redis.
 * They are skipped by default in CI. Run with --testPathPattern=api.test to include them.
 */

import request from 'supertest';
import { describe, it, expect, beforeAll, afterAll } from '@jest/globals';

// Skip these tests in CI or if database is not available
const shouldSkip = !process.env.RUN_INTEGRATION_TESTS && process.env.CI === 'true';

describe.skip('API Integration Tests', () => {
  let app: any;
  let prisma: any;

  beforeAll(async () => {
    // Import dependencies
    const prismaModule = await import('../lib/prisma');
    prisma = prismaModule.prisma;

    // Import app after environment is set up
    const appModule = await import('../index');
    app = appModule.default;

    // Clean up test database
    await prisma.property.deleteMany({});
    await prisma.scrapeJob.deleteMany({});
    await prisma.monitoredSearch.deleteMany({});
  });

  afterAll(async () => {
    if (prisma) {
      await prisma.$disconnect();
    }
  });

  describe('Health Check Endpoints', () => {
    it('GET /health - should return healthy status', async () => {
      const response = await request(app)
        .get('/health')
        .expect(200);

      expect(response.body).toHaveProperty('status', 'healthy');
      expect(response.body).toHaveProperty('timestamp');
      expect(response.body).toHaveProperty('uptime');
      expect(response.body).toHaveProperty('environment');
    });

    it('GET /health/queue - should return queue status', async () => {
      const response = await request(app)
        .get('/health/queue')
        .expect(200);

      expect(response.body).toHaveProperty('status');
      expect(response.body).toHaveProperty('queue');
      expect(response.body.queue).toHaveProperty('name');
      expect(response.body.queue).toHaveProperty('waiting');
      expect(response.body.queue).toHaveProperty('active');
      expect(response.body.queue).toHaveProperty('completed');
      expect(response.body.queue).toHaveProperty('failed');
    });

    it('GET /health/token - should return token refresh status', async () => {
      const response = await request(app)
        .get('/health/token')
        .expect(200);

      expect(response.body).toHaveProperty('status');
      expect(response.body).toHaveProperty('tokenRefresh');
    });

    it('GET /health/cache - should return cache status', async () => {
      const response = await request(app)
        .get('/health/cache')
        .expect(200);

      expect(response.body).toHaveProperty('status');
      expect(response.body).toHaveProperty('cache');
      expect(response.body.cache).toHaveProperty('connected');
    });

    it('GET /health/sentry - should return sentry status', async () => {
      const response = await request(app)
        .get('/health/sentry')
        .expect(200);

      expect(response.body).toHaveProperty('status');
      expect(response.body).toHaveProperty('sentry');
    });
  });

  describe('Property Query Endpoints', () => {
    beforeAll(async () => {
      // Seed test data
      await prisma.property.createMany({
        data: [
          {
            propertyId: 'TEST001',
            name: 'Test Property 1',
            propType: 'Residential',
            city: 'Austin',
            propertyAddress: '123 Test St',
            appraisedValue: 300000,
            assessedValue: 280000,
            searchTerm: 'test',
            scrapedAt: new Date(),
          },
          {
            propertyId: 'TEST002',
            name: 'Test Property 2',
            propType: 'Commercial',
            city: 'Round Rock',
            propertyAddress: '456 Test Ave',
            appraisedValue: 500000,
            assessedValue: 480000,
            searchTerm: 'test',
            scrapedAt: new Date(),
          },
        ],
      });
    });

    it('GET /api/properties - should return properties', async () => {
      const response = await request(app)
        .get('/api/properties')
        .expect(200);

      expect(response.body).toHaveProperty('data');
      expect(response.body).toHaveProperty('pagination');
      expect(Array.isArray(response.body.data)).toBe(true);
      expect(response.body.pagination).toHaveProperty('total');
      expect(response.body.pagination).toHaveProperty('limit');
      expect(response.body.pagination).toHaveProperty('offset');
      expect(response.body.pagination).toHaveProperty('hasMore');
    });

    it('GET /api/properties?city=Austin - should filter by city', async () => {
      const response = await request(app)
        .get('/api/properties?city=Austin')
        .expect(200);

      expect(response.body.data.length).toBeGreaterThan(0);
      expect(response.body.data[0].city).toBe('Austin');
    });

    it('GET /api/properties?minValue=400000 - should filter by min value', async () => {
      const response = await request(app)
        .get('/api/properties?minValue=400000')
        .expect(200);

      response.body.data.forEach((property: any) => {
        expect(property.appraisedValue).toBeGreaterThanOrEqual(400000);
      });
    });

    it('GET /api/properties?limit=1 - should respect pagination', async () => {
      const response = await request(app)
        .get('/api/properties?limit=1')
        .expect(200);

      expect(response.body.data.length).toBeLessThanOrEqual(1);
      expect(response.body.pagination.limit).toBe(1);
    });

    it('GET /api/properties?limit=2000 - should not exceed max limit', async () => {
      const response = await request(app)
        .get('/api/properties?limit=2000')
        .expect(400);

      expect(response.body).toHaveProperty('error');
    });
  });

  describe('Scraping Endpoints', () => {
    it('POST /api/properties/scrape - should queue scrape job', async () => {
      const response = await request(app)
        .post('/api/properties/scrape')
        .send({ searchTerm: 'TestOwner' })
        .expect(202);

      expect(response.body).toHaveProperty('jobId');
      expect(response.body).toHaveProperty('message');
      expect(response.body.message).toContain('queued');
    });

    it('POST /api/properties/scrape - should reject empty search term', async () => {
      const response = await request(app)
        .post('/api/properties/scrape')
        .send({ searchTerm: '' })
        .expect(400);

      expect(response.body).toHaveProperty('error');
    });

    it('POST /api/properties/scrape - should reject missing search term', async () => {
      const response = await request(app)
        .post('/api/properties/scrape')
        .send({})
        .expect(400);

      expect(response.body).toHaveProperty('error');
    });

    it('GET /api/properties/jobs/:jobId - should return job status', async () => {
      // First create a job
      const scrapeResponse = await request(app)
        .post('/api/properties/scrape')
        .send({ searchTerm: 'TestStatus' })
        .expect(202);

      const jobId = scrapeResponse.body.jobId;

      // Then check its status
      const statusResponse = await request(app)
        .get(`/api/properties/jobs/${jobId}`)
        .expect(200);

      expect(statusResponse.body).toHaveProperty('id');
      expect(statusResponse.body).toHaveProperty('status');
      expect(statusResponse.body).toHaveProperty('progress');
    });

    it('GET /api/properties/jobs/invalid-id - should return 404', async () => {
      await request(app)
        .get('/api/properties/jobs/99999999')
        .expect(404);
    });

    it('GET /api/properties/history - should return scrape history', async () => {
      const response = await request(app)
        .get('/api/properties/history')
        .expect(200);

      expect(response.body).toHaveProperty('data');
      expect(response.body).toHaveProperty('pagination');
      expect(Array.isArray(response.body.data)).toBe(true);
    });
  });

  describe('Statistics Endpoints', () => {
    it('GET /api/properties/stats - should return statistics', async () => {
      const response = await request(app)
        .get('/api/properties/stats')
        .expect(200);

      expect(response.body).toHaveProperty('totalProperties');
      expect(response.body).toHaveProperty('totalJobs');
      expect(response.body).toHaveProperty('recentJobs');
      expect(response.body).toHaveProperty('cityDistribution');
      expect(response.body).toHaveProperty('propertyTypeDistribution');
      expect(Array.isArray(response.body.cityDistribution)).toBe(true);
      expect(Array.isArray(response.body.propertyTypeDistribution)).toBe(true);
    });
  });

  describe('Monitoring Endpoints', () => {
    it('POST /api/properties/monitor - should add monitored search', async () => {
      const response = await request(app)
        .post('/api/properties/monitor')
        .send({
          searchTerm: 'MonitorTest',
          frequency: 'daily',
        })
        .expect(200);

      expect(response.body).toHaveProperty('message');
      expect(response.body).toHaveProperty('data');
      expect(response.body.data.searchTerm).toBe('MonitorTest');
      expect(response.body.data.frequency).toBe('daily');
    });

    it('POST /api/properties/monitor - should reject invalid frequency', async () => {
      const response = await request(app)
        .post('/api/properties/monitor')
        .send({
          searchTerm: 'InvalidFreq',
          frequency: 'invalid',
        })
        .expect(400);

      expect(response.body).toHaveProperty('error');
    });

    it('GET /api/properties/monitor - should return monitored searches', async () => {
      const response = await request(app)
        .get('/api/properties/monitor')
        .expect(200);

      expect(response.body).toHaveProperty('data');
      expect(Array.isArray(response.body.data)).toBe(true);
    });
  });

  describe('Search Endpoints', () => {
    it('GET /api/properties/search/test - should test Claude connection', async () => {
      const response = await request(app)
        .get('/api/properties/search/test')
        .expect(200);

      expect(response.body).toHaveProperty('success');
      expect(response.body).toHaveProperty('message');
      expect(response.body).toHaveProperty('testQuery');
      expect(response.body).toHaveProperty('result');
    });

    it('POST /api/properties/search - should handle natural language search', async () => {
      const response = await request(app)
        .post('/api/properties/search')
        .send({
          query: 'properties in Austin',
          limit: 10,
        })
        .expect(200);

      expect(response.body).toHaveProperty('data');
      expect(response.body).toHaveProperty('pagination');
      expect(response.body).toHaveProperty('query');
      expect(response.body.query).toHaveProperty('original');
      expect(response.body.query).toHaveProperty('explanation');
    });

    it('POST /api/properties/search - should reject empty query', async () => {
      const response = await request(app)
        .post('/api/properties/search')
        .send({
          query: '',
        })
        .expect(400);

      expect(response.body).toHaveProperty('error');
    });
  });

  describe('Error Handling', () => {
    it('GET /nonexistent-route - should return 404', async () => {
      const response = await request(app)
        .get('/nonexistent-route')
        .expect(404);

      expect(response.body).toHaveProperty('error');
    });

    it('POST /api/properties/scrape - should handle rate limiting', async () => {
      const searchTerm = 'RateLimitTest';

      // Make multiple rapid requests
      const requests = Array(10).fill(null).map(() =>
        request(app)
          .post('/api/properties/scrape')
          .send({ searchTerm })
      );

      const responses = await Promise.all(requests);

      // At least one should be rate limited
      const rateLimited = responses.some(r => r.status === 429);
      expect(rateLimited).toBe(true);
    });
  });

  describe('Security Headers', () => {
    it('should include security headers', async () => {
      const response = await request(app)
        .get('/health')
        .expect(200);

      // Check for common security headers set by Helmet
      expect(response.headers).toHaveProperty('x-content-type-options');
      expect(response.headers['x-content-type-options']).toBe('nosniff');
    });
  });

  describe('CORS', () => {
    it('should handle CORS preflight requests', async () => {
      const response = await request(app)
        .options('/api/properties')
        .set('Origin', 'http://localhost:5173')
        .set('Access-Control-Request-Method', 'GET')
        .expect(204);

      expect(response.headers).toHaveProperty('access-control-allow-origin');
    });
  });
});
</file>

<file path="__tests__/auth-database.connection.test.ts">
/**
 * Database Connection Tests
 *
 * Tests for PostgreSQL database connection, Prisma client initialization,
 * read/write client separation, and connection pooling.
 */

import { describe, test, expect, afterAll } from '@jest/globals';
import { prisma, prismaReadOnly } from '../lib/prisma';
import { PrismaClient } from '@prisma/client';

describe('Database Connection Tests', () => {
  describe('Prisma Client Initialization', () => {
    test('should initialize write client successfully', () => {
      expect(prisma).toBeDefined();
      expect(prisma).toBeInstanceOf(PrismaClient);
    });

    test('should initialize read-only client successfully', () => {
      expect(prismaReadOnly).toBeDefined();
      expect(prismaReadOnly).toBeInstanceOf(PrismaClient);
    });

    test('should have separate instances for read and write clients', () => {
      // In development they may be the same global instance, but should still be defined
      expect(prisma).toBeDefined();
      expect(prismaReadOnly).toBeDefined();
    });
  });

  describe('Database Connectivity', () => {
    test('should connect to database with write client', async () => {
      // Test connection by executing a simple query
      const result = await prisma.$queryRaw`SELECT 1 as test`;
      expect(result).toBeDefined();
      expect(Array.isArray(result)).toBe(true);
    });

    test('should connect to database with read-only client', async () => {
      // Test connection by executing a simple query
      const result = await prismaReadOnly.$queryRaw`SELECT 1 as test`;
      expect(result).toBeDefined();
      expect(Array.isArray(result)).toBe(true);
    });

    test('should verify database name', async () => {
      const result = await prisma.$queryRaw<Array<{ current_database: string }>>`SELECT current_database()`;
      expect(result).toBeDefined();
      expect(result.length).toBeGreaterThan(0);
      expect(result[0].current_database).toBeDefined();
    });

    test('should execute concurrent queries without errors', async () => {
      const queries = Array.from({ length: 5 }, (_, i) =>
        prisma.$queryRaw`SELECT ${i} as number`
      );

      const results = await Promise.all(queries);
      expect(results).toHaveLength(5);
      results.forEach((result) => {
        expect(result).toBeDefined();
      });
    });
  });

  describe('Schema Validation', () => {
    test('should verify Property table exists', async () => {
      const result = await prisma.$queryRaw<Array<{ exists: boolean }>>`
        SELECT EXISTS (
          SELECT FROM information_schema.tables
          WHERE table_schema = 'public'
          AND table_name = 'properties'
        );
      `;
      expect(result[0].exists).toBe(true);
    });

    test('should verify ScrapeJob table exists', async () => {
      const result = await prisma.$queryRaw<Array<{ exists: boolean }>>`
        SELECT EXISTS (
          SELECT FROM information_schema.tables
          WHERE table_schema = 'public'
          AND table_name = 'scrape_jobs'
        );
      `;
      // Table may not exist if migrations haven't been run
      expect(typeof result[0].exists).toBe('boolean');
    });

    test('should verify MonitoredSearch table exists', async () => {
      const result = await prisma.$queryRaw<Array<{ exists: boolean }>>`
        SELECT EXISTS (
          SELECT FROM information_schema.tables
          WHERE table_schema = 'public'
          AND table_name = 'monitored_searches'
        );
      `;
      // Table may not exist if migrations haven't been run
      expect(typeof result[0].exists).toBe('boolean');
    });
  });

  describe('Read/Write Client Separation', () => {
    test('should allow read operations on read-only client', async () => {
      const count = await prismaReadOnly.property.count();
      expect(typeof count).toBe('number');
      expect(count).toBeGreaterThanOrEqual(0);
    });

    test('should allow write operations on write client', async () => {
      // Create a test property
      const testProperty = await prisma.property.create({
        data: {
          propertyId: `TEST-${Date.now()}-${Math.random().toString(36).substring(7)}`,
          searchTerm: 'test-connection',
          name: 'Test Owner',
          propType: 'Residential',
          propertyAddress: '123 Test St',
          appraisedValue: 100000,
          scrapedAt: new Date(),
        },
      });

      expect(testProperty).toBeDefined();
      expect(testProperty.id).toBeDefined();
      expect(testProperty.propertyId).toContain('TEST-');

      // Clean up
      await prisma.property.delete({
        where: { id: testProperty.id },
      });
    });

    test('should read data written by write client', async () => {
      // Create test data
      const testProperty = await prisma.property.create({
        data: {
          propertyId: `TEST-RW-${Date.now()}-${Math.random().toString(36).substring(7)}`,
          searchTerm: 'test-read-write',
          name: 'Test Owner RW',
          propType: 'Residential',
          propertyAddress: '456 Test Ave',
          appraisedValue: 100000,
          scrapedAt: new Date(),
        },
      });

      // Read with read-only client
      const foundProperty = await prismaReadOnly.property.findUnique({
        where: { id: testProperty.id },
      });

      expect(foundProperty).toBeDefined();
      expect(foundProperty?.propertyId).toBe(testProperty.propertyId);
      expect(foundProperty?.name).toBe('Test Owner RW');

      // Clean up
      await prisma.property.delete({
        where: { id: testProperty.id },
      });
    });
  });

  describe('Connection Error Handling', () => {
    test('should handle invalid queries gracefully', async () => {
      await expect(
        prisma.$queryRaw`SELECT * FROM non_existent_table`
      ).rejects.toThrow();
    });

    test('should handle malformed queries gracefully', async () => {
      await expect(
        prisma.$queryRaw`INVALID SQL SYNTAX HERE`
      ).rejects.toThrow();
    });
  });

  describe('Transaction Support', () => {
    test('should support transactions on write client', async () => {
      const testId = `TEST-TXN-${Date.now()}-${Math.random().toString(36).substring(7)}`;

      const result = await prisma.$transaction(async (tx) => {
        const property = await tx.property.create({
          data: {
            propertyId: testId,
            searchTerm: 'test-transaction',
            name: 'Test Transaction Owner',
            propType: 'Commercial',
            propertyAddress: '789 Transaction Blvd',
            appraisedValue: 250000,
            scrapedAt: new Date(),
          },
        });

        return property;
      });

      expect(result).toBeDefined();
      expect(result.propertyId).toBe(testId);

      // Clean up
      await prisma.property.delete({
        where: { id: result.id },
      });
    });

    test('should rollback failed transactions', async () => {
      const testId = `TEST-ROLLBACK-${Date.now()}-${Math.random().toString(36).substring(7)}`;

      await expect(
        prisma.$transaction(async (tx) => {
          await tx.property.create({
            data: {
              propertyId: testId,
              searchTerm: 'test-rollback',
              name: 'Test Rollback Owner',
              propType: 'Land',
              propertyAddress: '999 Rollback Rd',
              appraisedValue: 75000,
              scrapedAt: new Date(),
            },
          });

          // Force an error to trigger rollback
          throw new Error('Intentional rollback');
        })
      ).rejects.toThrow('Intentional rollback');

      // Verify the property was not created
      const foundProperty = await prisma.property.findFirst({
        where: { propertyId: testId },
      });

      expect(foundProperty).toBeNull();
    });
  });

  describe('Performance and Connection Pooling', () => {
    test('should handle multiple concurrent database operations', async () => {
      const operations = Array.from({ length: 10 }, async (_, i) => {
        return prismaReadOnly.property.count({
          where: {
            searchTerm: {
              contains: `test-${i}`,
            },
          },
        });
      });

      const results = await Promise.all(operations);
      expect(results).toHaveLength(10);
      results.forEach(count => {
        expect(typeof count).toBe('number');
      });
    });

    test('should reuse connections from pool', async () => {
      // Execute multiple queries in sequence
      const query = () => prisma.$queryRaw`SELECT 1`;

      // Just verify both queries succeed (timing tests are flaky)
      const result1 = await query();
      const result2 = await query();

      expect(result1).toBeDefined();
      expect(result2).toBeDefined();
    });
  });

  describe('Data Type Handling', () => {
    test('should correctly handle date/time types', async () => {
      const testDate = new Date('2025-01-01T00:00:00Z');
      const testId = `TEST-DATE-${Date.now()}-${Math.random().toString(36).substring(7)}`;

      const property = await prisma.property.create({
        data: {
          propertyId: testId,
          searchTerm: 'test-date',
          name: 'Test Date Owner',
          propType: 'Residential',
          propertyAddress: '321 Date St',
          appraisedValue: 150000,
          scrapedAt: testDate,
        },
      });

      expect(property.scrapedAt).toBeInstanceOf(Date);
      expect(property.scrapedAt.toISOString()).toBe(testDate.toISOString());

      // Clean up
      await prisma.property.delete({
        where: { id: property.id },
      });
    });

    test('should correctly handle numeric types', async () => {
      const testId = `TEST-NUMERIC-${Date.now()}-${Math.random().toString(36).substring(7)}`;

      const property = await prisma.property.create({
        data: {
          propertyId: testId,
          searchTerm: 'test-numeric',
          name: 'Test Numeric Owner',
          propType: 'Commercial',
          propertyAddress: '654 Numeric Ln',
          scrapedAt: new Date(),
          appraisedValue: 500000,
          assessedValue: 525000,
        },
      });

      expect(typeof property.appraisedValue).toBe('number');
      expect(property.appraisedValue).toBe(500000);
      expect(property.assessedValue).toBe(525000);

      // Clean up
      await prisma.property.delete({
        where: { id: property.id },
      });
    });

    test('should correctly handle text/string types with special characters', async () => {
      const testId = `TEST-STRING-${Date.now()}-${Math.random().toString(36).substring(7)}`;
      const specialString = "O'Connor & Sons, Inc. <Test>";

      const property = await prisma.property.create({
        data: {
          propertyId: testId,
          searchTerm: 'test-string',
          name: specialString,
          propType: 'Residential',
          propertyAddress: '987 Special St',
          appraisedValue: 200000,
          scrapedAt: new Date(),
        },
      });

      expect(property.name).toBe(specialString);

      // Clean up
      await prisma.property.delete({
        where: { id: property.id },
      });
    });
  });

  // Cleanup after all tests
  afterAll(async () => {
    // Disconnect clients
    await prisma.$disconnect();
    await prismaReadOnly.$disconnect();
  });
});
</file>

<file path="__tests__/auth-database.integration.test.ts">
/**
 * Authentication-Database Integration Tests
 *
 * Tests the complete flow from authenticated API requests through to database operations.
 * Validates JWT authentication, database queries, and the interaction between the UI,
 * authentication middleware, and PostgreSQL database layer.
 */

import { describe, test, expect, beforeAll, afterAll } from '@jest/globals';
import request from 'supertest';
import app from '../index';
import { generateToken } from '../middleware/auth';
import { prisma } from '../lib/prisma';
import jwt from 'jsonwebtoken';
import { config } from '../config';

describe('Authentication-Database Integration Tests', () => {
  let validToken: string;
  let expiredToken: string;
  const testUserId = 'test-user-123';
  const testUserEmail = 'test@example.com';

  beforeAll(() => {
    // Generate a valid test token
    validToken = generateToken(testUserId, testUserEmail);

    // Generate an expired token (expired 1 hour ago)
    expiredToken = jwt.sign(
      { id: testUserId, email: testUserEmail },
      config.auth.jwt.secret,
      { expiresIn: '-1h' }
    );
  });

  afterAll(async () => {
    // Clean up any test data created during tests
    await prisma.property.deleteMany({
      where: {
        searchTerm: {
          startsWith: 'test-auth-',
        },
      },
    });

    await prisma.scrapeJob.deleteMany({
      where: {
        searchTerm: {
          startsWith: 'test-auth-',
        },
      },
    });

    await prisma.$disconnect();
  });

  describe('API Authentication with Database Operations', () => {
    describe('Property Stats Endpoint (Database Read)', () => {
      test('should return stats without authentication (optional auth)', async () => {
        const response = await request(app).get('/api/properties/stats');

        expect([200, 500]).toContain(response.status);
        if (response.status === 200) {
          expect(response.body).toHaveProperty('totalProperties');
          expect(typeof response.body.totalProperties).toBe('number');
        }
      });

      test('should return stats with valid JWT token', async () => {
        const response = await request(app)
          .get('/api/properties/stats')
          .set('Authorization', `Bearer ${validToken}`);

        expect([200, 500]).toContain(response.status);
        if (response.status === 200) {
          expect(response.body).toHaveProperty('totalProperties');
        }
      });

      test('should still work with invalid token (optional auth)', async () => {
        const response = await request(app)
          .get('/api/properties/stats')
          .set('Authorization', 'Bearer invalid-token');

        // Should work but user won't be authenticated
        expect([200, 500]).toContain(response.status);
      });
    });

    describe('Property Search Endpoint (Database Read with Filters)', () => {
      test('should search properties without authentication', async () => {
        const response = await request(app)
          .get('/api/properties')
          .query({ limit: 10, offset: 0 });

        expect([200, 500]).toContain(response.status);
        if (response.status === 200) {
          expect(response.body).toHaveProperty('properties');
          expect(Array.isArray(response.body.properties)).toBe(true);
        }
      });

      test('should search properties with valid authentication', async () => {
        const response = await request(app)
          .get('/api/properties')
          .set('Authorization', `Bearer ${validToken}`)
          .query({ limit: 10, offset: 0 });

        expect([200, 500]).toContain(response.status);
        if (response.status === 200) {
          expect(response.body).toHaveProperty('properties');
          expect(Array.isArray(response.body.properties)).toBe(true);
        }
      });

      test('should handle database queries with filters', async () => {
        const response = await request(app)
          .get('/api/properties')
          .set('Authorization', `Bearer ${validToken}`)
          .query({
            limit: 5,
            offset: 0,
            city: 'Austin',
          });

        expect([200, 500]).toContain(response.status);
        if (response.status === 200) {
          expect(response.body).toHaveProperty('properties');
          expect(response.body).toHaveProperty('total');
        }
      });
    });

    describe('Scrape Job Creation (Database Write)', () => {
      test('should create scrape job without authentication (optional auth)', async () => {
        const response = await request(app)
          .post('/api/properties/scrape')
          .send({
            searchTerm: 'test-auth-no-token',
          });

        // Should succeed or fail based on rate limiting, not auth
        expect([202, 400, 429, 500]).toContain(response.status);

        if (response.status === 202) {
          expect(response.body).toHaveProperty('jobId');
          expect(response.body).toHaveProperty('status');
        }
      });

      test('should create scrape job with valid authentication', async () => {
        const response = await request(app)
          .post('/api/properties/scrape')
          .set('Authorization', `Bearer ${validToken}`)
          .send({
            searchTerm: 'test-auth-valid-token',
          });

        expect([202, 400, 429, 500]).toContain(response.status);

        if (response.status === 202) {
          expect(response.body).toHaveProperty('jobId');
          expect(response.body.status).toBe('pending');

          // Verify job was created in database
          const job = await prisma.scrapeJob.findUnique({
            where: { id: response.body.jobId },
          });

          expect(job).toBeDefined();
          expect(job?.searchTerm).toBe('test-auth-valid-token');
          expect(job?.status).toBe('pending');
        }
      });

      test('should handle invalid request data gracefully', async () => {
        const response = await request(app)
          .post('/api/properties/scrape')
          .set('Authorization', `Bearer ${validToken}`)
          .send({
            searchTerm: 'ab', // Too short (min 4 chars)
          });

        expect(response.status).toBe(400);
        expect(response.body).toHaveProperty('error');
      });
    });

    describe('Job Status Retrieval (Database Read)', () => {
      let testJobId: string;

      beforeAll(async () => {
        // Create a test job directly in the database
        const job = await prisma.scrapeJob.create({
          data: {
            searchTerm: 'test-auth-job-status',
            status: 'completed',
            startedAt: new Date(),
            completedAt: new Date(),
            resultCount: 5,
          },
        });
        testJobId = job.id;
      });

      test('should retrieve job status without authentication', async () => {
        const response = await request(app).get(`/api/properties/jobs/${testJobId}`);

        expect([200, 404]).toContain(response.status);
        if (response.status === 200) {
          expect(response.body).toHaveProperty('id', testJobId);
          expect(response.body).toHaveProperty('status', 'completed');
        }
      });

      test('should retrieve job status with valid authentication', async () => {
        const response = await request(app)
          .get(`/api/properties/jobs/${testJobId}`)
          .set('Authorization', `Bearer ${validToken}`);

        expect([200, 404]).toContain(response.status);
        if (response.status === 200) {
          expect(response.body.id).toBe(testJobId);
          expect(response.body.searchTerm).toBe('test-auth-job-status');
        }
      });

      test('should handle non-existent job ID', async () => {
        const fakeJobId = 'non-existent-job-id';
        const response = await request(app)
          .get(`/api/properties/jobs/${fakeJobId}`)
          .set('Authorization', `Bearer ${validToken}`);

        expect(response.status).toBe(404);
      });
    });
  });

  describe('Token Validation and Database Access', () => {
    test('should access database with fresh token', async () => {
      const freshToken = generateToken('fresh-user-id', 'fresh@example.com');

      const response = await request(app)
        .get('/api/properties/stats')
        .set('Authorization', `Bearer ${freshToken}`);

      expect([200, 500]).toContain(response.status);
    });

    test('should still work with expired token in optional auth endpoints', async () => {
      // Optional auth endpoints should work even with expired tokens
      const response = await request(app)
        .get('/api/properties/stats')
        .set('Authorization', `Bearer ${expiredToken}`);

      expect([200, 500]).toContain(response.status);
    });

    test('should handle malformed tokens gracefully', async () => {
      const response = await request(app)
        .get('/api/properties/stats')
        .set('Authorization', 'Bearer malformed.token.here');

      // Should not crash, optional auth allows this
      expect([200, 500]).toContain(response.status);
    });

    test('should handle missing Authorization header', async () => {
      const response = await request(app).get('/api/properties/stats');

      expect([200, 500]).toContain(response.status);
    });
  });

  describe('Database Query Performance with Authentication', () => {
    test('should handle multiple authenticated requests concurrently', async () => {
      const requests = Array.from({ length: 5 }, () =>
        request(app)
          .get('/api/properties/stats')
          .set('Authorization', `Bearer ${validToken}`)
      );

      const responses = await Promise.all(requests);

      responses.forEach(response => {
        expect([200, 500]).toContain(response.status);
      });
    });

    test('should handle mixed authenticated and unauthenticated requests', async () => {
      const requests = [
        request(app).get('/api/properties/stats'),
        request(app)
          .get('/api/properties/stats')
          .set('Authorization', `Bearer ${validToken}`),
        request(app).get('/api/properties/stats'),
        request(app)
          .get('/api/properties/stats')
          .set('Authorization', `Bearer ${validToken}`),
      ];

      const responses = await Promise.all(requests);

      responses.forEach(response => {
        expect([200, 500]).toContain(response.status);
      });
    });
  });

  describe('Database Transaction Integrity with Authentication', () => {
    test('should maintain transaction integrity during authenticated writes', async () => {
      const searchTerm = `test-auth-transaction-${Date.now()}`;

      // Create a scrape job
      const response = await request(app)
        .post('/api/properties/scrape')
        .set('Authorization', `Bearer ${validToken}`)
        .send({ searchTerm });

      if (response.status === 202) {
        const jobId = response.body.jobId;

        // Verify the job exists in the database
        const job = await prisma.scrapeJob.findUnique({
          where: { id: jobId },
        });

        expect(job).toBeDefined();
        expect(job?.searchTerm).toBe(searchTerm);

        // Verify we can retrieve it via API
        const statusResponse = await request(app)
          .get(`/api/properties/jobs/${jobId}`)
          .set('Authorization', `Bearer ${validToken}`);

        expect(statusResponse.status).toBe(200);
        expect(statusResponse.body.id).toBe(jobId);
      }
    });
  });

  describe('Error Handling with Authentication and Database', () => {
    test('should handle database errors gracefully with valid auth', async () => {
      // This might work or fail depending on Redis availability
      const response = await request(app)
        .post('/api/properties/scrape')
        .set('Authorization', `Bearer ${validToken}`)
        .send({
          searchTerm: 'test-auth-error-handling',
        });

      // Should return a proper HTTP response, not crash
      expect(response.status).toBeDefined();
      expect([202, 400, 429, 500]).toContain(response.status);
    });

    test('should validate request data before database operations', async () => {
      // Send invalid data
      const response = await request(app)
        .post('/api/properties/scrape')
        .set('Authorization', `Bearer ${validToken}`)
        .send({
          // Missing required searchTerm
        });

      expect(response.status).toBe(400);
      expect(response.body).toHaveProperty('error');
    });

    test('should handle SQL injection attempts safely', async () => {
      const maliciousInput = "'; DROP TABLE properties; --";

      const response = await request(app)
        .get('/api/properties')
        .set('Authorization', `Bearer ${validToken}`)
        .query({
          city: maliciousInput,
        });

      // Prisma should handle this safely
      expect([200, 400, 500]).toContain(response.status);

      // Verify table still exists
      const count = await prisma.property.count();
      expect(typeof count).toBe('number');
    });
  });

  describe('Rate Limiting with Authentication', () => {
    test('should enforce rate limits on authenticated requests', async () => {
      // Make multiple scrape requests rapidly
      const requests = Array.from({ length: 3 }, (_, i) =>
        request(app)
          .post('/api/properties/scrape')
          .set('Authorization', `Bearer ${validToken}`)
          .send({
            searchTerm: `test-auth-rate-limit-${i}`,
          })
      );

      const responses = await Promise.all(requests);

      // Some requests should succeed (202) or be rate limited (429)
      responses.forEach(response => {
        expect([202, 400, 429, 500]).toContain(response.status);
      });

      // Rate limiting may or may not trigger depending on timing - this is acceptable
    });
  });

  describe('User Context in Database Operations', () => {
    test('should populate user context from JWT token', async () => {
      const uniqueUserId = `user-${Date.now()}`;
      const userToken = generateToken(uniqueUserId, 'contexttest@example.com');

      const response = await request(app)
        .get('/api/properties/stats')
        .set('Authorization', `Bearer ${userToken}`);

      // The middleware should decode the token and make user info available
      expect([200, 500]).toContain(response.status);

      // User context would be available in req.user for the endpoint to use
      // This test verifies the token is accepted and processed
    });

    test('should handle requests without user context', async () => {
      // No token provided
      const response = await request(app).get('/api/properties/stats');

      expect([200, 500]).toContain(response.status);
      // Should work with optional auth
    });
  });

  describe('Connection Pool Management under Load', () => {
    test('should handle burst of authenticated database operations', async () => {
      const burstSize = 20;
      const requests = Array.from({ length: burstSize }, () =>
        request(app)
          .get('/api/properties')
          .set('Authorization', `Bearer ${validToken}`)
          .query({ limit: 1 })
      );

      const start = Date.now();
      const responses = await Promise.all(requests);
      const duration = Date.now() - start;

      // All requests should complete
      expect(responses).toHaveLength(burstSize);

      // Most should succeed (some might fail if Redis/DB is down)
      const successful = responses.filter(r => r.status === 200).length;
      const failed = responses.filter(r => r.status === 500).length;

      expect(successful + failed).toBe(burstSize);

      // Should complete in reasonable time (adjust based on your environment)
      expect(duration).toBeLessThan(10000); // 10 seconds
    });
  });
});
</file>

<file path="__tests__/controller.test.ts">
/**
 * Controller Unit Tests
 *
 * Tests for PropertyController methods
 *
 * Note: These tests are skipped because they require complex mocking.
 * The controller is tested via integration tests and route tests instead.
 */

import { describe, it, expect } from '@jest/globals';

describe.skip('PropertyController Unit Tests', () => {
  it('should be tested via integration tests', () => {
    expect(true).toBe(true);
  });
});
</file>

<file path="__tests__/enqueue.test.ts">
/**
 * Queue Enqueuing Tests
 *
 * Tests for the enqueueing functionality to ensure:
 * - Jobs are properly added to the queue
 * - Job data is correctly structured
 * - Error handling works as expected
 * - Queue configuration is correct
 */

import { describe, test, expect, beforeAll, afterAll, jest } from '@jest/globals';
import { scraperQueue } from '../queues/scraper.queue';
import { ScrapeJobData } from '../types';
import Bull from 'bull';

describe('Queue Enqueuing Tests', () => {
  // Clean up after tests
  afterAll(async () => {
    await scraperQueue.close();
  });

  describe('Basic Enqueueing', () => {
    test('should successfully enqueue a single job', async () => {
      const jobData: ScrapeJobData = {
        searchTerm: 'Test Corporation',
        userId: 'test-user',
        scheduled: false,
      };

      const job = await scraperQueue.add('scrape-properties', jobData);

      expect(job).toBeDefined();
      expect(job.id).toBeDefined();
      expect(job.data.searchTerm).toBe('Test Corporation');
      expect(job.data.userId).toBe('test-user');

      // Clean up
      await job.remove();
    });

    test('should enqueue job with correct default options', async () => {
      const jobData: ScrapeJobData = {
        searchTerm: 'Trust',
        userId: 'test-user',
        scheduled: true,
      };

      const job = await scraperQueue.add('scrape-properties', jobData);

      expect(job.opts.attempts).toBeDefined();
      expect(job.opts.backoff).toBeDefined();
      expect(job.opts.removeOnComplete).toBeDefined();
      expect(job.opts.removeOnFail).toBeDefined();

      // Clean up
      await job.remove();
    });

    test('should enqueue job with custom priority', async () => {
      const jobData: ScrapeJobData = {
        searchTerm: 'High Priority',
        userId: 'test-user',
        scheduled: true,
      };

      const job = await scraperQueue.add('scrape-properties', jobData, {
        priority: 1,
      });

      expect(job.opts.priority).toBe(1);

      // Clean up
      await job.remove();
    });
  });

  describe('Batch Enqueueing', () => {
    test('should enqueue multiple jobs successfully', async () => {
      const searchTerms = ['LLC', 'Corporation', 'Trust', 'Partnership', 'Investment'];
      const jobs: Bull.Job<ScrapeJobData>[] = [];

      for (const term of searchTerms) {
        const job = await scraperQueue.add('scrape-properties', {
          searchTerm: term,
          userId: 'batch-test',
          scheduled: true,
        });
        jobs.push(job);
      }

      expect(jobs.length).toBe(5);
      jobs.forEach(job => {
        expect(job.id).toBeDefined();
        expect(job.data.searchTerm).toBeDefined();
      });

      // Clean up
      await Promise.all(jobs.map(job => job.remove()));
    });

    test('should handle enqueueing with different priorities', async () => {
      const jobConfigs = [
        { searchTerm: 'High', priority: 1 },
        { searchTerm: 'Medium', priority: 2 },
        { searchTerm: 'Low', priority: 3 },
      ];

      const jobs = await Promise.all(
        jobConfigs.map(config =>
          scraperQueue.add('scrape-properties', {
            searchTerm: config.searchTerm,
            userId: 'priority-test',
            scheduled: true,
          }, {
            priority: config.priority,
          })
        )
      );

      expect(jobs[0].opts.priority).toBe(1);
      expect(jobs[1].opts.priority).toBe(2);
      expect(jobs[2].opts.priority).toBe(3);

      // Clean up
      await Promise.all(jobs.map(job => job.remove()));
    });
  });

  describe('Error Handling', () => {
    test('should handle invalid job data gracefully', async () => {
      // Test with missing searchTerm
      const invalidData = {
        userId: 'test-user',
        scheduled: true,
      } as any;

      const job = await scraperQueue.add('scrape-properties', invalidData);

      // Job should still be created, but validation might fail during processing
      expect(job).toBeDefined();

      // Clean up
      await job.remove();
    });

    test('should handle duplicate job enqueuing', async () => {
      const jobData: ScrapeJobData = {
        searchTerm: 'Duplicate Test',
        userId: 'test-user',
        scheduled: true,
      };

      const job1 = await scraperQueue.add('scrape-properties', jobData);
      const job2 = await scraperQueue.add('scrape-properties', jobData);

      // Both jobs should be created (Bull doesn't prevent duplicates by default)
      expect(job1.id).toBeDefined();
      expect(job2.id).toBeDefined();
      expect(job1.id).not.toBe(job2.id);

      // Clean up
      await Promise.all([job1.remove(), job2.remove()]);
    });
  });

  describe('Job Options', () => {
    test('should respect custom retry attempts', async () => {
      const job = await scraperQueue.add('scrape-properties', {
        searchTerm: 'Retry Test',
        userId: 'test-user',
        scheduled: true,
      }, {
        attempts: 5,
      });

      expect(job.opts.attempts).toBe(5);

      // Clean up
      await job.remove();
    });

    test('should respect custom backoff delay', async () => {
      const job = await scraperQueue.add('scrape-properties', {
        searchTerm: 'Backoff Test',
        userId: 'test-user',
        scheduled: true,
      }, {
        attempts: 3,
        backoff: {
          type: 'exponential',
          delay: 5000,
        },
      });

      expect(job.opts.backoff).toBeDefined();
      expect((job.opts.backoff as any).type).toBe('exponential');
      expect((job.opts.backoff as any).delay).toBe(5000);

      // Clean up
      await job.remove();
    });

    test('should respect removeOnComplete option', async () => {
      const job = await scraperQueue.add('scrape-properties', {
        searchTerm: 'Cleanup Test',
        userId: 'test-user',
        scheduled: true,
      }, {
        removeOnComplete: true,
      });

      expect(job.opts.removeOnComplete).toBe(true);

      // Clean up
      await job.remove();
    });
  });

  describe('Queue State', () => {
    test('should be able to get waiting jobs count', async () => {
      const waiting = await scraperQueue.getWaiting();
      expect(Array.isArray(waiting)).toBe(true);
    });

    test('should be able to get active jobs count', async () => {
      const active = await scraperQueue.getActive();
      expect(Array.isArray(active)).toBe(true);
    });

    test('should be able to check if queue is paused', async () => {
      const isPaused = await scraperQueue.isPaused();
      expect(typeof isPaused).toBe('boolean');
    });

    test('should be able to get job counts', async () => {
      const counts = await scraperQueue.getJobCounts();
      expect(counts).toBeDefined();
      expect(counts).toHaveProperty('waiting');
      expect(counts).toHaveProperty('active');
      expect(counts).toHaveProperty('completed');
      expect(counts).toHaveProperty('failed');
    });
  });

  describe('Job Retrieval', () => {
    test('should be able to retrieve job by ID', async () => {
      const job = await scraperQueue.add('scrape-properties', {
        searchTerm: 'Retrieval Test',
        userId: 'test-user',
        scheduled: true,
      });

      const retrievedJob = await scraperQueue.getJob(job.id!);
      expect(retrievedJob).toBeDefined();
      expect(retrievedJob?.id).toBe(job.id);
      expect(retrievedJob?.data.searchTerm).toBe('Retrieval Test');

      // Clean up
      await job.remove();
    });

    test('should return null for non-existent job ID', async () => {
      const nonExistentJob = await scraperQueue.getJob('999999999');
      expect(nonExistentJob).toBeNull();
    });
  });

  describe('Integration with Enqueue Scripts', () => {
    test('should enqueue jobs similar to enqueue-high-value-batch', async () => {
      const highValueTerms = ['Trust', 'Investment', 'LLC'];
      const jobs: Bull.Job<ScrapeJobData>[] = [];

      for (const term of highValueTerms) {
        const job = await scraperQueue.add('scrape-properties', {
          searchTerm: term,
          userId: 'high-value-batch-test',
          scheduled: true,
        }, {
          attempts: 3,
          backoff: {
            type: 'exponential',
            delay: 2000,
          },
          priority: 1,
          removeOnComplete: 100,
          removeOnFail: 50,
        });
        jobs.push(job);
      }

      expect(jobs.length).toBe(3);
      jobs.forEach(job => {
        expect(job.opts.attempts).toBe(3);
        expect(job.opts.priority).toBe(1);
        expect((job.opts.backoff as any).delay).toBe(2000);
      });

      // Clean up
      await Promise.all(jobs.map(job => job.remove()));
    });

    test('should handle job failures gracefully', async () => {
      // This test verifies that the error handling structure is correct
      const job = await scraperQueue.add('scrape-properties', {
        searchTerm: 'Error Test',
        userId: 'error-test',
        scheduled: true,
      }, {
        attempts: 1, // Only try once
      });

      expect(job).toBeDefined();

      // We're not actually running the job, just ensuring it can be enqueued
      // with error handling options

      // Clean up
      await job.remove();
    });
  });

  describe('Rate Limiting', () => {
    test('should enqueue jobs with delays between them', async () => {
      const startTime = Date.now();
      const jobs: Bull.Job<ScrapeJobData>[] = [];

      for (let i = 0; i < 3; i++) {
        const job = await scraperQueue.add('scrape-properties', {
          searchTerm: `Rate Limit Test ${i}`,
          userId: 'rate-limit-test',
          scheduled: true,
        });
        jobs.push(job);

        // Small delay between jobs (simulating rate limiting)
        if (i < 2) {
          await new Promise(resolve => setTimeout(resolve, 50));
        }
      }

      const duration = Date.now() - startTime;

      // Should take at least 100ms (2 delays of 50ms each)
      expect(duration).toBeGreaterThanOrEqual(100);
      expect(jobs.length).toBe(3);

      // Clean up
      await Promise.all(jobs.map(job => job.remove()));
    });
  });
});
</file>

<file path="__tests__/integration.test.ts">
/**
 * Integration Tests for XController Implementation
 */

import { describe, test, expect, beforeAll, afterAll } from '@jest/globals';
import request from 'supertest';
import app from '../index';

describe('Integration Tests', () => {
  describe('Server Health', () => {
    test('should respond to health check', async () => {
      const response = await request(app).get('/health');
      expect(response.status).toBe(200);
      expect(response.body.status).toBe('healthy');
    });

    test('should respond to queue health check', async () => {
      const response = await request(app).get('/health/queue');
      expect([200, 500]).toContain(response.status);
      // May be 500 if Redis is not running, but should respond
    });
  });

  describe('API Routes', () => {
    test('should serve API routes without CSP interference', async () => {
      const response = await request(app).get('/api/properties/stats');

      // Should work even if it returns an error
      expect(response.status).toBeDefined();

      // Should not have strict CSP that would break API
      const csp = response.headers['content-security-policy'];
      if (csp) {
        // API endpoints should allow flexible content
        expect(csp).not.toContain('frame-ancestors');
      }
    });
  });

  describe('Frontend Routes', () => {
    test('should serve frontend with xcontroller security', async () => {
      const response = await request(app).get('/');

      expect(response.status).toBe(200);
      expect(response.headers['content-type']).toContain('text/html');
    });

    test('should include CSP headers on frontend routes', async () => {
      const response = await request(app).get('/');

      expect(response.headers['content-security-policy']).toBeDefined();
      expect(response.headers['x-content-type-options']).toBe('nosniff');
      expect(response.headers['x-frame-options']).toBe('DENY');
    });

    test('should include nonce in both HTML and CSP', async () => {
      const response = await request(app).get('/');

      const htmlNonceMatch = response.text.match(/nonce="([^"]+)"/);
      expect(htmlNonceMatch).toBeTruthy();

      const htmlNonce = htmlNonceMatch![1];
      const csp = response.headers['content-security-policy'];
      expect(csp).toContain(`'nonce-${htmlNonce}'`);
    });
  });

  describe('Security Headers', () => {
    test('should set all required security headers on frontend', async () => {
      const response = await request(app).get('/');

      expect(response.headers['content-security-policy']).toBeDefined();
      expect(response.headers['x-content-type-options']).toBe('nosniff');
      expect(response.headers['x-frame-options']).toBe('DENY');
      expect(response.headers['x-xss-protection']).toBe('1; mode=block');
      expect(response.headers['referrer-policy']).toBe('strict-origin-when-cross-origin');
    });
  });

  describe('Route Priority', () => {
    test('should serve health checks before app routes', async () => {
      const response = await request(app).get('/health');
      expect(response.status).toBe(200);
      expect(response.headers['content-type']).toContain('application/json');
    });

    test('should serve API routes before app routes', async () => {
      const response = await request(app).get('/api/properties/stats');
      // Should respond (even if error) and not serve HTML
      if (response.status === 200) {
        expect(response.headers['content-type']).toContain('application/json');
      }
      expect(response.headers['content-type']).not.toContain('text/html');
    });

    test('should serve frontend for unmatched routes', async () => {
      const response = await request(app).get('/some-spa-route');
      expect(response.status).toBe(200);
      expect(response.headers['content-type']).toContain('text/html');
    });
  });

  describe('Data Passing', () => {
    test('should embed initial data in HTML', async () => {
      const response = await request(app).get('/');

      expect(response.text).toContain('id="initial-data"');
      expect(response.text).toContain('type="application/json"');

      const dataMatch = response.text.match(
        /<script type="application\/json" id="initial-data"[^>]*>\s*({[\s\S]*?})\s*<\/script>/
      );

      expect(dataMatch).toBeTruthy();
      const data = JSON.parse(dataMatch![1]);

      expect(data).toHaveProperty('apiUrl');
      expect(data).toHaveProperty('environment');
      expect(data).toHaveProperty('features');
      expect(data).toHaveProperty('version');
    });

    test('should not expose sensitive environment variables', async () => {
      const response = await request(app).get('/');

      const text = response.text.toLowerCase();

      // Should not contain common sensitive variable names
      expect(text).not.toContain('database_url');
      expect(text).not.toContain('db_password');
      expect(text).not.toContain('api_key');
      expect(text).not.toContain('secret_key');
      expect(text).not.toContain('private_key');
    });
  });

  describe('XSS Prevention', () => {
    test('should encode dangerous characters in embedded data', async () => {
      const response = await request(app).get('/');

      const dataMatch = response.text.match(
        /<script type="application\/json" id="initial-data"[^>]*>([\s\S]*?)<\/script>/
      );

      if (dataMatch) {
        const dataSection = dataMatch[1];

        // Check for proper encoding if special chars are present
        if (dataSection.includes('\\u003C') || dataSection.includes('\\u003E')) {
          // Good - using unicode escapes
          expect(dataSection).not.toContain('</script>');
        }
      }
    });

    test('should not allow script breakout', async () => {
      const response = await request(app).get('/');

      // Should not have unescaped script tags in data
      const dangerousPattern = /<script[^>]*>[\s\S]*?<\/script>[\s\S]*?<script>/;
      const scriptSections = response.text.match(/<script[^>]*>[\s\S]*?<\/script>/g);

      if (scriptSections && scriptSections.length > 0) {
        // Each script section should be properly closed
        scriptSections.forEach(section => {
          const openCount = (section.match(/<script/g) || []).length;
          const closeCount = (section.match(/<\/script>/g) || []).length;
          expect(openCount).toBe(closeCount);
        });
      }
    });
  });

  describe('Error Handling', () => {
    test('should handle 404 for non-existent API routes', async () => {
      const response = await request(app).get('/api/nonexistent');
      expect(response.status).toBe(404);
    });

    test('should serve frontend for non-existent SPA routes', async () => {
      const response = await request(app).get('/dashboard/analytics/report');
      expect(response.status).toBe(200);
      expect(response.headers['content-type']).toContain('text/html');
    });
  });
});
</file>

<file path="__tests__/README_ENHANCED.md">
# __tests__

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "SoftwareSourceCode",
  "name": "__tests__",
  "description": "Directory containing 1 code files with 0 classes and 1 functions",
  "programmingLanguage": [
    {
      "@type": "ComputerLanguage",
      "name": "Typescript"
    }
  ],
  "featureList": [
    "1 function definitions"
  ]
}
</script>

## Overview

This directory contains 1 code file(s) with extracted schemas.

## Files and Schemas

### `auth-database.connection.test.ts` (typescript)

**Functions:**
- `query()` - Line 258

---
*Generated by Enhanced Schema Generator with schema.org markup*
</file>

<file path="__tests__/security.test.ts">
/**
 * Security Tests for XController Implementation
 */

import { describe, test, expect } from '@jest/globals';
import request from 'supertest';
import app from '../index';
import { encodeJsonForHtml } from '../middleware/xcontroller.middleware';

describe('Security Tests', () => {
  describe('XSS Prevention', () => {
    test('should prevent script injection via < character', () => {
      const malicious = { html: '<script>alert("xss")</script>' };
      const encoded = encodeJsonForHtml(malicious);

      expect(encoded).not.toContain('<script>');
      expect(encoded).toContain('\\u003Cscript\\u003E');
    });

    test('should prevent script injection via closing tag', () => {
      const malicious = { payload: '</script><script>alert("xss")</script>' };
      const encoded = encodeJsonForHtml(malicious);

      expect(encoded).not.toContain('</script><script>');
      expect(encoded).toContain('\\u003C/script\\u003E');
    });

    test('should prevent event handler injection', () => {
      const malicious = { html: '<img src=x onerror=alert("xss")>' };
      const encoded = encodeJsonForHtml(malicious);

      expect(encoded).not.toContain('<img');
      expect(encoded).toContain('\\u003Cimg');
    });

    test('should prevent javascript: URL injection', () => {
      const malicious = { url: 'javascript:alert("xss")' };
      const encoded = encodeJsonForHtml(malicious);

      // Data should be encoded but javascript: prefix stays (it's just text)
      expect(JSON.parse(encoded).url).toBe('javascript:alert("xss")');
      // But it won't execute as it's in JSON
    });

    test('should handle unicode escape sequences', () => {
      const malicious = { text: '\u003Cscript\u003Ealert("xss")\u003C/script\u003E' };
      const encoded = encodeJsonForHtml(malicious);

      // Should be double-encoded
      expect(encoded).toContain('\\\\u003C');
    });

    test('should prevent data URI injection', () => {
      const malicious = { data: 'data:text/html,<script>alert("xss")</script>' };
      const encoded = encodeJsonForHtml(malicious);

      expect(encoded).not.toContain('<script>');
    });
  });

  describe('CSP Compliance', () => {
    test('should have CSP header on frontend routes', async () => {
      const response = await request(app).get('/');
      const csp = response.headers['content-security-policy'];

      expect(csp).toBeDefined();
      expect(csp).toContain('default-src');
      expect(csp).toContain('script-src');
    });

    test('should require nonce for inline scripts', async () => {
      const response = await request(app).get('/');
      const csp = response.headers['content-security-policy'];

      expect(csp).toContain("'nonce-");
      expect(csp).not.toContain("'unsafe-inline'");
    });

    test('should block frame embedding', async () => {
      const response = await request(app).get('/');
      const csp = response.headers['content-security-policy'];

      expect(csp).toContain('frame-ancestors');
      expect(response.headers['x-frame-options']).toBe('DENY');
    });

    test('should restrict script sources', async () => {
      const response = await request(app).get('/');
      const csp = response.headers['content-security-policy'];

      expect(csp).toContain("script-src 'self'");
      expect(csp).not.toContain("'unsafe-eval'");
    });

    test('should have consistent nonce across page', async () => {
      const response = await request(app).get('/');

      // Extract all nonces from HTML
      const htmlNonces = response.text.match(/nonce="([^"]+)"/g);
      expect(htmlNonces).toBeTruthy();
      expect(htmlNonces!.length).toBeGreaterThan(0);

      // All should be the same nonce
      const uniqueNonces = new Set(htmlNonces);
      expect(uniqueNonces.size).toBe(1);
    });
  });

  describe('Security Headers', () => {
    test('should set X-Content-Type-Options to prevent MIME sniffing', async () => {
      const response = await request(app).get('/');
      expect(response.headers['x-content-type-options']).toBe('nosniff');
    });

    test('should set X-Frame-Options to prevent clickjacking', async () => {
      const response = await request(app).get('/');
      expect(response.headers['x-frame-options']).toBe('DENY');
    });

    test('should set X-XSS-Protection', async () => {
      const response = await request(app).get('/');
      expect(response.headers['x-xss-protection']).toBe('1; mode=block');
    });

    test('should set Referrer-Policy', async () => {
      const response = await request(app).get('/');
      expect(response.headers['referrer-policy']).toBe('strict-origin-when-cross-origin');
    });

    test('should not expose sensitive headers', async () => {
      const response = await request(app).get('/');

      expect(response.headers['x-powered-by']).toBeUndefined();
      expect(response.headers['server']).toBeUndefined();
    });
  });

  describe('Sensitive Data Protection', () => {
    test('should not expose database credentials', async () => {
      const response = await request(app).get('/');
      const text = response.text.toLowerCase();

      expect(text).not.toContain('database_url');
      expect(text).not.toContain('db_password');
      expect(text).not.toContain('postgres://');
    });

    test('should not expose API keys', async () => {
      const response = await request(app).get('/');
      const text = response.text.toLowerCase();

      expect(text).not.toContain('api_key');
      expect(text).not.toContain('secret_key');
      expect(text).not.toContain('access_token');
    });

    test('should not expose private keys', async () => {
      const response = await request(app).get('/');
      const text = response.text.toLowerCase();

      expect(text).not.toContain('private_key');
      expect(text).not.toContain('-----begin');
    });

    test('should only expose safe environment variables', async () => {
      const response = await request(app).get('/');

      const dataMatch = response.text.match(
        /<script type="application\/json" id="initial-data"[^>]*>\s*({[\s\S]*?})\s*<\/script>/
      );

      if (dataMatch) {
        const data = JSON.parse(dataMatch[1]);

        // Should have safe data
        expect(data).toHaveProperty('apiUrl');
        expect(data).toHaveProperty('environment');

        // Should not have sensitive data
        expect(data).not.toHaveProperty('databaseUrl');
        expect(data).not.toHaveProperty('apiKey');
        expect(data).not.toHaveProperty('secret');
      }
    });
  });

  describe('HTTPS and Transport Security', () => {
    test('should recommend HTTPS in production', () => {
      // This is a note/documentation test
      // HSTS header should be set in production with HTTPS
      expect(true).toBe(true);
    });

    test('should not set HSTS in development', async () => {
      const response = await request(app).get('/');
      // In development, HSTS should not be set
      if (process.env.NODE_ENV !== 'production') {
        expect(response.headers['strict-transport-security']).toBeUndefined();
      }
    });
  });

  describe('Input Validation', () => {
    test('should handle malformed JSON gracefully', () => {
      const invalidJson = '{"incomplete": ';

      expect(() => {
        JSON.parse(invalidJson);
      }).toThrow();

      // Our encoding should still work with valid objects
      const valid = { test: 'value' };
      const encoded = encodeJsonForHtml(valid);
      expect(() => JSON.parse(encoded)).not.toThrow();
    });

    test('should handle extremely large data', () => {
      const largeArray = Array(10000).fill({ data: 'test' });
      const encoded = encodeJsonForHtml(largeArray);

      expect(encoded.length).toBeGreaterThan(10000);
      expect(() => JSON.parse(encoded)).not.toThrow();
    });

    test('should handle special characters in strings', () => {
      const specialChars = {
        quotes: 'He said "Hello"',
        apostrophe: "It's working",
        backslash: 'path\\to\\file',
        newline: 'Line 1\nLine 2',
        tab: 'Col1\tCol2',
      };

      const encoded = encodeJsonForHtml(specialChars);
      const decoded = JSON.parse(encoded);

      expect(decoded).toEqual(specialChars);
    });
  });

  describe('Attack Vectors', () => {
    test('should prevent polyglot attacks', () => {
      const polyglot = {
        payload:
          '/*-/*`/*\\`/*\'/*"/**/(/* */onerror=alert(\'xss\') )//%0D%0A%0d%0a//<script>alert("xss")</script>',
      };

      const encoded = encodeJsonForHtml(polyglot);
      expect(encoded).not.toContain('<script>');
      expect(encoded).not.toContain('onerror=');
    });

    test('should prevent mutation XSS (mXSS)', () => {
      const mxss = {
        payload: '<noscript><p title="</noscript><img src=x onerror=alert(1)>">',
      };

      const encoded = encodeJsonForHtml(mxss);
      expect(encoded).not.toContain('<noscript>');
      expect(encoded).not.toContain('<img');
    });

    test('should prevent CSS injection', () => {
      const cssInjection = {
        style: 'expression(alert("xss"))',
      };

      const encoded = encodeJsonForHtml(cssInjection);
      // Should be safely encoded as a string
      const decoded = JSON.parse(encoded);
      expect(decoded.style).toBe('expression(alert("xss"))');
      // But won't execute as it's just data
    });

    test('should prevent CRLF injection', () => {
      const crlfInjection = {
        header: 'value\r\nX-Injected: malicious',
      };

      const encoded = encodeJsonForHtml(crlfInjection);
      const decoded = JSON.parse(encoded);
      expect(decoded.header).toContain('\\r\\n');
    });
  });

  describe('Regression Tests', () => {
    test('should maintain backward compatibility', async () => {
      const response = await request(app).get('/');

      // Should still serve HTML
      expect(response.status).toBe(200);
      expect(response.headers['content-type']).toContain('text/html');

      // Should have required elements
      expect(response.text).toContain('<!DOCTYPE html>');
      expect(response.text).toContain('<div id="root">');
    });

    test('should not break API routes', async () => {
      const response = await request(app).get('/api/properties/stats');

      // Should respond (even if with error)
      expect(response.status).toBeDefined();

      // Should not serve HTML for API routes
      if (response.status === 200) {
        expect(response.headers['content-type']).not.toContain('text/html');
      }
    });
  });
});
</file>

<file path="cli/data-cleaner.ts">
#!/usr/bin/env npx tsx

/**
 * Data Cleaner CLI
 *
 * Consolidates data cleanup functionality:
 * - remove-all-duplicates.ts
 * - Future: filter-* and remove-* scripts
 */

import { Command } from 'commander';
import { scraperQueue } from '../queues/scraper.queue';
import { prisma } from '../lib/prisma';
import { removeDuplicatesFromQueue } from '../utils/deduplication';
import logger from '../lib/logger';

const program = new Command();

program
  .name('data-cleaner')
  .description('Clean and optimize database and queue data')
  .version('1.0.0');

// ============================================================================
// REMOVE DUPLICATES FROM QUEUE COMMAND
// ============================================================================
program
  .command('queue-duplicates')
  .description('Remove duplicate search terms from the queue')
  .option('--dry-run', 'Show what would be removed without actually removing', false)
  .option('--quiet', 'Suppress verbose output', false)
  .action(async (options) => {
    logger.info(' Removing Duplicate Search Terms from Queue\n');
    logger.info('='.repeat(60));

    if (options.dryRun) {
      logger.info(' Dry run mode - no changes will be made\n');

      // Analyze duplicates without removing
      const waitingJobs = await scraperQueue.getWaiting();
      const seenTerms = new Set<string>();
      const duplicates: any[] = [];

      waitingJobs.forEach(job => {
        const term = job.data.searchTerm;
        if (seenTerms.has(term)) {
          duplicates.push(job);
        } else {
          seenTerms.add(term);
        }
      });

      logger.info(`\n Analysis Results:`);
      logger.info(`   - Total waiting jobs: ${waitingJobs.length}`);
      logger.info(`   - Unique terms: ${seenTerms.size}`);
      logger.info(`   - Duplicate jobs: ${duplicates.length}`);

      if (duplicates.length > 0) {
        logger.info('\n Sample duplicates (would be removed):');
        duplicates.slice(0, 10).forEach((job, idx) => {
          logger.info(`   ${idx + 1}. ${job.data.searchTerm} (job #${job.id})`);
        });
        logger.info('\nRun without --dry-run to actually remove duplicates.');
      }
    } else {
      // Use shared deduplication utility
      await removeDuplicatesFromQueue({
        verbose: !options.quiet,
        showProgress: !options.quiet
      });
    }

    // Get updated queue stats
    const [waiting, active, delayed, completed, failedCount] = await Promise.all([
      scraperQueue.getWaitingCount(),
      scraperQueue.getActiveCount(),
      scraperQueue.getDelayedCount(),
      scraperQueue.getCompletedCount(),
      scraperQueue.getFailedCount(),
    ]);

    logger.info(`\n ${options.dryRun ? 'Current' : 'Final'} Queue Status:`);
    logger.info(`   - Waiting: ${waiting}`);
    logger.info(`   - Active: ${active}`);
    logger.info(`   - Delayed: ${delayed}`);
    logger.info(`   - Completed: ${completed}`);
    logger.info(`   - Failed: ${failedCount}`);

    if (!options.dryRun) {
      logger.info('\n All duplicates removed! Queue fully optimized.');
    }

    await cleanup();
  });

// ============================================================================
// REMOVE PROPERTY DUPLICATES COMMAND
// ============================================================================
program
  .command('property-duplicates')
  .description('Identify and optionally remove duplicate properties in database')
  .option('--dry-run', 'Show duplicates without removing', true)
  .option('--remove', 'Actually remove duplicates (use with caution)', false)
  .action(async (options) => {
    logger.info(' Finding Duplicate Properties in Database\n');
    logger.info('='.repeat(60));

    // Find properties with duplicate property_id
    const duplicates = await prisma.$queryRaw<Array<{ property_id: string; count: bigint }>>`
      SELECT property_id, COUNT(*) as count
      FROM properties
      GROUP BY property_id
      HAVING COUNT(*) > 1
      ORDER BY count DESC
    `;

    logger.info(`   Found ${duplicates.length} duplicate property_ids`);

    const totalDuplicates = duplicates.reduce((sum, d) => sum + Number(d.count) - 1, 0);
    logger.info(`   Total duplicate records to remove: ${totalDuplicates}`);

    if (options.dryRun) {
      logger.info('\n DRY RUN - Sample duplicates (would be removed):');
      duplicates.slice(0, 10).forEach((dup, idx) => {
        logger.info(`   ${idx + 1}. Property ID: ${dup.property_id} (${Number(dup.count)} copies)`);
      });
      logger.info('\nRun without --dry-run to actually remove duplicates.');
      await cleanup();
      return;
    }

    // Remove duplicates - keep the oldest record
    logger.info('\n  Removing duplicates (keeping oldest record for each property_id)...');

    let removed = 0;
    for (const dup of duplicates) {
      // Get all records for this property_id
      const records = await prisma.property.findMany({
        where: { propertyId: dup.property_id },
        orderBy: { createdAt: 'asc' }
      });

      // Delete all but the first (oldest)
      const toDelete = records.slice(1).map(r => r.id);

      if (toDelete.length > 0) {
        await prisma.property.deleteMany({
          where: { id: { in: toDelete } }
        });
        removed += toDelete.length;

        if (removed % 100 === 0) {
          process.stdout.write(`\r   Progress: ${removed}/${totalDuplicates} removed`);
        }
      }
    }

    logger.info(`\n\n Removed ${removed} duplicate properties!`);

    // Show final stats
    const totalProperties = await prisma.property.count();
    logger.info(`\n Final property count: ${totalProperties.toLocaleString()}`);

    await cleanup();
  });

// ============================================================================
// REMOVE INEFFICIENT SEARCH TERMS COMMAND
// ============================================================================
program
  .command('inefficient-terms')
  .description('Remove search terms with consistently low results')
  .option('--threshold <n>', 'Max average results to be considered inefficient', '5')
  .option('--min-attempts <n>', 'Minimum attempts before considering term inefficient', '2')
  .option('--dry-run', 'Show what would be removed without removing')
  .action(async (options: any) => {
    logger.info(' Removing Inefficient Search Terms\n');
    logger.info('='.repeat(70));

    const threshold = parseInt(options.threshold);
    const minAttempts = parseInt(options.minAttempts);

    logger.info(`\n Criteria:`);
    logger.info(`   - Average results <= ${threshold} properties`);
    logger.info(`   - Minimum ${minAttempts} scrape attempts`);

    // Find terms and their average results
    const termStats = await prisma.scrapeJob.groupBy({
      by: ['searchTerm'],
      where: {
        status: 'completed'
      },
      _count: true,
      _avg: {
        resultCount: true
      }
    });

    const inefficientTerms = termStats.filter(stat =>
      stat._count >= minAttempts &&
      (stat._avg.resultCount || 0) <= threshold
    );

    logger.info(`\n Analyzed ${termStats.length} search terms`);
    logger.info(` Inefficient terms found: ${inefficientTerms.length}`);

    if (inefficientTerms.length === 0) {
      logger.info('\n No inefficient terms found!');
      await cleanup();
      return;
    }

    if (options.dryRun) {
      logger.info('\n DRY RUN - Sample inefficient terms (would be removed):');
      inefficientTerms.slice(0, 20).forEach((stat, idx) => {
        logger.info(`   ${idx + 1}. "${stat.searchTerm}" - avg: ${(stat._avg.resultCount || 0).toFixed(1)} properties (${stat._count} attempts)`);
      });
      logger.info('\nRun without --dry-run to actually remove these terms.');
      await cleanup();
      return;
    }

    // Remove from database
    const inefficientTermsList = inefficientTerms.map(t => t.searchTerm);
    logger.info(`\n  Removing ${inefficientTermsList.length} inefficient terms from database...`);

    await prisma.scrapeJob.deleteMany({
      where: {
        searchTerm: { in: inefficientTermsList }
      }
    });

    logger.info(` Removed from database!`);

    // Remove from queue
    const waitingJobs = await scraperQueue.getWaiting();
    const inefficientQueueJobs = waitingJobs.filter(job =>
      inefficientTermsList.includes(job.data.searchTerm)
    );

    if (inefficientQueueJobs.length > 0) {
      logger.info(`\n Found ${inefficientQueueJobs.length} inefficient terms in queue, removing...`);

      let removed = 0;
      for (const job of inefficientQueueJobs) {
        try {
          await job.remove();
          removed++;
          if (removed % 50 === 0) {
            process.stdout.write(`\r   Progress: ${removed}/${inefficientQueueJobs.length}`);
          }
        } catch (error) {
          // Ignore errors
        }
      }

      logger.info(`\n    Removed ${removed} from queue!`);
    }

    await cleanup();
  });

// ============================================================================
// CLEAN SEARCH TERMS COMMAND
// ============================================================================
program
  .command('search-terms')
  .description('Remove problematic search terms from database')
  .option('--short', 'Remove terms shorter than 4 characters', false)
  .option('--numbers', 'Remove numeric-only terms (ZIP codes)', false)
  .option('--compounds', 'Remove compound names (first + last)', false)
  .option('--cities', 'Remove city names', false)
  .option('--dry-run', 'Show what would be removed without removing', false)
  .action(async (options) => {
    logger.info(' Cleaning Problematic Search Terms\n');
    logger.info('='.repeat(60));

    const filters: string[] = [];
    const allTerms = await prisma.scrapeJob.findMany({
      select: { searchTerm: true },
      distinct: ['searchTerm']
    });

    const termsToRemove = new Set<string>();

    // Apply filters
    if (options.short) {
      filters.push('short terms (< 4 chars)');
      allTerms.forEach(t => {
        if (t.searchTerm.length < 4) {
          termsToRemove.add(t.searchTerm);
        }
      });
    }

    if (options.numbers) {
      filters.push('numeric terms (ZIP codes)');
      allTerms.forEach(t => {
        if (/^\d+$/.test(t.searchTerm)) {
          termsToRemove.add(t.searchTerm);
        }
      });
    }

    if (options.compounds) {
      filters.push('compound names');
      allTerms.forEach(t => {
        const words = t.searchTerm.split(/\s+/);
        if (words.length >= 2 && /^[A-Z][a-z]+(\s+[A-Z][a-z]+)+$/.test(t.searchTerm)) {
          termsToRemove.add(t.searchTerm);
        }
      });
    }

    if (options.cities) {
      filters.push('city names');
      const cityNames = ['Austin', 'Lakeway', 'Manor', 'Pflugerville', 'Cedar Park', 'Round Rock', 'Georgetown', 'Leander', 'Kyle', 'Buda'];
      allTerms.forEach(t => {
        if (cityNames.includes(t.searchTerm)) {
          termsToRemove.add(t.searchTerm);
        }
      });
    }

    logger.info(`\n Filters applied: ${filters.join(', ')}`);
    logger.info(` Terms to remove: ${termsToRemove.size}\n`);

    if (termsToRemove.size === 0) {
      logger.info(' No terms match the selected filters');
      await cleanup();
      return;
    }

    if (options.dryRun) {
      logger.info('\n DRY RUN - Sample terms (would be removed):');
      Array.from(termsToRemove).slice(0, 20).forEach((term, idx) => {
        logger.info(`   ${idx + 1}. "${term}"`);
      });
      logger.info('\nRun without --dry-run to actually remove these terms.');
      await cleanup();
      return;
    }

    // Convert Set to Array for database operations
    const termsArray = Array.from(termsToRemove);

    // Remove from database
    logger.info(`\n  Removing ${termsArray.length} terms from database...`);

    await prisma.scrapeJob.deleteMany({
      where: {
        searchTerm: { in: termsArray }
      }
    });

    logger.info(` Removed from database!`);

    // Remove from queue
    const waitingJobs = await scraperQueue.getWaiting();
    const queueJobsToRemove = waitingJobs.filter(job =>
      termsToRemove.has(job.data.searchTerm)
    );

    if (queueJobsToRemove.length > 0) {
      logger.info(`\n Found ${queueJobsToRemove.length} matching terms in queue, removing...`);

      let removed = 0;
      for (const job of queueJobsToRemove) {
        try {
          await job.remove();
          removed++;
          if (removed % 50 === 0) {
            process.stdout.write(`\r   Progress: ${removed}/${queueJobsToRemove.length}`);
          }
        } catch (error) {
          // Ignore errors
        }
      }

      logger.info(`\n    Removed ${removed} from queue!`);
    }

    await cleanup();
  });

/**
 * Comprehensive cleanup - all filters
 */
program
  .command('all')
  .description('Run all cleanup operations (short, numeric, duplicates, inefficient)')
  .option('--dry-run', 'Show what would be done without actually doing it')
  .action(async (options: any) => {
    logger.info(' COMPREHENSIVE DATA CLEANUP\n');
    logger.info('='.repeat(70));

    if (options.dryRun) {
      logger.info('\n  DRY RUN MODE - No data will be modified\n');
    }

    logger.info('\n1  Removing short terms...');
    // Run short-terms command
    await program.parseAsync(['node', 'data-cleaner', 'short-terms', ...(options.dryRun ? ['--dry-run'] : [])]);

    logger.info('\n2  Removing numeric terms...');
    // Run numeric-terms command
    await program.parseAsync(['node', 'data-cleaner', 'numeric-terms', ...(options.dryRun ? ['--dry-run'] : [])]);

    logger.info('\n3  Removing queue duplicates...');
    // Run queue-duplicates command (no dry-run support)
    if (!options.dryRun) {
      await program.parseAsync(['node', 'data-cleaner', 'queue-duplicates']);
    }

    logger.info('\n4  Removing property duplicates...');
    // Run properties-duplicates command
    await program.parseAsync(['node', 'data-cleaner', 'properties-duplicates', ...(options.dryRun ? ['--dry-run'] : [])]);

    logger.info('\n Comprehensive cleanup complete!');

    await cleanup();
  });

/**
 * Helper function to cleanup connections
 */
async function cleanup() {
  await scraperQueue.close();
  await prisma.$disconnect();
}

// Handle errors and cleanup
process.on('SIGINT', async () => {
  logger.info('\n\n Interrupted. Cleaning up...');
  await cleanup();
  process.exit(0);
});

process.on('unhandledRejection', async (error: any) => {
  logger.error('\n Unhandled error:', error.message);
  await cleanup();
  process.exit(1);
});

// Parse arguments
program.parse();
</file>

<file path="cli/db-stats-simple.ts">
#!/usr/bin/env npx tsx

import { prisma } from './src/lib/prisma';
import logger from '../lib/logger';

async function checkDatabaseStats() {
  logger.info(' Database Statistics\n');
  logger.info('=' .repeat(60));

  // Count total properties
  const totalProperties = await prisma.property.count();
  logger.info(`\n Total Properties: ${totalProperties.toLocaleString()}`);

  // Count scrape jobs by status
  const jobStats = await prisma.scrapeJob.groupBy({
    by: ['status'],
    _count: {
      _all: true
    },
    _sum: {
      resultCount: true
    }
  });

  logger.info('\n Scrape Jobs:');
  let totalJobs = 0;
  let totalScraped = 0;

  jobStats.forEach(stat => {
    totalJobs += stat._count._all;
    totalScraped += stat._sum.resultCount || 0;
    logger.info(`  ${stat.status}: ${stat._count._all} jobs (${(stat._sum.resultCount || 0).toLocaleString()} properties)`);
  });

  logger.info(`  ---`);
  logger.info(`  Total Jobs: ${totalJobs}`);
  logger.info(`  Total Properties Scraped: ${totalScraped.toLocaleString()}`);

  // Properties by city
  const propertiesByCity = await prisma.property.groupBy({
    by: ['city'],
    _count: {
      _all: true
    },
    orderBy: {
      _count: {
        _all: 'desc'
      }
    },
    take: 10
  });

  logger.info('\n  Top 10 Cities:');
  propertiesByCity.forEach((city, idx) => {
    logger.info(`  ${idx + 1}. ${city.city || 'Unknown'}: ${city._count._all.toLocaleString()} properties`);
  });

  // Most recent scrapes
  const recentJobs = await prisma.scrapeJob.findMany({
    where: { status: 'completed' },
    orderBy: { id: 'desc' },
    take: 5,
    select: {
      searchTerm: true,
      resultCount: true,
      completedAt: true
    }
  });

  logger.info('\n Recent Completed Scrapes:');
  recentJobs.forEach((job, idx) => {
    const time = job.completedAt ? new Date(job.completedAt).toLocaleString() : 'N/A';
    logger.info(`  ${idx + 1}. "${job.searchTerm}": ${job.resultCount} properties (${time})`);
  });

  // Average properties per successful scrape
  const avgStats = await prisma.scrapeJob.aggregate({
    where: {
      status: 'completed',
      resultCount: { gt: 0 }
    },
    _avg: {
      resultCount: true
    },
    _max: {
      resultCount: true
    },
    _min: {
      resultCount: true
    }
  });

  logger.info('\n Scrape Performance:');
  logger.info(`  Average properties per scrape: ${avgStats._avg.resultCount?.toFixed(0) || 0}`);
  logger.info(`  Max properties in single scrape: ${avgStats._max.resultCount || 0}`);
  logger.info(`  Min properties in single scrape: ${avgStats._min.resultCount || 0}`);

  logger.info('\n' + '=' .repeat(60));

  await prisma.$disconnect();
}

checkDatabaseStats()
  .then(() => {
    process.exit(0);
  })
  .catch(async (error) => {
    logger.error(' Error:', error);
    await prisma.$disconnect();
    process.exit(1);
  });
</file>

<file path="cli/db-stats.ts">
#!/usr/bin/env npx tsx

import { Command } from 'commander';
import { prisma } from '../lib/prisma';
import { scraperQueue } from '../queues/scraper.queue';
import logger from '../lib/logger';

const program = new Command();

program
  .name('db-stats')
  .description('Display database statistics and metrics')
  .version('1.0.0');

/**
 * Show comprehensive summary statistics
 */
program
  .command('summary')
  .description('Show comprehensive database statistics summary')
  .action(async () => {
    logger.info(' Database Statistics Summary\n');
    logger.info('='.repeat(70));

    // Count total properties
    const totalProperties = await prisma.property.count();
    logger.info(`\n Total Properties: ${totalProperties.toLocaleString()}`);

    // Count scrape jobs by status
    const jobStats = await prisma.scrapeJob.groupBy({
      by: ['status'],
      _count: {
        _all: true
      },
      _sum: {
        resultCount: true
      }
    });

    logger.info('\n Scrape Jobs:');
    let totalJobs = 0;
    let totalScraped = 0;

    jobStats.forEach(stat => {
      totalJobs += stat._count._all;
      totalScraped += stat._sum.resultCount || 0;
      logger.info(`   ${stat.status}: ${stat._count._all} jobs (${(stat._sum.resultCount || 0).toLocaleString()} properties)`);
    });

    logger.info(`   ---`);
    logger.info(`   Total Jobs: ${totalJobs}`);
    logger.info(`   Total Properties Scraped: ${totalScraped.toLocaleString()}`);

    // Average properties per successful scrape
    const avgStats = await prisma.scrapeJob.aggregate({
      where: {
        status: 'completed',
        resultCount: { gt: 0 }
      },
      _avg: {
        resultCount: true
      },
      _max: {
        resultCount: true
      },
      _min: {
        resultCount: true
      }
    });

    logger.info('\n Scrape Performance:');
    logger.info(`   Average properties per scrape: ${avgStats._avg.resultCount?.toFixed(0) || 0}`);
    logger.info(`   Max properties in single scrape: ${avgStats._max.resultCount || 0}`);
    logger.info(`   Min properties in single scrape: ${avgStats._min.resultCount || 0}`);

    // Most recent scrapes
    const recentJobs = await prisma.scrapeJob.findMany({
      where: { status: 'completed' },
      orderBy: { id: 'desc' },
      take: 5,
      select: {
        searchTerm: true,
        resultCount: true,
        completedAt: true
      }
    });

    logger.info('\n Recent Completed Scrapes:');
    recentJobs.forEach((job, idx) => {
      const time = job.completedAt ? new Date(job.completedAt).toLocaleString() : 'N/A';
      logger.info(`   ${idx + 1}. "${job.searchTerm}": ${job.resultCount} properties (${time})`);
    });

    logger.info('\n' + '='.repeat(70));

    await cleanup();
  });

/**
 * Show property statistics
 */
program
  .command('properties')
  .description('Show detailed property statistics')
  .option('--by-city', 'Show properties grouped by city')
  .option('--by-type', 'Show properties grouped by type')
  .option('--top <n>', 'Show top N results', '10')
  .action(async (options: any) => {
    logger.info(' Property Statistics\n');
    logger.info('='.repeat(70));

    const totalProperties = await prisma.property.count();
    logger.info(`\n Total Properties: ${totalProperties.toLocaleString()}`);

    // By city
    if (options.byCity) {
      const propertiesByCity = await prisma.property.groupBy({
        by: ['city'],
        _count: {
          id: true
        },
        orderBy: {
          _count: {
            id: 'desc'
          }
        },
        take: parseInt(options.top)
      });

      logger.info(`\n  Top ${options.top} Cities:`);
      propertiesByCity.forEach((city, idx) => {
        const count = city._count.id;
        const pct = ((count / totalProperties) * 100).toFixed(1);
        logger.info(`   ${idx + 1}. ${city.city || 'Unknown'}: ${count.toLocaleString()} (${pct}%)`);
      });
    }

    // By property type
    if (options.byType) {
      const propertiesByType = await prisma.property.groupBy({
        by: ['propType'],
        _count: {
          id: true
        },
        orderBy: {
          _count: {
            id: 'desc'
          }
        },
        take: parseInt(options.top)
      });

      logger.info(`\n  Top ${options.top} Property Types:`);
      propertiesByType.forEach((type, idx) => {
        const count = type._count.id;
        const pct = ((count / totalProperties) * 100).toFixed(1);
        logger.info(`   ${idx + 1}. ${type.propType}: ${count.toLocaleString()} (${pct}%)`);
      });
    }

    // Value statistics
    const valueStats = await prisma.property.aggregate({
      _avg: {
        appraisedValue: true,
        assessedValue: true
      },
      _max: {
        appraisedValue: true,
        assessedValue: true
      },
      _min: {
        appraisedValue: true,
        assessedValue: true
      }
    });

    logger.info('\n Property Values:');
    logger.info(`   Average Appraised: $${(valueStats._avg.appraisedValue || 0).toLocaleString()}`);
    logger.info(`   Max Appraised: $${(valueStats._max.appraisedValue || 0).toLocaleString()}`);
    logger.info(`   Min Appraised: $${(valueStats._min.appraisedValue || 0).toLocaleString()}`);
    logger.info(`   Average Assessed: $${(valueStats._avg.assessedValue || 0).toLocaleString()}`);

    logger.info('\n' + '='.repeat(70));

    await cleanup();
  });

/**
 * Show scraping rate and progress
 */
program
  .command('rate')
  .description('Show scraping rate and time-based statistics')
  .option('--days <n>', 'Analyze last N days', '7')
  .action(async (options: any) => {
    logger.info(' Scraping Rate Analysis\n');
    logger.info('='.repeat(70));

    const days = parseInt(options.days);
    const since = new Date();
    since.setDate(since.getDate() - days);

    // Get jobs completed in timeframe
    const recentJobs = await prisma.scrapeJob.findMany({
      where: {
        status: 'completed',
        completedAt: { gte: since }
      },
      select: {
        resultCount: true,
        completedAt: true,
        startedAt: true
      }
    });

    logger.info(`\n Last ${days} days:`);
    logger.info(`   Jobs completed: ${recentJobs.length}`);

    const totalProperties = recentJobs.reduce((sum, j) => sum + (j.resultCount || 0), 0);
    logger.info(`   Properties scraped: ${totalProperties.toLocaleString()}`);

    const jobsPerDay = recentJobs.length / days;
    const propertiesPerDay = totalProperties / days;

    logger.info(`\n Rates:`);
    logger.info(`   Jobs per day: ${jobsPerDay.toFixed(1)}`);
    logger.info(`   Properties per day: ${propertiesPerDay.toFixed(0)}`);
    logger.info(`   Avg properties per job: ${(totalProperties / recentJobs.length || 0).toFixed(1)}`);

    // Calculate processing time
    const processingTimes = recentJobs
      .filter(j => j.startedAt && j.completedAt)
      .map(j => {
        const created = new Date(j.startedAt!).getTime();
        const completed = new Date(j.completedAt!).getTime();
        return (completed - created) / 1000; // seconds
      });

    if (processingTimes.length > 0) {
      const avgTime = processingTimes.reduce((sum, t) => sum + t, 0) / processingTimes.length;

      logger.info(`\n  Average Processing Time:`);
      logger.info(`   ${(avgTime / 60).toFixed(1)} minutes per job`);
    }

    // Get queue status
    const [waiting, active] = await Promise.all([
      scraperQueue.getWaitingCount(),
      scraperQueue.getActiveCount()
    ]);

    logger.info(`\n Current Queue:`);
    logger.info(`   Waiting: ${waiting}`);
    logger.info(`   Active: ${active}`);

    // Estimate completion time
    if (waiting > 0 && jobsPerDay > 0) {
      const daysToComplete = waiting / jobsPerDay;
      logger.info(`\n Estimated time to clear queue:`);
      logger.info(`   ${daysToComplete.toFixed(1)} days at current rate`);
    }

    logger.info('\n' + '='.repeat(70));

    await cleanup();
  });

/**
 * Show search term statistics
 */
program
  .command('search-terms')
  .description('Show statistics about search terms')
  .option('--top <n>', 'Show top N most productive terms', '10')
  .action(async (options: any) => {
    logger.info(' Search Term Statistics\n');
    logger.info('='.repeat(70));

    // Count distinct search terms
    const distinctTerms = await prisma.scrapeJob.findMany({
      select: { searchTerm: true },
      distinct: ['searchTerm']
    });

    logger.info(`\n Total distinct search terms: ${distinctTerms.length.toLocaleString()}`);

    // Terms by status
    const termsByStatus = await prisma.scrapeJob.groupBy({
      by: ['status'],
      _count: {
        searchTerm: true
      }
    });

    logger.info('\n Search Terms by Status:');
    termsByStatus.forEach(stat => {
      logger.info(`   ${stat.status}: ${stat._count.searchTerm} terms`);
    });

    // Most productive terms
    const topTerms = await prisma.scrapeJob.findMany({
      where: {
        status: 'completed',
        resultCount: { gt: 0 }
      },
      orderBy: {
        resultCount: 'desc'
      },
      take: parseInt(options.top),
      select: {
        searchTerm: true,
        resultCount: true
      }
    });

    logger.info(`\n Top ${options.top} Most Productive Terms:`);
    topTerms.forEach((term, idx) => {
      logger.info(`   ${idx + 1}. "${term.searchTerm}": ${(term.resultCount || 0).toLocaleString()} properties`);
    });

    // Zero result terms
    const zeroResultCount = await prisma.scrapeJob.count({
      where: {
        status: 'completed',
        resultCount: 0
      }
    });

    logger.info(`\n Zero-result scrapes: ${zeroResultCount}`);

    // Average results per term
    const avgResults = await prisma.scrapeJob.aggregate({
      where: {
        status: 'completed',
        resultCount: { gt: 0 }
      },
      _avg: {
        resultCount: true
      }
    });

    logger.info(` Average results per successful term: ${(avgResults._avg.resultCount || 0).toFixed(1)}`);

    logger.info('\n' + '='.repeat(70));

    await cleanup();
  });

/**
 * Show priority job results
 */
program
  .command('priority')
  .description('Show statistics for priority jobs')
  .option('--recent <n>', 'Show last N priority jobs', '10')
  .action(async (options: any) => {
    logger.info(' Priority Job Statistics\n');
    logger.info('='.repeat(70));

    // This assumes priority jobs were marked with specific search terms
    // Adjust the query based on how priority jobs are identified
    const priorityJobs = await prisma.scrapeJob.findMany({
      where: {
        searchTerm: { in: ['Estate', 'Family', 'Trust'] }
      },
      select: {
        searchTerm: true,
        status: true,
        resultCount: true,
        completedAt: true,
        startedAt: true
      },
      orderBy: {
        startedAt: 'desc'
      },
      take: parseInt(options.recent)
    });

    logger.info(`\n Priority jobs found: ${priorityJobs.length}`);

    if (priorityJobs.length === 0) {
      logger.info('\nNo priority jobs found in database.');
      await cleanup();
      return;
    }

    // Group by status
    const statusCounts: Record<string, number> = {};
    let totalResults = 0;

    priorityJobs.forEach(job => {
      statusCounts[job.status] = (statusCounts[job.status] || 0) + 1;
      totalResults += job.resultCount || 0;
    });

    logger.info('\n By Status:');
    Object.entries(statusCounts).forEach(([status, count]) => {
      logger.info(`   ${status}: ${count}`);
    });

    logger.info(`\n Total properties from priority jobs: ${totalResults.toLocaleString()}`);
    logger.info(` Average per priority job: ${(totalResults / priorityJobs.length).toFixed(1)}`);

    logger.info(`\n Recent Priority Jobs:`);
    priorityJobs.forEach((job, idx) => {
      const status = job.status === 'completed' ? '' : job.status === 'failed' ? '' : '';
      const results = job.status === 'completed' ? ` (${job.resultCount} props)` : '';
      logger.info(`   ${idx + 1}. ${status} "${job.searchTerm}"${results}`);
    });

    logger.info('\n' + '='.repeat(70));

    await cleanup();
  });

/**
 * Show all statistics - comprehensive view
 */
program
  .command('all')
  .description('Show all available statistics (comprehensive report)')
  .action(async () => {
    logger.info(' COMPREHENSIVE DATABASE REPORT\n');
    logger.info('='.repeat(70));

    // Run all stat commands
    logger.info('\n1  SUMMARY\n');
    await program.parseAsync(['node', 'db-stats', 'summary']);

    logger.info('\n2  PROPERTIES\n');
    await program.parseAsync(['node', 'db-stats', 'properties', '--by-city', '--by-type']);

    logger.info('\n3  SCRAPING RATE\n');
    await program.parseAsync(['node', 'db-stats', 'rate']);

    logger.info('\n4  SEARCH TERMS\n');
    await program.parseAsync(['node', 'db-stats', 'search-terms']);

    logger.info('\n Comprehensive report complete!\n');
    logger.info('='.repeat(70));

    await cleanup();
  });

/**
 * Helper function to cleanup connections
 */
async function cleanup() {
  await scraperQueue.close();
  await prisma.$disconnect();
}

// Handle errors and cleanup
process.on('SIGINT', async () => {
  logger.info('\n\n Interrupted. Cleaning up...');
  await cleanup();
  process.exit(0);
});

process.on('unhandledRejection', async (error: any) => {
  logger.error('\n Unhandled error:', error.message);
  await cleanup();
  process.exit(1);
});

// Parse arguments
program.parse();
</file>

<file path="cli/queue-analyzer.ts">
#!/usr/bin/env npx tsx

import { Command } from 'commander';
import { scraperQueue } from '../queues/scraper.queue';
import { prisma } from '../lib/prisma';
import logger from '../lib/logger';

const program = new Command();

program
  .name('queue-analyzer')
  .description('Analyze queue performance and search term effectiveness')
  .version('1.0.0');

/**
 * Analyze successful search terms by category
 */
program
  .command('success')
  .description('Analyze most successful search term patterns')
  .option('--top <n>', 'Show top N examples per category', '5')
  .action(async (options: any) => {
    logger.info(' Analyzing Most Successful Search Term Types\n');
    logger.info('='.repeat(70));

    // Get all successful jobs (with results)
    const successfulJobs = await prisma.scrapeJob.findMany({
      where: {
        status: 'completed',
        resultCount: { gt: 0 }
      },
      select: {
        searchTerm: true,
        resultCount: true
      },
      orderBy: {
        resultCount: 'desc'
      }
    });

    logger.info(`\n Total successful scrapes: ${successfulJobs.length.toLocaleString()}`);

    const totalProperties = successfulJobs.reduce((sum, job) => sum + (job.resultCount || 0), 0);
    logger.info(` Total properties found: ${totalProperties.toLocaleString()}`);
    logger.info(` Average per successful search: ${(totalProperties / successfulJobs.length).toFixed(1)}`);

    // Categorize search terms
    const categories = {
      singleLastName: [] as typeof successfulJobs,
      fullName: [] as typeof successfulJobs,
      businessWithSuffix: [] as typeof successfulJobs,
      businessGeneric: [] as typeof successfulJobs,
      streetAddress: [] as typeof successfulJobs,
      streetName: [] as typeof successfulJobs,
      shortCode: [] as typeof successfulJobs,
      other: [] as typeof successfulJobs
    };

    const businessSuffixes = /\b(LLC|Inc|Corp|Company|Trust|Foundation|Partners|Group|Properties|Ventures|Capital|Holdings|Development|Estate|Assets|Portfolio|LTD|Enterprises|Management|Realty|Investment)\b/i;
    const streetSuffixes = /\b(Street|St|Avenue|Ave|Road|Rd|Drive|Dr|Lane|Ln|Boulevard|Blvd|Court|Ct|Circle|Cir|Way|Place|Pl|Parkway|Loop|Trail|Path|Highway|Hwy)\b/i;
    const commonStreets = /\b(Lamar|Congress|Riverside|Guadalupe|Airport|Burnet|Mopac|Anderson|MLK|Oltorf|Barton|Springs|Research|Metric|Wells Branch|Far West|Dean Keeton|Speedway|Red River|Manchaca|William Cannon|Slaughter|Parmer|Braker|Rundberg|Koenig|North Loop|South Congress|East Riverside|West Anderson|Capital of Texas|Loop 360|IH 35|Enfield|Exposition|Westlake|Windsor|Oak|Rainey|Cameron|Duval|San Jacinto|Shoal Creek|Cesar Chavez|Main|Howard|McNeil|Dessau|Jollyville|Spicewood|Bee Cave|Balcones|Mueller|Cherrywood|Sabine|Nueces|Trinity|Rio Grande|Manor|Springdale)\b/i;

    successfulJobs.forEach(job => {
      const term = job.searchTerm;
      const words = term.split(/\s+/);

      // Check for street address (starts with number + street name)
      if (/^\d+\s+/.test(term) && (streetSuffixes.test(term) || commonStreets.test(term))) {
        categories.streetAddress.push(job);
      }
      // Check for street name only
      else if (streetSuffixes.test(term) || commonStreets.test(term)) {
        categories.streetName.push(job);
      }
      // Check for business with suffix
      else if (businessSuffixes.test(term)) {
        categories.businessWithSuffix.push(job);
      }
      // Check for full name (2-3 words, mostly letters, capitalized)
      else if (words.length >= 2 && words.length <= 3 && /^[A-Z][a-z]+(\s+[A-Z][a-z]+)+$/.test(term)) {
        categories.fullName.push(job);
      }
      // Check for single last name (one word, mostly letters, capitalized)
      else if (words.length === 1 && /^[A-Z][a-z]+$/.test(term) && term.length > 3) {
        categories.singleLastName.push(job);
      }
      // Check for short codes (alphanumeric, short)
      else if (term.length <= 6 && /[A-Z0-9]/.test(term)) {
        categories.shortCode.push(job);
      }
      // Everything else
      else {
        categories.other.push(job);
      }
    });

    // Calculate statistics for each category
    const stats = Object.entries(categories).map(([name, jobs]) => {
      const total = jobs.reduce((sum, job) => sum + (job.resultCount || 0), 0);
      const avg = jobs.length > 0 ? total / jobs.length : 0;
      const max = jobs.length > 0 ? Math.max(...jobs.map(j => j.resultCount || 0)) : 0;
      return {
        name,
        count: jobs.length,
        totalProperties: total,
        avgProperties: avg,
        maxProperties: max,
        percentage: (jobs.length / successfulJobs.length) * 100
      };
    }).sort((a, b) => b.totalProperties - a.totalProperties);

    logger.info('\n Search Term Categories (by total properties found):\n');
    stats.forEach((stat, idx) => {
      const categoryName = stat.name
        .replace(/([A-Z])/g, ' $1')
        .replace(/^./, str => str.toUpperCase())
        .trim();

      logger.info(`${idx + 1}. ${categoryName}`);
      logger.info(`   Searches: ${stat.count.toLocaleString()} (${stat.percentage.toFixed(1)}%)`);
      logger.info(`   Properties: ${stat.totalProperties.toLocaleString()}`);
      logger.info(`   Avg per search: ${stat.avgProperties.toFixed(1)}`);
      logger.info(`   Max in single search: ${stat.maxProperties}`);
      logger.info('');
    });

    // Show top examples from each category
    logger.info('='.repeat(70));
    logger.info('\n TOP PERFORMERS BY CATEGORY:\n');

    const topN = parseInt(options.top);

    for (const [categoryName, jobs] of Object.entries(categories)) {
      if (jobs.length === 0) continue;

      const displayName = categoryName
        .replace(/([A-Z])/g, ' $1')
        .replace(/^./, str => str.toUpperCase())
        .trim();

      logger.info(`\n${displayName} (${jobs.length} total):`);

      const topJobs = jobs.sort((a, b) => (b.resultCount || 0) - (a.resultCount || 0)).slice(0, topN);

      topJobs.forEach((job, idx) => {
        logger.info(`  ${idx + 1}. "${job.searchTerm}" - ${(job.resultCount || 0).toLocaleString()} properties`);
      });
    }

    logger.info('\n' + '='.repeat(70));
    logger.info('\n Insights:');
    logger.info('   - Focus on search term types with high avg properties per search');
    logger.info('   - Consider filtering out or deprioritizing "Short Code" and "Other" categories');
    logger.info('   - Business names with suffixes (LLC, Trust, etc.) are highly effective');

    await cleanup();
  });

/**
 * Analyze failed searches
 */
program
  .command('failures')
  .description('Analyze failed search patterns and zero-result terms')
  .option('--limit <n>', 'Limit results', '50')
  .action(async (options: any) => {
    logger.info(' Analyzing Failed and Zero-Result Searches\n');
    logger.info('='.repeat(70));

    // Get failed jobs
    const failedJobs = await prisma.scrapeJob.findMany({
      where: { status: 'failed' },
      select: {
        searchTerm: true,
        error: true,
      },
      take: parseInt(options.limit)
    });

    logger.info(`\n Failed Jobs: ${failedJobs.length}`);

    if (failedJobs.length > 0) {
      logger.info('\nCommon Failure Patterns:');
      const errorCounts: Record<string, number> = {};

      failedJobs.forEach(job => {
        const errorType = job.error ? job.error.split(':')[0].trim() : 'Unknown';
        errorCounts[errorType] = (errorCounts[errorType] || 0) + 1;
      });

      Object.entries(errorCounts)
        .sort((a, b) => b[1] - a[1])
        .forEach(([error, count]) => {
          logger.info(`   - ${error}: ${count} occurrences`);
        });
    }

    // Get zero-result jobs
    const zeroResultJobs = await prisma.scrapeJob.findMany({
      where: {
        status: 'completed',
        resultCount: 0
      },
      select: {
        searchTerm: true,
      },
      take: parseInt(options.limit)
    });

    logger.info(`\n Zero-Result Searches: ${zeroResultJobs.length}`);

    // Analyze zero-result patterns
    if (zeroResultJobs.length > 0) {
      const patterns = {
        tooShort: zeroResultJobs.filter(j => j.searchTerm.length <= 2),
        numbers: zeroResultJobs.filter(j => /^\d+$/.test(j.searchTerm)),
        specialChars: zeroResultJobs.filter(j => /[^a-zA-Z0-9\s]/.test(j.searchTerm)),
        singleLetter: zeroResultJobs.filter(j => /^[A-Z]$/.test(j.searchTerm)),
      };

      logger.info('\nZero-Result Patterns:');
      logger.info(`   - Too short (<= 2 chars): ${patterns.tooShort.length}`);
      logger.info(`   - Pure numbers: ${patterns.numbers.length}`);
      logger.info(`   - Contains special chars: ${patterns.specialChars.length}`);
      logger.info(`   - Single letter: ${patterns.singleLetter.length}`);

      logger.info('\nSample Zero-Result Terms:');
      zeroResultJobs.slice(0, 10).forEach((job, idx) => {
        logger.info(`   ${idx + 1}. "${job.searchTerm}"`);
      });
    }

    logger.info('\n' + '='.repeat(70));
    logger.info('\n Recommendations:');
    logger.info('   - Filter out single letters and numbers before queuing');
    logger.info('   - Implement minimum length requirement (3+ characters)');
    logger.info('   - Consider removing terms with special characters');
    logger.info('   - Use "queue-manager cleanup --zero-results" to clean queue');

    await cleanup();
  });

/**
 * Analyze queue performance metrics
 */
program
  .command('performance')
  .description('Analyze queue performance metrics and throughput')
  .option('--days <n>', 'Analyze last N days', '7')
  .action(async (options: any) => {
    logger.info(' Queue Performance Analysis\n');
    logger.info('='.repeat(70));

    const days = parseInt(options.days);
    const since = new Date();
    since.setDate(since.getDate() - days);

    // Get completed jobs in timeframe
    const completed = await prisma.scrapeJob.findMany({
      where: {
        status: 'completed',
        completedAt: { gte: since }
      },
      select: {
        searchTerm: true,
        resultCount: true,
        completedAt: true,
        startedAt: true,
      }
    });

    logger.info(`\n Jobs completed in last ${days} days: ${completed.length}`);

    if (completed.length === 0) {
      logger.info('\nNo completed jobs in this timeframe.');
      await cleanup();
      return;
    }

    // Calculate throughput
    const totalProperties = completed.reduce((sum, j) => sum + (j.resultCount || 0), 0);
    const avgPropertiesPerJob = totalProperties / completed.length;
    const jobsPerDay = completed.length / days;
    const propertiesPerDay = totalProperties / days;

    logger.info(`\n Throughput:`);
    logger.info(`   - Jobs per day: ${jobsPerDay.toFixed(1)}`);
    logger.info(`   - Properties per day: ${propertiesPerDay.toFixed(0)}`);
    logger.info(`   - Avg properties per job: ${avgPropertiesPerJob.toFixed(1)}`);

    // Calculate processing time
    const processingTimes = completed
      .filter(j => j.startedAt && j.completedAt)
      .map(j => {
        const created = new Date(j.startedAt!).getTime();
        const completedTime = new Date(j.completedAt!).getTime();
        return (completedTime - created) / 1000; // seconds
      });

    if (processingTimes.length > 0) {
      const avgTime = processingTimes.reduce((sum, t) => sum + t, 0) / processingTimes.length;
      const minTime = Math.min(...processingTimes);
      const maxTime = Math.max(...processingTimes);

      logger.info(`\n  Processing Time:`);
      logger.info(`   - Average: ${(avgTime / 60).toFixed(1)} minutes`);
      logger.info(`   - Minimum: ${(minTime / 60).toFixed(1)} minutes`);
      logger.info(`   - Maximum: ${(maxTime / 60).toFixed(1)} minutes`);
    }

    // Get current queue metrics
    const [waiting, active, failed] = await Promise.all([
      scraperQueue.getWaitingCount(),
      scraperQueue.getActiveCount(),
      scraperQueue.getFailedCount(),
    ]);

    logger.info(`\n Current Queue State:`);
    logger.info(`   - Waiting: ${waiting}`);
    logger.info(`   - Active: ${active}`);
    logger.info(`   - Failed: ${failed}`);

    // Estimate completion time
    if (waiting > 0 && jobsPerDay > 0) {
      const daysToComplete = waiting / jobsPerDay;
      logger.info(`\n Estimated time to clear queue: ${daysToComplete.toFixed(1)} days`);
    }

    // Success rate
    const totalJobsAttempted = completed.length + failed;
    const successRate = (completed.length / totalJobsAttempted) * 100;

    logger.info(`\n Success Rate: ${successRate.toFixed(1)}% (${completed.length}/${totalJobsAttempted})`);

    logger.info('\n' + '='.repeat(70));

    await cleanup();
  });

/**
 * Comprehensive queue overview
 */
program
  .command('overview')
  .description('Show comprehensive queue and performance overview')
  .action(async () => {
    logger.info(' Queue Overview\n');
    logger.info('='.repeat(70));

    // Get all counts
    const [waiting, active, delayed, completed, failed] = await Promise.all([
      scraperQueue.getWaitingCount(),
      scraperQueue.getActiveCount(),
      scraperQueue.getDelayedCount(),
      scraperQueue.getCompletedCount(),
      scraperQueue.getFailedCount(),
    ]);

    logger.info(`\n Queue Counts:`);
    logger.info(`   - Waiting: ${waiting}`);
    logger.info(`   - Active: ${active}`);
    logger.info(`   - Delayed: ${delayed}`);
    logger.info(`   - Completed: ${completed}`);
    logger.info(`   - Failed: ${failed}`);

    // Get database stats
    const [totalProperties, totalJobs, distinctTerms] = await Promise.all([
      prisma.property.count(),
      prisma.scrapeJob.count(),
      prisma.scrapeJob.findMany({
        select: { searchTerm: true },
        distinct: ['searchTerm']
      }).then(results => results.length)
    ]);

    logger.info(`\n Database Stats:`);
    logger.info(`   - Total properties: ${totalProperties.toLocaleString()}`);
    logger.info(`   - Total scrape jobs: ${totalJobs.toLocaleString()}`);
    logger.info(`   - Distinct search terms: ${distinctTerms.toLocaleString()}`);

    // Get success/failure breakdown
    const successfulJobs = await prisma.scrapeJob.count({
      where: { status: 'completed', resultCount: { gt: 0 } }
    });

    const zeroResultJobs = await prisma.scrapeJob.count({
      where: { status: 'completed', resultCount: 0 }
    });

    const successRate = totalJobs > 0 ? (successfulJobs / totalJobs) * 100 : 0;

    logger.info(`\n Success Metrics:`);
    logger.info(`   - Successful jobs: ${successfulJobs.toLocaleString()}`);
    logger.info(`   - Zero-result jobs: ${zeroResultJobs.toLocaleString()}`);
    logger.info(`   - Failed jobs: ${failed}`);
    logger.info(`   - Success rate: ${successRate.toFixed(1)}%`);

    logger.info('\n' + '='.repeat(70));

    await cleanup();
  });

/**
 * Helper function to cleanup connections
 */
async function cleanup() {
  await scraperQueue.close();
  await prisma.$disconnect();
}

// Handle errors and cleanup
process.on('SIGINT', async () => {
  logger.info('\n\n Interrupted. Cleaning up...');
  await cleanup();
  process.exit(0);
});

process.on('unhandledRejection', async (error: any) => {
  logger.error('\n Unhandled error:', error.message);
  await cleanup();
  process.exit(1);
});

// Parse arguments
program.parse();
</file>

<file path="cli/queue-manager.ts">
#!/usr/bin/env npx tsx

import { Command } from 'commander';
import { scraperQueue } from '../queues/scraper.queue';
import { prisma } from '../lib/prisma';
import * as fs from 'fs';
import * as path from 'path';
import logger from '../lib/logger';

const program = new Command();

program
  .name('queue-manager')
  .description('Manage scraper job queue - consolidates queue management utilities')
  .version('1.0.0');

/**
 * Add search terms to queue from file
 */
program
  .command('add-terms')
  .description('Add search terms from file to queue')
  .argument('<file>', 'Path to file with one term per line')
  .option('-p, --priority', 'Add as priority jobs (highest priority)')
  .option('-d, --dedupe', 'Remove duplicates from database first')
  .option('--priority-level <level>', 'Set priority level (1-10, lower is higher priority)', '10')
  .action(async (file: string, options: any) => {
    logger.info(' Adding Search Terms to Queue\n');
    logger.info('='.repeat(60));

    const filePath = path.resolve(file);

    // Check if file exists
    if (!fs.existsSync(filePath)) {
      logger.error(` Error: File not found: ${filePath}`);
      process.exit(1);
    }

    // Read terms from file
    const content = fs.readFileSync(filePath, 'utf-8');
    const terms = content
      .split('\n')
      .map(line => line.trim())
      .filter(line => line && !line.startsWith('#'));

    logger.info(` File: ${path.basename(filePath)}`);
    logger.info(` Found ${terms.length} search terms`);

    // Dedupe if requested
    if (options.dedupe) {
      logger.info('\n Checking for existing search terms in database...');
      const existing = await prisma.scrapeJob.findMany({
        where: { searchTerm: { in: terms } },
        select: { searchTerm: true },
        distinct: ['searchTerm']
      });
      const existingSet = new Set(existing.map(j => j.searchTerm));
      const newTerms = terms.filter(t => !existingSet.has(t));
      logger.info(`   - Existing terms (skipped): ${existing.length}`);
      logger.info(`   - New terms to add: ${newTerms.length}`);

      if (newTerms.length === 0) {
        logger.info('\n No new terms to add (all already in database)');
        await cleanup();
        return;
      }
      // Use only new terms
      terms.length = 0;
      terms.push(...newTerms);
    }

    const priorityLevel = options.priority ? 1 : parseInt(options.priorityLevel);

    logger.info(`\n Adding ${terms.length} jobs to queue...`);
    logger.info(`   Priority: ${priorityLevel} ${options.priority ? '(highest)' : ''}`);

    let added = 0;
    for (const term of terms) {
      try {
        await scraperQueue.add(
          'scrape-properties',
          {
            searchTerm: term,
            userId: 'cli-queue-manager',
            scheduled: false,
          },
          {
            priority: priorityLevel,
            attempts: 3,
            backoff: {
              type: 'exponential',
              delay: 2000,
            },
          }
        );
        added++;
        if (added % 10 === 0) {
          process.stdout.write(`\r   Progress: ${added}/${terms.length} (${((added/terms.length)*100).toFixed(1)}%)`);
        }
      } catch (error: any) {
        logger.error(`\n    Failed to add "${term}":`, error.message);
      }
    }

    logger.info(`\n\n Added ${added} jobs to queue!`);

    // Show queue status
    const [waiting, active] = await Promise.all([
      scraperQueue.getWaitingCount(),
      scraperQueue.getActiveCount(),
    ]);

    logger.info(`\n Queue Status:`);
    logger.info(`   - Waiting: ${waiting}`);
    logger.info(`   - Active: ${active}`);

    await cleanup();
  });

/**
 * Stop all pending/waiting jobs
 */
program
  .command('stop')
  .description('Stop all pending jobs in queue (active jobs will complete)')
  .option('--force', 'Also attempt to fail active jobs')
  .action(async (options: any) => {
    logger.info(' Stopping All Jobs in Queue\n');
    logger.info('='.repeat(60));

    // Get current queue stats
    const [waiting, active, delayed] = await Promise.all([
      scraperQueue.getWaitingCount(),
      scraperQueue.getActiveCount(),
      scraperQueue.getDelayedCount(),
    ]);

    logger.info(` Current Queue State:`);
    logger.info(`   - Waiting: ${waiting}`);
    logger.info(`   - Active: ${active}`);
    logger.info(`   - Delayed: ${delayed}`);
    logger.info(`   - Total to stop: ${waiting + delayed}\n`);

    if (waiting + delayed === 0 && !options.force) {
      logger.info(' No pending jobs to stop (queue is empty)');

      if (active > 0) {
        logger.info(`\n  Note: ${active} jobs are currently active and cannot be stopped.`);
        logger.info('   They will finish processing. Use --force to attempt to fail them.');
      }
      await cleanup();
      return;
    }

    let removed = 0;
    let failed = 0;

    // Remove waiting jobs
    if (waiting > 0) {
      logger.info(` Removing ${waiting} waiting jobs...`);
      const waitingJobs = await scraperQueue.getWaiting();

      for (const job of waitingJobs) {
        try {
          await job.remove();
          removed++;
          if (removed % 50 === 0) {
            process.stdout.write(`\r   Progress: ${removed}/${waiting + delayed} (${((removed/(waiting + delayed))*100).toFixed(1)}%)`);
          }
        } catch (error: any) {
          failed++;
          if (failed <= 3) {
            logger.error(`\n    Failed to remove job ${job.id}:`, error.message);
          }
        }
      }
    }

    // Remove delayed jobs
    if (delayed > 0) {
      logger.info(`\n Removing ${delayed} delayed jobs...`);
      const delayedJobs = await scraperQueue.getDelayed();

      for (const job of delayedJobs) {
        try {
          await job.remove();
          removed++;
          if (removed % 50 === 0) {
            process.stdout.write(`\r   Progress: ${removed}/${waiting + delayed} (${((removed/(waiting + delayed))*100).toFixed(1)}%)`);
          }
        } catch (error: any) {
          failed++;
          if (failed <= 3) {
            logger.error(`\n    Failed to remove job ${job.id}:`, error.message);
          }
        }
      }
    }

    // Force-fail active jobs if requested
    if (options.force && active > 0) {
      logger.info(`\n  Force-failing ${active} active jobs...`);
      const activeJobs = await scraperQueue.getActive();

      for (const job of activeJobs) {
        try {
          await job.moveToFailed(new Error('Force-stopped by CLI'), false);
          removed++;
          if (removed % 10 === 0) {
            process.stdout.write(`\r   Progress: ${removed}/${waiting + delayed + active} jobs`);
          }
        } catch (error: any) {
          failed++;
          if (failed <= 3) {
            logger.error(`\n    Failed to stop job ${job.id}:`, error.message);
          }
        }
      }
    }

    logger.info(`\n\n Jobs stopped!`);
    logger.info(`   - Successfully stopped: ${removed}`);
    logger.info(`   - Failed to stop: ${failed}`);

    // Get final queue stats
    const [finalWaiting, finalActive, finalDelayed] = await Promise.all([
      scraperQueue.getWaitingCount(),
      scraperQueue.getActiveCount(),
      scraperQueue.getDelayedCount(),
    ]);

    logger.info(`\n Final Queue Status:`);
    logger.info(`   - Waiting: ${finalWaiting}`);
    logger.info(`   - Active: ${finalActive}`);
    logger.info(`   - Delayed: ${finalDelayed}`);

    await cleanup();
  });

/**
 * Cleanup queue - remove failed/completed jobs
 */
program
  .command('cleanup')
  .description('Clean up queue by removing old jobs')
  .option('--aggressive', 'Remove all completed and failed jobs')
  .option('--older-than <days>', 'Remove jobs older than N days', '7')
  .option('--zero-results', 'Remove waiting jobs for terms that previously returned zero results')
  .action(async (options: any) => {
    logger.info(' Queue Cleanup\n');
    logger.info('='.repeat(60));

    let totalRemoved = 0;
    let totalFailed = 0;

    // Aggressive cleanup - remove all completed/failed
    if (options.aggressive) {
      logger.info('\n  AGGRESSIVE MODE: Removing ALL completed and failed jobs...');

      const [completedCount, failedCount] = await Promise.all([
        scraperQueue.getCompletedCount(),
        scraperQueue.getFailedCount(),
      ]);

      logger.info(`   - Completed jobs: ${completedCount}`);
      logger.info(`   - Failed jobs: ${failedCount}`);
      logger.info(`   - Total to remove: ${completedCount + failedCount}`);

      if (completedCount + failedCount === 0) {
        logger.info('\n No jobs to clean up!');
        await cleanup();
        return;
      }

      logger.info('\n Removing jobs...');
      const [removedCompleted, removedFailed] = await Promise.all([
        scraperQueue.clean(0, 'completed'),
        scraperQueue.clean(0, 'failed'),
      ]);

      totalRemoved = removedCompleted.length + removedFailed.length;
      logger.info(`\n Removed ${totalRemoved} jobs (${removedCompleted.length} completed, ${removedFailed.length} failed)`);
    }

    // Remove jobs older than N days
    if (!options.aggressive && options.olderThan) {
      const days = parseInt(options.olderThan);
      const timestamp = Date.now() - (days * 24 * 60 * 60 * 1000);

      logger.info(`\n Removing jobs older than ${days} days...`);

      const [removedCompleted, removedFailed] = await Promise.all([
        scraperQueue.clean(timestamp, 'completed'),
        scraperQueue.clean(timestamp, 'failed'),
      ]);

      totalRemoved = removedCompleted.length + removedFailed.length;
      logger.info(`    Removed ${totalRemoved} old jobs`);
    }

    // Zero results cleanup
    if (options.zeroResults) {
      logger.info('\n Finding terms with zero results...');

      const emptyJobs = await prisma.scrapeJob.findMany({
        where: {
          status: 'completed',
          resultCount: 0
        },
        select: { searchTerm: true },
        distinct: ['searchTerm']
      });

      const emptyTerms = new Set(emptyJobs.map(j => j.searchTerm));
      logger.info(`   Found ${emptyTerms.size} terms that returned zero results`);

      const waitingJobs = await scraperQueue.getWaiting();
      const jobsToRemove = waitingJobs.filter(job =>
        emptyTerms.has(job.data.searchTerm)
      );

      logger.info(`   Found ${jobsToRemove.length} waiting jobs to remove`);

      if (jobsToRemove.length > 0) {
        logger.info('\n  Removing zero-result jobs...');
        let removed = 0;

        for (const job of jobsToRemove) {
          try {
            await job.remove();
            removed++;
            if (removed % 20 === 0) {
              process.stdout.write(`\r   Progress: ${removed}/${jobsToRemove.length} (${((removed/jobsToRemove.length)*100).toFixed(1)}%)`);
            }
          } catch (error: any) {
            totalFailed++;
          }
        }

        logger.info(`\n    Removed ${removed} zero-result jobs`);
        totalRemoved += removed;
      }
    }

    // Show final stats
    const [waiting, active, completed, failed] = await Promise.all([
      scraperQueue.getWaitingCount(),
      scraperQueue.getActiveCount(),
      scraperQueue.getCompletedCount(),
      scraperQueue.getFailedCount(),
    ]);

    logger.info(`\n Final Queue Status:`);
    logger.info(`   - Waiting: ${waiting}`);
    logger.info(`   - Active: ${active}`);
    logger.info(`   - Completed: ${completed}`);
    logger.info(`   - Failed: ${failed}`);
    logger.info(`\n Cleanup complete! Removed ${totalRemoved} jobs.`);

    await cleanup();
  });

/**
 * Show queue status
 */
program
  .command('status')
  .description('Show current queue status with job counts')
  .option('--detailed', 'Show detailed information about recent jobs')
  .action(async (options: any) => {
    logger.info(' Queue Status\n');
    logger.info('='.repeat(60));

    const [waiting, active, delayed, completed, failed, paused] = await Promise.all([
      scraperQueue.getWaitingCount(),
      scraperQueue.getActiveCount(),
      scraperQueue.getDelayedCount(),
      scraperQueue.getCompletedCount(),
      scraperQueue.getFailedCount(),
      scraperQueue.isPaused(),
    ]);

    logger.info(`\n Job Counts:`);
    logger.info(`   - Waiting: ${waiting}`);
    logger.info(`   - Active: ${active}`);
    logger.info(`   - Delayed: ${delayed}`);
    logger.info(`   - Completed: ${completed}`);
    logger.info(`   - Failed: ${failed}`);
    logger.info(`   - Paused: ${paused ? 'Yes' : 'No'}`);
    logger.info(`   - Total: ${waiting + active + delayed + completed + failed}`);

    if (options.detailed) {
      logger.info(`\n Recent Jobs:`);

      // Show recent active jobs
      if (active > 0) {
        const activeJobs = await scraperQueue.getActive(0, 5);
        logger.info(`\n   Active Jobs (${Math.min(5, active)}):`);
        activeJobs.forEach((job, idx) => {
          logger.info(`   ${idx + 1}. "${job.data.searchTerm}" (ID: ${job.id})`);
        });
      }

      // Show recent waiting jobs
      if (waiting > 0) {
        const waitingJobs = await scraperQueue.getWaiting(0, 5);
        logger.info(`\n   Waiting Jobs (showing ${Math.min(5, waiting)}):`);
        waitingJobs.forEach((job, idx) => {
          logger.info(`   ${idx + 1}. "${job.data.searchTerm}" (Priority: ${job.opts.priority || 10})`);
        });
      }

      // Show recent failed jobs
      if (failed > 0) {
        const failedJobs = await scraperQueue.getFailed(0, 3);
        logger.info(`\n   Recent Failed Jobs (showing ${Math.min(3, failed)}):`);
        failedJobs.forEach((job, idx) => {
          logger.info(`   ${idx + 1}. "${job.data.searchTerm}" - ${job.failedReason || 'Unknown error'}`);
        });
      }
    }

    logger.info('');
    await cleanup();
  });

/**
 * Pause/resume queue processing
 */
program
  .command('pause')
  .description('Pause queue processing')
  .action(async () => {
    logger.info('  Pausing queue...');
    await scraperQueue.pause();
    logger.info(' Queue paused. Jobs will not be processed until resumed.');
    await cleanup();
  });

program
  .command('resume')
  .description('Resume queue processing')
  .action(async () => {
    logger.info('  Resuming queue...');
    await scraperQueue.resume();
    logger.info(' Queue resumed. Processing will continue.');
    await cleanup();
  });

/**
 * Helper function to cleanup connections
 */
async function cleanup() {
  await scraperQueue.close();
  await prisma.$disconnect();
}

// Handle errors and cleanup
process.on('SIGINT', async () => {
  logger.info('\n\n Interrupted. Cleaning up...');
  await cleanup();
  process.exit(0);
});

process.on('unhandledRejection', async (error: any) => {
  logger.error('\n Unhandled error:', error.message);
  await cleanup();
  process.exit(1);
});

// Parse arguments
program.parse();
</file>

<file path="cli/README_ENHANCED.md">
# cli

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "SoftwareSourceCode",
  "name": "cli",
  "description": "Directory containing 5 code files with 0 classes and 5 functions",
  "programmingLanguage": [
    {
      "@type": "ComputerLanguage",
      "name": "Typescript"
    }
  ],
  "featureList": [
    "5 function definitions"
  ]
}
</script>

## Overview

This directory contains 5 code file(s) with extracted schemas.

## Files and Schemas

### `data-cleaner.ts` (typescript)

**Functions:**
- `async cleanup()` - Line 426

### `db-stats-simple.ts` (typescript)

**Functions:**
- `async checkDatabaseStats()` - Line 5

### `db-stats.ts` (typescript)

**Functions:**
- `async cleanup()` - Line 447

### `queue-analyzer.ts` (typescript)

**Functions:**
- `async cleanup()` - Line 405

### `queue-manager.ts` (typescript)

**Functions:**
- `async cleanup()` - Line 452

---
*Generated by Enhanced Schema Generator with schema.org markup*
</file>

<file path="config/index.ts">
/**
 * Centralized Configuration Module
 *
 * Single source of truth for all application configuration.
 * All environment variables and settings are defined here.
 *
 * Usage:
 *   import { config } from './config';
 *   const port = config.server.port;
 */

import dotenv from 'dotenv';
import logger from '../lib/logger';

// Load environment variables from .env or Doppler
dotenv.config();

/**
 * Parse environment variable as integer with fallback
 */
function parseIntEnv(key: string, defaultValue: number): number {
  const value = process.env[key];
  if (!value) return defaultValue;
  const parsed = parseInt(value, 10);
  return isNaN(parsed) ? defaultValue : parsed;
}

/**
 * Parse environment variable as boolean with fallback
 */
function parseBoolEnv(key: string, defaultValue: boolean): boolean {
  const value = process.env[key];
  if (!value) return defaultValue;
  return value.toLowerCase() === 'true' || value === '1';
}

/**
 * Parse comma-separated string to array
 */
function parseArrayEnv(key: string, defaultValue: string[]): string[] {
  const value = process.env[key];
  if (!value) return defaultValue;
  return value.split(',').map(s => s.trim()).filter(Boolean);
}

/**
 * Application Configuration
 */
export const config = {
  // Environment
  env: {
    nodeEnv: process.env.NODE_ENV || 'development',
    isDevelopment: process.env.NODE_ENV !== 'production',
    isProduction: process.env.NODE_ENV === 'production',
    isTest: process.env.NODE_ENV === 'test',
  },

  // Doppler Configuration
  doppler: {
    project: process.env.DOPPLER_PROJECT,
    config: process.env.DOPPLER_CONFIG,
    enabled: !!process.env.DOPPLER_PROJECT,
  },

  // Server Configuration
  server: {
    port: parseIntEnv('PORT', 3001),
    host: process.env.HOST || '0.0.0.0',
    logLevel: process.env.LOG_LEVEL,
    gracefulShutdownTimeout: parseIntEnv('GRACEFUL_SHUTDOWN_TIMEOUT', 10000),
  },

  // Database Configuration
  database: {
    url: process.env.DATABASE_URL || 'postgresql://localhost:5432/tcad_scraper',
    readOnlyUrl: process.env.DATABASE_READ_ONLY_URL,
    connectionTimeout: parseIntEnv('DATABASE_CONNECTION_TIMEOUT', 10000),
    poolSize: parseIntEnv('DATABASE_POOL_SIZE', 10),
  },

  // Redis Configuration
  redis: {
    host: process.env.REDIS_HOST || 'localhost',
    port: parseIntEnv('REDIS_PORT', 6379),
    password: process.env.REDIS_PASSWORD,
    db: parseIntEnv('REDIS_DB', 0),
    connectionTimeout: parseIntEnv('REDIS_CONNECTION_TIMEOUT', 10000),
  },

  // Queue Configuration
  queue: {
    name: 'scraper-queue',
    jobName: 'scrape-properties',
    concurrency: parseIntEnv('QUEUE_CONCURRENCY', 2),
    defaultJobOptions: {
      attempts: parseIntEnv('QUEUE_JOB_ATTEMPTS', 3),
      backoffDelay: parseIntEnv('QUEUE_BACKOFF_DELAY', 2000),
      removeOnComplete: parseIntEnv('QUEUE_REMOVE_ON_COMPLETE', 100),
      removeOnFail: parseIntEnv('QUEUE_REMOVE_ON_FAIL', 50),
    },
    cleanupInterval: parseIntEnv('QUEUE_CLEANUP_INTERVAL', 3600000), // 1 hour
    cleanupGracePeriod: parseIntEnv('QUEUE_CLEANUP_GRACE', 86400000), // 24 hours
    dashboard: {
      basePath: process.env.QUEUE_DASHBOARD_PATH || '/admin/queues',
      enabled: parseBoolEnv('QUEUE_DASHBOARD_ENABLED', true),
    },
  },

  // Rate Limiting Configuration
  rateLimit: {
    api: {
      windowMs: parseIntEnv('API_RATE_LIMIT_WINDOW', 900000), // 15 minutes
      max: parseIntEnv('API_RATE_LIMIT_MAX', 100),
      message: process.env.API_RATE_LIMIT_MESSAGE || 'Too many requests from this IP, please try again later.',
    },
    scraper: {
      windowMs: parseIntEnv('SCRAPER_RATE_LIMIT_WINDOW', 60000), // 1 minute
      max: parseIntEnv('SCRAPER_RATE_LIMIT_MAX', 5),
      message: process.env.SCRAPER_RATE_LIMIT_MESSAGE || 'Too many scrape requests, please wait before trying again.',
      jobDelay: parseIntEnv('SCRAPER_RATE_LIMIT_DELAY', 5000),
      cacheCleanupInterval: parseIntEnv('SCRAPER_RATE_CACHE_CLEANUP', 60000),
    },
  },

  // CORS Configuration
  cors: {
    allowedOrigins: parseArrayEnv('CORS_ALLOWED_ORIGINS', [
      'http://localhost:5173',
      'http://localhost:5174',
      'https://alephatx.info',
      'https://www.alephatx.info',
    ]),
    credentials: parseBoolEnv('CORS_CREDENTIALS', true),
    allowNoOrigin: parseBoolEnv('CORS_ALLOW_NO_ORIGIN', true), // For mobile apps, curl, etc.
  },

  // Security Configuration
  security: {
    helmet: {
      crossOriginResourcePolicy: process.env.HELMET_CORP || 'cross-origin',
      enableHsts: parseBoolEnv('HELMET_HSTS_ENABLED', false), // Disabled for HTTP/IP access
      enableCoop: parseBoolEnv('HELMET_COOP_ENABLED', false), // Disabled for IP access
      enableCsp: parseBoolEnv('HELMET_CSP_ENABLED', false), // Handled by xcontroller middleware
      enableOriginAgentCluster: parseBoolEnv('HELMET_OAC_ENABLED', false),
    },
    csp: {
      enabled: parseBoolEnv('CSP_ENABLED', true),
      nonceLength: parseIntEnv('CSP_NONCE_LENGTH', 16),
      directives: {
        defaultSrc: parseArrayEnv('CSP_DEFAULT_SRC', ["'self'"]),
        scriptSrc: parseArrayEnv('CSP_SCRIPT_SRC', ["'self'"]),
        styleSrc: parseArrayEnv('CSP_STYLE_SRC', ["'self'", "'unsafe-inline'"]),
        imgSrc: parseArrayEnv('CSP_IMG_SRC', ["'self'", 'data:', 'https:']),
        fontSrc: parseArrayEnv('CSP_FONT_SRC', ["'self'", 'data:']),
        connectSrc: parseArrayEnv('CSP_CONNECT_SRC', ["'self'"]),
        frameAncestors: parseArrayEnv('CSP_FRAME_ANCESTORS', ["'none'"]),
        baseUri: parseArrayEnv('CSP_BASE_URI', ["'self'"]),
        formAction: parseArrayEnv('CSP_FORM_ACTION', ["'self'"]),
      },
    },
    hsts: {
      maxAge: parseIntEnv('HSTS_MAX_AGE', 31536000), // 1 year
      includeSubDomains: parseBoolEnv('HSTS_INCLUDE_SUBDOMAINS', true),
    },
  },

  // Authentication Configuration
  auth: {
    apiKey: process.env.API_KEY,
    jwt: {
      secret: process.env.JWT_SECRET || 'fallback-secret-change-in-production',
      expiresIn: process.env.JWT_EXPIRES_IN || '7d',
    },
    skipInDevelopment: parseBoolEnv('AUTH_SKIP_IN_DEVELOPMENT', true),
  },

  // Scraper Configuration
  scraper: {
    tcadApiKey: process.env.TCAD_API_KEY,
    autoRefreshToken: parseBoolEnv('TCAD_AUTO_REFRESH_TOKEN', true),
    tokenRefreshInterval: parseIntEnv('TCAD_TOKEN_REFRESH_INTERVAL', 270000), // 4.5 minutes
    tokenRefreshCron: process.env.TCAD_TOKEN_REFRESH_CRON, // Optional cron schedule
    headless: parseBoolEnv('SCRAPER_HEADLESS', true),
    timeout: parseIntEnv('SCRAPER_TIMEOUT', 30000),
    retryAttempts: parseIntEnv('SCRAPER_RETRY_ATTEMPTS', 3),
    retryDelay: parseIntEnv('SCRAPER_RETRY_DELAY', 2000),
    humanDelay: {
      min: parseIntEnv('SCRAPER_HUMAN_DELAY_MIN', 100),
      max: parseIntEnv('SCRAPER_HUMAN_DELAY_MAX', 500),
    },
    userAgents: parseArrayEnv('SCRAPER_USER_AGENTS', [
      'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
      'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
      'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    ]),
    viewports: process.env.SCRAPER_VIEWPORTS
      ? JSON.parse(process.env.SCRAPER_VIEWPORTS)
      : [
          { width: 3840, height: 2160 }, // 4K to see all columns
          { width: 2560, height: 1440 }, // 1440p
          { width: 1920, height: 1080 }, // 1080p
        ],
    proxy: {
      enabled: parseBoolEnv('SCRAPER_PROXY_ENABLED', false),
      server: process.env.SCRAPER_PROXY_SERVER,
      username: process.env.SCRAPER_PROXY_USERNAME,
      password: process.env.SCRAPER_PROXY_PASSWORD,
    },
    brightData: {
      enabled: parseBoolEnv('BRIGHT_DATA_ENABLED', false),
      apiToken: process.env.BRIGHT_DATA_API_TOKEN,
      proxyHost: process.env.BRIGHT_DATA_PROXY_HOST || 'brd.superproxy.io',
      proxyPort: parseIntEnv('BRIGHT_DATA_PROXY_PORT', 22225),
    },
  },

  // Claude AI Configuration
  claude: {
    apiKey: process.env.ANTHROPIC_API_KEY || (() => {
      // Fallback: Try to fetch from Doppler personal-info/dev if not in current env
      try {
        const { execSync } = require('child_process');
        const key = execSync('doppler secrets get ANTHROPIC_API_KEY -p personal-info -c dev --plain', {
          encoding: 'utf-8',
          stdio: ['pipe', 'pipe', 'pipe']
        }).trim();
        if (key && key.startsWith('sk-ant-')) {
          logger.info('Using ANTHROPIC_API_KEY from Doppler personal-info/dev');
          return key;
        }
      } catch (error) {
        // Doppler fetch failed, will return undefined
      }
      return undefined;
    })(),
    model: process.env.CLAUDE_MODEL || 'claude-3-haiku-20240307',
    maxTokens: parseIntEnv('CLAUDE_MAX_TOKENS', 1024),
    timeout: parseIntEnv('CLAUDE_TIMEOUT', 30000),
  },

  // Logging Configuration
  logging: {
    level: process.env.LOG_LEVEL,
    format: process.env.LOG_FORMAT,
    colorize: parseBoolEnv('LOG_COLORIZE', true),
    files: {
      error: process.env.LOG_ERROR_FILE,
      combined: process.env.LOG_COMBINED_FILE,
      enabled: parseBoolEnv('LOG_FILES_ENABLED', true),
    },
    console: {
      enabled: parseBoolEnv('LOG_CONSOLE_ENABLED', true),
    },
  },

  // Frontend Configuration
  frontend: {
    url: process.env.FRONTEND_URL,
    apiUrl: process.env.API_URL,
    viteApiUrl: process.env.VITE_API_URL,
    appVersion: process.env.APP_VERSION || '1.0.0',
    features: {
      search: parseBoolEnv('FEATURE_SEARCH', true),
      analytics: parseBoolEnv('FEATURE_ANALYTICS', false),
      monitoring: parseBoolEnv('FEATURE_MONITORING', false),
    },
  },

  // Monitoring & Metrics Configuration
  monitoring: {
    sentry: {
      enabled: parseBoolEnv('SENTRY_ENABLED', false),
      dsn: process.env.SENTRY_DSN,
      environment: process.env.SENTRY_ENVIRONMENT || process.env.NODE_ENV || 'development',
      tracesSampleRate: parseFloat(process.env.SENTRY_TRACES_SAMPLE_RATE || '0.1'),
    },
  },
} as const;

/**
 * Validate required configuration
 * Throws error if critical config is missing
 */
export function validateConfig(): void {
  const errors: string[] = [];

  // Check critical environment variables
  if (!config.database.url) {
    errors.push('DATABASE_URL is required');
  }

  if (config.env.isProduction) {
    if (!config.auth.jwt.secret || config.auth.jwt.secret === 'fallback-secret-change-in-production') {
      errors.push('JWT_SECRET must be set in production');
    }
    if (!config.claude.apiKey) {
      errors.push('ANTHROPIC_API_KEY is required for AI search functionality');
    }
  }

  if (errors.length > 0) {
    throw new Error(`Configuration validation failed:\n${errors.join('\n')}`);
  }
}

/**
 * Log configuration summary (safe for production - no secrets)
 */
export function logConfigSummary(): void {
  logger.info('=== Configuration Summary ===');
  logger.info(`Environment: ${config.env.nodeEnv}`);
  logger.info(`Server: ${config.server.host}:${config.server.port}`);
  logger.info(`Database: ${config.database.url ? 'Configured' : 'Not configured'}`);
  logger.info(`Redis: ${config.redis.host}:${config.redis.port}`);
  logger.info(`Queue Dashboard: ${config.queue.dashboard.enabled ? config.queue.dashboard.basePath : 'Disabled'}`);
  logger.info(`Auth: ${config.auth.apiKey ? 'API Key configured' : 'No API Key'}, ${config.auth.jwt.secret ? 'JWT configured' : 'No JWT'}`);
  logger.info(`Claude AI: ${config.claude.apiKey ? 'Enabled' : 'Disabled'}`);
  logger.info(`TCAD API Token: ${config.scraper.tcadApiKey ? 'Configured (fast API mode)' : 'Not configured (fallback to browser capture)'}`);
  logger.info(`TCAD Auto Refresh: ${config.scraper.autoRefreshToken ? `Enabled (every ${config.scraper.tokenRefreshInterval / 60000} min)` : 'Disabled'}`);
  logger.info(`Scraper Proxy: ${config.scraper.proxy.enabled ? 'Enabled' : 'Disabled'}`);
  logger.info(`Bright Data: ${config.scraper.brightData.enabled ? 'Enabled' : 'Disabled'}`);
  logger.info(`Monitoring: ${config.monitoring.enabled ? 'Enabled' : 'Disabled'}`);

  if (config.doppler.enabled) {
    logger.info(`Doppler: ${config.doppler.project}/${config.doppler.config}`);
  }

  logger.info('============================');
}

// Export individual config sections for convenience
export const serverConfig = config.server;
export const databaseConfig = config.database;
export const redisConfig = config.redis;
export const queueConfig = config.queue;
export const rateLimitConfig = config.rateLimit;
export const corsConfig = config.cors;
export const securityConfig = config.security;
export const authConfig = config.auth;
export const scraperConfig = config.scraper;
export const claudeConfig = config.claude;
export const loggingConfig = config.logging;
export const frontendConfig = config.frontend;
export const monitoringConfig = config.monitoring;

// Default export
export default config;
</file>

<file path="config/swagger.ts">
/**
 * Swagger/OpenAPI Configuration
 *
 * Provides interactive API documentation at /api-docs
 */

import swaggerJSDoc from 'swagger-jsdoc';
import { config } from './index';

const swaggerDefinition = {
  openapi: '3.0.0',
  info: {
    title: 'TCAD Property Scraper API',
    version: '1.0.0',
    description: `
Production-ready API for scraping and querying Travis Central Appraisal District property data.

## Features

- **Web Scraping**: Automated property data collection from TCAD website
- **Job Queue**: BullMQ-based asynchronous job processing
- **AI-Powered Search**: Natural language queries via Claude AI
- **Caching**: Redis-backed caching for optimal performance
- **Monitoring**: Real-time job status and statistics

## Authentication

Most endpoints support optional authentication via:
- **API Key**: Include \`X-API-Key\` header
- **JWT Token**: Include \`Authorization: Bearer <token>\` header

In development mode, authentication can be skipped.

## Rate Limiting

- API endpoints: 100 requests per 15 minutes
- Scraping endpoints: 5 requests per minute

## Caching

- Property queries: Cached for 5 minutes
- Statistics: Cached for 10 minutes
- Cache automatically invalidated when new properties are scraped
    `,
    contact: {
      name: 'API Support',
      url: 'https://github.com/aledlie/tcad-scraper',
    },
    license: {
      name: 'MIT',
      url: 'https://opensource.org/licenses/MIT',
    },
  },
  servers: [
    {
      url: `http://${config.server.host}:${config.server.port}`,
      description: 'Local development server',
    },
    {
      url: 'https://api.production.example.com',
      description: 'Production server',
    },
  ],
  components: {
    securitySchemes: {
      ApiKeyAuth: {
        type: 'apiKey',
        in: 'header',
        name: 'X-API-Key',
        description: 'API key for authentication',
      },
      BearerAuth: {
        type: 'http',
        scheme: 'bearer',
        bearerFormat: 'JWT',
        description: 'JWT token for authentication',
      },
    },
    schemas: {
      Property: {
        type: 'object',
        properties: {
          id: {
            type: 'string',
            format: 'uuid',
            description: 'Internal database ID',
          },
          propertyId: {
            type: 'string',
            description: 'TCAD property ID',
            example: '12345678',
          },
          name: {
            type: 'string',
            description: 'Property owner name',
            example: 'SMITH JOHN & MARY',
          },
          propType: {
            type: 'string',
            description: 'Property type',
            example: 'Residential',
          },
          city: {
            type: 'string',
            nullable: true,
            description: 'City name',
            example: 'Austin',
          },
          propertyAddress: {
            type: 'string',
            description: 'Property address',
            example: '123 MAIN ST',
          },
          assessedValue: {
            type: 'number',
            nullable: true,
            description: 'Assessed value in USD',
            example: 250000,
          },
          appraisedValue: {
            type: 'number',
            description: 'Appraised value in USD',
            example: 300000,
          },
          geoId: {
            type: 'string',
            nullable: true,
            description: 'Geographic ID',
          },
          description: {
            type: 'string',
            nullable: true,
            description: 'Legal description',
          },
          searchTerm: {
            type: 'string',
            nullable: true,
            description: 'Search term that found this property',
          },
          scrapedAt: {
            type: 'string',
            format: 'date-time',
            description: 'When property was last scraped',
          },
          createdAt: {
            type: 'string',
            format: 'date-time',
            description: 'When property was first added',
          },
          updatedAt: {
            type: 'string',
            format: 'date-time',
            description: 'When property was last updated',
          },
        },
      },
      ScrapeJob: {
        type: 'object',
        properties: {
          id: {
            type: 'string',
            format: 'uuid',
            description: 'Job ID',
          },
          searchTerm: {
            type: 'string',
            description: 'Search term',
            example: 'Smith',
          },
          status: {
            type: 'string',
            enum: ['pending', 'processing', 'completed', 'failed'],
            description: 'Job status',
          },
          resultCount: {
            type: 'number',
            nullable: true,
            description: 'Number of properties found',
            example: 42,
          },
          error: {
            type: 'string',
            nullable: true,
            description: 'Error message if failed',
          },
          startedAt: {
            type: 'string',
            format: 'date-time',
            description: 'When job started',
          },
          completedAt: {
            type: 'string',
            format: 'date-time',
            nullable: true,
            description: 'When job completed',
          },
        },
      },
      Error: {
        type: 'object',
        properties: {
          error: {
            type: 'string',
            description: 'Error message',
            example: 'Resource not found',
          },
          message: {
            type: 'string',
            description: 'Detailed error message (development only)',
          },
        },
      },
    },
  },
  tags: [
    {
      name: 'Health',
      description: 'Health check and monitoring endpoints',
    },
    {
      name: 'Scraping',
      description: 'Web scraping operations',
    },
    {
      name: 'Properties',
      description: 'Property data queries',
    },
    {
      name: 'Search',
      description: 'AI-powered natural language search',
    },
    {
      name: 'Statistics',
      description: 'Aggregate statistics and analytics',
    },
    {
      name: 'Monitoring',
      description: 'Scheduled monitoring configuration',
    },
  ],
};

const options: swaggerJSDoc.Options = {
  definition: swaggerDefinition,
  apis: [
    './src/routes/*.ts',
    './src/controllers/*.ts',
    './src/index.ts',
  ],
};

export const swaggerSpec = swaggerJSDoc(options);
</file>

<file path="controllers/__tests__/property.controller.test.ts">
import { Request, Response } from 'express';
import { PropertyController } from '../property.controller';

// Mock dependencies with proper structure
jest.mock('../../queues/scraper.queue', () => ({
  scraperQueue: {
    add: jest.fn(),
    getJob: jest.fn(),
    clean: jest.fn(),
  },
  canScheduleJob: jest.fn(),
}));

jest.mock('../../lib/prisma', () => ({
  prisma: {
    property: {
      findMany: jest.fn(),
      count: jest.fn(),
      groupBy: jest.fn(),
    },
    scrapeJob: {
      findMany: jest.fn(),
      count: jest.fn(),
      create: jest.fn(),
    },
    monitoredSearch: {
      upsert: jest.fn(),
      findMany: jest.fn(),
    },
  },
  prismaReadOnly: {
    property: {
      findMany: jest.fn(),
      count: jest.fn(),
      groupBy: jest.fn(),
    },
    scrapeJob: {
      findMany: jest.fn(),
      count: jest.fn(),
    },
    monitoredSearch: {
      findMany: jest.fn(),
    },
  },
}));

jest.mock('../../lib/claude.service', () => ({
  claudeSearchService: {
    parseNaturalLanguageQuery: jest.fn(),
  },
}));

jest.mock('../../lib/redis-cache.service', () => ({
  cacheService: {
    getOrSet: jest.fn(),
    get: jest.fn(),
    set: jest.fn(),
    invalidatePattern: jest.fn(),
  },
}));

describe('PropertyController', () => {
  let controller: PropertyController;
  let mockReq: Partial<Request>;
  let mockRes: Partial<Response>;
  let jsonMock: jest.Mock;
  let statusMock: jest.Mock;

  // Import mocked modules
  let scraperQueue: any;
  let canScheduleJob: any;
  let prisma: any;
  let prismaReadOnly: any;
  let claudeSearchService: any;
  let cacheService: any;

  beforeEach(() => {
    // Clear all mocks
    jest.clearAllMocks();

    // Set up response mocks
    jsonMock = jest.fn();
    statusMock = jest.fn().mockReturnValue({ json: jsonMock });

    mockReq = {
      body: {},
      params: {},
      query: {},
      headers: {},
    };

    mockRes = {
      status: statusMock,
      json: jsonMock,
    };

    // Import mocked modules
    const scraperQueueModule = require('../../queues/scraper.queue');
    scraperQueue = scraperQueueModule.scraperQueue;
    canScheduleJob = scraperQueueModule.canScheduleJob;

    const prismaModule = require('../../lib/prisma');
    prisma = prismaModule.prisma;
    prismaReadOnly = prismaModule.prismaReadOnly;

    const claudeModule = require('../../lib/claude.service');
    claudeSearchService = claudeModule.claudeSearchService;

    const cacheModule = require('../../lib/redis-cache.service');
    cacheService = cacheModule.cacheService;

    // Create controller instance
    controller = new PropertyController();
  });

  describe('scrapeProperties', () => {
    it('should queue a scrape job successfully', async () => {
      const searchTerm = 'Smith';
      mockReq.body = { searchTerm };

      // Mock canScheduleJob to allow
      canScheduleJob.mockResolvedValue(true);

      // Mock queue add
      const mockJobId = 'job-123';
      scraperQueue.add = jest.fn().mockResolvedValue({
        id: mockJobId,
      });

      await controller.scrapeProperties(
        mockReq as Request,
        mockRes as Response
      );

      expect(canScheduleJob).toHaveBeenCalledWith(searchTerm);
      expect(scraperQueue.add).toHaveBeenCalledWith(
        'scrape-properties',
        { searchTerm },
        { delay: 0, attempts: 3 }
      );
      expect(statusMock).toHaveBeenCalledWith(202);
      expect(jsonMock).toHaveBeenCalledWith({
        jobId: mockJobId,
        message: 'Scrape job queued successfully',
      });
    });

    it('should return 429 when rate limited', async () => {
      const searchTerm = 'Smith';
      mockReq.body = { searchTerm };

      // Mock canScheduleJob to deny
      canScheduleJob.mockResolvedValue(false);

      await controller.scrapeProperties(
        mockReq as Request,
        mockRes as Response
      );

      expect(canScheduleJob).toHaveBeenCalledWith(searchTerm);
      expect(scraperQueue.add).not.toHaveBeenCalled();
      expect(statusMock).toHaveBeenCalledWith(429);
      expect(jsonMock).toHaveBeenCalledWith({
        error: 'Rate limit exceeded. Please wait before scraping the same search term again.',
      });
    });
  });

  describe('getJobStatus', () => {
    it('should return job status for completed job', async () => {
      const jobId = 'job-123';
      mockReq.params = { jobId };

      const mockJob = {
        id: jobId,
        timestamp: Date.now(),
        finishedOn: Date.now() + 5000,
        getState: jest.fn().mockResolvedValue('completed'),
        progress: jest.fn().mockReturnValue(100),
        returnvalue: { count: 42 },
        failedReason: null,
      };

      scraperQueue.getJob = jest.fn().mockResolvedValue(mockJob);

      await controller.getJobStatus(
        mockReq as Request,
        mockRes as Response
      );

      expect(scraperQueue.getJob).toHaveBeenCalledWith(jobId);
      expect(jsonMock).toHaveBeenCalledWith({
        id: jobId,
        status: 'completed',
        progress: 100,
        resultCount: 42,
        error: null,
        createdAt: expect.any(Date),
        completedAt: expect.any(Date),
      });
    });

    it('should return job status for failed job', async () => {
      const jobId = 'job-456';
      mockReq.params = { jobId };

      const mockJob = {
        id: jobId,
        timestamp: Date.now(),
        finishedOn: null,
        getState: jest.fn().mockResolvedValue('failed'),
        progress: jest.fn().mockReturnValue(50),
        returnvalue: null,
        failedReason: 'Network timeout',
      };

      scraperQueue.getJob = jest.fn().mockResolvedValue(mockJob);

      await controller.getJobStatus(
        mockReq as Request,
        mockRes as Response
      );

      expect(jsonMock).toHaveBeenCalledWith({
        id: jobId,
        status: 'failed',
        progress: 50,
        resultCount: undefined,
        error: 'Network timeout',
        createdAt: expect.any(Date),
        completedAt: null,
      });
    });

    it('should return 404 when job not found', async () => {
      const jobId = 'nonexistent';
      mockReq.params = { jobId };

      scraperQueue.getJob = jest.fn().mockResolvedValue(null);

      await controller.getJobStatus(
        mockReq as Request,
        mockRes as Response
      );

      expect(statusMock).toHaveBeenCalledWith(404);
      expect(jsonMock).toHaveBeenCalledWith({ error: 'Job not found' });
    });
  });

  describe('getProperties', () => {
    it('should return cached properties when available', async () => {
      const filters = { limit: 10, offset: 0 };
      mockReq.query = filters;

      const mockResult = {
        data: [
          {
            id: '1',
            propertyId: 'PROP-1',
            name: 'John Smith',
            propertyAddress: '123 Main St',
            appraisedValue: 500000,
          },
        ],
        pagination: {
          total: 1,
          limit: 10,
          offset: 0,
          hasMore: false,
        },
      };

      // Mock cacheService to return cached data
      cacheService.getOrSet = jest.fn().mockResolvedValue(mockResult);

      await controller.getProperties(
        mockReq as Request,
        mockRes as Response
      );

      expect(cacheService.getOrSet).toHaveBeenCalled();
      expect(jsonMock).toHaveBeenCalledWith(mockResult);
    });

    it('should fetch from database on cache miss', async () => {
      const filters = { limit: 10, offset: 0 };
      mockReq.query = filters;

      const mockProperties = [
        {
          id: '1',
          propertyId: 'PROP-1',
          name: 'John Smith',
          propType: 'R',
          city: 'AUSTIN',
          propertyAddress: '123 Main St',
          assessedValue: 480000,
          appraisedValue: 500000,
          geoId: 'GEO123',
          description: 'Residential Property',
          searchTerm: 'Smith',
          scrapedAt: new Date('2025-01-01T00:00:00.000Z'),
          createdAt: new Date('2025-01-01T00:00:00.000Z'),
          updatedAt: new Date('2025-01-01T00:00:00.000Z'),
        },
      ];

      // Mock cacheService to execute the callback (cache miss)
      cacheService.getOrSet.mockImplementation(async (key: string, callback: () => Promise<any>) => {
        return await callback();
      });

      // Mock Prisma queries
      prismaReadOnly.property.findMany.mockResolvedValue(mockProperties);
      prismaReadOnly.property.count.mockResolvedValue(1);

      await controller.getProperties(
        mockReq as Request,
        mockRes as Response
      );

      expect(prismaReadOnly.property.findMany).toHaveBeenCalledWith({
        where: {},
        skip: 0,
        take: 10,
        orderBy: { scrapedAt: 'desc' },
      });
      expect(prismaReadOnly.property.count).toHaveBeenCalledWith({
        where: {},
      });
    });

    it('should apply filters correctly', async () => {
      const filters = {
        searchTerm: 'Smith',
        city: 'AUSTIN',
        propType: 'R',
        minValue: 100000,
        maxValue: 500000,
        limit: 10,
        offset: 0,
      };
      mockReq.query = filters;

      cacheService.getOrSet.mockImplementation(async (key: string, callback: () => Promise<any>) => {
        return await callback();
      });

      prismaReadOnly.property.findMany.mockResolvedValue([]);
      prismaReadOnly.property.count.mockResolvedValue(0);

      await controller.getProperties(
        mockReq as Request,
        mockRes as Response
      );

      // Verify filters were applied
      const whereClause = prismaReadOnly.property.findMany.mock.calls[0][0].where;
      expect(whereClause.city).toBe('AUSTIN');
      expect(whereClause.propType).toBe('R');
      expect(whereClause.appraisedValue).toEqual({
        gte: 100000,
        lte: 500000,
      });
      expect(whereClause.OR).toBeDefined();
    });
  });

  describe('testClaudeConnection', () => {
    it('should test Claude API connection successfully', async () => {
      const mockResult = {
        whereClause: { city: 'AUSTIN' },
        orderBy: { scrapedAt: 'desc' },
        explanation: 'Looking for properties in Austin',
      };

      claudeSearchService.parseNaturalLanguageQuery = jest.fn().mockResolvedValue(mockResult);

      await controller.testClaudeConnection(
        mockReq as Request,
        mockRes as Response
      );

      expect(claudeSearchService.parseNaturalLanguageQuery).toHaveBeenCalledWith('properties in Austin');
      expect(jsonMock).toHaveBeenCalledWith({
        success: true,
        message: 'Claude API connection successful',
        testQuery: 'properties in Austin',
        result: mockResult,
      });
    });
  });

  describe('naturalLanguageSearch', () => {
    it('should perform natural language search successfully', async () => {
      const query = 'properties in Austin worth more than $500k';
      mockReq.body = { query, limit: 100, offset: 0 };

      const mockClaudeResponse = {
        whereClause: {
          city: 'AUSTIN',
          appraisedValue: { gte: 500000 },
        },
        orderBy: { appraisedValue: 'desc' },
        explanation: 'Properties in Austin with value > $500k',
      };

      const mockProperties = [
        {
          id: '1',
          propertyId: 'PROP-1',
          name: 'Luxury Estate',
          propType: 'R',
          city: 'AUSTIN',
          propertyAddress: '100 Rich St',
          assessedValue: 720000,
          appraisedValue: 750000,
          geoId: 'GEO456',
          description: 'Luxury Residential Property',
          searchTerm: 'properties in Austin worth more than $500k',
          scrapedAt: new Date('2025-01-01T00:00:00.000Z'),
          createdAt: new Date('2025-01-01T00:00:00.000Z'),
          updatedAt: new Date('2025-01-01T00:00:00.000Z'),
        },
      ];

      claudeSearchService.parseNaturalLanguageQuery.mockResolvedValue(mockClaudeResponse);

      prismaReadOnly.property.findMany.mockResolvedValue(mockProperties);
      prismaReadOnly.property.count.mockResolvedValue(1);

      await controller.naturalLanguageSearch(
        mockReq as Request,
        mockRes as Response
      );

      expect(claudeSearchService.parseNaturalLanguageQuery).toHaveBeenCalledWith(query);
      expect(prismaReadOnly.property.findMany).toHaveBeenCalledWith({
        where: mockClaudeResponse.whereClause,
        orderBy: mockClaudeResponse.orderBy,
        skip: 0,
        take: 100,
      });

      // Expect transformed snake_case data
      expect(jsonMock).toHaveBeenCalledWith({
        data: [{
          id: '1',
          property_id: 'PROP-1',
          name: 'Luxury Estate',
          prop_type: 'R',
          city: 'AUSTIN',
          property_address: '100 Rich St',
          assessed_value: 720000,
          appraised_value: 750000,
          geo_id: 'GEO456',
          description: 'Luxury Residential Property',
          search_term: 'properties in Austin worth more than $500k',
          scraped_at: '2025-01-01T00:00:00.000Z',
          created_at: '2025-01-01T00:00:00.000Z',
          updated_at: '2025-01-01T00:00:00.000Z',
        }],
        pagination: {
          total: 1,
          limit: 100,
          offset: 0,
          hasMore: false,
        },
        query: {
          original: query,
          explanation: mockClaudeResponse.explanation,
        },
      });
    });

    it('should return 400 when query is missing', async () => {
      mockReq.body = {};

      await controller.naturalLanguageSearch(
        mockReq as Request,
        mockRes as Response
      );

      expect(statusMock).toHaveBeenCalledWith(400);
      expect(jsonMock).toHaveBeenCalledWith({
        error: 'Query is required and must be a string',
      });
    });

    it('should return 400 when query is not a string', async () => {
      mockReq.body = { query: 123 };

      await controller.naturalLanguageSearch(
        mockReq as Request,
        mockRes as Response
      );

      expect(statusMock).toHaveBeenCalledWith(400);
      expect(jsonMock).toHaveBeenCalledWith({
        error: 'Query is required and must be a string',
      });
    });
  });

  describe('getScrapeHistory', () => {
    it('should return scrape job history', async () => {
      mockReq.query = { limit: 20, offset: 0 };

      const mockJobs = [
        {
          id: 'job-1',
          searchTerm: 'Smith',
          status: 'completed',
          resultCount: 42,
          startedAt: new Date(),
        },
      ];

      prismaReadOnly.scrapeJob.findMany.mockResolvedValue(mockJobs);
      prismaReadOnly.scrapeJob.count.mockResolvedValue(1);

      await controller.getScrapeHistory(
        mockReq as Request,
        mockRes as Response
      );

      expect(prismaReadOnly.scrapeJob.findMany).toHaveBeenCalledWith({
        orderBy: { startedAt: 'desc' },
        skip: 0,
        take: 20,
      });
      expect(jsonMock).toHaveBeenCalledWith({
        data: mockJobs,
        pagination: {
          total: 1,
          limit: 20,
          offset: 0,
          hasMore: false,
        },
      });
    });
  });

  describe('getStats', () => {
    it('should return statistics with cache', async () => {
      const mockStats = {
        totalProperties: 1000,
        totalJobs: 50,
        recentJobs: 10,
        cityDistribution: [
          { city: 'AUSTIN', _count: 500 },
          { city: 'LAKEWAY', _count: 300 },
        ],
        propertyTypeDistribution: [
          { propType: 'R', _count: 800, _avg: { appraisedValue: 400000 } },
          { propType: 'P', _count: 200, _avg: { appraisedValue: 150000 } },
        ],
      };

      cacheService.getOrSet = jest.fn().mockResolvedValue(mockStats);

      await controller.getStats(
        mockReq as Request,
        mockRes as Response
      );

      expect(cacheService.getOrSet).toHaveBeenCalled();
      expect(jsonMock).toHaveBeenCalledWith(mockStats);
    });

    it('should fetch statistics from database on cache miss', async () => {
      cacheService.getOrSet.mockImplementation(async (key: string, callback: () => Promise<any>) => {
        return await callback();
      });

      prismaReadOnly.property.count.mockResolvedValue(1000);
      prismaReadOnly.property.groupBy
        .mockResolvedValueOnce([{ city: 'AUSTIN', _count: 500 }]) // cityStats
        .mockResolvedValueOnce([{ propType: 'R', _count: 800, _avg: { appraisedValue: 400000 } }]); // typeStats

      prismaReadOnly.scrapeJob.count
        .mockResolvedValueOnce(50) // totalJobs
        .mockResolvedValueOnce(10); // recentJobs

      await controller.getStats(
        mockReq as Request,
        mockRes as Response
      );

      expect(prismaReadOnly.property.count).toHaveBeenCalled();
      expect(prismaReadOnly.scrapeJob.count).toHaveBeenCalledTimes(2);
      expect(prismaReadOnly.property.groupBy).toHaveBeenCalledTimes(2);
    });
  });

  describe('addMonitoredSearch', () => {
    it('should add a new monitored search', async () => {
      const searchTerm = 'Smith';
      const frequency = 'daily';
      mockReq.body = { searchTerm, frequency };

      const mockMonitoredSearch = {
        id: 'monitor-1',
        searchTerm,
        frequency,
        active: true,
        createdAt: new Date(),
      };

      prisma.monitoredSearch.upsert.mockResolvedValue(mockMonitoredSearch);

      await controller.addMonitoredSearch(
        mockReq as Request,
        mockRes as Response
      );

      expect(prisma.monitoredSearch.upsert).toHaveBeenCalledWith({
        where: { searchTerm },
        update: { active: true, frequency },
        create: { searchTerm, frequency },
      });
      expect(jsonMock).toHaveBeenCalledWith({
        message: 'Search term added to monitoring',
        data: mockMonitoredSearch,
      });
    });

    it('should return 400 when search term is missing', async () => {
      mockReq.body = {};

      await controller.addMonitoredSearch(
        mockReq as Request,
        mockRes as Response
      );

      expect(statusMock).toHaveBeenCalledWith(400);
      expect(jsonMock).toHaveBeenCalledWith({
        error: 'Search term is required',
      });
    });
  });

  describe('getMonitoredSearches', () => {
    it('should return active monitored searches', async () => {
      const mockMonitoredSearches = [
        {
          id: 'monitor-1',
          searchTerm: 'Smith',
          frequency: 'daily',
          active: true,
          createdAt: new Date(),
        },
        {
          id: 'monitor-2',
          searchTerm: 'Johnson',
          frequency: 'weekly',
          active: true,
          createdAt: new Date(),
        },
      ];

      prismaReadOnly.monitoredSearch.findMany.mockResolvedValue(mockMonitoredSearches);

      await controller.getMonitoredSearches(
        mockReq as Request,
        mockRes as Response
      );

      expect(prismaReadOnly.monitoredSearch.findMany).toHaveBeenCalledWith({
        where: { active: true },
        orderBy: { createdAt: 'desc' },
      });
      expect(jsonMock).toHaveBeenCalledWith({
        data: mockMonitoredSearches,
      });
    });
  });
});
</file>

<file path="controllers/property.controller.ts">
import { Request, Response } from 'express';
import { scraperQueue, canScheduleJob } from '../queues/scraper.queue';
import { prisma, prismaReadOnly } from '../lib/prisma';
import { ScrapeResponse } from '../types';
import { claudeSearchService } from '../lib/claude.service';
import { cacheService } from '../lib/redis-cache.service';
import type {
  ScrapeRequestBody,
  PropertyFilters,
  NaturalLanguageSearchBody,
  HistoryQueryParams,
  MonitorRequestBody
} from '../types/property.types';

export class PropertyController {
  /**
   * POST /api/properties/scrape - Trigger a new scrape job
   */
  async scrapeProperties(req: Request<{}, {}, ScrapeRequestBody>, res: Response) {
    const validatedData = req.body;

    // Check rate limiting
    const canSchedule = await canScheduleJob(validatedData.searchTerm);
    if (!canSchedule) {
      return res.status(429).json({
        error: 'Rate limit exceeded. Please wait before scraping the same search term again.',
      });
    }

    // Add job to queue
    const job = await scraperQueue.add('scrape-properties', validatedData, {
      delay: 0,
      attempts: 3,
    });

    const response: ScrapeResponse = {
      jobId: job.id.toString(),
      message: 'Scrape job queued successfully',
    };

    res.status(202).json(response);
  }

  /**
   * GET /api/properties/jobs/:jobId - Get job status
   */
  async getJobStatus(req: Request<{ jobId: string }>, res: Response) {
    const { jobId } = req.params;

    const job = await scraperQueue.getJob(jobId);
    if (!job) {
      return res.status(404).json({ error: 'Job not found' });
    }

    const state = await job.getState();
    const progress = job.progress();

    let result = null;
    if (state === 'completed') {
      result = job.returnvalue;
    }

    let error = null;
    if (state === 'failed') {
      error = job.failedReason;
    }

    res.json({
      id: jobId,
      status: state,
      progress: typeof progress === 'number' ? progress : 0,
      resultCount: result?.count,
      error,
      createdAt: new Date(job.timestamp),
      completedAt: job.finishedOn ? new Date(job.finishedOn) : null,
    });
  }

  /**
   * GET /api/properties - Get properties from database with filters
   * Cached for 5 minutes per unique filter combination
   */
  async getProperties(req: Request<{}, {}, {}, PropertyFilters>, res: Response) {
    const filters = req.query as PropertyFilters;

    // Generate cache key based on filters
    const cacheKey = `properties:list:${JSON.stringify(filters)}`;

    // Try to get from cache first (cache-aside pattern)
    const result = await cacheService.getOrSet(
      cacheKey,
      async () => {
        const where = this.buildWhereClause(filters);

        const [properties, total] = await Promise.all([
          prismaReadOnly.property.findMany({
            where,
            skip: filters.offset,
            take: filters.limit,
            orderBy: { scrapedAt: 'desc' },
          }),
          prismaReadOnly.property.count({ where }),
        ]);

        // Transform properties from camelCase (Prisma) to snake_case (frontend expectation)
        const transformedProperties = properties.map(prop => ({
          id: prop.id,
          property_id: prop.propertyId,
          name: prop.name,
          prop_type: prop.propType,
          city: prop.city,
          property_address: prop.propertyAddress,
          assessed_value: prop.assessedValue,
          appraised_value: prop.appraisedValue,
          geo_id: prop.geoId,
          description: prop.description,
          search_term: prop.searchTerm,
          scraped_at: prop.scrapedAt.toISOString(),
          created_at: prop.createdAt.toISOString(),
          updated_at: prop.updatedAt.toISOString(),
        }));

        return {
          data: transformedProperties,
          pagination: {
            total,
            limit: filters.limit,
            offset: filters.offset,
            hasMore: filters.offset + filters.limit < total,
          },
        };
      },
      300 // 5 minutes TTL
    );

    res.json(result);
  }

  /**
   * GET /api/properties/search/test - Test Claude API connection
   */
  async testClaudeConnection(req: Request, res: Response) {
    const testQuery = 'properties in Austin';
    const result = await claudeSearchService.parseNaturalLanguageQuery(testQuery);

    res.json({
      success: true,
      message: 'Claude API connection successful',
      testQuery,
      result,
    });
  }

  /**
   * POST /api/properties/search - Natural language search powered by Claude
   */
  async naturalLanguageSearch(req: Request<{}, {}, NaturalLanguageSearchBody>, res: Response) {
    const { query, limit = 100, offset = 0 } = req.body;

    if (!query || typeof query !== 'string') {
      return res.status(400).json({ error: 'Query is required and must be a string' });
    }

    // Use Claude to parse the natural language query
    const { whereClause, orderBy, explanation } = await claudeSearchService.parseNaturalLanguageQuery(query);

    // Query the database with the generated filters
    const [properties, total] = await Promise.all([
      prismaReadOnly.property.findMany({
        where: whereClause,
        orderBy: orderBy || { scrapedAt: 'desc' },
        skip: offset,
        take: Math.min(limit, 1000),
      }),
      prismaReadOnly.property.count({ where: whereClause }),
    ]);

    // Transform properties from camelCase (Prisma) to snake_case (frontend expectation)
    const transformedProperties = properties.map(prop => ({
      id: prop.id,
      property_id: prop.propertyId,
      name: prop.name,
      prop_type: prop.propType,
      city: prop.city,
      property_address: prop.propertyAddress,
      assessed_value: prop.assessedValue,
      appraised_value: prop.appraisedValue,
      geo_id: prop.geoId,
      description: prop.description,
      search_term: prop.searchTerm,
      scraped_at: prop.scrapedAt.toISOString(),
      created_at: prop.createdAt.toISOString(),
      updated_at: prop.updatedAt.toISOString(),
    }));

    res.json({
      data: transformedProperties,
      pagination: {
        total,
        limit: Math.min(limit, 1000),
        offset,
        hasMore: offset + properties.length < total,
      },
      query: {
        original: query,
        explanation,
      },
    });
  }

  /**
   * GET /api/properties/history - Get scrape job history
   */
  async getScrapeHistory(req: Request<{}, {}, {}, HistoryQueryParams>, res: Response) {
    const { limit = 20, offset = 0 } = req.query;

    const jobs = await prismaReadOnly.scrapeJob.findMany({
      orderBy: { startedAt: 'desc' },
      skip: offset,
      take: limit,
    });

    const total = await prismaReadOnly.scrapeJob.count();

    res.json({
      data: jobs,
      pagination: {
        total,
        limit,
        offset,
        hasMore: offset + limit < total,
      },
    });
  }

  /**
   * GET /api/properties/stats - Get statistics
   * Cached for 10 minutes (expensive aggregation queries)
   */
  async getStats(req: Request, res: Response) {
    const cacheKey = 'properties:stats:all';

    // Cache stats for 10 minutes (600 seconds)
    const stats = await cacheService.getOrSet(
      cacheKey,
      async () => {
        const [totalProperties, totalJobs, recentJobs, cityStats, typeStats] = await Promise.all([
          prismaReadOnly.property.count(),
          prismaReadOnly.scrapeJob.count(),
          prismaReadOnly.scrapeJob.count({
            where: {
              startedAt: {
                gte: new Date(Date.now() - 24 * 60 * 60 * 1000), // Last 24 hours
              },
            },
          }),
          prismaReadOnly.property.groupBy({
            by: ['city'],
            _count: true,
            where: {
              city: { not: null },
            },
            orderBy: {
              _count: {
                city: 'desc',
              },
            },
            take: 10,
          }),
          prismaReadOnly.property.groupBy({
            by: ['propType'],
            _count: true,
            _avg: {
              appraisedValue: true,
            },
            orderBy: {
              _count: {
                propType: 'desc',
              },
            },
          }),
        ]);

        return {
          totalProperties,
          totalJobs,
          recentJobs,
          cityDistribution: cityStats,
          propertyTypeDistribution: typeStats,
        };
      },
      600 // 10 minutes TTL
    );

    res.json(stats);
  }

  /**
   * POST /api/properties/monitor - Add a search term to monitor
   */
  async addMonitoredSearch(req: Request<{}, {}, MonitorRequestBody>, res: Response) {
    const { searchTerm, frequency = 'daily' } = req.body;

    if (!searchTerm) {
      return res.status(400).json({ error: 'Search term is required' });
    }

    const monitoredSearch = await prisma.monitoredSearch.upsert({
      where: { searchTerm },
      update: { active: true, frequency },
      create: { searchTerm, frequency },
    });

    res.json({
      message: 'Search term added to monitoring',
      data: monitoredSearch,
    });
  }

  /**
   * GET /api/properties/monitor - Get monitored search terms
   */
  async getMonitoredSearches(req: Request, res: Response) {
    const monitoredSearches = await prismaReadOnly.monitoredSearch.findMany({
      where: { active: true },
      orderBy: { createdAt: 'desc' },
    });

    res.json({ data: monitoredSearches });
  }

  /**
   * Helper method to build Prisma where clause from filters
   */
  private buildWhereClause(filters: PropertyFilters) {
    const where: any = {};

    if (filters.searchTerm) {
      where.OR = [
        { searchTerm: { contains: filters.searchTerm, mode: 'insensitive' } },
        { name: { contains: filters.searchTerm, mode: 'insensitive' } },
        { propertyAddress: { contains: filters.searchTerm, mode: 'insensitive' } },
      ];
    }

    if (filters.city) {
      where.city = filters.city;
    }

    if (filters.propType) {
      where.propType = filters.propType;
    }

    if (filters.minValue || filters.maxValue) {
      where.appraisedValue = {};
      if (filters.minValue) where.appraisedValue.gte = filters.minValue;
      if (filters.maxValue) where.appraisedValue.lte = filters.maxValue;
    }

    return where;
  }
}

export const propertyController = new PropertyController();
</file>

<file path="controllers/README_ENHANCED.md">
# controllers

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "SoftwareSourceCode",
  "name": "controllers",
  "description": "Directory containing 1 code files with 1 classes and 0 functions",
  "programmingLanguage": [
    {
      "@type": "ComputerLanguage",
      "name": "Typescript"
    }
  ],
  "featureList": [
    "1 class definitions"
  ]
}
</script>

## Overview

This directory contains 1 code file(s) with extracted schemas.

## Subdirectories

- `__tests__/`

## Files and Schemas

### `property.controller.ts` (typescript)

**Classes:**
- `PropertyController` - Line 14

---
*Generated by Enhanced Schema Generator with schema.org markup*
</file>

<file path="examples/property-page.example.html">
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>123 Main St, Austin TX - TCAD Property Details</title>
    <meta name="description" content="Single Family property at 123 Main St, Austin TX. Appraised value: $450,000. View complete TCAD property details, tax assessment, and ownership information.">

    <!-- Open Graph Tags for Social Sharing -->
    <meta property="og:title" content="123 Main St, Austin TX - TCAD Property">
    <meta property="og:description" content="Single Family property valued at $450,000">
    <meta property="og:type" content="place">
    <meta property="og:url" content="https://example.com/properties/TCAD-123456">
    <meta property="og:locale" content="en_US">

    <!-- Property-specific meta tags -->
    <meta property="place:location:latitude" content="30.2672">
    <meta property="place:location:longitude" content="-97.7431">

    <!-- JSON-LD Structured Data for Property -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "RealEstateListing",
        "@id": "https://example.com/properties/TCAD-123456",
        "identifier": "TCAD-123456",
        "name": "123 Main St, Austin TX - TCAD Property",
        "description": "Single Family property located at 123 Main St, Austin, TX 78701",

        "address": {
            "@type": "PostalAddress",
            "streetAddress": "123 Main St",
            "addressLocality": "Austin",
            "addressRegion": "TX",
            "addressCountry": "US",
            "postalCode": "78701"
        },

        "geo": {
            "@type": "GeoCoordinates",
            "latitude": 30.2672,
            "longitude": -97.7431
        },

        "additionalType": "Single Family",

        "seller": {
            "@type": "Person",
            "name": "John Doe"
        },

        "offers": {
            "@type": "Offer",
            "price": 450000,
            "priceCurrency": "USD",
            "priceSpecification": [
                {
                    "@type": "PriceSpecification",
                    "price": 450000,
                    "priceCurrency": "USD",
                    "name": "Appraised Value",
                    "description": "Market value as determined by TCAD"
                },
                {
                    "@type": "PriceSpecification",
                    "price": 425000,
                    "priceCurrency": "USD",
                    "name": "Assessed Value",
                    "description": "Tax assessed value for property tax calculations"
                }
            ],
            "seller": {
                "@type": "Organization",
                "name": "Travis County Appraisal District",
                "url": "https://www.traviscad.org"
            },
            "validFrom": "2024-01-15T00:00:00Z"
        },

        "containedInPlace": {
            "@type": "Place",
            "name": "Downtown Austin"
        },

        "provider": {
            "@type": "Organization",
            "name": "Travis County Appraisal District",
            "url": "https://www.traviscad.org"
        },

        "datePosted": "2024-01-15T00:00:00Z",
        "dateModified": "2024-11-06T00:00:00Z",

        "potentialAction": [
            {
                "@type": "ViewAction",
                "target": "https://example.com/properties/TCAD-123456",
                "name": "View Property Details"
            }
        ]
    }
    </script>

    <!-- Breadcrumb JSON-LD -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BreadcrumbList",
        "itemListElement": [
            {
                "@type": "ListItem",
                "position": 1,
                "name": "Home",
                "item": "https://example.com"
            },
            {
                "@type": "ListItem",
                "position": 2,
                "name": "Properties",
                "item": "https://example.com/properties"
            },
            {
                "@type": "ListItem",
                "position": 3,
                "name": "Austin",
                "item": "https://example.com/properties/austin"
            },
            {
                "@type": "ListItem",
                "position": 4,
                "name": "123 Main St"
            }
        ]
    }
    </script>

    <!-- Additional Organization/WebSite JSON-LD -->
    <script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "WebSite",
        "@id": "https://example.com",
        "name": "TCAD Property Search",
        "url": "https://example.com",
        "potentialAction": {
            "@type": "SearchAction",
            "target": {
                "@type": "EntryPoint",
                "urlTemplate": "https://example.com/search?q={search_term_string}"
            },
            "query-input": "required name=search_term_string"
        }
    }
    </script>
</head>
<body>
    <!-- Semantic HTML5 Structure -->
    <header>
        <nav aria-label="Breadcrumb">
            <ol itemscope itemtype="https://schema.org/BreadcrumbList">
                <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                    <a itemprop="item" href="/">
                        <span itemprop="name">Home</span>
                    </a>
                    <meta itemprop="position" content="1" />
                </li>
                <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                    <a itemprop="item" href="/properties">
                        <span itemprop="name">Properties</span>
                    </a>
                    <meta itemprop="position" content="2" />
                </li>
                <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                    <a itemprop="item" href="/properties/austin">
                        <span itemprop="name">Austin</span>
                    </a>
                    <meta itemprop="position" content="3" />
                </li>
                <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
                    <span itemprop="name">123 Main St</span>
                    <meta itemprop="position" content="4" />
                </li>
            </ol>
        </nav>
    </header>

    <main>
        <!-- Property Details with Microdata -->
        <article itemscope itemtype="https://schema.org/RealEstateListing">
            <meta itemprop="identifier" content="TCAD-123456" />

            <header>
                <h1 itemprop="name">123 Main St, Austin TX</h1>
                <p class="property-type">
                    <span itemprop="additionalType">Single Family</span> Property
                </p>
            </header>

            <!-- Address Section -->
            <section class="address-section">
                <h2>Property Address</h2>
                <address itemprop="address" itemscope itemtype="https://schema.org/PostalAddress">
                    <span itemprop="streetAddress">123 Main St</span><br>
                    <span itemprop="addressLocality">Austin</span>,
                    <span itemprop="addressRegion">TX</span>
                    <span itemprop="postalCode">78701</span>
                    <meta itemprop="addressCountry" content="US" />
                </address>

                <!-- Geographic Coordinates -->
                <div itemprop="geo" itemscope itemtype="https://schema.org/GeoCoordinates">
                    <meta itemprop="latitude" content="30.2672" />
                    <meta itemprop="longitude" content="-97.7431" />
                </div>
            </section>

            <!-- Valuation Section -->
            <section class="valuation-section" itemprop="offers" itemscope itemtype="https://schema.org/Offer">
                <h2>Property Valuation</h2>

                <dl>
                    <dt>Appraised Value:</dt>
                    <dd>
                        <span itemprop="price" content="450000">$450,000</span>
                        <meta itemprop="priceCurrency" content="USD" />
                    </dd>

                    <dt>Assessed Value:</dt>
                    <dd>$425,000</dd>

                    <dt>Land Value:</dt>
                    <dd>$150,000</dd>

                    <dt>Improvement Value:</dt>
                    <dd>$300,000</dd>
                </dl>

                <p class="valuation-date">
                    <time itemprop="validFrom" datetime="2024-01-15">
                        Last Updated: January 15, 2024
                    </time>
                </p>
            </section>

            <!-- Owner Information -->
            <section class="owner-section">
                <h2>Owner Information</h2>
                <div itemprop="seller" itemscope itemtype="https://schema.org/Person">
                    <p>Owner: <span itemprop="name">John Doe</span></p>
                </div>
            </section>

            <!-- Property Description -->
            <section class="description-section">
                <h2>Legal Description</h2>
                <p itemprop="description">
                    LOT 1 BLK A, DOWNTOWN SUBDIVISION, PLAT NO: 2024-001
                </p>
            </section>

            <!-- Additional Details -->
            <section class="details-section">
                <h2>Additional Details</h2>
                <dl>
                    <dt>Property ID:</dt>
                    <dd>TCAD-123456</dd>

                    <dt>Geographic ID:</dt>
                    <dd>0101010101</dd>

                    <dt>Neighborhood:</dt>
                    <dd itemprop="containedInPlace" itemscope itemtype="https://schema.org/Place">
                        <span itemprop="name">Downtown Austin</span>
                    </dd>

                    <dt>School District:</dt>
                    <dd>Austin ISD</dd>

                    <dt>Tax District:</dt>
                    <dd>Travis County</dd>
                </dl>
            </section>

            <!-- Tax Information -->
            <section class="tax-section">
                <h2>Tax Information</h2>
                <table>
                    <thead>
                        <tr>
                            <th>Tax Entity</th>
                            <th>Rate</th>
                            <th>Amount</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Travis County</td>
                            <td>0.3697%</td>
                            <td>$1,571</td>
                        </tr>
                        <tr>
                            <td>Austin ISD</td>
                            <td>0.9496%</td>
                            <td>$4,036</td>
                        </tr>
                        <tr>
                            <td>City of Austin</td>
                            <td>0.4481%</td>
                            <td>$1,904</td>
                        </tr>
                    </tbody>
                    <tfoot>
                        <tr>
                            <th colspan="2">Total Annual Tax:</th>
                            <td><strong>$7,511</strong></td>
                        </tr>
                    </tfoot>
                </table>
            </section>

            <!-- Exemptions -->
            <section class="exemptions-section">
                <h2>Tax Exemptions</h2>
                <ul>
                    <li>Homestead Exemption: $40,000</li>
                    <li>Over 65 Exemption: $10,000</li>
                </ul>
            </section>

            <!-- Data Source -->
            <footer class="property-footer">
                <p>
                    Data provided by
                    <span itemprop="provider" itemscope itemtype="https://schema.org/Organization">
                        <a itemprop="url" href="https://www.traviscad.org">
                            <span itemprop="name">Travis County Appraisal District</span>
                        </a>
                    </span>
                </p>
                <p>
                    <time itemprop="dateModified" datetime="2024-11-06">
                        Last scraped: November 6, 2024
                    </time>
                </p>
            </footer>
        </article>

        <!-- Related Properties -->
        <aside>
            <h2>Similar Properties</h2>
            <ul class="property-list">
                <li itemscope itemtype="https://schema.org/RealEstateListing">
                    <a itemprop="url" href="/properties/TCAD-123457">
                        <span itemprop="name">125 Main St</span> -
                        <span itemprop="offers" itemscope itemtype="https://schema.org/Offer">
                            <span itemprop="price" content="475000">$475,000</span>
                            <meta itemprop="priceCurrency" content="USD" />
                        </span>
                    </a>
                </li>
                <li itemscope itemtype="https://schema.org/RealEstateListing">
                    <a itemprop="url" href="/properties/TCAD-123458">
                        <span itemprop="name">127 Main St</span> -
                        <span itemprop="offers" itemscope itemtype="https://schema.org/Offer">
                            <span itemprop="price" content="425000">$425,000</span>
                            <meta itemprop="priceCurrency" content="USD" />
                        </span>
                    </a>
                </li>
            </ul>
        </aside>
    </main>

    <footer>
        <p>&copy; 2024 TCAD Property Search. All rights reserved.</p>
    </footer>
</body>
</html>
</file>

<file path="lib/__tests__/claude.service.test.ts">
/**
 * Claude Search Service Tests
 */

import { describe, test, expect, jest, beforeEach, afterEach } from '@jest/globals';

// Mock the config module before importing claude.service
jest.mock('../../config', () => ({
  config: {
    claude: {
      apiKey: 'test-api-key',
      model: 'claude-3-haiku-20240307',
      maxTokens: 1024,
    },
  },
}));

// Mock Anthropic SDK
const mockCreate = jest.fn();
jest.mock('@anthropic-ai/sdk', () => {
  return jest.fn().mockImplementation(() => ({
    messages: {
      create: mockCreate,
    },
  }));
});

// Import after mocks are set up
import { ClaudeSearchService } from '../claude.service';

describe('ClaudeSearchService', () => {
  let service: ClaudeSearchService;

  beforeEach(() => {
    // Reset mocks before each test
    jest.clearAllMocks();
    service = new ClaudeSearchService();
  });

  afterEach(() => {
    jest.clearAllMocks();
  });

  describe('parseNaturalLanguageQuery', () => {
    describe('Successful Claude API Responses', () => {
      test('should parse city-based query', async () => {
        mockCreate.mockResolvedValue({
          content: [{
            type: 'text',
            text: JSON.stringify({
              whereClause: {
                city: { contains: 'Austin', mode: 'insensitive' }
              },
              explanation: 'Searching for properties in Austin'
            })
          }]
        });

        const result = await service.parseNaturalLanguageQuery('properties in Austin');

        expect(result.whereClause).toEqual({
          city: { contains: 'Austin', mode: 'insensitive' }
        });
        expect(result.explanation).toBe('Searching for properties in Austin');
        expect(mockCreate).toHaveBeenCalledTimes(1);
      });

      test('should parse value-based query with range', async () => {
        mockCreate.mockResolvedValue({
          content: [{
            type: 'text',
            text: JSON.stringify({
              whereClause: {
                appraisedValue: { gte: 300000, lte: 600000 }
              },
              orderBy: { appraisedValue: 'asc' },
              explanation: 'Searching for properties with appraised value between $300,000 and $600,000'
            })
          }]
        });

        const result = await service.parseNaturalLanguageQuery('properties appraised between 300k and 600k');

        expect(result.whereClause).toEqual({
          appraisedValue: { gte: 300000, lte: 600000 }
        });
        expect(result.orderBy).toEqual({ appraisedValue: 'asc' });
        expect(mockCreate).toHaveBeenCalledTimes(1);
      });

      test('should parse owner name query', async () => {
        mockCreate.mockResolvedValue({
          content: [{
            type: 'text',
            text: JSON.stringify({
              whereClause: {
                name: { contains: 'Smith', mode: 'insensitive' }
              },
              explanation: 'Searching for properties owned by Smith'
            })
          }]
        });

        const result = await service.parseNaturalLanguageQuery('properties owned by Smith');

        expect(result.whereClause).toEqual({
          name: { contains: 'Smith', mode: 'insensitive' }
        });
        expect(mockCreate).toHaveBeenCalledTimes(1);
      });

      test('should parse property type query', async () => {
        mockCreate.mockResolvedValue({
          content: [{
            type: 'text',
            text: JSON.stringify({
              whereClause: {
                propType: { contains: 'Commercial', mode: 'insensitive' }
              },
              explanation: 'Searching for commercial properties'
            })
          }]
        });

        const result = await service.parseNaturalLanguageQuery('commercial properties');

        expect(result.whereClause).toEqual({
          propType: { contains: 'Commercial', mode: 'insensitive' }
        });
        expect(mockCreate).toHaveBeenCalledTimes(1);
      });

      test('should parse address-based query', async () => {
        mockCreate.mockResolvedValue({
          content: [{
            type: 'text',
            text: JSON.stringify({
              whereClause: {
                propertyAddress: { contains: 'Congress', mode: 'insensitive' }
              },
              explanation: "Searching for properties with 'Congress' in the address"
            })
          }]
        });

        const result = await service.parseNaturalLanguageQuery('properties on Congress Ave');

        expect(result.whereClause).toEqual({
          propertyAddress: { contains: 'Congress', mode: 'insensitive' }
        });
        expect(mockCreate).toHaveBeenCalledTimes(1);
      });

      test('should parse complex combined query', async () => {
        mockCreate.mockResolvedValue({
          content: [{
            type: 'text',
            text: JSON.stringify({
              whereClause: {
                city: 'Austin',
                propType: { contains: 'Residential', mode: 'insensitive' },
                appraisedValue: { gte: 500000 }
              },
              orderBy: { appraisedValue: 'desc' },
              explanation: 'Searching for residential properties in Austin with appraised value over $500,000, sorted by value (highest first)'
            })
          }]
        });

        const result = await service.parseNaturalLanguageQuery('residential properties in Austin worth over 500k');

        expect(result.whereClause).toEqual({
          city: 'Austin',
          propType: { contains: 'Residential', mode: 'insensitive' },
          appraisedValue: { gte: 500000 }
        });
        expect(result.orderBy).toEqual({ appraisedValue: 'desc' });
        expect(mockCreate).toHaveBeenCalledTimes(1);
      });

      test('should handle orderBy being optional', async () => {
        mockCreate.mockResolvedValue({
          content: [{
            type: 'text',
            text: JSON.stringify({
              whereClause: {
                city: { contains: 'Austin', mode: 'insensitive' }
              },
              explanation: 'Searching for properties in Austin'
            })
          }]
        });

        const result = await service.parseNaturalLanguageQuery('properties in Austin');

        expect(result.whereClause).toBeDefined();
        expect(result.orderBy).toBeUndefined();
        expect(mockCreate).toHaveBeenCalledTimes(1);
      });
    });

    describe('Error Handling and Fallback', () => {
      test('should fallback to simple text search on API error', async () => {
        mockCreate.mockRejectedValue(new Error('API Error'));

        const result = await service.parseNaturalLanguageQuery('test query');

        expect(result.whereClause).toEqual({
          OR: [
            { name: { contains: 'test query', mode: 'insensitive' } },
            { propertyAddress: { contains: 'test query', mode: 'insensitive' } },
            { city: { contains: 'test query', mode: 'insensitive' } },
            { description: { contains: 'test query', mode: 'insensitive' } },
          ]
        });
        expect(result.explanation).toBe('Searching for "test query" across property names, addresses, cities, and descriptions');
      });

      test('should fallback on authentication error', async () => {
        mockCreate.mockRejectedValue(new Error('401 authentication_error: invalid x-api-key'));

        const result = await service.parseNaturalLanguageQuery('Austin properties');

        expect(result.whereClause.OR).toBeDefined();
        expect(result.whereClause.OR).toHaveLength(4);
      });

      test('should fallback on model not found error', async () => {
        mockCreate.mockRejectedValue(new Error('404 not_found_error: model: claude-3-5-sonnet-20241022'));

        const result = await service.parseNaturalLanguageQuery('Austin properties');

        expect(result.whereClause.OR).toBeDefined();
        expect(result.explanation).toContain('Austin properties');
      });

      test('should fallback on invalid JSON response', async () => {
        mockCreate.mockResolvedValue({
          content: [{
            type: 'text',
            text: 'Invalid JSON response'
          }]
        });

        const result = await service.parseNaturalLanguageQuery('test query');

        expect(result.whereClause.OR).toBeDefined();
      });

      test('should fallback on empty response', async () => {
        mockCreate.mockResolvedValue({
          content: [{
            type: 'text',
            text: ''
          }]
        });

        const result = await service.parseNaturalLanguageQuery('test query');

        expect(result.whereClause.OR).toBeDefined();
      });

      test('should handle missing whereClause in response', async () => {
        mockCreate.mockResolvedValue({
          content: [{
            type: 'text',
            text: JSON.stringify({
              explanation: 'Some explanation'
            })
          }]
        });

        const result = await service.parseNaturalLanguageQuery('test query');

        expect(result.whereClause).toEqual({});
        expect(result.explanation).toBe('Some explanation');
      });

      test('should provide default explanation when missing', async () => {
        mockCreate.mockResolvedValue({
          content: [{
            type: 'text',
            text: JSON.stringify({
              whereClause: { city: 'Austin' }
            })
          }]
        });

        const result = await service.parseNaturalLanguageQuery('test query');

        expect(result.explanation).toBe('Searching properties based on your query');
      });
    });

    describe('API Request Parameters', () => {
      test('should use correct model', async () => {
        mockCreate.mockResolvedValue({
          content: [{
            type: 'text',
            text: JSON.stringify({ whereClause: {}, explanation: 'Test' })
          }]
        });

        await service.parseNaturalLanguageQuery('test');

        expect(mockCreate).toHaveBeenCalledWith(
          expect.objectContaining({
            model: 'claude-3-haiku-20240307'
          })
        );
      });

      test('should set appropriate max_tokens', async () => {
        mockCreate.mockResolvedValue({
          content: [{
            type: 'text',
            text: JSON.stringify({ whereClause: {}, explanation: 'Test' })
          }]
        });

        await service.parseNaturalLanguageQuery('test');

        expect(mockCreate).toHaveBeenCalledWith(
          expect.objectContaining({
            max_tokens: 1024
          })
        );
      });

      test('should include user query in prompt', async () => {
        mockCreate.mockResolvedValue({
          content: [{
            type: 'text',
            text: JSON.stringify({ whereClause: {}, explanation: 'Test' })
          }]
        });

        await service.parseNaturalLanguageQuery('find expensive homes');

        const callArgs = mockCreate.mock.calls[0][0];
        expect(callArgs.messages[0].content).toContain('find expensive homes');
      });
    });

    describe('Edge Cases', () => {
      test('should handle empty query string', async () => {
        mockCreate.mockRejectedValue(new Error('Empty query'));

        const result = await service.parseNaturalLanguageQuery('');

        expect(result.whereClause.OR).toBeDefined();
      });

      test('should handle very long query', async () => {
        const longQuery = 'properties '.repeat(100);
        mockCreate.mockResolvedValue({
          content: [{
            type: 'text',
            text: JSON.stringify({
              whereClause: { city: 'Austin' },
              explanation: 'Processed long query'
            })
          }]
        });

        const result = await service.parseNaturalLanguageQuery(longQuery);

        expect(result.whereClause).toBeDefined();
        expect(mockCreate).toHaveBeenCalledTimes(1);
      });

      test('should handle special characters in query', async () => {
        mockCreate.mockResolvedValue({
          content: [{
            type: 'text',
            text: JSON.stringify({
              whereClause: { propertyAddress: { contains: "O'Connor", mode: 'insensitive' } },
              explanation: 'Searching for properties on O\'Connor'
            })
          }]
        });

        const result = await service.parseNaturalLanguageQuery("properties on O'Connor St");

        expect(result.whereClause).toBeDefined();
      });

      test('should handle Unicode characters', async () => {
        mockCreate.mockResolvedValue({
          content: [{
            type: 'text',
            text: JSON.stringify({
              whereClause: { city: { contains: 'So Paulo', mode: 'insensitive' } },
              explanation: 'Searching for properties in So Paulo'
            })
          }]
        });

        const result = await service.parseNaturalLanguageQuery('properties in So Paulo');

        expect(result.whereClause).toBeDefined();
      });
    });

    describe('Schema Field Names', () => {
      test('should use searchTerm field (camelCase) not search_term', async () => {
        mockCreate.mockResolvedValue({
          content: [{
            type: 'text',
            text: JSON.stringify({
              whereClause: {
                searchTerm: { contains: 'Smith', mode: 'insensitive' }
              },
              explanation: 'Searching for properties found via Smith search term'
            })
          }]
        });

        const result = await service.parseNaturalLanguageQuery('properties from Smith search');

        expect(result.whereClause).toEqual({
          searchTerm: { contains: 'Smith', mode: 'insensitive' }
        });
        expect(result.explanation).toBe('Searching for properties found via Smith search term');
      });

      test('should use propType field (camelCase) not prop_type', async () => {
        mockCreate.mockResolvedValue({
          content: [{
            type: 'text',
            text: JSON.stringify({
              whereClause: {
                propType: { contains: 'Residential', mode: 'insensitive' }
              },
              explanation: 'Searching for residential properties'
            })
          }]
        });

        const result = await service.parseNaturalLanguageQuery('residential properties');

        expect(result.whereClause).toHaveProperty('propType');
        expect(result.whereClause).not.toHaveProperty('prop_type');
      });

      test('should use propertyAddress field (camelCase) not property_address', async () => {
        mockCreate.mockResolvedValue({
          content: [{
            type: 'text',
            text: JSON.stringify({
              whereClause: {
                propertyAddress: { contains: 'Main St', mode: 'insensitive' }
              },
              explanation: 'Searching for properties on Main St'
            })
          }]
        });

        const result = await service.parseNaturalLanguageQuery('properties on Main St');

        expect(result.whereClause).toHaveProperty('propertyAddress');
        expect(result.whereClause).not.toHaveProperty('property_address');
      });

      test('should use appraisedValue field (camelCase) not appraised_value', async () => {
        mockCreate.mockResolvedValue({
          content: [{
            type: 'text',
            text: JSON.stringify({
              whereClause: {
                appraisedValue: { gte: 500000 }
              },
              orderBy: { appraisedValue: 'desc' },
              explanation: 'Searching for properties appraised over $500,000'
            })
          }]
        });

        const result = await service.parseNaturalLanguageQuery('properties worth over 500k');

        expect(result.whereClause).toHaveProperty('appraisedValue');
        expect(result.whereClause).not.toHaveProperty('appraised_value');
        expect(result.orderBy).toHaveProperty('appraisedValue');
      });

      test('should verify prompt includes correct Prisma field names', async () => {
        mockCreate.mockResolvedValue({
          content: [{
            type: 'text',
            text: JSON.stringify({ whereClause: {}, explanation: 'Test' })
          }]
        });

        await service.parseNaturalLanguageQuery('test');

        const callArgs = mockCreate.mock.calls[0][0];
        const prompt = callArgs.messages[0].content;

        // Verify the prompt uses camelCase Prisma field names, not snake_case DB names
        expect(prompt).toContain('searchTerm');
        expect(prompt).toContain('propType');
        expect(prompt).toContain('propertyAddress');
        expect(prompt).toContain('appraisedValue');
        expect(prompt).toContain('assessedValue');
        expect(prompt).toContain('geoId');
        expect(prompt).toContain('scrapedAt');
        expect(prompt).toContain('createdAt');
        expect(prompt).toContain('updatedAt');

        // Should NOT contain snake_case versions
        expect(prompt).not.toContain('search_term');
        expect(prompt).not.toContain('prop_type');
        expect(prompt).not.toContain('property_address');
        expect(prompt).not.toContain('appraised_value');
        expect(prompt).not.toContain('assessed_value');
      });
    });
  });
});
</file>

<file path="lib/__tests__/metrics.service.test.ts">
import {
  getMetrics,
  getRegistry,
  resetMetrics,
  updateQueueMetrics,
  updateCacheMetrics,
  recordHttpRequest,
  recordScrapeJob,
  recordDbQuery,
  recordCacheOperation,
  recordError,
  updateCodeComplexityMetrics,
  httpRequestsTotal,
  httpRequestDuration,
  scrapeJobsTotal,
  scrapeJobDuration,
  propertiesScrapedTotal,
  activeScrapeJobs,
  queueSize,
  dbQueryDuration,
  dbQueriesTotal,
  cacheOperations,
  cacheHitRate,
  cacheSize,
  errorsTotal,
  codeComplexityCyclomatic,
  type CodeComplexityMetrics,
} from '../metrics.service';

describe('Metrics Service', () => {
  beforeEach(() => {
    // Reset all metrics before each test
    resetMetrics();
  });

  describe('Registry', () => {
    test('should return a valid registry', () => {
      const registry = getRegistry();
      expect(registry).toBeDefined();
      expect(typeof registry.metrics).toBe('function');
    });

    test('should return metrics in Prometheus format', async () => {
      const metrics = await getMetrics();
      expect(typeof metrics).toBe('string');
      expect(metrics).toContain('tcad_scraper_');
    });
  });

  describe('HTTP Metrics', () => {
    test('should record HTTP requests', async () => {
      recordHttpRequest('GET', '/api/properties', 200, 0.5);

      const metrics = await getMetrics();
      expect(metrics).toContain('tcad_scraper_http_requests_total');
      expect(metrics).toContain('method="GET"');
      expect(metrics).toContain('route="/api/properties"');
      expect(metrics).toContain('status_code="200"');
    });

    test('should record multiple HTTP requests', async () => {
      recordHttpRequest('GET', '/api/properties', 200, 0.5);
      recordHttpRequest('GET', '/api/properties', 200, 0.3);
      recordHttpRequest('POST', '/api/search', 201, 1.2);

      const metrics = await getMetrics();
      expect(metrics).toContain('method="GET"');
      expect(metrics).toContain('method="POST"');
      expect(metrics).toContain('status_code="200"');
      expect(metrics).toContain('status_code="201"');
    });

    test('should record HTTP request durations', async () => {
      recordHttpRequest('GET', '/api/properties', 200, 1.5);

      const metrics = await getMetrics();
      expect(metrics).toContain('tcad_scraper_http_request_duration_seconds');
      expect(metrics).toContain('method="GET"');
    });
  });

  describe('Scrape Job Metrics', () => {
    test('should record completed scrape job', async () => {
      recordScrapeJob('completed', 30.5, 10);

      const metrics = await getMetrics();
      expect(metrics).toContain('tcad_scraper_jobs_total');
      expect(metrics).toContain('status="completed"');
      expect(metrics).toContain('tcad_scraper_properties_scraped_total');
    });

    test('should record failed scrape job', async () => {
      recordScrapeJob('failed', 15.2);

      const metrics = await getMetrics();
      expect(metrics).toContain('tcad_scraper_jobs_total');
      expect(metrics).toContain('status="failed"');
    });

    test('should record job durations', async () => {
      recordScrapeJob('completed', 45.3, 20);

      const metrics = await getMetrics();
      expect(metrics).toContain('tcad_scraper_job_duration_seconds');
      expect(metrics).toContain('status="completed"');
    });

    test('should not increment properties for completed job without count', async () => {
      resetMetrics();
      recordScrapeJob('completed', 30.5);

      const metrics = await getMetrics();
      // Should not contain properties_scraped metric if no count provided
      const lines = metrics.split('\n');
      const propertiesLines = lines.filter(l => l.includes('tcad_scraper_properties_scraped_total') && !l.startsWith('#'));
      expect(propertiesLines.length).toBe(0);
    });
  });

  describe('Queue Metrics', () => {
    test('should update queue metrics', async () => {
      await updateQueueMetrics(5, 2, 100, 3);

      const metrics = await getMetrics();
      expect(metrics).toContain('tcad_scraper_queue_size');
      expect(metrics).toContain('status="waiting"');
      expect(metrics).toContain('status="active"');
      expect(metrics).toContain('tcad_scraper_active_jobs');
    });

    test('should update queue metrics to zero', async () => {
      await updateQueueMetrics(0, 0, 50, 0);

      const metrics = await getMetrics();
      expect(metrics).toContain('tcad_scraper_queue_size');
      expect(metrics).toContain('tcad_scraper_active_jobs');
    });
  });

  describe('Database Metrics', () => {
    test('should record successful database query', async () => {
      recordDbQuery('select', 'properties', 'success', 0.05);

      const metrics = await getMetrics();
      expect(metrics).toContain('tcad_scraper_db_queries_total');
      expect(metrics).toContain('operation="select"');
      expect(metrics).toContain('table="properties"');
      expect(metrics).toContain('status="success"');
      expect(metrics).toContain('tcad_scraper_db_query_duration_seconds');
    });

    test('should record failed database query', async () => {
      recordDbQuery('insert', 'properties', 'error', 0.02);

      const metrics = await getMetrics();
      expect(metrics).toContain('tcad_scraper_db_queries_total');
      expect(metrics).toContain('operation="insert"');
      expect(metrics).toContain('status="error"');
    });

    test('should track different database operations', async () => {
      recordDbQuery('select', 'properties', 'success', 0.01);
      recordDbQuery('insert', 'properties', 'success', 0.03);
      recordDbQuery('update', 'properties', 'success', 0.02);
      recordDbQuery('delete', 'properties', 'success', 0.01);

      const metrics = await getMetrics();
      expect(metrics).toContain('operation="select"');
      expect(metrics).toContain('operation="insert"');
      expect(metrics).toContain('operation="update"');
      expect(metrics).toContain('operation="delete"');
    });
  });

  describe('Cache Metrics', () => {
    test('should record cache hit', async () => {
      recordCacheOperation('get', 'hit');

      const metrics = await getMetrics();
      expect(metrics).toContain('tcad_scraper_cache_operations_total');
      expect(metrics).toContain('operation="get"');
      expect(metrics).toContain('status="hit"');
    });

    test('should record cache miss', async () => {
      recordCacheOperation('get', 'miss');

      const metrics = await getMetrics();
      expect(metrics).toContain('tcad_scraper_cache_operations_total');
      expect(metrics).toContain('status="miss"');
    });

    test('should record cache set operations', async () => {
      recordCacheOperation('set', 'success');

      const metrics = await getMetrics();
      expect(metrics).toContain('operation="set"');
      expect(metrics).toContain('status="success"');
    });

    test('should record cache delete operations', async () => {
      recordCacheOperation('del', 'success');

      const metrics = await getMetrics();
      expect(metrics).toContain('operation="del"');
      expect(metrics).toContain('status="success"');
    });

    test('should update cache metrics with hit rate calculation', async () => {
      updateCacheMetrics(80, 20, 150);

      const metrics = await getMetrics();
      expect(metrics).toContain('tcad_scraper_cache_hit_rate');
      expect(metrics).toContain('tcad_scraper_cache_size');
    });

    test('should handle zero total for hit rate', async () => {
      updateCacheMetrics(0, 0, 0);

      const metrics = await getMetrics();
      expect(metrics).toContain('tcad_scraper_cache_hit_rate');
      expect(metrics).toContain('tcad_scraper_cache_size');
    });

    test('should calculate hit rate correctly', async () => {
      updateCacheMetrics(75, 25, 100);

      const metrics = await getMetrics();
      expect(metrics).toContain('tcad_scraper_cache_hit_rate');
    });
  });

  describe('Error Metrics', () => {
    test('should record errors by type and source', async () => {
      recordError('validation', 'controller');

      const metrics = await getMetrics();
      expect(metrics).toContain('tcad_scraper_errors_total');
      expect(metrics).toContain('type="validation"');
      expect(metrics).toContain('source="controller"');
    });

    test('should track multiple error types', async () => {
      recordError('validation', 'controller');
      recordError('database', 'service');
      recordError('scraper', 'worker');

      const metrics = await getMetrics();
      expect(metrics).toContain('type="validation"');
      expect(metrics).toContain('type="database"');
      expect(metrics).toContain('type="scraper"');
      expect(metrics).toContain('source="controller"');
      expect(metrics).toContain('source="service"');
      expect(metrics).toContain('source="worker"');
    });
  });

  describe('Code Complexity Metrics', () => {
    test('should update all code complexity metrics', () => {
      const metrics: CodeComplexityMetrics = {
        avgCyclomatic: 5.2,
        maxCyclomatic: 15,
        totalLines: 10000,
        codeLines: 7000,
        commentLines: 1500,
        totalFiles: 50,
        totalFunctions: 200,
        totalClasses: 25,
        maxFunctionLines: 150,
      };

      updateCodeComplexityMetrics(metrics);

      expect(codeComplexityCyclomatic['hashMap'][''].value).toBe(5.2);
    });

    test('should update optional code complexity metrics', () => {
      const metrics: CodeComplexityMetrics = {
        avgCyclomatic: 4.0,
        maxCyclomatic: 12,
        totalLines: 8000,
        codeLines: 6000,
        commentLines: 1000,
        totalFiles: 40,
        totalFunctions: 150,
        totalClasses: 20,
        maxFunctionLines: 120,
        maintainabilityIndex: 75,
        technicalDebtRatio: 5.5,
      };

      updateCodeComplexityMetrics(metrics);

      expect(codeComplexityCyclomatic['hashMap'][''].value).toBe(4.0);
    });

    test('should update per-file metrics', () => {
      const metrics: CodeComplexityMetrics = {
        avgCyclomatic: 5.0,
        maxCyclomatic: 10,
        totalLines: 5000,
        codeLines: 4000,
        commentLines: 500,
        totalFiles: 25,
        totalFunctions: 100,
        totalClasses: 10,
        maxFunctionLines: 80,
        fileMetrics: [
          { file: 'src/index.ts', lines: 200 },
          { file: 'src/service.ts', lines: 350 },
        ],
      };

      updateCodeComplexityMetrics(metrics);

      // File metrics should be updated (implementation depends on internal structure)
      expect(codeComplexityCyclomatic['hashMap'][''].value).toBe(5.0);
    });
  });

  describe('Reset Functionality', () => {
    test('should reset all metrics', async () => {
      // Record some metrics
      recordHttpRequest('GET', '/api/test', 200, 0.5);
      recordScrapeJob('completed', 30, 10);
      recordDbQuery('select', 'properties', 'success', 0.05);
      recordCacheOperation('get', 'hit');

      // Verify metrics are present
      let metrics = await getMetrics();
      expect(metrics).toContain('tcad_scraper_http_requests_total');

      // Reset metrics
      resetMetrics();

      // Metrics should be reset
      metrics = await getMetrics();
      const lines = metrics.split('\n').filter(l => !l.startsWith('#') && l.trim());
      // Should only have default metrics, not our custom recorded ones
      const httpRequestLines = lines.filter(l => l.includes('tcad_scraper_http_requests_total{'));
      expect(httpRequestLines.length).toBe(0);
    });

    test('should allow recording after reset', async () => {
      recordHttpRequest('GET', '/api/test', 200, 0.5);
      resetMetrics();
      recordHttpRequest('POST', '/api/test', 201, 0.3);

      const metrics = await getMetrics();
      expect(metrics).toContain('method="POST"');
      expect(metrics).toContain('status_code="201"');
    });
  });

  describe('Metrics Export', () => {
    test('should export metrics in Prometheus format', async () => {
      recordHttpRequest('GET', '/api/properties', 200, 0.5);
      recordScrapeJob('completed', 30, 10);

      const metrics = await getMetrics();

      expect(metrics).toContain('tcad_scraper_http_requests_total');
      expect(metrics).toContain('tcad_scraper_jobs_total');
      expect(metrics).toContain('method="GET"');
      expect(metrics).toContain('status="completed"');
    });

    test('should include default Node.js metrics', async () => {
      const metrics = await getMetrics();

      // Should include default metrics like process_cpu_seconds_total
      expect(metrics).toContain('tcad_scraper_');
      expect(typeof metrics).toBe('string');
      expect(metrics.length).toBeGreaterThan(0);
    });
  });

  describe('Edge Cases', () => {
    test('should handle zero duration for HTTP requests', async () => {
      recordHttpRequest('GET', '/api/fast', 200, 0);

      const metrics = await getMetrics();
      expect(metrics).toContain('tcad_scraper_http_request_duration_seconds');
      expect(metrics).toContain('route="/api/fast"');
    });

    test('should handle large durations', async () => {
      recordHttpRequest('GET', '/api/slow', 200, 300);

      const metrics = await getMetrics();
      expect(metrics).toContain('tcad_scraper_http_request_duration_seconds');
      expect(metrics).toContain('route="/api/slow"');
    });

    test('should handle various HTTP status codes', async () => {
      recordHttpRequest('GET', '/api/test', 200, 0.1);
      recordHttpRequest('GET', '/api/test', 404, 0.1);
      recordHttpRequest('GET', '/api/test', 500, 0.1);

      const metrics = await getMetrics();
      expect(metrics).toContain('status_code="200"');
      expect(metrics).toContain('status_code="404"');
      expect(metrics).toContain('status_code="500"');
    });

    test('should handle negative queue sizes as zero', async () => {
      await updateQueueMetrics(0, 0, 0, 0);

      const metrics = await getMetrics();
      expect(metrics).toContain('tcad_scraper_queue_size');
      expect(metrics).toContain('tcad_scraper_active_jobs');
    });
  });

  describe('Concurrent Operations', () => {
    test('should handle multiple concurrent HTTP requests', async () => {
      const routes = ['/api/a', '/api/b', '/api/c'];

      routes.forEach((route) => {
        recordHttpRequest('GET', route, 200, 0.5);
        recordHttpRequest('GET', route, 200, 0.3);
      });

      const metrics = await getMetrics();
      expect(metrics).toContain('route="/api/a"');
      expect(metrics).toContain('route="/api/b"');
      expect(metrics).toContain('route="/api/c"');
      expect(metrics).toContain('tcad_scraper_http_requests_total');
    });

    test('should handle multiple scrape jobs', async () => {
      for (let i = 0; i < 10; i++) {
        recordScrapeJob('completed', 30 + i, 5);
      }

      const metrics = await getMetrics();
      expect(metrics).toContain('tcad_scraper_jobs_total');
      expect(metrics).toContain('status="completed"');
      expect(metrics).toContain('tcad_scraper_properties_scraped_total');
    });
  });
});
</file>

<file path="lib/__tests__/prisma.test.ts">
/**
 * Prisma Client Tests
 *
 * Tests for Prisma client initialization and configuration
 */

// Mock PrismaClient before imports
const mockPrismaClient = jest.fn().mockImplementation(() => ({
  $connect: jest.fn().mockResolvedValue(undefined),
  $disconnect: jest.fn().mockResolvedValue(undefined),
}));

jest.mock('@prisma/client', () => ({
  PrismaClient: mockPrismaClient,
}));

describe('Prisma Client Module', () => {
  let originalEnv: NodeJS.ProcessEnv;

  beforeEach(() => {
    // Save original environment
    originalEnv = { ...process.env };

    // Clear module cache and global state
    jest.clearAllMocks();
    delete (global as any).prisma;
    delete (global as any).prismaReadOnly;

    // Reset module cache to force re-import
    jest.resetModules();
  });

  afterEach(() => {
    // Restore original environment
    process.env = originalEnv;
  });

  describe('Write Client Initialization', () => {
    it('should create write client with error logging in production', () => {
      process.env.NODE_ENV = 'production';

      // Re-import after setting environment
      require('../prisma');

      expect(mockPrismaClient).toHaveBeenCalledWith(
        expect.objectContaining({
          log: ['error'],
        })
      );
    });

    it('should create write client with verbose logging in development', () => {
      process.env.NODE_ENV = 'development';

      require('../prisma');

      expect(mockPrismaClient).toHaveBeenCalledWith(
        expect.objectContaining({
          log: ['query', 'error', 'warn'],
        })
      );
    });

    it('should use error-only logging when NODE_ENV is not development', () => {
      process.env.NODE_ENV = 'test';

      require('../prisma');

      expect(mockPrismaClient).toHaveBeenCalledWith(
        expect.objectContaining({
          log: ['error'],
        })
      );
    });

    it('should not set global.prisma in production', () => {
      process.env.NODE_ENV = 'production';

      require('../prisma');

      expect((global as any).prisma).toBeUndefined();
    });

    it('should set global.prisma in non-production environments', () => {
      process.env.NODE_ENV = 'development';

      require('../prisma');

      expect((global as any).prisma).toBeDefined();
    });

    it('should reuse existing global.prisma if available', () => {
      const existingClient = { existing: 'client' };
      (global as any).prisma = existingClient;

      const { prisma } = require('../prisma');

      expect(prisma).toBe(existingClient);
      // Write client reused from global, but read-only client still created
      expect(mockPrismaClient).toHaveBeenCalledTimes(1); // Only for read-only client
    });
  });

  describe('Read-Only Client Initialization', () => {
    it('should create read-only client with separate database URL', () => {
      process.env.DATABASE_READ_ONLY_URL = 'postgresql://readonly:pass@localhost:5432/db';
      process.env.DATABASE_URL = 'postgresql://write:pass@localhost:5432/db';
      process.env.NODE_ENV = 'production';

      require('../prisma');

      expect(mockPrismaClient).toHaveBeenCalledWith(
        expect.objectContaining({
          datasources: {
            db: {
              url: 'postgresql://readonly:pass@localhost:5432/db',
            },
          },
          log: ['error'],
        })
      );
    });

    it('should fallback to DATABASE_URL when DATABASE_READ_ONLY_URL is not set', () => {
      delete process.env.DATABASE_READ_ONLY_URL;
      process.env.DATABASE_URL = 'postgresql://main:pass@localhost:5432/db';
      process.env.NODE_ENV = 'production';

      require('../prisma');

      expect(mockPrismaClient).toHaveBeenCalledWith(
        expect.objectContaining({
          datasources: {
            db: {
              url: 'postgresql://main:pass@localhost:5432/db',
            },
          },
        })
      );
    });

    it('should create read-only client with verbose logging in development', () => {
      process.env.NODE_ENV = 'development';
      process.env.DATABASE_URL = 'postgresql://localhost:5432/db';

      require('../prisma');

      // Second call should be for read-only client
      expect(mockPrismaClient).toHaveBeenNthCalledWith(
        2,
        expect.objectContaining({
          log: ['query', 'error', 'warn'],
        })
      );
    });

    it('should not set global.prismaReadOnly in production', () => {
      process.env.NODE_ENV = 'production';

      require('../prisma');

      expect((global as any).prismaReadOnly).toBeUndefined();
    });

    it('should set global.prismaReadOnly in non-production environments', () => {
      process.env.NODE_ENV = 'development';

      require('../prisma');

      expect((global as any).prismaReadOnly).toBeDefined();
    });

    it('should reuse existing global.prismaReadOnly if available', () => {
      const existingReadClient = { existing: 'readClient' };
      (global as any).prismaReadOnly = existingReadClient;

      const { prismaReadOnly } = require('../prisma');

      expect(prismaReadOnly).toBe(existingReadClient);
    });
  });

  describe('Module Exports', () => {
    it('should export prisma write client', () => {
      const { prisma } = require('../prisma');

      expect(prisma).toBeDefined();
    });

    it('should export prismaReadOnly client', () => {
      const { prismaReadOnly } = require('../prisma');

      expect(prismaReadOnly).toBeDefined();
    });

    it('should export both clients as separate instances when no globals exist', () => {
      const { prisma, prismaReadOnly } = require('../prisma');

      expect(prisma).toBeDefined();
      expect(prismaReadOnly).toBeDefined();
      // When created fresh (not from globals), they should be different instances
      expect(mockPrismaClient).toHaveBeenCalledTimes(2);
    });
  });

  describe('Singleton Pattern', () => {
    it('should maintain singleton across multiple imports in non-production', () => {
      process.env.NODE_ENV = 'development';

      // First import
      const module1 = require('../prisma');

      // Clear require cache for module but keep globals
      const moduleId = require.resolve('../prisma');
      delete require.cache[moduleId];

      // Second import should reuse global
      const module2 = require('../prisma');

      expect(module1.prisma).toBe(module2.prisma);
      expect(module1.prismaReadOnly).toBe(module2.prismaReadOnly);
    });

    it.skip('should create new instances in production on each import - SKIPPED (Jest module caching)', () => {
      process.env.NODE_ENV = 'production';

      // First import
      require('../prisma');

      // Track how many times mock was called in first import
      const firstImportCalls = mockPrismaClient.mock.calls.length;
      expect(firstImportCalls).toBe(2); // write + read clients

      // Clear require cache to force re-import
      const moduleId = require.resolve('../prisma');
      delete require.cache[moduleId];

      // Second import should create new instances (globals not set in production)
      require('../prisma');

      // Should have created 2 more clients (4 total)
      expect(mockPrismaClient).toHaveBeenCalledTimes(4);
    });
  });

  describe('Environment Variable Handling', () => {
    it('should handle missing DATABASE_URL gracefully', () => {
      delete process.env.DATABASE_URL;
      delete process.env.DATABASE_READ_ONLY_URL;

      // Should not throw when importing
      expect(() => require('../prisma')).not.toThrow();
    });

    it('should handle undefined NODE_ENV with error-only logging', () => {
      delete process.env.NODE_ENV;

      require('../prisma');

      // Should use error-only logging (only 'development' gets verbose logging)
      expect(mockPrismaClient).toHaveBeenCalledWith(
        expect.objectContaining({
          log: ['error'],
        })
      );
    });
  });
});
</file>

<file path="lib/__tests__/redis-cache.service.test.ts">
// Mock redis BEFORE importing the service
jest.mock('redis', () => {
  const mockClient = {
    connect: jest.fn().mockResolvedValue(undefined),
    quit: jest.fn().mockResolvedValue(undefined),
    get: jest.fn(),
    set: jest.fn(),
    setEx: jest.fn(),
    del: jest.fn(),
    keys: jest.fn(),
    exists: jest.fn(),
    ttl: jest.fn(),
    flushDb: jest.fn(),
    ping: jest.fn(),
    on: jest.fn(),
  };

  return {
    createClient: jest.fn(() => mockClient),
  };
});

import { RedisCacheService } from '../redis-cache.service';

jest.mock('../../config', () => ({
  config: {
    redis: {
      host: 'localhost',
      port: 6379,
      password: '',
      db: 0,
      connectionTimeout: 5000,
    },
    logging: {
      level: 'error', // Suppress logs during tests
    },
  },
}));

describe.skip('RedisCacheService - SKIPPED (complex Redis mocking issue)', () => {
  let service: RedisCacheService;
  let mockRedisClient: any;

  beforeEach(async () => {
    jest.clearAllMocks();

    // Create service and connect
    service = new RedisCacheService();

    // Connect to Redis (this will call createClient)
    await service.connect();

    // Get the mock client instance
    const { createClient } = require('redis');
    mockRedisClient = createClient.mock.results[0].value;

    // Trigger the 'ready' event to set isConnected = true
    const onReadyHandler = mockRedisClient.on.mock.calls.find(
      (call: any[]) => call[0] === 'ready'
    )?.[1];
    if (onReadyHandler) onReadyHandler();
  });

  afterEach(async () => {
    if (service) {
      await service.disconnect();
    }
  });

  describe('connect', () => {
    it('should initialize Redis connection successfully', async () => {
      const newService = new RedisCacheService();
      mockRedisClient.connect.mockResolvedValue(undefined);

      await newService.connect();

      expect(mockRedisClient.connect).toHaveBeenCalled();
    });

    it('should not reconnect if already connected', async () => {
      mockRedisClient.connect.mockClear();

      await service.connect();

      expect(mockRedisClient.connect).not.toHaveBeenCalled();
    });

    it('should handle connection errors', async () => {
      const newService = new RedisCacheService();
      const error = new Error('Connection failed');
      mockRedisClient.connect.mockRejectedValue(error);

      await expect(newService.connect()).rejects.toThrow('Connection failed');
    });
  });

  describe('get', () => {
    it('should get value from cache and parse JSON', async () => {
      const key = 'test:key';
      const value = { data: 'test' };
      mockRedisClient.get.mockResolvedValue(JSON.stringify(value));

      const result = await service.get(key);

      expect(result).toEqual(value);
      expect(mockRedisClient.get).toHaveBeenCalledWith(key);
    });

    it('should return null for cache miss', async () => {
      const key = 'nonexistent';
      mockRedisClient.get.mockResolvedValue(null);

      const result = await service.get(key);

      expect(result).toBeNull();
    });

    it('should handle get errors gracefully', async () => {
      const key = 'error:key';
      mockRedisClient.get.mockRejectedValue(new Error('Redis error'));

      const result = await service.get(key);

      expect(result).toBeNull();
    });

    it('should return null when not connected', async () => {
      await service.disconnect();

      const result = await service.get('test:key');

      expect(result).toBeNull();
    });
  });

  describe('set', () => {
    it('should set value in cache with default TTL', async () => {
      const key = 'test:key';
      const value = { data: 'test' };
      mockRedisClient.setEx.mockResolvedValue('OK');

      const result = await service.set(key, value);

      expect(result).toBe(true);
      expect(mockRedisClient.setEx).toHaveBeenCalledWith(
        key,
        300, // default TTL
        JSON.stringify(value)
      );
    });

    it('should set value with custom TTL', async () => {
      const key = 'test:key';
      const value = { data: 'test' };
      const ttl = 600;
      mockRedisClient.setEx.mockResolvedValue('OK');

      const result = await service.set(key, value, ttl);

      expect(result).toBe(true);
      expect(mockRedisClient.setEx).toHaveBeenCalledWith(
        key,
        ttl,
        JSON.stringify(value)
      );
    });

    it('should handle set errors', async () => {
      const key = 'error:key';
      mockRedisClient.setEx.mockRejectedValue(new Error('Redis error'));

      const result = await service.set(key, { data: 'test' });

      expect(result).toBe(false);
    });

    it('should return false when not connected', async () => {
      await service.disconnect();

      const result = await service.set('test:key', { data: 'test' });

      expect(result).toBe(false);
    });
  });

  describe('delete', () => {
    it('should delete key successfully', async () => {
      const key = 'test:key';
      mockRedisClient.del.mockResolvedValue(1);

      const result = await service.delete(key);

      expect(result).toBe(true);
      expect(mockRedisClient.del).toHaveBeenCalledWith(key);
    });

    it('should return false when key does not exist', async () => {
      const key = 'nonexistent';
      mockRedisClient.del.mockResolvedValue(0);

      const result = await service.delete(key);

      expect(result).toBe(false);
    });

    it('should handle delete errors', async () => {
      const key = 'error:key';
      mockRedisClient.del.mockRejectedValue(new Error('Redis error'));

      const result = await service.delete(key);

      expect(result).toBe(false);
    });

    it('should return false when not connected', async () => {
      await service.disconnect();

      const result = await service.delete('test:key');

      expect(result).toBe(false);
    });
  });

  describe('deletePattern', () => {
    it('should delete all keys matching pattern', async () => {
      const pattern = 'test:*';
      const keys = ['test:1', 'test:2', 'test:3'];
      mockRedisClient.keys.mockResolvedValue(keys);
      mockRedisClient.del.mockResolvedValue(3);

      const result = await service.deletePattern(pattern);

      expect(result).toBe(3);
      expect(mockRedisClient.keys).toHaveBeenCalledWith(pattern);
      expect(mockRedisClient.del).toHaveBeenCalledWith(keys);
    });

    it('should return 0 when no keys match pattern', async () => {
      const pattern = 'nonexistent:*';
      mockRedisClient.keys.mockResolvedValue([]);

      const result = await service.deletePattern(pattern);

      expect(result).toBe(0);
      expect(mockRedisClient.del).not.toHaveBeenCalled();
    });

    it('should handle delete pattern errors', async () => {
      const pattern = 'error:*';
      mockRedisClient.keys.mockRejectedValue(new Error('Redis error'));

      const result = await service.deletePattern(pattern);

      expect(result).toBe(0);
    });

    it('should return 0 when not connected', async () => {
      await service.disconnect();

      const result = await service.deletePattern('test:*');

      expect(result).toBe(0);
    });
  });

  describe('exists', () => {
    it('should return true when key exists', async () => {
      const key = 'test:key';
      mockRedisClient.exists.mockResolvedValue(1);

      const result = await service.exists(key);

      expect(result).toBe(true);
      expect(mockRedisClient.exists).toHaveBeenCalledWith(key);
    });

    it('should return false when key does not exist', async () => {
      const key = 'nonexistent';
      mockRedisClient.exists.mockResolvedValue(0);

      const result = await service.exists(key);

      expect(result).toBe(false);
    });

    it('should return false on error', async () => {
      const key = 'error:key';
      mockRedisClient.exists.mockRejectedValue(new Error('Redis error'));

      const result = await service.exists(key);

      expect(result).toBe(false);
    });

    it('should return false when not connected', async () => {
      await service.disconnect();

      const result = await service.exists('test:key');

      expect(result).toBe(false);
    });
  });

  describe('ttl', () => {
    it('should return time to live for key', async () => {
      const key = 'test:key';
      const ttl = 300;
      mockRedisClient.ttl.mockResolvedValue(ttl);

      const result = await service.ttl(key);

      expect(result).toBe(ttl);
      expect(mockRedisClient.ttl).toHaveBeenCalledWith(key);
    });

    it('should return -1 on error', async () => {
      const key = 'error:key';
      mockRedisClient.ttl.mockRejectedValue(new Error('Redis error'));

      const result = await service.ttl(key);

      expect(result).toBe(-1);
    });

    it('should return -1 when not connected', async () => {
      await service.disconnect();

      const result = await service.ttl('test:key');

      expect(result).toBe(-1);
    });
  });

  describe('flush', () => {
    it('should flush all cache entries', async () => {
      mockRedisClient.flushDb.mockResolvedValue('OK');

      const result = await service.flush();

      expect(result).toBe(true);
      expect(mockRedisClient.flushDb).toHaveBeenCalled();
    });

    it('should handle flush errors', async () => {
      mockRedisClient.flushDb.mockRejectedValue(new Error('Redis error'));

      const result = await service.flush();

      expect(result).toBe(false);
    });

    it('should return false when not connected', async () => {
      await service.disconnect();

      const result = await service.flush();

      expect(result).toBe(false);
    });
  });

  describe('getStats', () => {
    it('should return cache statistics', async () => {
      // Generate some cache activity
      mockRedisClient.get.mockResolvedValueOnce(null); // miss
      mockRedisClient.get.mockResolvedValueOnce(JSON.stringify({ data: 'test' })); // hit
      mockRedisClient.setEx.mockResolvedValue('OK');

      await service.get('miss:key');
      await service.get('hit:key');
      await service.set('new:key', { data: 'test' });

      const stats = service.getStats();

      expect(stats.hits).toBe(1);
      expect(stats.misses).toBe(1);
      expect(stats.sets).toBe(1);
      expect(stats.totalRequests).toBe(2);
      expect(stats.hitRate).toBe('50.00%');
      expect(stats.isConnected).toBe(true);
    });

    it('should calculate 0% hit rate when no requests', async () => {
      const stats = service.getStats();

      expect(stats.hitRate).toBe('0%');
      expect(stats.totalRequests).toBe(0);
    });
  });

  describe('resetStats', () => {
    it('should reset statistics to zero', async () => {
      // Generate some activity
      mockRedisClient.get.mockResolvedValue(JSON.stringify({ data: 'test' }));
      await service.get('test:key');

      service.resetStats();

      const stats = service.getStats();
      expect(stats.hits).toBe(0);
      expect(stats.misses).toBe(0);
      expect(stats.sets).toBe(0);
      expect(stats.deletes).toBe(0);
      expect(stats.errors).toBe(0);
    });
  });

  describe('disconnect', () => {
    it('should close Redis connection', async () => {
      mockRedisClient.quit.mockResolvedValue('OK');

      await service.disconnect();

      expect(mockRedisClient.quit).toHaveBeenCalled();
    });

    it('should not error when disconnecting while not connected', async () => {
      await service.disconnect();

      // Second disconnect should not throw
      await expect(service.disconnect()).resolves.not.toThrow();
    });
  });

  describe('getOrSet', () => {
    it('should return cached value if exists', async () => {
      const key = 'test:key';
      const cachedValue = { data: 'cached' };
      mockRedisClient.get.mockResolvedValue(JSON.stringify(cachedValue));

      const fetchFn = jest.fn();
      const result = await service.getOrSet(key, fetchFn);

      expect(result).toEqual(cachedValue);
      expect(fetchFn).not.toHaveBeenCalled();
    });

    it('should fetch and cache value on cache miss', async () => {
      const key = 'test:key';
      const fetchedValue = { data: 'fetched' };
      mockRedisClient.get.mockResolvedValue(null); // cache miss
      mockRedisClient.setEx.mockResolvedValue('OK');

      const fetchFn = jest.fn().mockResolvedValue(fetchedValue);
      const result = await service.getOrSet(key, fetchFn);

      expect(result).toEqual(fetchedValue);
      expect(fetchFn).toHaveBeenCalled();
      expect(mockRedisClient.setEx).toHaveBeenCalledWith(
        key,
        300,
        JSON.stringify(fetchedValue)
      );
    });

    it('should use custom TTL in getOrSet', async () => {
      const key = 'test:key';
      const value = { data: 'test' };
      const ttl = 600;
      mockRedisClient.get.mockResolvedValue(null);
      mockRedisClient.setEx.mockResolvedValue('OK');

      const fetchFn = jest.fn().mockResolvedValue(value);
      await service.getOrSet(key, fetchFn, ttl);

      expect(mockRedisClient.setEx).toHaveBeenCalledWith(
        key,
        ttl,
        JSON.stringify(value)
      );
    });
  });

  describe('healthCheck', () => {
    it('should return true when Redis is healthy', async () => {
      mockRedisClient.ping.mockResolvedValue('PONG');

      const result = await service.healthCheck();

      expect(result).toBe(true);
      expect(mockRedisClient.ping).toHaveBeenCalled();
    });

    it('should return false when ping fails', async () => {
      mockRedisClient.ping.mockRejectedValue(new Error('Connection lost'));

      const result = await service.healthCheck();

      expect(result).toBe(false);
    });

    it('should return false when not connected', async () => {
      await service.disconnect();

      const result = await service.healthCheck();

      expect(result).toBe(false);
    });
  });
});
</file>

<file path="lib/__tests__/search-term-deduplicator.test.ts">
import { SearchTermDeduplicator } from '../search-term-deduplicator';

describe('SearchTermDeduplicator', () => {
  let deduplicator: SearchTermDeduplicator;

  beforeEach(() => {
    deduplicator = new SearchTermDeduplicator();
  });

  describe('Exact Duplicates', () => {
    test('should skip exact duplicates', () => {
      deduplicator.markTermAsUsed('Smith');
      expect(deduplicator.shouldSkipTerm('Smith')).toBe(true);
      expect(deduplicator.getStats().exactDuplicates).toBe(1);
    });

    test('should not skip new unique terms', () => {
      deduplicator.markTermAsUsed('Smith');
      expect(deduplicator.shouldSkipTerm('Jones')).toBe(false);
    });
  });

  describe('Business Entity Supersets', () => {
    test('should skip "Name LLC" when "Name" exists', () => {
      deduplicator.markTermAsUsed('Smith');
      expect(deduplicator.shouldSkipTerm('Smith LLC')).toBe(true);
      expect(deduplicator.getStats().businessSupersets).toBe(1);
    });

    test('should skip various business suffixes', () => {
      deduplicator.markTermAsUsed('Johnson');

      expect(deduplicator.shouldSkipTerm('Johnson Inc')).toBe(true);
      expect(deduplicator.shouldSkipTerm('Johnson Corp')).toBe(true);
      expect(deduplicator.shouldSkipTerm('Johnson Trust')).toBe(true);
      expect(deduplicator.shouldSkipTerm('Johnson Properties')).toBe(true);

      expect(deduplicator.getStats().businessSupersets).toBe(4);
    });

    test('should NOT skip business entity if base name does not exist', () => {
      expect(deduplicator.shouldSkipTerm('NewCompany LLC')).toBe(false);
    });

    test('should NOT skip single word terms', () => {
      deduplicator.markTermAsUsed('Trust');
      expect(deduplicator.shouldSkipTerm('Smith')).toBe(false);
    });
  });

  describe('Two-Word Supersets', () => {
    test('should skip "Oak Street" when both "Oak" and "Street" exist', () => {
      deduplicator.markTermAsUsed('Oak');
      deduplicator.markTermAsUsed('Street');

      expect(deduplicator.shouldSkipTerm('Oak Street')).toBe(true);
      expect(deduplicator.getStats().twoWordSupersets).toBe(1);
    });

    test('should NOT skip "Oak Street" if only "Oak" exists', () => {
      deduplicator.markTermAsUsed('Oak');
      expect(deduplicator.shouldSkipTerm('Oak Street')).toBe(false);
    });

    test('should NOT skip "Oak Street" if only "Street" exists', () => {
      deduplicator.markTermAsUsed('Street');
      expect(deduplicator.shouldSkipTerm('Oak Street')).toBe(false);
    });

    test('should allow if neither word exists', () => {
      expect(deduplicator.shouldSkipTerm('Pine Avenue')).toBe(false);
    });
  });

  describe('Multi-Word Supersets', () => {
    test('should skip when all 3 words exist', () => {
      deduplicator.markTermAsUsed('Oak');
      deduplicator.markTermAsUsed('Hill');
      deduplicator.markTermAsUsed('Drive');

      expect(deduplicator.shouldSkipTerm('Oak Hill Drive')).toBe(true);
      expect(deduplicator.getStats().multiWordSupersets).toBe(1);
    });

    test('should NOT skip if any word is missing', () => {
      deduplicator.markTermAsUsed('Oak');
      deduplicator.markTermAsUsed('Hill');
      // Missing "Drive"

      expect(deduplicator.shouldSkipTerm('Oak Hill Drive')).toBe(false);
    });
  });

  describe('Edge Cases', () => {
    test('should skip terms shorter than 4 characters', () => {
      expect(deduplicator.shouldSkipTerm('Oak')).toBe(true);
      expect(deduplicator.shouldSkipTerm('AB')).toBe(true);
      expect(deduplicator.shouldSkipTerm('A')).toBe(true);
    });

    test('should skip empty or null terms', () => {
      expect(deduplicator.shouldSkipTerm('')).toBe(true);
      expect(deduplicator.shouldSkipTerm('   ')).toBe(true);
    });

    test('should handle case sensitivity correctly', () => {
      deduplicator.markTermAsUsed('Smith');
      // Assuming case-sensitive matching
      expect(deduplicator.shouldSkipTerm('smith')).toBe(false);
    });
  });

  describe('Statistics Tracking', () => {
    test('should track multiple types of skips', () => {
      deduplicator.markTermAsUsed('Smith');
      deduplicator.markTermAsUsed('Oak');
      deduplicator.markTermAsUsed('Street');

      deduplicator.shouldSkipTerm('Smith'); // exact duplicate
      deduplicator.shouldSkipTerm('Smith LLC'); // business superset
      deduplicator.shouldSkipTerm('Oak Street'); // two-word superset

      const stats = deduplicator.getStats();
      expect(stats.exactDuplicates).toBe(1);
      expect(stats.businessSupersets).toBe(1);
      expect(stats.twoWordSupersets).toBe(1);
      expect(deduplicator.getTotalSkipped()).toBe(3);
    });

    test('should reset statistics', () => {
      deduplicator.markTermAsUsed('Smith');
      deduplicator.shouldSkipTerm('Smith');

      expect(deduplicator.getTotalSkipped()).toBe(1);

      deduplicator.resetStats();
      expect(deduplicator.getTotalSkipped()).toBe(0);
    });
  });

  describe('Utility Methods', () => {
    test('should track used terms count', () => {
      expect(deduplicator.getUsedTermsCount()).toBe(0);

      deduplicator.markTermAsUsed('Smith');
      deduplicator.markTermAsUsed('Jones');

      expect(deduplicator.getUsedTermsCount()).toBe(2);
    });

    test('should return used terms array', () => {
      deduplicator.markTermAsUsed('Smith');
      deduplicator.markTermAsUsed('Jones');

      const terms = deduplicator.getUsedTerms();
      expect(terms).toContain('Smith');
      expect(terms).toContain('Jones');
      expect(terms.length).toBe(2);
    });
  });

  describe('Integration with Existing Terms', () => {
    test('should initialize with existing terms', () => {
      const existingTerms = new Set(['Smith', 'Jones', 'Williams']);
      const dedup = new SearchTermDeduplicator(existingTerms);

      expect(dedup.shouldSkipTerm('Smith')).toBe(true);
      expect(dedup.shouldSkipTerm('Smith LLC')).toBe(true);
      expect(dedup.shouldSkipTerm('Brown')).toBe(false);
    });
  });
});
</file>

<file path="lib/__tests__/tcad-scraper.test.ts">
/**
 * TCAD Scraper Tests
 *
 * Tests for helper methods and configuration
 */

// Mock Playwright
const mockBrowser = {
  newContext: jest.fn(),
  close: jest.fn(),
};

jest.mock('playwright', () => ({
  chromium: {
    launch: jest.fn().mockResolvedValue(mockBrowser),
  },
}));

// Mock config
jest.mock('../../config', () => ({
  config: {
    logging: {
      level: 'error',
    },
    scraper: {
      headless: true,
      timeout: 30000,
      retryAttempts: 3,
      retryDelay: 1000,
      userAgents: [
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
      ],
      viewports: [
        { width: 1920, height: 1080 },
        { width: 1366, height: 768 },
      ],
      humanDelay: {
        min: 500,
        max: 2000,
      },
      brightData: {
        enabled: false,
        apiToken: null,
        proxyHost: 'brd.superproxy.io',
        proxyPort: 22225,
      },
      proxy: {
        enabled: false,
        server: null,
        username: null,
        password: null,
      },
    },
  },
}));

// Mock token refresh service
jest.mock('../../services/token-refresh.service', () => ({
  tokenRefreshService: {
    getCurrentToken: jest.fn().mockReturnValue(null),
  },
}));

// Mock DOM scraper fallback
jest.mock('../fallback/dom-scraper', () => ({
  scrapeDOMFallback: jest.fn().mockResolvedValue([]),
}));

import { TCADScraper } from '../tcad-scraper';
import { chromium } from 'playwright';

describe.skip('TCADScraper - SKIPPED (complex Playwright mocking)', () => {
  let scraper: TCADScraper;

  beforeEach(() => {
    jest.clearAllMocks();
    scraper = new TCADScraper();
  });

  afterEach(async () => {
    if (scraper) {
      // Cleanup if needed
    }
  });

  describe('constructor', () => {
    it('should initialize with default config', () => {
      const scraper = new TCADScraper();
      expect(scraper).toBeDefined();
    });

    it('should accept custom config', () => {
      const customScraper = new TCADScraper({
        headless: false,
        timeout: 60000,
      });
      expect(customScraper).toBeDefined();
    });

    it('should configure proxy if enabled in config', () => {
      // Test with Bright Data proxy
      jest.resetModules();
      jest.doMock('../../config', () => ({
        config: {
          logging: { level: 'error' },
          scraper: {
            headless: true,
            timeout: 30000,
            retryAttempts: 3,
            retryDelay: 1000,
            userAgents: ['test-agent'],
            viewports: [{ width: 1920, height: 1080 }],
            humanDelay: { min: 500, max: 2000 },
            brightData: {
              enabled: true,
              apiToken: 'test-token-12345678',
              proxyHost: 'brd.superproxy.io',
              proxyPort: 22225,
            },
            proxy: {
              enabled: false,
              server: null,
            },
          },
        },
      }));

      // Should not throw when creating scraper with proxy config
      expect(() => new TCADScraper()).not.toThrow();
    });
  });

  describe('initialize', () => {
    it('should launch browser with correct options', async () => {
      await scraper.initialize();

      expect(chromium.launch).toHaveBeenCalledWith(
        expect.objectContaining({
          headless: true,
          args: expect.arrayContaining([
            '--disable-blink-features=AutomationControlled',
            '--disable-web-security',
            '--no-sandbox',
          ]),
        })
      );
    });

    it('should handle browser launch failure', async () => {
      (chromium.launch as jest.Mock).mockRejectedValue(new Error('Launch failed'));

      await expect(scraper.initialize()).rejects.toThrow('Launch failed');
    });

    it('should include proxy config when provided', async () => {
      const scraperWithProxy = new TCADScraper({
        proxyServer: 'http://proxy.example.com:8080',
        proxyUsername: 'user',
        proxyPassword: 'pass',
      });

      await scraperWithProxy.initialize();

      expect(chromium.launch).toHaveBeenCalledWith(
        expect.objectContaining({
          proxy: {
            server: 'http://proxy.example.com:8080',
            username: 'user',
            password: 'pass',
          },
        })
      );
    });
  });

  describe('Helper Methods', () => {
    describe('getRandomElement', () => {
      it('should return element from array', () => {
        // Access private method via any
        const scraperAny = scraper as any;
        const testArray = [1, 2, 3, 4, 5];

        const result = scraperAny.getRandomElement(testArray);

        expect(testArray).toContain(result);
      });

      it('should handle single element array', () => {
        const scraperAny = scraper as any;
        const testArray = ['only-element'];

        const result = scraperAny.getRandomElement(testArray);

        expect(result).toBe('only-element');
      });

      it('should return different elements on multiple calls', () => {
        const scraperAny = scraper as any;
        const testArray = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10];
        const results = new Set();

        // Call 20 times, should get variety
        for (let i = 0; i < 20; i++) {
          results.add(scraperAny.getRandomElement(testArray));
        }

        // With 20 calls on 10 elements, should get more than 1 unique value
        expect(results.size).toBeGreaterThan(1);
      });
    });

    describe('humanDelay', () => {
      beforeEach(() => {
        jest.useFakeTimers();
      });

      afterEach(() => {
        jest.useRealTimers();
      });

      it('should delay within specified range', async () => {
        const scraperAny = scraper as any;

        const delayPromise = scraperAny.humanDelay(100, 200);

        // Fast-forward time
        jest.advanceTimersByTime(150);

        await delayPromise;

        expect(true).toBe(true); // If we got here, delay worked
      });

      it('should use default config values when not specified', async () => {
        const scraperAny = scraper as any;

        const delayPromise = scraperAny.humanDelay();

        // Should use config values (500-2000ms)
        jest.advanceTimersByTime(1000);

        await delayPromise;

        expect(true).toBe(true);
      });
    });
  });

  describe('Configuration', () => {
    it('should merge custom config with defaults', () => {
      const customScraper = new TCADScraper({
        timeout: 45000,
        retryAttempts: 5,
      });

      expect(customScraper).toBeDefined();
      // Config should be accessible and merged
    });

    it('should handle empty config object', () => {
      const defaultScraper = new TCADScraper({});
      expect(defaultScraper).toBeDefined();
    });
  });

  describe('Error Handling', () => {
    it('should throw error if scrapePropertiesViaAPI called without initialization', async () => {
      const uninitializedScraper = new TCADScraper();

      await expect(
        uninitializedScraper.scrapePropertiesViaAPI('test')
      ).rejects.toThrow('Browser not initialized');
    });

    it('should throw error if scrapeProperties called without initialization', async () => {
      const uninitializedScraper = new TCADScraper();

      await expect(
        uninitializedScraper.scrapeProperties('test')
      ).rejects.toThrow('Browser not initialized');
    });
  });

  describe('cleanup', () => {
    it('should close browser if initialized', async () => {
      await scraper.initialize();

      await scraper.cleanup();

      expect(mockBrowser.close).toHaveBeenCalled();
    });

    it('should handle cleanup when browser not initialized', async () => {
      await expect(scraper.cleanup()).resolves.not.toThrow();
    });

    it('should handle browser close errors gracefully', async () => {
      await scraper.initialize();

      mockBrowser.close.mockRejectedValue(new Error('Close failed'));

      // Should not throw
      await expect(scraper.cleanup()).resolves.not.toThrow();
    });
  });

  describe('User Agent and Viewport Selection', () => {
    it('should use random user agent from config', async () => {
      await scraper.initialize();

      const mockNewContext = mockBrowser.newContext as jest.Mock;

      // Initialize will be called later, but config is set in constructor
      expect(scraper).toBeDefined();
    });

    it('should use random viewport from config', async () => {
      await scraper.initialize();

      expect(scraper).toBeDefined();
    });
  });

  describe('Retry Logic', () => {
    it('should respect retry configuration', () => {
      const scraperWithRetries = new TCADScraper({
        retryAttempts: 5,
        retryDelay: 2000,
      });

      expect(scraperWithRetries).toBeDefined();
    });
  });
});
</file>

<file path="lib/fallback/dom-scraper.ts">
/**
 * DOM-BASED SCRAPER - FALLBACK MECHANISM ONLY
 *
 *  WARNING: This is a DEPRECATED fallback method
 *
 * This scraper is limited to 20 results per search due to AG Grid's hidden pagination.
 * It should ONLY be used when the primary API-based scraping method fails.
 *
 * Primary method: scrapePropertiesViaAPI() in tcad-scraper.ts
 * Fallback method: scrapeDOMFallback() in this file
 *
 * Limitations:
 * - Maximum 20 results per search (AG Grid pagination restriction)
 * - Slower performance (DOM manipulation + individual page scraping)
 * - Higher resource usage
 * - More fragile (breaks if UI changes)
 *
 * Use cases:
 * - API authentication failures
 * - API rate limiting
 * - API endpoint changes
 * - Emergency data retrieval
 */

import { Browser, Page, BrowserContext } from 'playwright';
import winston from 'winston';
import { PropertyData, ScraperConfig } from '../../types';
import { config as appConfig } from '../../config';

const logger = winston.createLogger({
  level: appConfig.logging.level,
  format: winston.format.json(),
  transports: [
    new winston.transports.Console({
      format: winston.format.simple(),
    }),
  ],
});

/**
 * Human-like delay between actions
 */
async function humanDelay(
  min: number = appConfig.scraper.humanDelay.min,
  max: number = appConfig.scraper.humanDelay.max
): Promise<void> {
  const delay = Math.floor(Math.random() * (max - min) + min);
  await new Promise(resolve => setTimeout(resolve, delay));
}

/**
 * Scrape property details from individual property page
 */
async function scrapePropertyDetail(page: Page, propertyId: string): Promise<PropertyData | null> {
  try {
    const detailUrl = `https://travis.prodigycad.com/property-detail?pid=${propertyId}`;
    await page.goto(detailUrl, {
      waitUntil: 'networkidle',
      timeout: 15000,
    });

    await humanDelay(1000, 2000);

    const propertyData = await page.evaluate(() => {
      const getValueByLabel = (labelText: string): string | null => {
        const labels = document.querySelectorAll('label, dt, th, .label, [class*="label"]');

        let labelIdx = 0;
        while (labelIdx < labels.length) {
          const label = labels[labelIdx];
          const text = label.textContent?.trim().toLowerCase() || '';

          if (text.includes(labelText.toLowerCase())) {
            let valueElem = label.nextElementSibling;
            if (valueElem && valueElem.textContent) {
              return valueElem.textContent.trim();
            }

            if (label.parentElement) {
              valueElem = label.parentElement.nextElementSibling;
              if (valueElem && valueElem.textContent) {
                return valueElem.textContent.trim();
              }
            }

            if (label.tagName === 'TH') {
              const row = label.closest('tr');
              if (row) {
                const cells = row.querySelectorAll('td');
                if (cells.length > 0) {
                  return cells[0].textContent?.trim() || null;
                }
              }
            }
          }

          labelIdx++;
        }

        return null;
      };

      const name = getValueByLabel('owner') || getValueByLabel('name') || '';
      const propType = getValueByLabel('property type') || getValueByLabel('type') || '';
      const city = getValueByLabel('city') || getValueByLabel('situs city') || null;
      const propertyAddress = getValueByLabel('address') || getValueByLabel('situs address') || getValueByLabel('street') || '';

      const appraisedValueText = getValueByLabel('appraised value') ||
                                 getValueByLabel('market value') ||
                                 getValueByLabel('total value') || '0';
      const appraisedValue = parseFloat(appraisedValueText.replace(/[$,]/g, '')) || 0;

      const assessedValueText = getValueByLabel('assessed value') ||
                                getValueByLabel('taxable value') || '0';
      const assessedValue = parseFloat(assessedValueText.replace(/[$,]/g, '')) || 0;

      const geoId = getValueByLabel('geo id') || getValueByLabel('geographic id') || null;
      const description = getValueByLabel('legal description') || getValueByLabel('description') || null;

      return {
        name,
        propType,
        city,
        propertyAddress,
        appraisedValue,
        assessedValue,
        geoId,
        description,
      };
    });

    return {
      propertyId,
      ...propertyData,
    };

  } catch (error) {
    logger.error(`Error scraping detail page for property ${propertyId}:`, error);
    return null;
  }
}

/**
 * FALLBACK: DOM-based property scraping
 *
 *  This method is LIMITED to 20 results due to AG Grid pagination restrictions
 *  Use only when API-based scraping fails
 *
 * @param browser - Playwright browser instance
 * @param config - Scraper configuration
 * @param searchTerm - Search term
 * @param maxRetries - Maximum retry attempts
 * @returns Array of PropertyData (max 20 results)
 */
export async function scrapeDOMFallback(
  browser: Browser,
  config: ScraperConfig,
  searchTerm: string,
  maxRetries: number = 3
): Promise<PropertyData[]> {
  logger.warn(' FALLBACK: Using DOM-based scraping (limited to 20 results)');

  let lastError: Error | null = null;

  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      logger.info(`DOM fallback attempt ${attempt} for search term: ${searchTerm}`);

      const context = await browser.newContext({
        userAgent: config.userAgents[Math.floor(Math.random() * config.userAgents.length)],
        viewport: config.viewports[Math.floor(Math.random() * config.viewports.length)],
        locale: 'en-US',
        timezoneId: 'America/Chicago',
      });

      const page = await context.newPage();

      await page.setExtraHTTPHeaders({
        'Accept-Language': 'en-US,en;q=0.9',
        'Accept-Encoding': 'gzip, deflate, br',
        'Cache-Control': 'no-cache',
        'Pragma': 'no-cache',
      });

      try {
        await page.goto('https://travis.prodigycad.com/property-search', {
          waitUntil: 'networkidle',
          timeout: config.timeout,
        });

        logger.info('Page loaded, waiting for React app...');

        await page.waitForFunction(() => {
          const root = document.getElementById('root');
          return root && root.children.length > 0;
        }, { timeout: 15000 });

        logger.info('React app loaded, performing search...');
        await humanDelay(1000, 1500);

        await page.waitForSelector('#searchInput', { timeout: 10000 });
        await humanDelay(500, 1000);
        await page.type('#searchInput', searchTerm, { delay: 50 + Math.random() * 100 });
        await humanDelay(300, 700);
        await page.press('#searchInput', 'Enter');
        await humanDelay(2000, 3000);

        await page.waitForFunction(
          () => {
            const hasGridCells = document.querySelector('[role="gridcell"]') !== null;
            const hasNoResults = document.querySelector('.ag-overlay-no-rows-center') !== null ||
                                document.body.textContent?.includes('No Rows To Show');
            return hasGridCells || hasNoResults;
          },
          { timeout: 15000 }
        );

        await humanDelay(1000, 1500);

        const hasNoResults = await page.evaluate(() => {
          const noResultsOverlay = document.querySelector('.ag-overlay-no-rows-center') !== null;
          const hasGridCells = document.querySelector('[role="gridcell"]') !== null;
          return noResultsOverlay && !hasGridCells;
        });

        if (hasNoResults) {
          logger.info('No results found for search term:', searchTerm);
          await context.close();
          return [];
        }

        logger.info('Results loaded, extracting property IDs...');

        const propertyIds = await page.evaluate(() => {
          const rows = document.querySelectorAll('[role="row"][row-index]');
          const ids = [];

          let rowIndex = 0;
          while (rowIndex < rows.length) {
            const row = rows[rowIndex];
            const pidElem = row.querySelector('[col-id="pid"]');
            const propertyId = pidElem ? pidElem.textContent.trim() : '';

            if (propertyId) {
              ids.push(propertyId);
            }

            rowIndex++;
          }

          return ids;
        });

        logger.warn(` DOM scraping found ${propertyIds.length} property IDs (max 20 due to pagination limit)`);

        const properties = [];
        let successCount = 0;
        let failCount = 0;

        for (let i = 0; i < propertyIds.length; i++) {
          const propertyId = propertyIds[i];

          try {
            logger.info(`Scraping property ${i + 1}/${propertyIds.length}: ${propertyId}`);

            const propertyData = await scrapePropertyDetail(page, propertyId);

            if (propertyData) {
              properties.push(propertyData);
              successCount++;
            } else {
              failCount++;
            }

            await humanDelay(500, 1000);

          } catch (error) {
            logger.error(`Failed to scrape property ${propertyId}:`, error);
            failCount++;
          }
        }

        logger.info(`DOM fallback complete: ${successCount} succeeded, ${failCount} failed`);
        logger.warn(` Results limited to ${properties.length} properties (20 max due to AG Grid pagination)`);

        await context.close();
        return properties;

      } finally {
        await context.close();
      }

    } catch (error) {
      lastError = error as Error;
      logger.error(`DOM fallback attempt ${attempt} failed:`, error);

      if (attempt < maxRetries) {
        const delay = config.retryDelay * Math.pow(2, attempt - 1);
        logger.info(`Retrying in ${delay}ms...`);
        await new Promise(resolve => setTimeout(resolve, delay));
      }
    }
  }

  throw lastError || new Error('All DOM fallback scraping attempts failed');
}
</file>

<file path="lib/fallback/README.md">
# Fallback Scraping Mechanisms

This directory contains **FALLBACK scraping methods** that are used only when the primary API-based scraping fails.

##  Important Limitations

All fallback methods in this directory have significant limitations and should **ONLY** be used as a last resort when the primary method fails.

## Directory Structure

### `dom-scraper.ts`
**DOM-based property scraping - DEPRECATED FALLBACK**

- **Limitation**: Maximum 20 results per search
- **Reason**: AG Grid pagination restrictions in the UI
- **Performance**: Slower than API method (requires individual page scraping)
- **Fragility**: Breaks if UI HTML structure changes

**When it's used:**
- API authentication failures
- API endpoint changes
- Network issues preventing API access
- Emergency data retrieval

## Primary vs Fallback Methods

### Primary Method (RECOMMENDED)
Location: `/server/src/lib/tcad-scraper.ts::scrapePropertiesViaAPI()`

Benefits:
-  Up to 1000 results per API call
-  Fast and efficient
-  Automatic authentication handling
-  Adaptive page sizing
-  Reliable data structure

### Fallback Method (USE ONLY IF PRIMARY FAILS)
Location: `/server/src/lib/fallback/dom-scraper.ts::scrapeDOMFallback()`

Limitations:
-  Maximum 20 results (AG Grid pagination limit)
-  Slower performance
-  Higher resource usage
-  More brittle (depends on UI structure)

## How the Fallback System Works

The main scraper class provides a `scrapePropertiesWithFallback()` method that:

1. **Attempts primary method** (API-based scraping)
2. **On failure, automatically falls back** to DOM scraping
3. **Logs clear warnings** about which method is being used
4. **Returns whichever method succeeds**

```typescript
// Usage example
const scraper = new TCADScraper();
await scraper.initialize();

// This will try API first, then DOM if API fails
const properties = await scraper.scrapePropertiesWithFallback('search term');
```

## Logging and Monitoring

The fallback system provides clear log messages:

```
 Attempting primary method: API-based scraping
 Primary method succeeded: Retrieved 150 properties
```

Or if fallback is triggered:

```
 Attempting primary method: API-based scraping
 Primary API method failed after all retries
 Falling back to DOM-based scraping (limited to 20 results)
 Fallback method succeeded: Retrieved 20 properties (max 20)
```

## Adding New Fallback Methods

If you need to add new fallback methods:

1. Create a new file in this directory (e.g., `another-scraper.ts`)
2. Export a function with clear documentation about its limitations
3. Update the main scraper's fallback chain
4. Document the method in this README

## Testing Fallback Methods

To test the fallback mechanism:

```bash
# Set environment to intentionally break API method
TCAD_API_KEY=invalid_token npm run test:scraper

# The system should automatically fall back to DOM scraping
```

## Performance Comparison

| Method | Results | Speed | Resource Usage | Reliability |
|--------|---------|-------|----------------|-------------|
| API (Primary) | Up to 1000 | Fast | Low | High |
| DOM (Fallback) | Max 20 | Slow | High | Medium |

## When to Update Fallback Methods

Update fallback methods when:
- The TCAD website UI changes significantly
- New data fields need to be extracted
- Alternative scraping approaches become available
- Performance improvements can be made

## Related Files

- `/server/src/lib/tcad-scraper.ts` - Main scraper with primary method
- `/server/src/lib/fallback/dom-scraper.ts` - DOM fallback implementation
- `/server/src/lib/scraper.queue.ts` - Job queue that uses the scraper
- `/server/src/routes/properties.ts` - API routes that trigger scraping
</file>

<file path="lib/claude.service.ts">
import Anthropic from '@anthropic-ai/sdk';
import { Prisma } from '@prisma/client';
import logger from './logger';
import { config } from '../config';

const anthropic = new Anthropic({
  apiKey: config.claude.apiKey,
});

interface SearchFilters {
  whereClause: Prisma.PropertyWhereInput;
  orderBy?: Prisma.PropertyOrderByWithRelationInput;
  explanation: string;
}

export class ClaudeSearchService {
  async parseNaturalLanguageQuery(query: string): Promise<SearchFilters> {
    try {
      const message = await anthropic.messages.create({
        model: config.claude.model,
        max_tokens: config.claude.maxTokens,
        messages: [
          {
            role: 'user',
            content: `You are a database query generator for a property search system. Convert the user's natural language query into Prisma query filters.

Available fields in the properties table:
- id (text): unique identifier
- propertyId (text): property ID from TCAD
- name (text): owner name
- propType (text): property type (e.g., "Residential", "Commercial", "Industrial")
- city (text): city name
- propertyAddress (text): full address
- assessedValue (number): assessed value in dollars
- appraisedValue (number): appraised value in dollars
- geoId (text): geographic ID
- description (text): property description
- searchTerm (text): original search term used to find this property
- scrapedAt (datetime): when the data was scraped
- createdAt (datetime): record creation time
- updatedAt (datetime): last update time

User query: "${query}"

Generate a JSON response with these fields:
1. "whereClause": Prisma where clause as JSON (use "contains" for text searches with "mode": "insensitive" for case-insensitive, "gte"/"lte" for number ranges, "gt"/"lt" for comparisons)
2. "orderBy": Prisma orderBy clause (optional, use "asc" or "desc")
3. "explanation": Brief explanation of what you're searching for

Examples:

Query: "properties in Austin worth over 500k"
Response:
{
  "whereClause": {
    "city": "Austin",
    "appraisedValue": { "gte": 500000 }
  },
  "orderBy": { "appraisedValue": "desc" },
  "explanation": "Searching for properties in Austin with appraised value over $500,000, sorted by value (highest first)"
}

Query: "commercial properties owned by Smith"
Response:
{
  "whereClause": {
    "propType": { "contains": "Commercial", "mode": "insensitive" },
    "name": { "contains": "Smith", "mode": "insensitive" }
  },
  "explanation": "Searching for commercial properties where owner name contains 'Smith'"
}

Query: "show me the most expensive residential properties"
Response:
{
  "whereClause": {
    "propType": { "contains": "Residential", "mode": "insensitive" }
  },
  "orderBy": { "appraisedValue": "desc" },
  "explanation": "Showing residential properties sorted by appraised value (highest first)"
}

Query: "properties on Congress Ave"
Response:
{
  "whereClause": {
    "propertyAddress": { "contains": "Congress", "mode": "insensitive" }
  },
  "explanation": "Searching for properties with 'Congress' in the address"
}

Query: "find properties appraised between 300k and 600k"
Response:
{
  "whereClause": {
    "appraisedValue": { "gte": 300000, "lte": 600000 }
  },
  "orderBy": { "appraisedValue": "asc" },
  "explanation": "Searching for properties with appraised value between $300,000 and $600,000"
}

IMPORTANT:
- Return ONLY valid JSON, no markdown formatting
- Use "mode": "insensitive" for all text searches
- Convert dollar amounts (like "500k" or "$1M") to numbers (500000, 1000000)
- For text searches, use "contains" with "mode": "insensitive"
- Only include orderBy if the query implies sorting
- Keep explanations brief and user-friendly

Now generate the JSON for the user's query above.`,
          },
        ],
      });

      const responseText = message.content[0].type === 'text' ? message.content[0].text : '';
      logger.info('Claude response:', { responseText });

      // Parse the JSON response
      const parsed = JSON.parse(responseText);

      return {
        whereClause: parsed.whereClause || {},
        orderBy: parsed.orderBy,
        explanation: parsed.explanation || 'Searching properties based on your query',
      };
    } catch (error) {
      // Safely log the error without risking serialization issues
      const errorDetails = {
        message: error instanceof Error ? error.message : String(error),
        name: error instanceof Error ? error.name : 'Unknown',
        stack: error instanceof Error ? error.stack : undefined,
      };
      logger.error('Error parsing natural language query with Claude:', errorDetails);
      logger.error('Claude API Error Details:', JSON.stringify(errorDetails, null, 2));

      // Fallback: simple text search across multiple fields
      return {
        whereClause: {
          OR: [
            { name: { contains: query, mode: 'insensitive' } },
            { propertyAddress: { contains: query, mode: 'insensitive' } },
            { city: { contains: query, mode: 'insensitive' } },
            { description: { contains: query, mode: 'insensitive' } },
          ],
        },
        explanation: `Searching for "${query}" across property names, addresses, cities, and descriptions`,
      };
    }
  }
}

export const claudeSearchService = new ClaudeSearchService();
</file>

<file path="lib/logger.ts">
// src/lib/logger.ts
import pino from 'pino';

const logger = pino({
  level: process.env.LOG_LEVEL || 'info',
  transport: {
    target: 'pino-pretty',
    options: {
      colorize: true,
      translateTime: 'SYS:standard',
      ignore: 'pid,hostname',
    },
  },
});

export default logger;
</file>

<file path="lib/metrics.service.ts">
/**
 * Prometheus Metrics Service
 *
 * Provides comprehensive application monitoring with Prometheus metrics
 */

import { Registry, Counter, Histogram, Gauge, collectDefaultMetrics } from 'prom-client';
import logger from './logger';

// Create a new registry
const register = new Registry();

// Add default Node.js metrics (memory, CPU, event loop, etc.)
collectDefaultMetrics({
  register,
  prefix: 'tcad_scraper_',
});

// ============================================================================
// HTTP Metrics
// ============================================================================

/**
 * HTTP request counter
 * Tracks total number of HTTP requests by method, route, and status
 */
export const httpRequestsTotal = new Counter({
  name: 'tcad_scraper_http_requests_total',
  help: 'Total number of HTTP requests',
  labelNames: ['method', 'route', 'status_code'],
  registers: [register],
});

/**
 * HTTP request duration histogram
 * Tracks request processing time distribution
 */
export const httpRequestDuration = new Histogram({
  name: 'tcad_scraper_http_request_duration_seconds',
  help: 'HTTP request duration in seconds',
  labelNames: ['method', 'route', 'status_code'],
  buckets: [0.1, 0.3, 0.5, 0.7, 1, 3, 5, 7, 10], // Response time buckets in seconds
  registers: [register],
});

// ============================================================================
// Scraper Metrics
// ============================================================================

/**
 * Scrape job counter
 * Tracks total number of scrape jobs by status
 */
export const scrapeJobsTotal = new Counter({
  name: 'tcad_scraper_jobs_total',
  help: 'Total number of scrape jobs',
  labelNames: ['status'], // pending, processing, completed, failed
  registers: [register],
});

/**
 * Scrape job duration histogram
 * Tracks how long scrape jobs take to complete
 */
export const scrapeJobDuration = new Histogram({
  name: 'tcad_scraper_job_duration_seconds',
  help: 'Scrape job duration in seconds',
  labelNames: ['status'],
  buckets: [5, 10, 30, 60, 120, 300, 600], // Job duration buckets in seconds
  registers: [register],
});

/**
 * Properties scraped counter
 * Tracks total number of properties scraped
 */
export const propertiesScrapedTotal = new Counter({
  name: 'tcad_scraper_properties_scraped_total',
  help: 'Total number of properties scraped',
  labelNames: ['search_term'],
  registers: [register],
});

/**
 * Active scrape jobs gauge
 * Tracks current number of active scrape jobs
 */
export const activeScrapeJobs = new Gauge({
  name: 'tcad_scraper_active_jobs',
  help: 'Current number of active scrape jobs',
  registers: [register],
});

// ============================================================================
// Queue Metrics
// ============================================================================

/**
 * Queue size gauge
 * Tracks current queue depth by status
 */
export const queueSize = new Gauge({
  name: 'tcad_scraper_queue_size',
  help: 'Current number of jobs in queue',
  labelNames: ['status'], // waiting, active, completed, failed
  registers: [register],
});

/**
 * Queue processing rate
 * Tracks jobs processed per second
 */
export const queueProcessingRate = new Counter({
  name: 'tcad_scraper_queue_processed_total',
  help: 'Total number of jobs processed from queue',
  labelNames: ['status'],
  registers: [register],
});

// ============================================================================
// Database Metrics
// ============================================================================

/**
 * Database query duration histogram
 * Tracks database query performance
 */
export const dbQueryDuration = new Histogram({
  name: 'tcad_scraper_db_query_duration_seconds',
  help: 'Database query duration in seconds',
  labelNames: ['operation', 'table'],
  buckets: [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2, 5],
  registers: [register],
});

/**
 * Database connection pool gauge
 * Tracks active database connections
 */
export const dbConnectionsActive = new Gauge({
  name: 'tcad_scraper_db_connections_active',
  help: 'Current number of active database connections',
  registers: [register],
});

/**
 * Database query counter
 * Tracks total number of database queries
 */
export const dbQueriesTotal = new Counter({
  name: 'tcad_scraper_db_queries_total',
  help: 'Total number of database queries',
  labelNames: ['operation', 'table', 'status'],
  registers: [register],
});

// ============================================================================
// Cache Metrics
// ============================================================================

/**
 * Cache operations counter
 * Tracks cache hits and misses
 */
export const cacheOperations = new Counter({
  name: 'tcad_scraper_cache_operations_total',
  help: 'Total number of cache operations',
  labelNames: ['operation', 'status'], // operation: get/set/del, status: hit/miss/success/error
  registers: [register],
});

/**
 * Cache hit rate gauge
 * Tracks current cache hit rate percentage
 */
export const cacheHitRate = new Gauge({
  name: 'tcad_scraper_cache_hit_rate',
  help: 'Cache hit rate percentage',
  registers: [register],
});

/**
 * Cache size gauge
 * Tracks current number of items in cache
 */
export const cacheSize = new Gauge({
  name: 'tcad_scraper_cache_size',
  help: 'Current number of items in cache',
  registers: [register],
});

// ============================================================================
// External Service Metrics
// ============================================================================

/**
 * TCAD API requests counter
 * Tracks requests to TCAD website
 */
export const tcadRequestsTotal = new Counter({
  name: 'tcad_scraper_tcad_requests_total',
  help: 'Total number of requests to TCAD website',
  labelNames: ['endpoint', 'status'],
  registers: [register],
});

/**
 * Claude AI API requests counter
 * Tracks requests to Claude AI API
 */
export const claudeRequestsTotal = new Counter({
  name: 'tcad_scraper_claude_requests_total',
  help: 'Total number of requests to Claude AI API',
  labelNames: ['status'],
  registers: [register],
});

/**
 * Claude AI API duration histogram
 * Tracks Claude AI response times
 */
export const claudeRequestDuration = new Histogram({
  name: 'tcad_scraper_claude_request_duration_seconds',
  help: 'Claude AI request duration in seconds',
  labelNames: ['status'],
  buckets: [0.5, 1, 2, 3, 5, 10, 15, 20, 30],
  registers: [register],
});

// ============================================================================
// Token Refresh Metrics
// ============================================================================

/**
 * Token refresh counter
 * Tracks TCAD token refresh operations
 */
export const tokenRefreshTotal = new Counter({
  name: 'tcad_scraper_token_refresh_total',
  help: 'Total number of token refresh operations',
  labelNames: ['status'], // success, failure
  registers: [register],
});

/**
 * Token age gauge
 * Tracks time since last successful token refresh
 */
export const tokenAge = new Gauge({
  name: 'tcad_scraper_token_age_seconds',
  help: 'Time since last successful token refresh in seconds',
  registers: [register],
});

// ============================================================================
// Error Metrics
// ============================================================================

/**
 * Application errors counter
 * Tracks all application errors by type
 */
export const errorsTotal = new Counter({
  name: 'tcad_scraper_errors_total',
  help: 'Total number of application errors',
  labelNames: ['type', 'source'], // type: validation/scraper/database/etc, source: controller/service/etc
  registers: [register],
});

// ============================================================================
// Code Complexity Metrics
// ============================================================================

/**
 * Cyclomatic complexity gauge
 * Tracks average cyclomatic complexity across the codebase
 */
export const codeComplexityCyclomatic = new Gauge({
  name: 'tcad_scraper_code_complexity_cyclomatic',
  help: 'Average cyclomatic complexity of functions',
  registers: [register],
});

/**
 * Maximum cyclomatic complexity gauge
 * Tracks the highest cyclomatic complexity value in the codebase
 */
export const codeComplexityMaxCyclomatic = new Gauge({
  name: 'tcad_scraper_code_complexity_max_cyclomatic',
  help: 'Maximum cyclomatic complexity of any single function',
  registers: [register],
});

/**
 * Total lines of code gauge
 * Tracks total lines of code (including blank lines and comments)
 */
export const codeComplexityTotalLines = new Gauge({
  name: 'tcad_scraper_code_complexity_total_lines',
  help: 'Total lines of code in the codebase',
  registers: [register],
});

/**
 * Code lines gauge (excluding comments and blank lines)
 * Tracks actual code lines
 */
export const codeComplexityCodeLines = new Gauge({
  name: 'tcad_scraper_code_complexity_code_lines',
  help: 'Lines of actual code (excluding comments and blank lines)',
  registers: [register],
});

/**
 * Comment lines gauge
 * Tracks number of comment lines
 */
export const codeComplexityCommentLines = new Gauge({
  name: 'tcad_scraper_code_complexity_comment_lines',
  help: 'Lines of comments in the codebase',
  registers: [register],
});

/**
 * Total files gauge
 * Tracks number of source files
 */
export const codeComplexityTotalFiles = new Gauge({
  name: 'tcad_scraper_code_complexity_total_files',
  help: 'Total number of source files',
  registers: [register],
});

/**
 * Total functions gauge
 * Tracks number of functions/methods
 */
export const codeComplexityTotalFunctions = new Gauge({
  name: 'tcad_scraper_code_complexity_total_functions',
  help: 'Total number of functions and methods',
  registers: [register],
});

/**
 * Total classes gauge
 * Tracks number of classes
 */
export const codeComplexityTotalClasses = new Gauge({
  name: 'tcad_scraper_code_complexity_total_classes',
  help: 'Total number of classes',
  registers: [register],
});

/**
 * Maximum function lines gauge
 * Tracks the largest function by line count
 */
export const codeComplexityMaxFunctionLines = new Gauge({
  name: 'tcad_scraper_code_complexity_max_function_lines',
  help: 'Maximum number of lines in any single function',
  registers: [register],
});

/**
 * File lines gauge
 * Tracks lines per file (for identifying large files)
 */
export const codeComplexityFileLines = new Gauge({
  name: 'tcad_scraper_code_complexity_file_lines',
  help: 'Number of lines per file',
  labelNames: ['file'],
  registers: [register],
});

/**
 * Maintainability index gauge
 * Tracks code maintainability score (0-100, higher is better)
 */
export const codeComplexityMaintainability = new Gauge({
  name: 'tcad_scraper_code_complexity_maintainability_index',
  help: 'Code maintainability index (0-100, higher is better)',
  registers: [register],
});

/**
 * Technical debt ratio gauge
 * Tracks ratio of technical debt (time to fix vs time to build from scratch)
 */
export const codeComplexityTechnicalDebtRatio = new Gauge({
  name: 'tcad_scraper_code_complexity_technical_debt_ratio',
  help: 'Technical debt ratio as percentage',
  registers: [register],
});

// ============================================================================
// Utility Functions
// ============================================================================

/**
 * Get all metrics in Prometheus format
 */
export async function getMetrics(): Promise<string> {
  return register.metrics();
}

/**
 * Get metric registry
 */
export function getRegistry(): Registry {
  return register;
}

/**
 * Reset all metrics (useful for testing)
 */
export function resetMetrics(): void {
  register.resetMetrics();
}

/**
 * Update queue metrics
 * Call this periodically to update queue size gauges
 */
export async function updateQueueMetrics(
  waiting: number,
  active: number,
  completed: number,
  failed: number
): Promise<void> {
  queueSize.set({ status: 'waiting' }, waiting);
  queueSize.set({ status: 'active' }, active);
  queueSize.set({ status: 'completed' }, completed);
  queueSize.set({ status: 'failed' }, failed);

  activeScrapeJobs.set(active);
}

/**
 * Update cache metrics
 * Call this periodically to update cache statistics
 */
export function updateCacheMetrics(
  hits: number,
  misses: number,
  size: number
): void {
  const total = hits + misses;
  const hitRate = total > 0 ? (hits / total) * 100 : 0;

  cacheHitRate.set(hitRate);
  cacheSize.set(size);
}

/**
 * Record HTTP request
 */
export function recordHttpRequest(
  method: string,
  route: string,
  statusCode: number,
  durationSeconds: number
): void {
  httpRequestsTotal.inc({ method, route, status_code: statusCode });
  httpRequestDuration.observe({ method, route, status_code: statusCode }, durationSeconds);
}

/**
 * Record scrape job completion
 */
export function recordScrapeJob(
  status: 'completed' | 'failed',
  durationSeconds: number,
  propertiesCount?: number
): void {
  scrapeJobsTotal.inc({ status });
  scrapeJobDuration.observe({ status }, durationSeconds);

  if (propertiesCount !== undefined && status === 'completed') {
    propertiesScrapedTotal.inc({}, propertiesCount);
  }
}

/**
 * Record database query
 */
export function recordDbQuery(
  operation: string,
  table: string,
  status: 'success' | 'error',
  durationSeconds: number
): void {
  dbQueriesTotal.inc({ operation, table, status });
  dbQueryDuration.observe({ operation, table }, durationSeconds);
}

/**
 * Record cache operation
 */
export function recordCacheOperation(
  operation: 'get' | 'set' | 'del',
  status: 'hit' | 'miss' | 'success' | 'error'
): void {
  cacheOperations.inc({ operation, status });
}

/**
 * Record error
 */
export function recordError(type: string, source: string): void {
  errorsTotal.inc({ type, source });
}

/**
 * Update code complexity metrics
 * Call this periodically (e.g., hourly) to update codebase complexity metrics
 */
export interface CodeComplexityMetrics {
  avgCyclomatic: number;
  maxCyclomatic: number;
  totalLines: number;
  codeLines: number;
  commentLines: number;
  totalFiles: number;
  totalFunctions: number;
  totalClasses: number;
  maxFunctionLines: number;
  fileMetrics?: Array<{ file: string; lines: number }>;
  maintainabilityIndex?: number;
  technicalDebtRatio?: number;
}

export function updateCodeComplexityMetrics(metrics: CodeComplexityMetrics): void {
  codeComplexityCyclomatic.set(metrics.avgCyclomatic);
  codeComplexityMaxCyclomatic.set(metrics.maxCyclomatic);
  codeComplexityTotalLines.set(metrics.totalLines);
  codeComplexityCodeLines.set(metrics.codeLines);
  codeComplexityCommentLines.set(metrics.commentLines);
  codeComplexityTotalFiles.set(metrics.totalFiles);
  codeComplexityTotalFunctions.set(metrics.totalFunctions);
  codeComplexityTotalClasses.set(metrics.totalClasses);
  codeComplexityMaxFunctionLines.set(metrics.maxFunctionLines);

  // Update per-file metrics if provided
  if (metrics.fileMetrics) {
    // Reset file metrics
    codeComplexityFileLines.reset();
    // Set new values
    metrics.fileMetrics.forEach(({ file, lines }) => {
      codeComplexityFileLines.set({ file }, lines);
    });
  }

  // Update optional metrics if provided
  if (metrics.maintainabilityIndex !== undefined) {
    codeComplexityMaintainability.set(metrics.maintainabilityIndex);
  }

  if (metrics.technicalDebtRatio !== undefined) {
    codeComplexityTechnicalDebtRatio.set(metrics.technicalDebtRatio);
  }
}

logger.info('Prometheus metrics service initialized');

export default {
  getMetrics,
  getRegistry,
  resetMetrics,
  updateQueueMetrics,
  updateCacheMetrics,
  recordHttpRequest,
  recordScrapeJob,
  recordDbQuery,
  recordCacheOperation,
  recordError,
  updateCodeComplexityMetrics,
  // Export all metrics for direct access if needed
  httpRequestsTotal,
  httpRequestDuration,
  scrapeJobsTotal,
  scrapeJobDuration,
  propertiesScrapedTotal,
  activeScrapeJobs,
  queueSize,
  queueProcessingRate,
  dbQueryDuration,
  dbConnectionsActive,
  dbQueriesTotal,
  cacheOperations,
  cacheHitRate,
  cacheSize,
  tcadRequestsTotal,
  claudeRequestsTotal,
  claudeRequestDuration,
  tokenRefreshTotal,
  tokenAge,
  errorsTotal,
  codeComplexityCyclomatic,
  codeComplexityMaxCyclomatic,
  codeComplexityTotalLines,
  codeComplexityCodeLines,
  codeComplexityCommentLines,
  codeComplexityTotalFiles,
  codeComplexityTotalFunctions,
  codeComplexityTotalClasses,
  codeComplexityMaxFunctionLines,
  codeComplexityFileLines,
  codeComplexityMaintainability,
  codeComplexityTechnicalDebtRatio,
};
</file>

<file path="lib/prisma.ts">
import { PrismaClient } from '@prisma/client';

declare global {
  var prisma: PrismaClient | undefined;
  var prismaReadOnly: PrismaClient | undefined;
}

const writeClient = global.prisma || new PrismaClient({
  log: process.env.NODE_ENV === 'development' ? ['query', 'error', 'warn'] : ['error'],
});

if (process.env.NODE_ENV !== 'production') {
  global.prisma = writeClient;
}

const readClient = global.prismaReadOnly || new PrismaClient({
  datasources: {
    db: {
      url: process.env.DATABASE_READ_ONLY_URL || process.env.DATABASE_URL,
    },
  },
  log: process.env.NODE_ENV === 'development' ? ['query', 'error', 'warn'] : ['error'],
});

if (process.env.NODE_ENV !== 'production') {
  global.prismaReadOnly = readClient;
}

export const prisma = writeClient;
export const prismaReadOnly = readClient;
</file>

<file path="lib/README_ENHANCED.md">
# lib

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "SoftwareSourceCode",
  "name": "lib",
  "description": "Directory containing 6 code files with 7 classes and 3 functions",
  "programmingLanguage": [
    {
      "@type": "ComputerLanguage",
      "name": "Typescript"
    }
  ],
  "featureList": [
    "7 class definitions",
    "3 function definitions"
  ]
}
</script>

## Overview

This directory contains 6 code file(s) with extracted schemas.

## Subdirectories

- `__tests__/`
- `fallback/`

## Files and Schemas

### `claude.service.ts` (typescript)

**Classes:**
- `ClaudeSearchService` - Line 15
- `SearchFilters` - Line 9

### `metrics.service.ts` (typescript)

**Classes:**
- `CodeComplexityMetrics` - Line 516

### `redis-cache.service.ts` (typescript)

**Classes:**
- `RedisCacheService` - Line 30

### `search-term-deduplicator.ts` (typescript)

**Classes:**
- `SearchTermDeduplicator` - Line 15
- `DeduplicationStats` - Line 7

### `sentry.service.ts` (typescript)

**Functions:**
- `sentryRequestHandler()` - Line 99
- `sentryTracingHandler()` - Line 109
- `sentryErrorHandler()` - Line 119

### `tcad-scraper.ts` (typescript)

**Classes:**
- `TCADScraper` - Line 17

---
*Generated by Enhanced Schema Generator with schema.org markup*
</file>

<file path="lib/README.md">
# lib

## Overview

This directory contains 1 code file(s) with extracted schemas.

## Files and Schemas

### `tcad-scraper.ts` (typescript)

**Classes:**
- `TCADScraper` - Line 15

**Key Imports:** `../types`, `playwright`, `winston`

---
*Generated by Schema Generator*
</file>

<file path="lib/redis-cache.service.ts">
/**
 * Redis Cache Service
 *
 * Provides caching layer for frequently accessed data with:
 * - Automatic TTL management
 * - Cache-aside pattern
 * - Serialization/deserialization
 * - Cache statistics and monitoring
 */

import { createClient, RedisClientType } from 'redis';
import winston from 'winston';
import { config } from '../config';

const logger = winston.createLogger({
  level: config.logging.level || 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.json()
  ),
  transports: [
    new winston.transports.Console({
      format: winston.format.combine(
        winston.format.colorize(),
        winston.format.simple()
      ),
    }),
  ],
});

export class RedisCacheService {
  private client: RedisClientType | null = null;
  private isConnected: boolean = false;
  private stats = {
    hits: 0,
    misses: 0,
    sets: 0,
    deletes: 0,
    errors: 0,
  };

  /**
   * Initialize Redis client connection
   */
  async connect(): Promise<void> {
    if (this.isConnected) {
      logger.warn('Redis cache already connected');
      return;
    }

    try {
      this.client = createClient({
        socket: {
          host: config.redis.host,
          port: config.redis.port,
          connectTimeout: config.redis.connectionTimeout,
        },
        password: config.redis.password,
        database: config.redis.db,
      });

      this.client.on('error', (err) => {
        logger.error('Redis cache error:', err);
        this.stats.errors++;
      });

      this.client.on('connect', () => {
        logger.info('Redis cache connecting...');
      });

      this.client.on('ready', () => {
        logger.info('Redis cache ready');
        this.isConnected = true;
      });

      this.client.on('end', () => {
        logger.info('Redis cache connection closed');
        this.isConnected = false;
      });

      await this.client.connect();
      logger.info('Redis cache service initialized');

    } catch (error) {
      logger.error('Failed to connect to Redis cache:', error);
      this.stats.errors++;
      throw error;
    }
  }

  /**
   * Get value from cache
   */
  async get<T>(key: string): Promise<T | null> {
    if (!this.client || !this.isConnected) {
      logger.warn('Redis cache not connected, skipping get');
      return null;
    }

    try {
      const value = await this.client.get(key);

      if (value === null) {
        this.stats.misses++;
        logger.debug(`Cache MISS: ${key}`);
        return null;
      }

      this.stats.hits++;
      logger.debug(`Cache HIT: ${key}`);
      return JSON.parse(value) as T;

    } catch (error) {
      logger.error(`Cache get error for key ${key}:`, error);
      this.stats.errors++;
      return null;
    }
  }

  /**
   * Set value in cache with TTL
   * @param key Cache key
   * @param value Value to cache (will be JSON stringified)
   * @param ttlSeconds Time to live in seconds (default: 300 = 5 minutes)
   */
  async set(key: string, value: any, ttlSeconds: number = 300): Promise<boolean> {
    if (!this.client || !this.isConnected) {
      logger.warn('Redis cache not connected, skipping set');
      return false;
    }

    try {
      const serialized = JSON.stringify(value);
      await this.client.setEx(key, ttlSeconds, serialized);

      this.stats.sets++;
      logger.debug(`Cache SET: ${key} (TTL: ${ttlSeconds}s)`);
      return true;

    } catch (error) {
      logger.error(`Cache set error for key ${key}:`, error);
      this.stats.errors++;
      return false;
    }
  }

  /**
   * Delete value from cache
   */
  async delete(key: string): Promise<boolean> {
    if (!this.client || !this.isConnected) {
      logger.warn('Redis cache not connected, skipping delete');
      return false;
    }

    try {
      const result = await this.client.del(key);

      this.stats.deletes++;
      logger.debug(`Cache DELETE: ${key}`);
      return result > 0;

    } catch (error) {
      logger.error(`Cache delete error for key ${key}:`, error);
      this.stats.errors++;
      return false;
    }
  }

  /**
   * Delete all keys matching a pattern
   * @param pattern Redis key pattern (e.g., "property:*")
   */
  async deletePattern(pattern: string): Promise<number> {
    if (!this.client || !this.isConnected) {
      logger.warn('Redis cache not connected, skipping delete pattern');
      return 0;
    }

    try {
      const keys = await this.client.keys(pattern);

      if (keys.length === 0) {
        return 0;
      }

      const result = await this.client.del(keys);

      this.stats.deletes += result;
      logger.info(`Cache DELETE PATTERN: ${pattern} (${result} keys deleted)`);
      return result;

    } catch (error) {
      logger.error(`Cache delete pattern error for ${pattern}:`, error);
      this.stats.errors++;
      return 0;
    }
  }

  /**
   * Check if key exists in cache
   */
  async exists(key: string): Promise<boolean> {
    if (!this.client || !this.isConnected) {
      return false;
    }

    try {
      const result = await this.client.exists(key);
      return result === 1;
    } catch (error) {
      logger.error(`Cache exists error for key ${key}:`, error);
      return false;
    }
  }

  /**
   * Get time to live for a key
   */
  async ttl(key: string): Promise<number> {
    if (!this.client || !this.isConnected) {
      return -1;
    }

    try {
      return await this.client.ttl(key);
    } catch (error) {
      logger.error(`Cache TTL error for key ${key}:`, error);
      return -1;
    }
  }

  /**
   * Flush all cache entries
   */
  async flush(): Promise<boolean> {
    if (!this.client || !this.isConnected) {
      logger.warn('Redis cache not connected, skipping flush');
      return false;
    }

    try {
      await this.client.flushDb();
      logger.info('Cache flushed');
      return true;
    } catch (error) {
      logger.error('Cache flush error:', error);
      this.stats.errors++;
      return false;
    }
  }

  /**
   * Get cache statistics
   */
  getStats() {
    const totalRequests = this.stats.hits + this.stats.misses;
    const hitRate = totalRequests > 0
      ? ((this.stats.hits / totalRequests) * 100).toFixed(2) + '%'
      : '0%';

    return {
      ...this.stats,
      totalRequests,
      hitRate,
      isConnected: this.isConnected,
    };
  }

  /**
   * Reset statistics
   */
  resetStats(): void {
    this.stats = {
      hits: 0,
      misses: 0,
      sets: 0,
      deletes: 0,
      errors: 0,
    };
    logger.info('Cache statistics reset');
  }

  /**
   * Close Redis connection
   */
  async disconnect(): Promise<void> {
    if (this.client && this.isConnected) {
      await this.client.quit();
      this.isConnected = false;
      logger.info('Redis cache disconnected');
    }
  }

  /**
   * Cache-aside pattern helper
   * Automatically gets from cache or fetches from source
   *
   * @param key Cache key
   * @param fetchFn Function to fetch data if not in cache
   * @param ttlSeconds Cache TTL in seconds
   */
  async getOrSet<T>(
    key: string,
    fetchFn: () => Promise<T>,
    ttlSeconds: number = 300
  ): Promise<T> {
    // Try to get from cache first
    const cached = await this.get<T>(key);
    if (cached !== null) {
      return cached;
    }

    // Cache miss - fetch from source
    const data = await fetchFn();

    // Store in cache for next time
    await this.set(key, data, ttlSeconds);

    return data;
  }

  /**
   * Health check
   */
  async healthCheck(): Promise<boolean> {
    if (!this.client || !this.isConnected) {
      return false;
    }

    try {
      const result = await this.client.ping();
      return result === 'PONG';
    } catch (error) {
      logger.error('Cache health check failed:', error);
      return false;
    }
  }
}

// Export singleton instance
export const cacheService = new RedisCacheService();

// Initialize on module load
cacheService.connect().catch((error) => {
  logger.error('Failed to initialize Redis cache on startup:', error);
});

// Graceful shutdown
process.on('SIGTERM', async () => {
  logger.info('SIGTERM received, closing Redis cache connection...');
  await cacheService.disconnect();
});

process.on('SIGINT', async () => {
  logger.info('SIGINT received, closing Redis cache connection...');
  await cacheService.disconnect();
});
</file>

<file path="lib/search-term-deduplicator.ts">
/**
 * Search Term Deduplicator
 *
 * Smart containment checking to avoid redundant search terms while allowing
 * useful variations that might yield unique results.
 */

export interface DeduplicationStats {
  exactDuplicates: number;
  businessSupersets: number;
  twoWordSupersets: number;
  multiWordSupersets: number;
  tooCommonTerms: number;
}

export class SearchTermDeduplicator {
  private usedTerms: Set<string>;
  private stats: DeduplicationStats;

  // Known terms that are too common and cause TCAD API timeouts (HTTP 504)
  // These terms likely have 20,000+ properties which exceeds TCAD's result limits
  private static readonly TOO_COMMON_TERMS = new Set([
    'Street', 'Drive', 'Lane', 'Road', 'Way', 'Court', 'Place', 'Circle',
    'Avenue', 'Boulevard', // These work but are at the edge
  ]);

  constructor(usedTerms: Set<string> = new Set()) {
    this.usedTerms = usedTerms;
    this.stats = {
      exactDuplicates: 0,
      businessSupersets: 0,
      twoWordSupersets: 0,
      multiWordSupersets: 0,
      tooCommonTerms: 0,
    };
  }

  /**
   * Check if a search term should be skipped based on duplication rules
   * @param term - The search term to check
   * @returns true if the term should be skipped, false if it's unique enough
   */
  public shouldSkipTerm(term: string): boolean {
    if (!term || term.length < 4) {
      return true; // Skip invalid/too-short terms
    }

    // Check if term is too common (causes TCAD API timeouts)
    if (this.isTooCommon(term)) {
      this.stats.tooCommonTerms++;
      return true;
    }

    // Check exact duplicate
    if (this.isExactDuplicate(term)) {
      this.stats.exactDuplicates++;
      return true;
    }

    // Check business entity superset (e.g., "Smith LLC" when "Smith" exists)
    if (this.isBusinessSuperset(term)) {
      this.stats.businessSupersets++;
      return true;
    }

    // Check two-word superset (e.g., "Oak Street" when both "Oak" and "Street" exist)
    if (this.isTwoWordSuperset(term)) {
      this.stats.twoWordSupersets++;
      return true;
    }

    // Check multi-word superset (e.g., "Oak Hill Street" when all three words exist)
    if (this.isMultiWordSuperset(term)) {
      this.stats.multiWordSupersets++;
      return true;
    }

    return false;
  }

  /**
   * Mark a term as used (adds to the set of known terms)
   */
  public markTermAsUsed(term: string): void {
    this.usedTerms.add(term);
  }

  /**
   * Get current deduplication statistics
   */
  public getStats(): DeduplicationStats {
    return { ...this.stats };
  }

  /**
   * Reset statistics counters
   */
  public resetStats(): void {
    this.stats = {
      exactDuplicates: 0,
      businessSupersets: 0,
      twoWordSupersets: 0,
      multiWordSupersets: 0,
      tooCommonTerms: 0,
    };
  }

  /**
   * Get total number of skipped terms
   */
  public getTotalSkipped(): number {
    return (
      this.stats.exactDuplicates +
      this.stats.businessSupersets +
      this.stats.twoWordSupersets +
      this.stats.multiWordSupersets +
      this.stats.tooCommonTerms
    );
  }

  // Private helper methods

  private isTooCommon(term: string): boolean {
    // Check if term is in the known too-common list
    // These terms cause HTTP 504 timeouts from TCAD API because they return 20,000+ results
    return SearchTermDeduplicator.TOO_COMMON_TERMS.has(term);
  }

  private isExactDuplicate(term: string): boolean {
    return this.usedTerms.has(term);
  }

  private isBusinessSuperset(term: string): boolean {
    const words = term.split(/\s+/);

    // Only check two-word combinations
    if (words.length !== 2) {
      return false;
    }

    const [base, suffix] = words;
    const businessSuffixes = /^(LLC|Inc|LTD|Ltd|Corp|Company|Partner|Partners|Assoc|Associates|Holding|Holdings|Properties|Property|Real|Develop|Development|Trust|Trusts|Estate|Estates)$/i;

    // Skip if it's a business suffix added to an existing term
    // Example: Skip "Smith LLC" if "Smith" already exists
    return businessSuffixes.test(suffix) && this.usedTerms.has(base);
  }

  private isTwoWordSuperset(term: string): boolean {
    const words = term.split(/\s+/);

    // Only check two-word combinations
    if (words.length !== 2) {
      return false;
    }

    // Skip if BOTH words already exist individually
    // Example: Skip "Oak Street" when we have both "Oak" and "Street"
    // This prevents redundant searches that would just find a subset of existing results
    return this.usedTerms.has(words[0]) && this.usedTerms.has(words[1]);
  }

  private isMultiWordSuperset(term: string): boolean {
    const words = term.split(/\s+/);

    // Only check 3+ word combinations
    if (words.length < 3) {
      return false;
    }

    // Skip if ALL words already exist individually
    // Example: Skip "Oak Hill Street" when we have "Oak", "Hill", and "Street"
    return words.every((word) => this.usedTerms.has(word));
  }

  /**
   * Get all used terms (useful for debugging or reporting)
   */
  public getUsedTerms(): string[] {
    return Array.from(this.usedTerms);
  }

  /**
   * Get count of unique terms tracked
   */
  public getUsedTermsCount(): number {
    return this.usedTerms.size;
  }
}
</file>

<file path="lib/sentry.service.ts">
/**
 * Sentry Error Tracking Service
 *
 * Provides comprehensive error tracking and performance monitoring with:
 * - Automatic error capture
 * - Performance tracing
 * - User context
 * - Release tracking
 * - Environment separation
 */

import * as Sentry from '@sentry/node';
import { ProfilingIntegration } from '@sentry/profiling-node';
import { Request, Response, NextFunction } from 'express';
import { config } from '../config';
import logger from './logger';

/**
 * Initialize Sentry with configuration
 */
export function initializeSentry(): void {
  if (!config.monitoring.sentry.enabled) {
    logger.info('Sentry monitoring is disabled');
    return;
  }

  if (!config.monitoring.sentry.dsn) {
    logger.warn('Sentry DSN not configured - skipping initialization');
    return;
  }

  Sentry.init({
    dsn: config.monitoring.sentry.dsn,
    environment: config.monitoring.sentry.environment,

    // Performance Monitoring
    tracesSampleRate: config.monitoring.sentry.tracesSampleRate,
    profilesSampleRate: config.monitoring.sentry.tracesSampleRate, // Profile 100% of sampled transactions

    // Integrations
    integrations: [
      // Performance profiling
      new ProfilingIntegration(),

      // Automatic instrumentation
      new Sentry.Integrations.Http({ tracing: true }),
      new Sentry.Integrations.Express({ app: true }),
      new Sentry.Integrations.Postgres(),
      new Sentry.Integrations.OnUncaughtException({
        onFatalError: async (err) => {
          logger.error('Fatal error:', err);
          process.exit(1);
        },
      }),
      new Sentry.Integrations.OnUnhandledRejection({
        mode: 'warn',
      }),
    ],

    // Error Filtering
    beforeSend(event, hint) {
      // Filter out expected errors
      const error = hint.originalException;

      if (error instanceof Error) {
        // Ignore rate limit errors (expected)
        if (error.message.includes('Rate limit exceeded')) {
          return null;
        }

        // Ignore 404 errors (expected)
        if (error.message.includes('not found') || error.message.includes('404')) {
          return null;
        }

        // Ignore auth errors in development
        if (config.env.isDevelopment && error.message.includes('Unauthorized')) {
          return null;
        }
      }

      return event;
    },

    // Release tracking (use git commit hash or version)
    release: config.frontend.appVersion || 'unknown',

    // Additional options
    attachStacktrace: true,
    maxBreadcrumbs: 50,
    debug: config.env.isDevelopment,
  });

  logger.info(`Sentry initialized (environment: ${config.monitoring.sentry.environment})`);
}

/**
 * Sentry request handler middleware (must be first)
 */
export const sentryRequestHandler = () => {
  if (!config.monitoring.sentry.enabled) {
    return (req: Request, res: Response, next: NextFunction) => next();
  }
  return Sentry.Handlers.requestHandler();
};

/**
 * Sentry tracing middleware (must be after requestHandler)
 */
export const sentryTracingHandler = () => {
  if (!config.monitoring.sentry.enabled) {
    return (req: Request, res: Response, next: NextFunction) => next();
  }
  return Sentry.Handlers.tracingHandler();
};

/**
 * Sentry error handler middleware (must be last, before other error handlers)
 */
export const sentryErrorHandler = () => {
  if (!config.monitoring.sentry.enabled) {
    return (err: Error, req: Request, res: Response, next: NextFunction) => next(err);
  }
  return Sentry.Handlers.errorHandler({
    shouldHandleError(error) {
      // Capture all 5xx errors
      return true;
    },
  });
};

/**
 * Manually capture an exception
 */
export function captureException(error: Error, context?: Record<string, any>): string {
  if (!config.monitoring.sentry.enabled) {
    logger.error('Error (Sentry disabled):', error);
    return '';
  }

  return Sentry.captureException(error, {
    extra: context,
  });
}

/**
 * Capture a message
 */
export function captureMessage(message: string, level: Sentry.SeverityLevel = 'info', context?: Record<string, any>): string {
  if (!config.monitoring.sentry.enabled) {
    logger.info(`Message (Sentry disabled) [${level}]:`, message);
    return '';
  }

  return Sentry.captureMessage(message, {
    level,
    extra: context,
  });
}

/**
 * Add breadcrumb for debugging
 */
export function addBreadcrumb(breadcrumb: {
  message: string;
  category?: string;
  level?: Sentry.SeverityLevel;
  data?: Record<string, any>;
}): void {
  if (!config.monitoring.sentry.enabled) {
    return;
  }

  Sentry.addBreadcrumb({
    message: breadcrumb.message,
    category: breadcrumb.category || 'default',
    level: breadcrumb.level || 'info',
    data: breadcrumb.data,
    timestamp: Date.now() / 1000,
  });
}

/**
 * Set user context for error tracking
 */
export function setUser(user: {
  id?: string;
  email?: string;
  username?: string;
  ip_address?: string;
}): void {
  if (!config.monitoring.sentry.enabled) {
    return;
  }

  Sentry.setUser(user);
}

/**
 * Clear user context
 */
export function clearUser(): void {
  if (!config.monitoring.sentry.enabled) {
    return;
  }

  Sentry.setUser(null);
}

/**
 * Set custom context for error tracking
 */
export function setContext(name: string, context: Record<string, any>): void {
  if (!config.monitoring.sentry.enabled) {
    return;
  }

  Sentry.setContext(name, context);
}

/**
 * Set tags for filtering and grouping
 */
export function setTag(key: string, value: string): void {
  if (!config.monitoring.sentry.enabled) {
    return;
  }

  Sentry.setTag(key, value);
}

/**
 * Set multiple tags at once
 */
export function setTags(tags: Record<string, string>): void {
  if (!config.monitoring.sentry.enabled) {
    return;
  }

  Sentry.setTags(tags);
}

/**
 * Start a performance transaction
 */
export function startTransaction(name: string, op: string): Sentry.Transaction | null {
  if (!config.monitoring.sentry.enabled) {
    return null;
  }

  return Sentry.startTransaction({
    name,
    op,
  });
}

/**
 * Wrap async function with error tracking
 */
export function wrapAsync<T extends (...args: any[]) => Promise<any>>(
  fn: T,
  name?: string
): T {
  if (!config.monitoring.sentry.enabled) {
    return fn;
  }

  return (async (...args: any[]) => {
    const transaction = Sentry.startTransaction({
      name: name || fn.name || 'anonymous',
      op: 'function',
    });

    try {
      const result = await fn(...args);
      transaction.setStatus('ok');
      return result;
    } catch (error) {
      transaction.setStatus('internal_error');
      Sentry.captureException(error);
      throw error;
    } finally {
      transaction.finish();
    }
  }) as T;
}

/**
 * Flush all pending events (useful before shutdown)
 */
export async function flush(timeout: number = 2000): Promise<boolean> {
  if (!config.monitoring.sentry.enabled) {
    return true;
  }

  return await Sentry.flush(timeout);
}

/**
 * Close Sentry client
 */
export async function close(timeout: number = 2000): Promise<boolean> {
  if (!config.monitoring.sentry.enabled) {
    return true;
  }

  return await Sentry.close(timeout);
}

/**
 * Get Sentry health status
 */
export function getHealth(): {
  enabled: boolean;
  dsn: string | null;
  environment: string;
  release: string;
} {
  return {
    enabled: config.monitoring.sentry.enabled,
    dsn: config.monitoring.sentry.dsn ? 'configured' : null,
    environment: config.monitoring.sentry.environment,
    release: config.frontend.appVersion || 'unknown',
  };
}

// Export Sentry for direct access if needed
export { Sentry };
</file>

<file path="lib/tcad-scraper.ts">
import { chromium, Browser, Page, BrowserContext } from 'playwright';
import winston from 'winston';
import { ScraperConfig, PropertyData } from '../types';
import { config as appConfig } from '../config';
import { scrapeDOMFallback } from './fallback/dom-scraper';
import { tokenRefreshService } from '../services/token-refresh.service';

const logger = winston.createLogger({
  level: appConfig.logging.level,
  format: winston.format.json(),
  transports: [
    new winston.transports.Console({
      format: winston.format.simple(),
    }),
  ],
});

export class TCADScraper {
  private browser: Browser | null = null;
  private config: ScraperConfig;

  constructor(config?: Partial<ScraperConfig>) {
    // Configure proxy if enabled
    let proxyConfig = {};

    if (appConfig.scraper.brightData.enabled && appConfig.scraper.brightData.apiToken) {
      // Bright Data proxy configuration
      proxyConfig = {
        proxyServer: `http://${appConfig.scraper.brightData.proxyHost}:${appConfig.scraper.brightData.proxyPort}`,
        proxyUsername: `brd-customer-${appConfig.scraper.brightData.apiToken.substring(0, 8)}-zone-residential`,
        proxyPassword: appConfig.scraper.brightData.apiToken,
      };
      logger.info('Bright Data proxy configured');
    } else if (appConfig.scraper.proxy.enabled && appConfig.scraper.proxy.server) {
      // Generic proxy configuration
      proxyConfig = {
        proxyServer: appConfig.scraper.proxy.server,
        proxyUsername: appConfig.scraper.proxy.username,
        proxyPassword: appConfig.scraper.proxy.password,
      };
      logger.info('Generic proxy configured');
    }

    this.config = {
      headless: appConfig.scraper.headless,
      timeout: appConfig.scraper.timeout,
      retryAttempts: appConfig.scraper.retryAttempts,
      retryDelay: appConfig.scraper.retryDelay,
      userAgents: appConfig.scraper.userAgents,
      viewports: appConfig.scraper.viewports,
      ...proxyConfig,
      ...config,
    };
  }

  async initialize(): Promise<void> {
    try {
      const proxyEnabled = !!this.config.proxyServer;
      logger.info(`Initializing browser${proxyEnabled ? ' with Bright Data proxy' : ''}...`);

      const launchOptions: any = {
        headless: this.config.headless,
        executablePath: process.env.PLAYWRIGHT_CHROMIUM_EXECUTABLE_PATH || undefined,
        args: [
          '--disable-blink-features=AutomationControlled',
          '--disable-web-security',
          '--disable-features=IsolateOrigins,site-per-process',
          '--no-sandbox',
          '--disable-setuid-sandbox',
        ],
      };

      // Add proxy configuration if available
      if (this.config.proxyServer) {
        launchOptions.proxy = {
          server: this.config.proxyServer,
          username: this.config.proxyUsername,
          password: this.config.proxyPassword,
        };
        logger.info(`Using proxy: ${this.config.proxyServer}`);
      }

      this.browser = await chromium.launch(launchOptions);
      logger.info('Browser initialized successfully');
    } catch (error) {
      logger.error('Failed to initialize browser:', error);
      throw error;
    }
  }

  private getRandomElement<T>(array: T[]): T {
    return array[Math.floor(Math.random() * array.length)];
  }

  private async humanDelay(
    min: number = appConfig.scraper.humanDelay.min,
    max: number = appConfig.scraper.humanDelay.max
  ): Promise<void> {
    const delay = Math.floor(Math.random() * (max - min) + min);
    await new Promise(resolve => setTimeout(resolve, delay));
  }

  /**
   * PRIMARY METHOD: Scrape properties using direct API calls through browser context
   *
   * This is the RECOMMENDED method that:
   * - Bypasses the 20-result UI limitation
   * - Can fetch up to 1000 results per API call
   * - Handles authentication automatically
   * - Implements adaptive page sizing
   *
   * If this method fails after all retries, the system will automatically
   * fall back to DOM-based scraping (limited to 20 results).
   *
   * @param searchTerm - The search term to query
   * @param maxRetries - Maximum retry attempts (default: 3)
   * @returns Array of PropertyData
   * @throws Error if all API attempts fail (triggers fallback in calling code)
   */
  async scrapePropertiesViaAPI(searchTerm: string, maxRetries: number = 3): Promise<PropertyData[]> {
    if (!this.browser) {
      throw new Error('Browser not initialized. Call initialize() first.');
    }

    let lastError: Error | null = null;

    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        logger.info(`API scraping attempt ${attempt} for search term: ${searchTerm}`);

        const context = await this.browser.newContext({
          userAgent: this.getRandomElement(this.config.userAgents),
          viewport: this.getRandomElement(this.config.viewports),
          locale: 'en-US',
          timezoneId: 'America/Chicago',
        });

        const page = await context.newPage();

        try {
          // Step 1: Get auth token - priority order:
          // 1. Token from auto-refresh service (if enabled)
          // 2. Token from environment/config
          // 3. Capture from browser (fallback)
          let authToken: string | null = null;

          // Try to get token from refresh service first (if auto-refresh is enabled)
          if (appConfig.scraper.autoRefreshToken) {
            authToken = tokenRefreshService.getCurrentToken();
            if (authToken) {
              logger.info('Using token from auto-refresh service');
            }
          }

          // Fall back to config token if refresh service doesn't have one
          if (!authToken) {
            authToken = appConfig.scraper.tcadApiKey || null;
          }

          if (authToken) {
            logger.info('Using pre-fetched TCAD_API_KEY from environment');
          } else {
            logger.info('No TCAD_API_KEY found, capturing token from browser...');

            page.on('request', (request) => {
              const headers = request.headers();
              const authHeader = headers['authorization'];

              // Only capture valid tokens (ignore "null" string and ensure it looks like a JWT)
              if (authHeader &&
                  authHeader !== 'null' &&
                  authHeader.length > 50 &&
                  authHeader.startsWith('eyJ') &&
                  !authToken) {
                authToken = authHeader;
                logger.info(`Auth token captured: length ${authToken.length}, preview: ${authToken.substring(0, 50)}...`);
              }
            });

            await page.goto('https://travis.prodigycad.com/property-search', {
              waitUntil: 'networkidle',
              timeout: this.config.timeout,
            });

            logger.info('Page loaded, waiting for React app...');

            await page.waitForFunction(() => {
              const root = document.getElementById('root');
              return root && root.children.length > 0;
            }, { timeout: 15000 });

            // Trigger a search to activate auth token
            await page.waitForSelector('#searchInput', { timeout: 10000 });
            await this.humanDelay(500, 1000);
            await page.type('#searchInput', 'test', { delay: 50 });
            await page.press('#searchInput', 'Enter');
            await this.humanDelay(3000, 4000); // Wait for API request to be made

            if (!authToken) {
              throw new Error('Failed to capture authorization token');
            }

            logger.info('Auth token captured from browser');
          }

          // Step 2: Make API calls from browser context using string injection to avoid tsx transformation
          // Inject function as raw string to bypass __name issues
          await page.addScriptTag({
            content: `
              window.__tcad_search = function(token, term) {
                const apiUrl = 'https://prod-container.trueprodigyapi.com/public/property/searchfulltext';
                const pageSizes = [1000, 500, 100, 50];
                let currentSizeIndex = 0;
                let lastErr = '';

                return new Promise(function(resolve, reject) {
                  function tryNextPageSize() {
                    if (currentSizeIndex >= pageSizes.length) {
                      reject(new Error('All page sizes failed. Last: ' + lastErr));
                      return;
                    }

                    const pageSize = pageSizes[currentSizeIndex];
                    const allResults = [];
                    let totalCount = 0;
                    let currentPage = 1;

                    // Fetch first page
                    fetch(apiUrl + '?page=1&pageSize=' + pageSize, {
                      method: 'POST',
                      headers: {
                        'Authorization': token,
                        'Content-Type': 'application/json',
                        'Accept': 'application/json'
                      },
                      body: JSON.stringify({
                        pYear: { operator: '=', value: '2025' },
                        fullTextSearch: { operator: 'match', value: term }
                      })
                    })
                    .then(function(r) {
                      if (!r.ok) throw new Error('HTTP ' + r.status);
                      return r.text();
                    })
                    .then(function(text) {
                      const trimmed = text.trim();
                      if (trimmed.length > 0 && trimmed[trimmed.length - 1] !== '}' && trimmed[trimmed.length - 1] !== ']') {
                        throw new Error('TRUNCATED');
                      }

                      const data = JSON.parse(trimmed);
                      totalCount = data.totalProperty?.propertyCount || 0;
                      const firstPageResults = data.results || [];
                      allResults.push.apply(allResults, firstPageResults);

                      if (allResults.length >= totalCount || firstPageResults.length < pageSize) {
                        resolve({ totalCount: totalCount, results: allResults, pageSize: pageSize });
                        return;
                      }

                      // Fetch remaining pages
                      function fetchNextPage() {
                        currentPage++;
                        if (allResults.length >= totalCount || currentPage > 100) {
                          resolve({ totalCount: totalCount, results: allResults, pageSize: pageSize });
                          return;
                        }

                        fetch(apiUrl + '?page=' + currentPage + '&pageSize=' + pageSize, {
                          method: 'POST',
                          headers: {
                            'Authorization': token,
                            'Content-Type': 'application/json',
                            'Accept': 'application/json'
                          },
                          body: JSON.stringify({
                            pYear: { operator: '=', value: '2025' },
                            fullTextSearch: { operator: 'match', value: term }
                          })
                        })
                        .then(function(r) {
                          if (!r.ok) throw new Error('HTTP ' + r.status);
                          return r.text();
                        })
                        .then(function(text) {
                          const trimmed = text.trim();
                          if (trimmed.length > 0 && trimmed[trimmed.length - 1] !== '}' && trimmed[trimmed.length - 1] !== ']') {
                            throw new Error('TRUNCATED');
                          }

                          const data = JSON.parse(trimmed);
                          const pageResults = data.results || [];
                          allResults.push.apply(allResults, pageResults);

                          if (pageResults.length < pageSize || allResults.length >= totalCount) {
                            resolve({ totalCount: totalCount, results: allResults, pageSize: pageSize });
                          } else {
                            fetchNextPage();
                          }
                        })
                        .catch(function(err) {
                          if (err.message === 'TRUNCATED' || err.message.indexOf('JSON') >= 0) {
                            currentSizeIndex++;
                            lastErr = err.message;
                            tryNextPageSize();
                          } else {
                            reject(err);
                          }
                        });
                      }

                      fetchNextPage();
                    })
                    .catch(function(err) {
                      if (err.message === 'TRUNCATED' || err.message.indexOf('JSON') >= 0) {
                        currentSizeIndex++;
                        lastErr = err.message;
                        tryNextPageSize();
                      } else {
                        reject(err);
                      }
                    });
                  }

                  tryNextPageSize();
                });
              };
            `
          });

          // Call the injected function
          const allProperties = await page.evaluate(`window.__tcad_search('${authToken}', '${searchTerm.replace(/'/g, "\\'")}')`) as any;

          logger.info(`API returned ${allProperties.totalCount} total properties, fetched ${allProperties.results.length} results (pageSize: ${allProperties.pageSize})`);

          // Step 3: Transform API response to PropertyData format
          const properties: PropertyData[] = allProperties.results.map((r: any) => ({
            propertyId: r.pid?.toString() || '',
            name: r.displayName || '',
            propType: r.propType || '',
            city: r.city || null,
            propertyAddress: r.streetPrimary || '',
            assessedValue: parseFloat(r.assessedValue) || 0,
            appraisedValue: parseFloat(r.appraisedValue) || 0,
            geoId: r.geoID || null,
            description: r.legalDescription || null,
          }));

          logger.info(`Extracted ${properties.length} properties via API`);

          return properties;

        } finally {
          await context.close();
        }

      } catch (error) {
        lastError = error as Error;
        logger.error(`API scraping attempt ${attempt} failed:`, error);

        if (attempt < maxRetries) {
          const delay = this.config.retryDelay * Math.pow(2, attempt - 1);
          logger.info(`Retrying in ${delay}ms...`);
          await new Promise(resolve => setTimeout(resolve, delay));
        }
      }
    }

    throw lastError || new Error('All API scraping attempts failed');
  }

  /**
   * FALLBACK METHOD: Scrape properties with automatic fallback to DOM scraping
   *
   * This method attempts the primary API-based scraping first.
   * If the API method fails after all retries, it automatically falls back
   * to DOM-based scraping (limited to 20 results).
   *
   * @param searchTerm - The search term to query
   * @param maxRetries - Maximum retry attempts for each method
   * @returns Array of PropertyData
   */
  async scrapePropertiesWithFallback(searchTerm: string, maxRetries: number = 3): Promise<PropertyData[]> {
    logger.info(`Starting scrape for: ${searchTerm}`);

    try {
      logger.info(' Attempting primary method: API-based scraping');
      const properties = await this.scrapePropertiesViaAPI(searchTerm, maxRetries);
      logger.info(` Primary method succeeded: Retrieved ${properties.length} properties`);
      return properties;
    } catch (apiError) {
      logger.error(' Primary API method failed after all retries:', apiError);
      logger.warn(' Falling back to DOM-based scraping (limited to 20 results)');

      try {
        const properties = await scrapeDOMFallback(
          this.browser!,
          this.config,
          searchTerm,
          maxRetries
        );
        logger.info(` Fallback method succeeded: Retrieved ${properties.length} properties (max 20)`);
        return properties;
      } catch (fallbackError) {
        logger.error(' Fallback method also failed:', fallbackError);
        throw new Error(
          `Both scraping methods failed. API error: ${(apiError as Error).message}. ` +
          `Fallback error: ${(fallbackError as Error).message}`
        );
      }
    }
  }

  /**
   * @deprecated Legacy DOM scraping method - moved to fallback/dom-scraper.ts
   * Use scrapePropertiesWithFallback() instead for automatic fallback support.
   *
   * The legacy scrapeProperties() method has been extracted to:
   * server/src/lib/fallback/dom-scraper.ts
   *
   * This keeps the main scraper file focused on the primary API method,
   * while the fallback mechanism is clearly separated and documented.
   */

  /**
   * Helper method to discover API endpoints (for debugging/development)
   */
  private async discoverApiEndpoint(searchTerm: string): Promise<void> {
    if (!this.browser) {
      throw new Error('Browser not initialized. Call initialize() first.');
    }

    const context = await this.browser.newContext({
      userAgent: this.getRandomElement(this.config.userAgents),
      viewport: { width: 1920, height: 1080 },
    });

    const page = await context.newPage();

    // Capture all network requests
    const apiRequests: Array<{ url: string; method: string; postData?: string; response?: any }> = [];

    page.on('request', (request) => {
      const url = request.url();
      // Look for API-like requests (JSON, contains "api", "search", "property", etc.)
      if (url.includes('api') || url.includes('search') || url.includes('property') || url.includes('data')) {
        apiRequests.push({
          url,
          method: request.method(),
          postData: request.postData() || undefined,
        });
        logger.info(` API Request: ${request.method()} ${url}`);
      }
    });

    page.on('response', async (response) => {
      const url = response.url();
      if (url.includes('api') || url.includes('search') || url.includes('property') || url.includes('data')) {
        try {
          const contentType = response.headers()['content-type'] || '';
          if (contentType.includes('application/json')) {
            const json = await response.json();
            logger.info(` API Response from ${url}:`, JSON.stringify(json).substring(0, 500));

            // Find matching request and attach response
            const matchingRequest = apiRequests.find(r => r.url === url && !r.response);
            if (matchingRequest) {
              matchingRequest.response = json;
            }
          }
        } catch (error) {
          // Response might not be JSON
        }
      }
    });

    try {
      // Navigate to search page
      await page.goto('https://stage.travis.prodigycad.com/property-search', {
        waitUntil: 'networkidle',
        timeout: 30000,
      });

      logger.info('Page loaded, performing search to trigger API calls...');

      // Wait for search input
      await page.waitForSelector('input[type="text"]', { timeout: 10000 });
      await this.humanDelay(500, 1000);

      // Type search term
      await page.type('input[type="text"]', searchTerm, { delay: 50 });
      await this.humanDelay(300, 700);

      // Submit search
      await page.press('input[type="text"]', 'Enter');

      // Wait for results or API calls
      await this.humanDelay(5000, 7000);

      logger.info(`\n=== API Discovery Summary ===`);
      logger.info(`Found ${apiRequests.length} API-like requests:`);

      for (const req of apiRequests) {
        logger.info(`\n  ${req.method} ${req.url}`);
        if (req.postData) {
          logger.info(`  POST Data: ${req.postData.substring(0, 200)}`);
        }
        if (req.response) {
          logger.info(`  Response Preview: ${JSON.stringify(req.response).substring(0, 300)}...`);
        }
      }

    } finally {
      await context.close();
    }
  }

  private async scrapePropertyDetail(page: Page, propertyId: string): Promise<PropertyData | null> {
    try {
      // Navigate to property detail page
      const detailUrl = `https://stage.travis.prodigycad.com/property-detail?pid=${propertyId}`;
      await page.goto(detailUrl, {
        waitUntil: 'networkidle',
        timeout: 15000,
      });

      // Wait for content to load
      await this.humanDelay(1000, 2000);

      // Extract all property details from the detail page
      const propertyData = await page.evaluate(() => {
        // Helper function to get text content by label
        const getValueByLabel = (labelText: string): string | null => {
          // Try multiple selector strategies
          const labels = document.querySelectorAll('label, dt, th, .label, [class*="label"]');

          let labelIdx = 0;
          while (labelIdx < labels.length) {
            const label = labels[labelIdx];
            const text = label.textContent?.trim().toLowerCase() || '';

            if (text.includes(labelText.toLowerCase())) {
              // Try to find the associated value
              // Strategy 1: Next sibling
              let valueElem = label.nextElementSibling;
              if (valueElem && valueElem.textContent) {
                return valueElem.textContent.trim();
              }

              // Strategy 2: Parent's next sibling
              if (label.parentElement) {
                valueElem = label.parentElement.nextElementSibling;
                if (valueElem && valueElem.textContent) {
                  return valueElem.textContent.trim();
                }
              }

              // Strategy 3: Within same row (td after th)
              if (label.tagName === 'TH') {
                const row = label.closest('tr');
                if (row) {
                  const cells = row.querySelectorAll('td');
                  if (cells.length > 0) {
                    return cells[0].textContent?.trim() || null;
                  }
                }
              }
            }

            labelIdx++;
          }

          return null;
        };

        // Extract fields
        const name = getValueByLabel('owner') || getValueByLabel('name') || '';
        const propType = getValueByLabel('property type') || getValueByLabel('type') || '';
        const city = getValueByLabel('city') || getValueByLabel('situs city') || null;
        const propertyAddress = getValueByLabel('address') || getValueByLabel('situs address') || getValueByLabel('street') || '';

        // Parse appraised value
        const appraisedValueText = getValueByLabel('appraised value') ||
                                   getValueByLabel('market value') ||
                                   getValueByLabel('total value') || '0';
        const appraisedValue = parseFloat(appraisedValueText.replace(/[$,]/g, '')) || 0;

        // Parse assessed value
        const assessedValueText = getValueByLabel('assessed value') ||
                                  getValueByLabel('taxable value') || '0';
        const assessedValue = parseFloat(assessedValueText.replace(/[$,]/g, '')) || 0;

        const geoId = getValueByLabel('geo id') || getValueByLabel('geographic id') || null;
        const description = getValueByLabel('legal description') || getValueByLabel('description') || null;

        return {
          name,
          propType,
          city,
          propertyAddress,
          appraisedValue,
          assessedValue,
          geoId,
          description,
        };
      });

      // Return complete property data
      return {
        propertyId,
        ...propertyData,
      };

    } catch (error) {
      logger.error(`Error scraping detail page for property ${propertyId}:`, error);
      return null;
    }
  }

  async cleanup(): Promise<void> {
    if (this.browser) {
      logger.info('Closing browser...');
      await this.browser.close();
      this.browser = null;
      logger.info('Browser closed');
    }
  }

  // Helper method for health check
  async testConnection(): Promise<boolean> {
    try {
      await this.initialize();
      const context = await this.browser!.newContext();
      const page = await context.newPage();

      const response = await page.goto('https://travis.prodigycad.com/property-search', {
        waitUntil: 'domcontentloaded',
        timeout: 10000,
      });

      await context.close();
      return response?.status() === 200;
    } catch (error) {
      logger.error('Connection test failed:', error);
      return false;
    } finally {
      await this.cleanup();
    }
  }
}

// Export a singleton instance for reuse
export const scraperInstance = new TCADScraper();
</file>

<file path="middleware/__tests__/auth.test.ts">
import { Request, Response, NextFunction } from 'express';
import jwt from 'jsonwebtoken';
import { apiKeyAuth, jwtAuth, optionalAuth, generateToken, AuthRequest } from '../auth';

// Mock the config module
jest.mock('../../config', () => ({
  config: {
    env: {
      isDevelopment: false,
    },
    auth: {
      apiKey: 'test-api-key',
      skipInDevelopment: false,
      jwt: {
        secret: 'test-jwt-secret',
        expiresIn: '1h',
      },
    },
  },
}));

describe('Auth Middleware', () => {
  let mockReq: Partial<AuthRequest>;
  let mockRes: Partial<Response>;
  let mockNext: NextFunction;
  let jsonMock: jest.Mock;
  let statusMock: jest.Mock;

  beforeEach(() => {
    jsonMock = jest.fn();
    statusMock = jest.fn().mockReturnValue({ json: jsonMock });

    mockReq = {
      headers: {},
    };

    mockRes = {
      status: statusMock,
      json: jsonMock,
    };

    mockNext = jest.fn();

    // Reset config to default test values
    const { config } = require('../../config');
    config.env.isDevelopment = false;
    config.auth.skipInDevelopment = false;
    config.auth.apiKey = 'test-api-key';
    config.auth.jwt.secret = 'test-jwt-secret';
  });

  describe('apiKeyAuth', () => {
    it('should allow request with valid API key', () => {
      mockReq.headers = { 'x-api-key': 'test-api-key' };

      apiKeyAuth(mockReq as Request, mockRes as Response, mockNext);

      expect(mockNext).toHaveBeenCalled();
      expect(statusMock).not.toHaveBeenCalled();
    });

    it('should reject request with invalid API key', () => {
      mockReq.headers = { 'x-api-key': 'wrong-key' };

      apiKeyAuth(mockReq as Request, mockRes as Response, mockNext);

      expect(mockNext).not.toHaveBeenCalled();
      expect(statusMock).toHaveBeenCalledWith(401);
      expect(jsonMock).toHaveBeenCalledWith({ error: 'Unauthorized - Invalid API key' });
    });

    it('should reject request without API key', () => {
      mockReq.headers = {};

      apiKeyAuth(mockReq as Request, mockRes as Response, mockNext);

      expect(mockNext).not.toHaveBeenCalled();
      expect(statusMock).toHaveBeenCalledWith(401);
      expect(jsonMock).toHaveBeenCalledWith({ error: 'Unauthorized - Invalid API key' });
    });

    it('should skip auth in development when skipInDevelopment is true and no API key configured', () => {
      const { config } = require('../../config');
      config.env.isDevelopment = true;
      config.auth.skipInDevelopment = true;
      config.auth.apiKey = undefined;

      mockReq.headers = {};

      apiKeyAuth(mockReq as Request, mockRes as Response, mockNext);

      expect(mockNext).toHaveBeenCalled();
      expect(statusMock).not.toHaveBeenCalled();
    });

    it('should still validate API key in development if skipInDevelopment is false', () => {
      const { config } = require('../../config');
      config.env.isDevelopment = true;
      config.auth.skipInDevelopment = false;

      mockReq.headers = {};

      apiKeyAuth(mockReq as Request, mockRes as Response, mockNext);

      expect(mockNext).not.toHaveBeenCalled();
      expect(statusMock).toHaveBeenCalledWith(401);
    });
  });

  describe('jwtAuth', () => {
    it('should allow request with valid JWT token', () => {
      const token = jwt.sign({ id: 'user123', email: 'test@example.com' }, 'test-jwt-secret');
      mockReq.headers = { authorization: `Bearer ${token}` };

      jwtAuth(mockReq as AuthRequest, mockRes as Response, mockNext);

      expect(mockNext).toHaveBeenCalled();
      expect(statusMock).not.toHaveBeenCalled();
      expect(mockReq.user).toMatchObject({ id: 'user123', email: 'test@example.com' });
    });

    it('should allow request with valid JWT token without email', () => {
      const token = jwt.sign({ id: 'user123' }, 'test-jwt-secret');
      mockReq.headers = { authorization: `Bearer ${token}` };

      jwtAuth(mockReq as AuthRequest, mockRes as Response, mockNext);

      expect(mockNext).toHaveBeenCalled();
      expect(mockReq.user).toMatchObject({ id: 'user123' });
    });

    it('should reject request with invalid JWT token', () => {
      mockReq.headers = { authorization: 'Bearer invalid-token' };

      jwtAuth(mockReq as AuthRequest, mockRes as Response, mockNext);

      expect(mockNext).not.toHaveBeenCalled();
      expect(statusMock).toHaveBeenCalledWith(403);
      expect(jsonMock).toHaveBeenCalledWith({ error: 'Forbidden - Invalid token' });
    });

    it('should reject request without token', () => {
      mockReq.headers = {};

      jwtAuth(mockReq as AuthRequest, mockRes as Response, mockNext);

      expect(mockNext).not.toHaveBeenCalled();
      expect(statusMock).toHaveBeenCalledWith(401);
      expect(jsonMock).toHaveBeenCalledWith({ error: 'Unauthorized - No token provided' });
    });

    it('should reject request with malformed authorization header', () => {
      mockReq.headers = { authorization: 'InvalidFormat' };

      jwtAuth(mockReq as AuthRequest, mockRes as Response, mockNext);

      expect(mockNext).not.toHaveBeenCalled();
      expect(statusMock).toHaveBeenCalledWith(401);
    });

    it('should reject request with expired JWT token', () => {
      const expiredToken = jwt.sign(
        { id: 'user123', email: 'test@example.com' },
        'test-jwt-secret',
        { expiresIn: '-1h' }
      );
      mockReq.headers = { authorization: `Bearer ${expiredToken}` };

      jwtAuth(mockReq as AuthRequest, mockRes as Response, mockNext);

      expect(mockNext).not.toHaveBeenCalled();
      expect(statusMock).toHaveBeenCalledWith(403);
      expect(jsonMock).toHaveBeenCalledWith({ error: 'Forbidden - Invalid token' });
    });

    it('should skip auth in development when skipInDevelopment is true and no JWT secret configured', () => {
      const { config } = require('../../config');
      config.env.isDevelopment = true;
      config.auth.skipInDevelopment = true;
      config.auth.jwt.secret = undefined;

      mockReq.headers = {};

      jwtAuth(mockReq as AuthRequest, mockRes as Response, mockNext);

      expect(mockNext).toHaveBeenCalled();
      expect(statusMock).not.toHaveBeenCalled();
    });
  });

  describe('optionalAuth', () => {
    it('should attach user to request when valid token provided', () => {
      const token = jwt.sign({ id: 'user123', email: 'test@example.com' }, 'test-jwt-secret');
      mockReq.headers = { authorization: `Bearer ${token}` };

      optionalAuth(mockReq as AuthRequest, mockRes as Response, mockNext);

      expect(mockNext).toHaveBeenCalled();
      expect(mockReq.user).toMatchObject({ id: 'user123', email: 'test@example.com' });
    });

    it('should continue without user when no token provided', () => {
      mockReq.headers = {};

      optionalAuth(mockReq as AuthRequest, mockRes as Response, mockNext);

      expect(mockNext).toHaveBeenCalled();
      expect(mockReq.user).toBeUndefined();
    });

    it('should continue without user when invalid token provided', () => {
      mockReq.headers = { authorization: 'Bearer invalid-token' };

      optionalAuth(mockReq as AuthRequest, mockRes as Response, mockNext);

      expect(mockNext).toHaveBeenCalled();
      expect(mockReq.user).toBeUndefined();
    });

    it('should continue without user when token secret is not configured', () => {
      const { config } = require('../../config');
      config.auth.jwt.secret = undefined;

      const token = jwt.sign({ id: 'user123' }, 'some-secret');
      mockReq.headers = { authorization: `Bearer ${token}` };

      optionalAuth(mockReq as AuthRequest, mockRes as Response, mockNext);

      expect(mockNext).toHaveBeenCalled();
      expect(mockReq.user).toBeUndefined();
    });
  });

  describe('generateToken', () => {
    it('should generate valid JWT token with user ID and email', () => {
      const token = generateToken('user123', 'test@example.com');

      expect(token).toBeTruthy();
      expect(typeof token).toBe('string');

      const decoded = jwt.verify(token, 'test-jwt-secret') as any;
      expect(decoded.id).toBe('user123');
      expect(decoded.email).toBe('test@example.com');
      expect(decoded.exp).toBeTruthy();
    });

    it('should generate valid JWT token with only user ID', () => {
      const token = generateToken('user123');

      expect(token).toBeTruthy();

      const decoded = jwt.verify(token, 'test-jwt-secret') as any;
      expect(decoded.id).toBe('user123');
      expect(decoded.email).toBeUndefined();
    });

    it('should generate token that expires according to config', () => {
      const { config } = require('../../config');
      config.auth.jwt.expiresIn = '2h';

      const token = generateToken('user123');
      const decoded = jwt.verify(token, 'test-jwt-secret') as any;

      const now = Math.floor(Date.now() / 1000);
      const expectedExpiration = now + 2 * 60 * 60; // 2 hours from now

      // Allow 5 second tolerance
      expect(decoded.exp).toBeGreaterThan(now);
      expect(decoded.exp).toBeLessThanOrEqual(expectedExpiration + 5);
    });
  });
});
</file>

<file path="middleware/__tests__/error.middleware.test.ts">
import { Request, Response, NextFunction } from 'express';
import { asyncHandler, errorHandler, notFoundHandler } from '../error.middleware';
import logger from '../../lib/logger';

// Mock logger
jest.mock('../../lib/logger', () => ({
  error: jest.fn(),
}));

describe('Error Middleware', () => {
  let mockReq: Partial<Request>;
  let mockRes: Partial<Response>;
  let mockNext: NextFunction;
  let jsonMock: jest.Mock;
  let statusMock: jest.Mock;

  beforeEach(() => {
    jsonMock = jest.fn();
    statusMock = jest.fn().mockReturnValue({ json: jsonMock });

    mockReq = {
      method: 'GET',
      path: '/test-path',
    };

    mockRes = {
      status: statusMock,
      json: jsonMock,
    };

    mockNext = jest.fn();

    // Clear mock calls
    jest.clearAllMocks();
  });

  describe('asyncHandler', () => {
    it('should call next with error when async function throws', async () => {
      const error = new Error('Test error');
      const asyncFn = jest.fn().mockRejectedValue(error);

      const wrappedFn = asyncHandler(asyncFn);
      wrappedFn(mockReq as Request, mockRes as Response, mockNext);

      // Wait for promise to resolve
      await new Promise(resolve => setImmediate(resolve));

      expect(mockNext).toHaveBeenCalledWith(error);
      expect(asyncFn).toHaveBeenCalledWith(mockReq, mockRes, mockNext);
    });

    it('should not call next when async function succeeds', async () => {
      const asyncFn = jest.fn().mockResolvedValue('success');

      const wrappedFn = asyncHandler(asyncFn);
      wrappedFn(mockReq as Request, mockRes as Response, mockNext);

      // Wait for promise to resolve
      await new Promise(resolve => setImmediate(resolve));

      expect(mockNext).not.toHaveBeenCalled();
      expect(asyncFn).toHaveBeenCalledWith(mockReq, mockRes, mockNext);
    });

    it('should handle errors in async operations', async () => {
      const errorMessage = 'Async operation error';
      const asyncFn = jest.fn().mockImplementation(async () => {
        await Promise.resolve(); // Make it actually async
        throw new Error(errorMessage);
      });

      const wrappedFn = asyncHandler(asyncFn);
      wrappedFn(mockReq as Request, mockRes as Response, mockNext);

      // Wait for promise to resolve
      await new Promise(resolve => setImmediate(resolve));

      expect(mockNext).toHaveBeenCalled();
      expect(mockNext).toHaveBeenCalledWith(expect.objectContaining({
        message: errorMessage
      }));
    });
  });

  describe('errorHandler', () => {
    const originalEnv = process.env.NODE_ENV;

    afterEach(() => {
      process.env.NODE_ENV = originalEnv;
    });

    it('should handle generic errors with 500 status', () => {
      const error = new Error('Generic error');

      errorHandler(error, mockReq as Request, mockRes as Response, mockNext);

      expect(logger.error).toHaveBeenCalledWith('Error:', error);
      expect(statusMock).toHaveBeenCalledWith(500);
      expect(jsonMock).toHaveBeenCalledWith({
        error: 'Internal server error',
        message: 'An unexpected error occurred',
      });
    });

    it('should include error message and stack in development mode', () => {
      process.env.NODE_ENV = 'development';
      const error = new Error('Dev error');
      error.stack = 'Error stack trace';

      errorHandler(error, mockReq as Request, mockRes as Response, mockNext);

      expect(jsonMock).toHaveBeenCalledWith({
        error: 'Internal server error',
        message: 'Dev error',
        stack: 'Error stack trace',
      });
    });

    it('should handle ValidationError with 400 status', () => {
      const error = new Error('Invalid input') as any;
      error.name = 'ValidationError';

      errorHandler(error, mockReq as Request, mockRes as Response, mockNext);

      expect(statusMock).toHaveBeenCalledWith(400);
      expect(jsonMock).toHaveBeenCalledWith({
        error: 'Validation failed',
        message: 'Invalid input',
      });
    });

    it('should handle UnauthorizedError with 401 status', () => {
      const error = new Error('Not authorized') as any;
      error.name = 'UnauthorizedError';

      errorHandler(error, mockReq as Request, mockRes as Response, mockNext);

      expect(statusMock).toHaveBeenCalledWith(401);
      expect(jsonMock).toHaveBeenCalledWith({
        error: 'Unauthorized',
        message: 'Not authorized',
      });
    });

    it('should log all errors', () => {
      const error = new Error('Test error');

      errorHandler(error, mockReq as Request, mockRes as Response, mockNext);

      expect(logger.error).toHaveBeenCalledWith('Error:', error);
    });

    it('should hide error details in production', () => {
      process.env.NODE_ENV = 'production';
      const error = new Error('Sensitive error information');

      errorHandler(error, mockReq as Request, mockRes as Response, mockNext);

      expect(jsonMock).toHaveBeenCalledWith({
        error: 'Internal server error',
        message: 'An unexpected error occurred',
      });
    });
  });

  describe('notFoundHandler', () => {
    it('should return 404 with route information', () => {
      mockReq.method = 'GET';
      mockReq.path = '/api/nonexistent';

      notFoundHandler(mockReq as Request, mockRes as Response);

      expect(statusMock).toHaveBeenCalledWith(404);
      expect(jsonMock).toHaveBeenCalledWith({
        error: 'Not found',
        message: 'Route GET /api/nonexistent not found',
      });
    });

    it('should handle POST requests', () => {
      mockReq.method = 'POST';
      mockReq.path = '/api/invalid';

      notFoundHandler(mockReq as Request, mockRes as Response);

      expect(jsonMock).toHaveBeenCalledWith({
        error: 'Not found',
        message: 'Route POST /api/invalid not found',
      });
    });

    it('should handle different HTTP methods', () => {
      const methods = ['GET', 'POST', 'PUT', 'DELETE', 'PATCH'];

      methods.forEach(method => {
        jest.clearAllMocks();
        mockReq.method = method;
        mockReq.path = '/test';

        notFoundHandler(mockReq as Request, mockRes as Response);

        expect(jsonMock).toHaveBeenCalledWith({
          error: 'Not found',
          message: `Route ${method} /test not found`,
        });
      });
    });
  });
});
</file>

<file path="middleware/__tests__/metrics.middleware.test.ts">
import { Request, Response, NextFunction } from 'express';
import { metricsMiddleware } from '../metrics.middleware';
import * as metricsService from '../../lib/metrics.service';

// Mock the metrics service
jest.mock('../../lib/metrics.service', () => ({
  recordHttpRequest: jest.fn(),
}));

describe('Metrics Middleware', () => {
  let mockReq: Partial<Request>;
  let mockRes: Partial<Response>;
  let mockNext: NextFunction;
  let finishListeners: Array<() => void>;

  beforeEach(() => {
    finishListeners = [];

    mockReq = {
      method: 'GET',
      path: '/api/test',
      baseUrl: '/api',
      route: {
        path: '/test',
      } as any,
    };

    mockRes = {
      statusCode: 200,
      on: jest.fn((event: string, callback: () => void) => {
        if (event === 'finish') {
          finishListeners.push(callback);
        }
        return mockRes as Response;
      }),
    };

    mockNext = jest.fn();

    jest.clearAllMocks();
  });

  it('should call next immediately', () => {
    metricsMiddleware(mockReq as Request, mockRes as Response, mockNext);

    expect(mockNext).toHaveBeenCalledTimes(1);
  });

  it('should record metrics when response finishes', () => {
    metricsMiddleware(mockReq as Request, mockRes as Response, mockNext);

    // Simulate response finishing
    finishListeners.forEach(listener => listener());

    expect(metricsService.recordHttpRequest).toHaveBeenCalledWith(
      'GET',
      '/api/test',
      200,
      expect.any(Number)
    );
  });

  it('should measure request duration accurately', async () => {
    const startTime = Date.now();

    metricsMiddleware(mockReq as Request, mockRes as Response, mockNext);

    // Simulate 100ms delay
    await new Promise(resolve => setTimeout(resolve, 100));

    // Simulate response finishing
    finishListeners.forEach(listener => listener());

    const call = (metricsService.recordHttpRequest as jest.Mock).mock.calls[0];
    const duration = call[3];

    // Duration should be in seconds and approximately 0.1
    expect(duration).toBeGreaterThanOrEqual(0.1);
    expect(duration).toBeLessThan(0.2); // Allow some tolerance
  });

  it('should record correct HTTP method', () => {
    const methods = ['GET', 'POST', 'PUT', 'DELETE', 'PATCH'];

    methods.forEach(method => {
      jest.clearAllMocks();
      finishListeners = [];

      mockReq.method = method;
      mockRes!.on = jest.fn((event: string, callback: () => void) => {
        if (event === 'finish') finishListeners.push(callback);
        return mockRes as Response;
      });

      metricsMiddleware(mockReq as Request, mockRes as Response, mockNext);
      finishListeners.forEach(listener => listener());

      expect(metricsService.recordHttpRequest).toHaveBeenCalledWith(
        method,
        expect.any(String),
        expect.any(Number),
        expect.any(Number)
      );
    });
  });

  it('should record correct status codes', () => {
    const statusCodes = [200, 201, 400, 401, 404, 500, 503];

    statusCodes.forEach(statusCode => {
      jest.clearAllMocks();
      finishListeners = [];

      mockRes!.statusCode = statusCode;
      mockRes!.on = jest.fn((event: string, callback: () => void) => {
        if (event === 'finish') finishListeners.push(callback);
        return mockRes as Response;
      });

      metricsMiddleware(mockReq as Request, mockRes as Response, mockNext);
      finishListeners.forEach(listener => listener());

      expect(metricsService.recordHttpRequest).toHaveBeenCalledWith(
        expect.any(String),
        expect.any(String),
        statusCode,
        expect.any(Number)
      );
    });
  });

  it('should use route pattern when available', () => {
    mockReq.baseUrl = '/api';
    mockReq.route = {
      path: '/properties/:id',
    } as any;

    metricsMiddleware(mockReq as Request, mockRes as Response, mockNext);
    finishListeners.forEach(listener => listener());

    expect(metricsService.recordHttpRequest).toHaveBeenCalledWith(
      'GET',
      '/api/properties/:id',
      200,
      expect.any(Number)
    );
  });

  it('should fallback to path when route is not available', () => {
    mockReq.route = undefined;
    mockReq.path = '/api/custom/path';

    metricsMiddleware(mockReq as Request, mockRes as Response, mockNext);
    finishListeners.forEach(listener => listener());

    expect(metricsService.recordHttpRequest).toHaveBeenCalledWith(
      'GET',
      '/api/custom/path',
      200,
      expect.any(Number)
    );
  });

  it('should handle routes with empty baseUrl', () => {
    mockReq.baseUrl = '';
    mockReq.route = {
      path: '/health',
    } as any;

    metricsMiddleware(mockReq as Request, mockRes as Response, mockNext);
    finishListeners.forEach(listener => listener());

    expect(metricsService.recordHttpRequest).toHaveBeenCalledWith(
      'GET',
      '/health',
      200,
      expect.any(Number)
    );
  });

  it('should handle parameterized routes correctly', () => {
    mockReq.baseUrl = '/api/properties';
    mockReq.route = {
      path: '/:id/details',
    } as any;

    metricsMiddleware(mockReq as Request, mockRes as Response, mockNext);
    finishListeners.forEach(listener => listener());

    expect(metricsService.recordHttpRequest).toHaveBeenCalledWith(
      'GET',
      '/api/properties/:id/details',
      200,
      expect.any(Number)
    );
  });

  it('should handle routes with no path correctly', () => {
    mockReq.route = {
      path: undefined,
    } as any;
    mockReq.path = '/fallback/path';

    metricsMiddleware(mockReq as Request, mockRes as Response, mockNext);
    finishListeners.forEach(listener => listener());

    expect(metricsService.recordHttpRequest).toHaveBeenCalledWith(
      'GET',
      '/fallback/path',
      200,
      expect.any(Number)
    );
  });

  it('should only record metrics once per request', () => {
    metricsMiddleware(mockReq as Request, mockRes as Response, mockNext);

    // Call finish listener once (finish event only fires once in reality)
    finishListeners.forEach(listener => listener());

    // Should only record once
    expect(metricsService.recordHttpRequest).toHaveBeenCalledTimes(1);
  });

  it('should measure very fast requests', () => {
    metricsMiddleware(mockReq as Request, mockRes as Response, mockNext);

    // Immediately finish
    finishListeners.forEach(listener => listener());

    const call = (metricsService.recordHttpRequest as jest.Mock).mock.calls[0];
    const duration = call[3];

    // Duration should be very small but >= 0
    expect(duration).toBeGreaterThanOrEqual(0);
    expect(duration).toBeLessThan(0.01); // Less than 10ms
  });
});
</file>

<file path="middleware/__tests__/validation.middleware.test.ts">
import { Request, Response, NextFunction } from 'express';
import { z } from 'zod';
import { validate, validateBody, validateQuery, validateParams } from '../validation.middleware';

describe('Validation Middleware', () => {
  let mockReq: Partial<Request>;
  let mockRes: Partial<Response>;
  let mockNext: NextFunction;
  let jsonMock: jest.Mock;
  let statusMock: jest.Mock;

  beforeEach(() => {
    jsonMock = jest.fn();
    statusMock = jest.fn().mockReturnValue({ json: jsonMock });

    mockReq = {
      body: {},
      query: {},
      params: {},
    };

    mockRes = {
      status: statusMock,
      json: jsonMock,
    };

    mockNext = jest.fn();
  });

  describe('validate', () => {
    const userSchema = z.object({
      name: z.string().min(1),
      email: z.string().email(),
      age: z.number().min(0).optional(),
    });

    it('should validate and pass valid body data', () => {
      mockReq.body = {
        name: 'John Doe',
        email: 'john@example.com',
        age: 30,
      };

      const middleware = validate(userSchema, 'body');
      middleware(mockReq as Request, mockRes as Response, mockNext);

      expect(mockNext).toHaveBeenCalledWith();
      expect(statusMock).not.toHaveBeenCalled();
      expect(mockReq.body).toEqual({
        name: 'John Doe',
        email: 'john@example.com',
        age: 30,
      });
    });

    it('should validate and pass valid query data', () => {
      mockReq.query = {
        name: 'John Doe',
        email: 'john@example.com',
      };

      const middleware = validate(userSchema, 'query');
      middleware(mockReq as Request, mockRes as Response, mockNext);

      expect(mockNext).toHaveBeenCalledWith();
      expect(statusMock).not.toHaveBeenCalled();
    });

    it('should validate and pass valid params data', () => {
      const idSchema = z.object({
        id: z.string().uuid(),
      });

      mockReq.params = {
        id: '123e4567-e89b-12d3-a456-426614174000',
      };

      const middleware = validate(idSchema, 'params');
      middleware(mockReq as Request, mockRes as Response, mockNext);

      expect(mockNext).toHaveBeenCalledWith();
      expect(statusMock).not.toHaveBeenCalled();
    });

    it('should reject invalid data and return 400', () => {
      mockReq.body = {
        name: '',
        email: 'invalid-email',
      };

      const middleware = validate(userSchema, 'body');
      middleware(mockReq as Request, mockRes as Response, mockNext);

      expect(mockNext).not.toHaveBeenCalled();
      expect(statusMock).toHaveBeenCalledWith(400);
      expect(jsonMock).toHaveBeenCalledWith(
        expect.objectContaining({
          error: 'Invalid request data',
          details: expect.arrayContaining([
            expect.objectContaining({
              path: expect.any(String),
              message: expect.any(String),
            }),
          ]),
        })
      );
    });

    it('should return detailed validation errors', () => {
      mockReq.body = {
        name: '',
        email: 'not-an-email',
      };

      const middleware = validate(userSchema, 'body');
      middleware(mockReq as Request, mockRes as Response, mockNext);

      const response = jsonMock.mock.calls[0][0];
      expect(response.details).toHaveLength(2);
      expect(response.details).toEqual(
        expect.arrayContaining([
          expect.objectContaining({
            path: 'name',
            message: expect.stringContaining('String must contain at least 1 character'),
          }),
          expect.objectContaining({
            path: 'email',
            message: expect.stringContaining('Invalid email'),
          }),
        ])
      );
    });

    it('should apply defaults from schema', () => {
      const schemaWithDefaults = z.object({
        name: z.string(),
        role: z.string().default('user'),
        active: z.boolean().default(true),
      });

      mockReq.body = {
        name: 'John',
      };

      const middleware = validate(schemaWithDefaults, 'body');
      middleware(mockReq as Request, mockRes as Response, mockNext);

      expect(mockNext).toHaveBeenCalled();
      expect(mockReq.body).toEqual({
        name: 'John',
        role: 'user',
        active: true,
      });
    });

    it('should handle nested object validation', () => {
      const nestedSchema = z.object({
        user: z.object({
          profile: z.object({
            firstName: z.string().min(1),
            lastName: z.string(),
          }),
        }),
      });

      mockReq.body = {
        user: {
          profile: {
            firstName: '',
          },
        },
      };

      const middleware = validate(nestedSchema, 'body');
      middleware(mockReq as Request, mockRes as Response, mockNext);

      expect(statusMock).toHaveBeenCalledWith(400);
      const response = jsonMock.mock.calls[0][0];
      expect(response.details).toContainEqual(
        expect.objectContaining({
          path: 'user.profile.firstName',
        })
      );
      expect(response.details).toContainEqual(
        expect.objectContaining({
          path: 'user.profile.lastName',
        })
      );
    });

    it('should handle array validation errors', () => {
      const arraySchema = z.object({
        tags: z.array(z.string().min(1)),
      });

      mockReq.body = {
        tags: ['valid', '', 'another-valid'],
      };

      const middleware = validate(arraySchema, 'body');
      middleware(mockReq as Request, mockRes as Response, mockNext);

      expect(statusMock).toHaveBeenCalledWith(400);
      const response = jsonMock.mock.calls[0][0];
      expect(response.details[0].path).toBe('tags.1');
    });

    it('should pass non-Zod errors to next middleware', () => {
      const throwingSchema = {
        parse: () => {
          throw new Error('Non-Zod error');
        },
      } as any;

      const middleware = validate(throwingSchema, 'body');
      middleware(mockReq as Request, mockRes as Response, mockNext);

      expect(mockNext).toHaveBeenCalledWith(expect.any(Error));
      expect(statusMock).not.toHaveBeenCalled();
    });
  });

  describe('validateBody', () => {
    it('should be a convenience wrapper for body validation', () => {
      const schema = z.object({ name: z.string() });
      mockReq.body = { name: 'Test' };

      const middleware = validateBody(schema);
      middleware(mockReq as Request, mockRes as Response, mockNext);

      expect(mockNext).toHaveBeenCalled();
      expect(statusMock).not.toHaveBeenCalled();
    });
  });

  describe('validateQuery', () => {
    it('should be a convenience wrapper for query validation', () => {
      const schema = z.object({ search: z.string() });
      mockReq.query = { search: 'test query' };

      const middleware = validateQuery(schema);
      middleware(mockReq as Request, mockRes as Response, mockNext);

      expect(mockNext).toHaveBeenCalled();
      expect(statusMock).not.toHaveBeenCalled();
    });
  });

  describe('validateParams', () => {
    it('should be a convenience wrapper for params validation', () => {
      const schema = z.object({ id: z.string() });
      mockReq.params = { id: '123' };

      const middleware = validateParams(schema);
      middleware(mockReq as Request, mockRes as Response, mockNext);

      expect(mockNext).toHaveBeenCalled();
      expect(statusMock).not.toHaveBeenCalled();
    });
  });

  describe('edge cases', () => {
    it('should handle empty validation schema', () => {
      const emptySchema = z.object({});
      mockReq.body = { anything: 'goes' };

      const middleware = validate(emptySchema, 'body');
      middleware(mockReq as Request, mockRes as Response, mockNext);

      expect(mockNext).toHaveBeenCalled();
      expect(mockReq.body).toEqual({});
    });

    it('should handle strict schemas that disallow extra keys', () => {
      const strictSchema = z.object({ name: z.string() }).strict();
      mockReq.body = { name: 'Test', extra: 'field' };

      const middleware = validate(strictSchema, 'body');
      middleware(mockReq as Request, mockRes as Response, mockNext);

      expect(statusMock).toHaveBeenCalledWith(400);
      const response = jsonMock.mock.calls[0][0];
      expect(response.details[0].message).toContain('Unrecognized key');
    });

    it('should transform data types when using coercion', () => {
      const coerceSchema = z.object({
        age: z.coerce.number(),
        active: z.coerce.boolean(),
      });

      mockReq.query = { age: '25', active: '1' };

      const middleware = validate(coerceSchema, 'query');
      middleware(mockReq as Request, mockRes as Response, mockNext);

      expect(mockNext).toHaveBeenCalled();
      expect(mockReq.query).toEqual({ age: 25, active: true });
    });
  });
});
</file>

<file path="middleware/__tests__/xcontroller.middleware.test.ts">
/**
 * XController Middleware Tests
 */

import { describe, test, expect, beforeEach, afterEach, jest } from '@jest/globals';
import { Request, Response, NextFunction } from 'express';

// Mock the config module before importing middleware
jest.mock('../../config', () => {
  const mockConfig = {
    env: {
      nodeEnv: 'development',
      isDevelopment: true,
      isProduction: false,
      isTest: false,
    },
    security: {
      csp: {
        enabled: true,
        nonceLength: 16,
        directives: {
          defaultSrc: ["'self'"],
          scriptSrc: ["'self'"],
          styleSrc: ["'self'", "'unsafe-inline'"],
          imgSrc: ["'self'", 'data:', 'https:'],
          fontSrc: ["'self'", 'data:'],
          connectSrc: ["'self'"],
          frameAncestors: ["'none'"],
          baseUri: ["'self'"],
          formAction: ["'self'"],
        },
      },
      hsts: {
        maxAge: 31536000,
        includeSubDomains: true,
      },
    },
    frontend: {
      apiUrl: '/api',
      appVersion: '1.0.0',
      features: {
        search: true,
        analytics: false,
        monitoring: false,
      },
    },
  };

  return {
    config: mockConfig,
  };
});

import {
  generateNonce,
  encodeJsonForHtml,
  nonceMiddleware,
  cspMiddleware,
  generateSecureHtml,
  getInitialAppData,
} from '../xcontroller.middleware';
import { config } from '../../config';

describe('XController Middleware', () => {
  describe('generateNonce', () => {
    test('should generate a base64 string', () => {
      const nonce = generateNonce();
      expect(typeof nonce).toBe('string');
      expect(nonce.length).toBeGreaterThan(16);
    });

    test('should generate unique nonces', () => {
      const nonce1 = generateNonce();
      const nonce2 = generateNonce();
      expect(nonce1).not.toBe(nonce2);
    });

    test('should be cryptographically secure (16 bytes = 24 base64 chars)', () => {
      const nonce = generateNonce();
      // 16 bytes in base64 = 24 characters (rounded up)
      expect(nonce.length).toBeGreaterThanOrEqual(20);
    });
  });

  describe('encodeJsonForHtml', () => {
    test('should encode dangerous < character', () => {
      const data = { html: '<script>alert("xss")</script>' };
      const encoded = encodeJsonForHtml(data);
      expect(encoded).not.toContain('<script>');
      expect(encoded).toContain('\\u003C');
    });

    test('should encode dangerous > character', () => {
      const data = { html: '<div>' };
      const encoded = encodeJsonForHtml(data);
      expect(encoded).not.toContain('>');
      expect(encoded).toContain('\\u003E');
    });

    test('should encode dangerous & character', () => {
      const data = { html: 'foo & bar' };
      const encoded = encodeJsonForHtml(data);
      expect(encoded).not.toContain('&');
      expect(encoded).toContain('\\u0026');
    });

    test('should prevent script injection', () => {
      const malicious = {
        payload: '</script><script>alert("xss")</script>',
      };
      const encoded = encodeJsonForHtml(malicious);
      expect(encoded).not.toContain('</script>');
      expect(encoded).not.toContain('<script>');
    });

    test('should handle unicode line separators', () => {
      const data = { text: 'line\u2028separator' };
      const encoded = encodeJsonForHtml(data);
      expect(encoded).toContain('\\u2028');
    });

    test('should be valid JSON after encoding', () => {
      const data = { test: 'value', number: 123 };
      const encoded = encodeJsonForHtml(data);
      const decoded = JSON.parse(encoded);
      expect(decoded).toEqual(data);
    });
  });

  describe('nonceMiddleware', () => {
    let req: Partial<Request>;
    let res: Partial<Response>;
    let next: NextFunction;

    beforeEach(() => {
      req = {};
      res = {
        locals: {},
      };
      next = jest.fn();
    });

    test('should add nonce to res.locals', () => {
      nonceMiddleware(req as Request, res as Response, next);
      expect(res.locals?.nonce).toBeDefined();
      expect(typeof res.locals?.nonce).toBe('string');
    });

    test('should call next()', () => {
      nonceMiddleware(req as Request, res as Response, next);
      expect(next).toHaveBeenCalled();
    });

    test('should generate different nonces for different requests', () => {
      const res1: Partial<Response> = { locals: {} };
      const res2: Partial<Response> = { locals: {} };

      nonceMiddleware(req as Request, res1 as Response, next);
      nonceMiddleware(req as Request, res2 as Response, next);

      expect(res1.locals?.nonce).not.toBe(res2.locals?.nonce);
    });
  });

  describe('cspMiddleware', () => {
    let req: Partial<Request>;
    let res: Partial<Response>;
    let next: NextFunction;

    beforeEach(() => {
      req = {
        protocol: 'http',
      };
      res = {
        locals: { nonce: 'test-nonce-12345' },
        setHeader: jest.fn(),
      };
      next = jest.fn();
      // Reset config to development mode
      (config.env as any).isProduction = false;
      (config.env as any).nodeEnv = 'development';
    });

    test('should set Content-Security-Policy header with nonce', () => {
      cspMiddleware(req as Request, res as Response, next);
      expect(res.setHeader).toHaveBeenCalledWith(
        'Content-Security-Policy',
        expect.stringContaining("'nonce-test-nonce-12345'")
      );
    });

    test('should set X-Content-Type-Options header', () => {
      cspMiddleware(req as Request, res as Response, next);
      expect(res.setHeader).toHaveBeenCalledWith('X-Content-Type-Options', 'nosniff');
    });

    test('should set X-Frame-Options header', () => {
      cspMiddleware(req as Request, res as Response, next);
      expect(res.setHeader).toHaveBeenCalledWith('X-Frame-Options', 'DENY');
    });

    test('should set X-XSS-Protection header', () => {
      cspMiddleware(req as Request, res as Response, next);
      expect(res.setHeader).toHaveBeenCalledWith('X-XSS-Protection', '1; mode=block');
    });

    test('should set Referrer-Policy header', () => {
      cspMiddleware(req as Request, res as Response, next);
      expect(res.setHeader).toHaveBeenCalledWith(
        'Referrer-Policy',
        'strict-origin-when-cross-origin'
      );
    });

    test('should include default-src directive', () => {
      cspMiddleware(req as Request, res as Response, next);
      const cspCall = (res.setHeader as jest.Mock).mock.calls.find(
        call => call[0] === 'Content-Security-Policy'
      );
      expect(cspCall[1]).toContain("default-src 'self'");
    });

    test('should include script-src with nonce', () => {
      cspMiddleware(req as Request, res as Response, next);
      const cspCall = (res.setHeader as jest.Mock).mock.calls.find(
        call => call[0] === 'Content-Security-Policy'
      );
      expect(cspCall[1]).toContain("script-src 'self' 'nonce-test-nonce-12345'");
    });

    test('should set HSTS in production with HTTPS', () => {
      (config.env as any).isProduction = true;
      (config.env as any).nodeEnv = 'production';
      req.protocol = 'https';
      cspMiddleware(req as Request, res as Response, next);
      expect(res.setHeader).toHaveBeenCalledWith(
        'Strict-Transport-Security',
        'max-age=31536000; includeSubDomains'
      );
    });

    test('should not set HSTS in development', () => {
      (config.env as any).isProduction = false;
      (config.env as any).nodeEnv = 'development';
      cspMiddleware(req as Request, res as Response, next);
      expect(res.setHeader).not.toHaveBeenCalledWith(
        'Strict-Transport-Security',
        expect.anything()
      );
    });

    test('should not set HSTS with HTTP in production', () => {
      (config.env as any).isProduction = true;
      (config.env as any).nodeEnv = 'production';
      req.protocol = 'http';
      cspMiddleware(req as Request, res as Response, next);
      expect(res.setHeader).not.toHaveBeenCalledWith(
        'Strict-Transport-Security',
        expect.anything()
      );
    });

    test('should call next()', () => {
      cspMiddleware(req as Request, res as Response, next);
      expect(next).toHaveBeenCalled();
    });
  });

  describe('generateSecureHtml', () => {
    test('should generate valid HTML', () => {
      const html = generateSecureHtml({
        title: 'Test App',
        nonce: 'test-nonce',
        scriptSrc: '/app.js',
      });

      expect(html).toContain('<!DOCTYPE html>');
      expect(html).toContain('<title>Test App</title>');
      expect(html).toContain('<div id="root"></div>');
    });

    test('should include nonce in script tag', () => {
      const html = generateSecureHtml({
        title: 'Test App',
        nonce: 'test-nonce-123',
        scriptSrc: '/app.js',
      });

      expect(html).toContain('nonce="test-nonce-123"');
    });

    test('should embed initial data when provided', () => {
      const html = generateSecureHtml({
        title: 'Test App',
        nonce: 'test-nonce',
        initialData: { test: 'value' },
        scriptSrc: '/app.js',
      });

      expect(html).toContain('type="application/json"');
      expect(html).toContain('id="initial-data"');
      expect(html).toContain('"test"');
    });

    test('should properly encode initial data', () => {
      const html = generateSecureHtml({
        title: 'Test App',
        nonce: 'test-nonce',
        initialData: { html: '<script>alert("xss")</script>' },
        scriptSrc: '/app.js',
      });

      expect(html).not.toContain('<script>alert');
      expect(html).toContain('\\u003Cscript\\u003E');
    });

    test('should include style link when provided', () => {
      const html = generateSecureHtml({
        title: 'Test App',
        nonce: 'test-nonce',
        scriptSrc: '/app.js',
        styleSrc: '/app.css',
      });

      expect(html).toContain('<link rel="stylesheet" href="/app.css"');
    });

    test('should not include data script when no initial data', () => {
      const html = generateSecureHtml({
        title: 'Test App',
        nonce: 'test-nonce',
        scriptSrc: '/app.js',
      });

      expect(html).not.toContain('id="initial-data"');
    });
  });

  describe('getInitialAppData', () => {
    beforeEach(() => {
      // Reset config to defaults
      (config.frontend as any).apiUrl = '/api';
      (config.env as any).nodeEnv = 'development';
      (config.env as any).isProduction = false;
      (config.frontend as any).appVersion = '1.0.0';
      (config.frontend.features as any).analytics = false;
    });

    test('should return valid initial data structure', () => {
      const data = getInitialAppData();

      expect(data).toHaveProperty('apiUrl');
      expect(data).toHaveProperty('environment');
      expect(data).toHaveProperty('features');
      expect(data).toHaveProperty('version');
    });

    test('should use environment variables when available', () => {
      (config.frontend as any).apiUrl = 'https://api.example.com';
      (config.env as any).nodeEnv = 'production';
      (config.frontend as any).appVersion = '2.0.0';

      const data = getInitialAppData();

      expect(data.apiUrl).toBe('https://api.example.com');
      expect(data.environment).toBe('production');
      expect(data.version).toBe('2.0.0');
    });

    test('should use defaults when environment variables are missing', () => {
      (config.frontend as any).apiUrl = '/api';
      (config.env as any).nodeEnv = 'development';
      (config.frontend as any).appVersion = '1.0.0';

      const data = getInitialAppData();

      expect(data.apiUrl).toBe('/api');
      expect(data.environment).toBe('development');
      expect(data.version).toBe('1.0.0');
    });

    test('should enable analytics in production', () => {
      (config.env as any).nodeEnv = 'production';
      (config.env as any).isProduction = true;
      (config.frontend.features as any).analytics = true;

      const data = getInitialAppData();
      expect(data.features.analytics).toBe(true);
    });

    test('should disable analytics in development', () => {
      (config.env as any).nodeEnv = 'development';
      (config.env as any).isProduction = false;
      (config.frontend.features as any).analytics = false;

      const data = getInitialAppData();
      expect(data.features.analytics).toBe(false);
    });

    test('should not expose sensitive data', () => {
      const data = getInitialAppData();
      const json = JSON.stringify(data);

      expect(json).not.toContain('DATABASE_URL');
      expect(json).not.toContain('API_KEY');
      expect(json).not.toContain('JWT_SECRET');
      expect(json).not.toContain('ANTHROPIC_API_KEY');
    });
  });
});
</file>

<file path="middleware/auth.ts">
import { Request, Response, NextFunction } from 'express';
import jwt from 'jsonwebtoken';
import { config } from '../config';

export interface AuthRequest extends Request {
  user?: {
    id: string;
    email?: string;
  };
}

// Simple API key authentication middleware
export const apiKeyAuth = (req: Request, res: Response, next: NextFunction) => {
  const apiKey = req.headers['x-api-key'] as string;

  // Skip auth in development if no API key is set and skip is enabled
  if (config.env.isDevelopment && config.auth.skipInDevelopment && !config.auth.apiKey) {
    return next();
  }

  if (!apiKey || apiKey !== config.auth.apiKey) {
    return res.status(401).json({ error: 'Unauthorized - Invalid API key' });
  }

  next();
};

// JWT authentication middleware
export const jwtAuth = (req: AuthRequest, res: Response, next: NextFunction) => {
  const authHeader = req.headers['authorization'];
  const token = authHeader && authHeader.split(' ')[1]; // Bearer TOKEN

  // Skip auth in development if no JWT secret is set and skip is enabled
  if (config.env.isDevelopment && config.auth.skipInDevelopment && !config.auth.jwt.secret) {
    return next();
  }

  if (!token) {
    return res.status(401).json({ error: 'Unauthorized - No token provided' });
  }

  try {
    const decoded = jwt.verify(token, config.auth.jwt.secret) as { id: string; email?: string };
    req.user = decoded;
    next();
  } catch (error) {
    return res.status(403).json({ error: 'Forbidden - Invalid token' });
  }
};

// Optional auth middleware (allows both authenticated and unauthenticated access)
export const optionalAuth = (req: AuthRequest, res: Response, next: NextFunction) => {
  const authHeader = req.headers['authorization'];
  const token = authHeader && authHeader.split(' ')[1];

  if (token && config.auth.jwt.secret) {
    try {
      const decoded = jwt.verify(token, config.auth.jwt.secret) as { id: string; email?: string };
      req.user = decoded;
    } catch (error) {
      // Invalid token, but we continue anyway
    }
  }

  next();
};

// Generate JWT token
export const generateToken = (userId: string, email?: string): string => {
  return jwt.sign({ id: userId, email }, config.auth.jwt.secret, {
    expiresIn: config.auth.jwt.expiresIn as string | number,
  });
};
</file>

<file path="middleware/error.middleware.ts">
import { Request, Response, NextFunction } from 'express';
import logger from '../lib/logger';

/**
 * Async handler wrapper to catch errors in async route handlers
 */
export const asyncHandler = (
  fn: (req: Request, res: Response, next: NextFunction) => Promise<any>
) => {
  return (req: Request, res: Response, next: NextFunction) => {
    Promise.resolve(fn(req, res, next)).catch(next);
  };
};

/**
 * Global error handling middleware
 */
export const errorHandler = (
  error: Error,
  req: Request,
  res: Response,
  next: NextFunction
) => {
  logger.error('Error:', error);

  // Handle specific error types
  if (error.name === 'ValidationError') {
    return res.status(400).json({
      error: 'Validation failed',
      message: error.message,
    });
  }

  if (error.name === 'UnauthorizedError') {
    return res.status(401).json({
      error: 'Unauthorized',
      message: error.message,
    });
  }

  // Default to 500 server error
  res.status(500).json({
    error: 'Internal server error',
    message: process.env.NODE_ENV === 'development' ? error.message : 'An unexpected error occurred',
    ...(process.env.NODE_ENV === 'development' && { stack: error.stack }),
  });
};

/**
 * 404 Not Found handler
 */
export const notFoundHandler = (req: Request, res: Response) => {
  res.status(404).json({
    error: 'Not found',
    message: `Route ${req.method} ${req.path} not found`,
  });
};
</file>

<file path="middleware/metrics.middleware.ts">
/**
 * Prometheus Metrics Middleware
 *
 * Automatically tracks HTTP request metrics
 */

import { Request, Response, NextFunction } from 'express';
import { recordHttpRequest } from '../lib/metrics.service';

/**
 * Extract route pattern from request
 * Converts /api/properties/123 to /api/properties/:id
 */
function getRoutePattern(req: Request): string {
  // If route is available, use it (Express 4.x)
  if (req.route?.path) {
    return req.baseUrl + req.route.path;
  }

  // Otherwise use the actual path
  return req.path;
}

/**
 * Metrics middleware
 * Records HTTP request metrics for all requests
 */
export function metricsMiddleware(req: Request, res: Response, next: NextFunction): void {
  const startTime = Date.now();

  // Capture the response finish event
  res.on('finish', () => {
    const duration = (Date.now() - startTime) / 1000; // Convert to seconds
    const route = getRoutePattern(req);
    const method = req.method;
    const statusCode = res.statusCode;

    recordHttpRequest(method, route, statusCode, duration);
  });

  next();
}
</file>

<file path="middleware/README_ENHANCED.md">
# middleware

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "SoftwareSourceCode",
  "name": "middleware",
  "description": "Directory containing 4 code files with 1 classes and 12 functions",
  "programmingLanguage": [
    {
      "@type": "ComputerLanguage",
      "name": "Typescript"
    }
  ],
  "featureList": [
    "1 class definitions",
    "12 function definitions"
  ]
}
</script>

## Overview

This directory contains 4 code file(s) with extracted schemas.

## Subdirectories

- `__tests__/`

## Files and Schemas

### `auth.ts` (typescript)

**Functions:**
- `apiKeyAuth()` - Line 12
- `jwtAuth()` - Line 28
- `optionalAuth()` - Line 51

### `error.middleware.ts` (typescript)

**Functions:**
- `asyncHandler()` - Line 6
- `errorHandler()` - Line 17
- `notFoundHandler()` - Line 51

### `validation.middleware.ts` (typescript)

**Functions:**
- `validate()` - Line 6
- `validateBody()` - Line 34
- `validateQuery()` - Line 35
- `validateParams()` - Line 36

### `xcontroller.middleware.ts` (typescript)

**Classes:**
- `InitialAppData` - Line 131

**Functions:**
- `nonceMiddleware()` - Line 34
- `cspMiddleware()` - Line 43

---
*Generated by Enhanced Schema Generator with schema.org markup*
</file>

<file path="middleware/validation.middleware.ts">
import { Request, Response, NextFunction } from 'express';
import { z, ZodSchema } from 'zod';

/**
 * Middleware factory for validating request data using Zod schemas
 */
export const validate = (schema: ZodSchema, source: 'body' | 'query' | 'params' = 'body') => {
  return (req: Request, res: Response, next: NextFunction) => {
    try {
      const dataToValidate = req[source];
      const validatedData = schema.parse(dataToValidate);

      // Replace the original data with validated data (with defaults applied)
      req[source] = validatedData;

      next();
    } catch (error) {
      if (error instanceof z.ZodError) {
        return res.status(400).json({
          error: 'Invalid request data',
          details: error.errors.map(err => ({
            path: err.path.join('.'),
            message: err.message,
          })),
        });
      }
      next(error);
    }
  };
};

/**
 * Convenience functions for common validation scenarios
 */
export const validateBody = (schema: ZodSchema) => validate(schema, 'body');
export const validateQuery = (schema: ZodSchema) => validate(schema, 'query');
export const validateParams = (schema: ZodSchema) => validate(schema, 'params');
</file>

<file path="middleware/xcontroller.middleware.ts">
/**
 * XController Middleware
 * Implements secure server-to-client data passing with CSP Level 3 compliance
 */

import crypto from 'crypto';
import { Request, Response, NextFunction } from 'express';
import { config } from '../config';
import logger from '../lib/logger';

/**
 * Generate cryptographically secure nonce for CSP
 */
export function generateNonce(): string {
  return crypto.randomBytes(config.security.csp.nonceLength).toString('base64');
}

/**
 * Encode JSON safely for embedding in HTML
 * Prevents XSS by encoding dangerous characters
 */
export function encodeJsonForHtml(data: any): string {
  return JSON.stringify(data)
    .replace(/</g, '\\u003C')
    .replace(/>/g, '\\u003E')
    .replace(/&/g, '\\u0026')
    .replace(/\u2028/g, '\\u2028')  // Line separator
    .replace(/\u2029/g, '\\u2029'); // Paragraph separator
}

/**
 * Middleware to add CSP nonce to response locals
 * Usage: app.use(nonceMiddleware)
 */
export function nonceMiddleware(req: Request, res: Response, next: NextFunction) {
  res.locals.nonce = generateNonce();
  next();
}

/**
 * Middleware to set CSP headers with nonce support
 * Usage: app.use(cspMiddleware)
 */
export function cspMiddleware(req: Request, res: Response, next: NextFunction) {
  const nonce = res.locals.nonce;

  if (!nonce) {
    logger.warn('CSP middleware called without nonce. Use nonceMiddleware first.');
  }

  // CSP Level 3 with nonce support
  if (config.security.csp.enabled) {
    const directives = config.security.csp.directives;
    const cspDirectives = [
      `default-src ${directives.defaultSrc.join(' ')}`,
      nonce
        ? `script-src ${directives.scriptSrc.join(' ')} 'nonce-${nonce}'`
        : `script-src ${directives.scriptSrc.join(' ')}`,
      nonce
        ? `style-src ${directives.styleSrc.join(' ')} 'nonce-${nonce}'`
        : `style-src ${directives.styleSrc.join(' ')}`,
      `img-src ${directives.imgSrc.join(' ')}`,
      `font-src ${directives.fontSrc.join(' ')}`,
      `connect-src ${directives.connectSrc.join(' ')}`,
      `frame-ancestors ${directives.frameAncestors.join(' ')}`,
      `base-uri ${directives.baseUri.join(' ')}`,
      `form-action ${directives.formAction.join(' ')}`,
    ].join('; ');

    res.setHeader('Content-Security-Policy', cspDirectives);
  }

  // Additional security headers
  res.setHeader('X-Content-Type-Options', 'nosniff');
  res.setHeader('X-Frame-Options', 'DENY');
  res.setHeader('X-XSS-Protection', '1; mode=block');
  res.setHeader('Referrer-Policy', 'strict-origin-when-cross-origin');

  // HSTS (only in production with HTTPS)
  if (config.env.isProduction && req.protocol === 'https') {
    res.setHeader(
      'Strict-Transport-Security',
      `max-age=${config.security.hsts.maxAge}${config.security.hsts.includeSubDomains ? '; includeSubDomains' : ''}`
    );
  }

  next();
}

/**
 * Generate HTML with embedded secure data
 * Uses JSON Script Tag pattern for CSP compliance
 */
export function generateSecureHtml(options: {
  title: string;
  nonce: string;
  initialData?: any;
  scriptSrc: string;
  styleSrc?: string;
}): string {
  const { title, nonce, initialData, scriptSrc, styleSrc } = options;

  let dataScript = '';
  if (initialData) {
    const encodedData = encodeJsonForHtml(initialData);
    dataScript = `
    <!-- Initial app data (secure) -->
    <script type="application/json" id="initial-data" nonce="${nonce}">
      ${encodedData}
    </script>`;
  }

  return `<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>${title}</title>
    ${styleSrc ? `<link rel="stylesheet" href="${styleSrc}" nonce="${nonce}">` : ''}
  </head>
  <body>
    <div id="root"></div>
    ${dataScript}
    <script src="${scriptSrc}" nonce="${nonce}"></script>
  </body>
</html>`;
}

/**
 * Type-safe initial data interface
 */
export interface InitialAppData {
  apiUrl: string;
  environment: string;
  features: {
    search: boolean;
    analytics: boolean;
    monitoring: boolean;
  };
  version: string;
}

/**
 * Generate initial app configuration
 * Never include sensitive data here!
 */
export function getInitialAppData(): InitialAppData {
  return {
    apiUrl: config.frontend.apiUrl,
    environment: config.env.nodeEnv,
    features: {
      search: config.frontend.features.search,
      analytics: config.frontend.features.analytics,
      monitoring: config.frontend.features.monitoring,
    },
    version: config.frontend.appVersion,
  };
}
</file>

<file path="queues/__tests__/scraper.queue.test.ts">
/**
 * Scraper Queue Tests
 *
 * Tests for the BullMQ scraper queue including:
 * - Rate limiting (canScheduleJob)
 * - Queue configuration
 * - Event listeners
 */

// Mock dependencies BEFORE imports
const mockBullQueue = {
  process: jest.fn(),
  on: jest.fn(),
  clean: jest.fn().mockResolvedValue(undefined),
  add: jest.fn(),
  getJob: jest.fn(),
  getJobs: jest.fn(),
  pause: jest.fn(),
  resume: jest.fn(),
  close: jest.fn(),
};

jest.mock('bull', () => {
  return jest.fn(() => mockBullQueue);
});

jest.mock('../../lib/tcad-scraper');
jest.mock('../../lib/prisma', () => ({
  prisma: {
    scrapeJob: {
      create: jest.fn(),
      update: jest.fn(),
    },
    $executeRawUnsafe: jest.fn(),
  },
}));

jest.mock('../../lib/redis-cache.service', () => ({
  cacheService: {
    deletePattern: jest.fn().mockResolvedValue(undefined),
    delete: jest.fn().mockResolvedValue(undefined),
  },
}));

jest.mock('../../services/search-term-optimizer', () => ({
  searchTermOptimizer: {
    updateAnalytics: jest.fn().mockResolvedValue(undefined),
  },
}));

jest.mock('../../config', () => ({
  config: {
    logging: {
      level: 'error',
    },
    queue: {
      name: 'tcad-scraper',
      jobName: 'scrape',
      concurrency: 2,
      defaultJobOptions: {
        attempts: 3,
        backoffDelay: 5000,
        removeOnComplete: 100,
        removeOnFail: 50,
      },
      cleanupGracePeriod: 86400000,
      cleanupInterval: 3600000,
    },
    redis: {
      host: 'localhost',
      port: 6379,
      password: '',
      db: 0,
    },
    rateLimit: {
      scraper: {
        jobDelay: 60000, // 1 minute
        cacheCleanupInterval: 300000, // 5 minutes
      },
    },
    env: {
      isProduction: false,
    },
    scraper: {
      headless: true,
      brightData: {
        enabled: false,
        apiToken: null,
        proxyHost: 'brd.superproxy.io',
        proxyPort: 22225,
      },
      proxy: {
        enabled: false,
        server: null,
        username: null,
        password: null,
      },
      timeout: 30000,
      retryAttempts: 3,
      retryDelay: 1000,
      userAgents: ['Mozilla/5.0'],
      viewports: [{ width: 1920, height: 1080 }],
      humanDelay: { min: 500, max: 2000 },
    },
  },
}));

// Mock setInterval at module level to prevent cleanup interval from running
jest.spyOn(global, 'setInterval').mockReturnValue({} as any);

describe('Scraper Queue', () => {
  beforeEach(() => {
    jest.clearAllMocks();
  });

  describe('canScheduleJob', () => {
    // Import after mocks are set up
    let canScheduleJob: (searchTerm: string) => Promise<boolean>;

    beforeEach(async () => {
      // Use fake timers for this test suite
      jest.useFakeTimers();

      // Reset module to clear the activeJobs Map
      jest.resetModules();
      const module = await import('../scraper.queue');
      canScheduleJob = module.canScheduleJob;
    });

    afterEach(() => {
      jest.useRealTimers();
    });

    it.skip('should allow scheduling a new job for a search term - SKIPPED (covered by other tests)', async () => {
      const result = await canScheduleJob('Smith');
      expect(result).toBe(true);
    });

    it('should prevent scheduling duplicate jobs within delay period', async () => {
      const searchTerm = 'Johnson';

      // First job should be allowed
      const result1 = await canScheduleJob(searchTerm);
      expect(result1).toBe(true);

      // Second job within delay period should be denied
      const result2 = await canScheduleJob(searchTerm);
      expect(result2).toBe(false);
    });

    it('should allow scheduling after delay period has passed', async () => {
      const searchTerm = 'Williams';

      // Schedule first job
      const result1 = await canScheduleJob(searchTerm);
      expect(result1).toBe(true);

      // Advance time past the job delay (60 seconds)
      jest.advanceTimersByTime(61000);

      // Should allow second job after delay
      const result2 = await canScheduleJob(searchTerm);
      expect(result2).toBe(true);
    });

    it('should track different search terms independently', async () => {
      const result1 = await canScheduleJob('Brown');
      const result2 = await canScheduleJob('Davis');
      const result3 = await canScheduleJob('Miller');

      // All different search terms should be allowed
      expect(result1).toBe(true);
      expect(result2).toBe(true);
      expect(result3).toBe(true);
    });

    it('should clean up old entries from activeJobs map', async () => {
      const searchTerm = 'Wilson';

      // Schedule first job
      await canScheduleJob(searchTerm);

      // Advance time past cleanup interval (5 minutes)
      jest.advanceTimersByTime(301000);

      // Schedule another job to trigger cleanup
      await canScheduleJob('Moore');

      // Original job should be cleaned up, so scheduling it again should work
      const result = await canScheduleJob(searchTerm);
      expect(result).toBe(true);
    });

    it('should handle multiple rapid calls correctly', async () => {
      const searchTerm = 'Taylor';

      // Simulate rapid successive calls
      const results = await Promise.all([
        canScheduleJob(searchTerm),
        canScheduleJob(searchTerm),
        canScheduleJob(searchTerm),
      ]);

      // Only first call should succeed
      expect(results[0]).toBe(true);
      expect(results[1]).toBe(false);
      expect(results[2]).toBe(false);
    });

    it('should handle empty search term', async () => {
      const result = await canScheduleJob('');
      expect(result).toBe(true);
    });

    it('should handle special characters in search term', async () => {
      const specialTerms = ['Smith & Co.', 'LLC.', 'Trust-Family'];

      for (const term of specialTerms) {
        const result = await canScheduleJob(term);
        expect(result).toBe(true);
      }
    });
  });

  describe.skip('Queue Configuration - SKIPPED (complex module loading)', () => {
    it('should create Bull queue with correct configuration', () => {
      const Bull = require('bull');

      expect(Bull).toHaveBeenCalledWith(
        'tcad-scraper',
        expect.objectContaining({
          redis: expect.objectContaining({
            host: 'localhost',
            port: 6379,
            password: '',
            db: 0,
          }),
          defaultJobOptions: expect.objectContaining({
            attempts: 3,
            backoff: expect.objectContaining({
              type: 'exponential',
              delay: 5000,
            }),
            removeOnComplete: 100,
            removeOnFail: 50,
          }),
        })
      );
    });

    it('should register queue processor with correct concurrency', () => {
      expect(mockBullQueue.process).toHaveBeenCalledWith(
        'scrape',
        2,
        expect.any(Function)
      );
    });
  });

  describe.skip('Queue Event Listeners - SKIPPED (complex module loading)', () => {
    it('should register completed event listener', () => {
      expect(mockBullQueue.on).toHaveBeenCalledWith(
        'completed',
        expect.any(Function)
      );
    });

    it('should register failed event listener', () => {
      expect(mockBullQueue.on).toHaveBeenCalledWith(
        'failed',
        expect.any(Function)
      );
    });

    it('should register stalled event listener', () => {
      expect(mockBullQueue.on).toHaveBeenCalledWith(
        'stalled',
        expect.any(Function)
      );
    });

    it('should handle completed event correctly', () => {
      const completedHandler = mockBullQueue.on.mock.calls.find(
        (call: any[]) => call[0] === 'completed'
      )?.[1];

      expect(completedHandler).toBeDefined();

      // Simulate completed event
      const mockJob = { id: 'test-job-123' };
      const mockResult = {
        count: 50,
        duration: 5000,
        searchTerm: 'Test',
        properties: [],
      };

      // Should not throw
      expect(() => completedHandler(mockJob, mockResult)).not.toThrow();
    });

    it('should handle failed event correctly', () => {
      const failedHandler = mockBullQueue.on.mock.calls.find(
        (call: any[]) => call[0] === 'failed'
      )?.[1];

      expect(failedHandler).toBeDefined();

      // Simulate failed event
      const mockJob = { id: 'test-job-456', attemptsMade: 3 };
      const mockError = new Error('Test error');

      // Should not throw
      expect(() => failedHandler(mockJob, mockError)).not.toThrow();
    });

    it('should handle stalled event correctly', () => {
      const stalledHandler = mockBullQueue.on.mock.calls.find(
        (call: any[]) => call[0] === 'stalled'
      )?.[1];

      expect(stalledHandler).toBeDefined();

      // Simulate stalled event
      const mockJob = { id: 'test-job-789' };

      // Should not throw
      expect(() => stalledHandler(mockJob)).not.toThrow();
    });
  });

  describe('Queue Export', () => {
    it('should export scraperQueue instance', () => {
      const { scraperQueue } = require('../scraper.queue');

      expect(scraperQueue).toBeDefined();
      expect(scraperQueue).toBe(mockBullQueue);
    });

    it('should export canScheduleJob function', () => {
      const { canScheduleJob } = require('../scraper.queue');

      expect(canScheduleJob).toBeDefined();
      expect(typeof canScheduleJob).toBe('function');
    });
  });
});
</file>

<file path="queues/README.md">
# queues

## Overview

This directory contains 1 code file(s) with extracted schemas.

## Files and Schemas

### `scraper.queue.ts` (typescript)

**Functions:**
- `canScheduleJob(searchTerm) -> Promise<boolean>` - Line 171

**Key Imports:** `../lib/prisma`, `../lib/tcad-scraper`, `../types`, `bull`, `winston`

---
*Generated by Schema Generator*
</file>

<file path="queues/scraper.queue.ts">
import Bull from 'bull';
import { TCADScraper } from '../lib/tcad-scraper';
import { ScrapeJobData, ScrapeJobResult } from '../types';
import winston from 'winston';
import { prisma } from '../lib/prisma';
import { config } from '../config';
import { cacheService } from '../lib/redis-cache.service';
import { searchTermOptimizer } from '../services/search-term-optimizer';

const logger = winston.createLogger({
  level: config.logging.level,
  format: winston.format.json(),
  transports: [
    new winston.transports.Console({
      format: winston.format.simple(),
    }),
  ],
});

// Create the Bull queue
export const scraperQueue = new Bull<ScrapeJobData>(config.queue.name, {
  redis: {
    host: config.redis.host,
    port: config.redis.port,
    password: config.redis.password,
    db: config.redis.db,
  },
  defaultJobOptions: {
    attempts: config.queue.defaultJobOptions.attempts,
    backoff: {
      type: 'exponential',
      delay: config.queue.defaultJobOptions.backoffDelay,
    },
    removeOnComplete: config.queue.defaultJobOptions.removeOnComplete,
    removeOnFail: config.queue.defaultJobOptions.removeOnFail,
  },
});

// Process scraping jobs
scraperQueue.process(config.queue.jobName, config.queue.concurrency, async (job) => {
  const startTime = Date.now();
  const { searchTerm } = job.data;

  logger.info(`Processing scrape job ${job.id} for search term: ${searchTerm}`);

  // Create a job record in the database
  const scrapeJob = await prisma.scrapeJob.create({
    data: {
      searchTerm,
      status: 'processing',
    },
  });

  const scraper = new TCADScraper({
    headless: config.env.isProduction ? true : config.scraper.headless,
  });

  try {
    // Update progress: Initializing
    await job.progress(10);
    await scraper.initialize();

    // Update progress: Scraping
    // Using API-based scraping for better results (up to 1000x more properties)
    await job.progress(30);
    const properties = await scraper.scrapePropertiesViaAPI(searchTerm);

    // Update progress: Saving to database
    await job.progress(70);

    // Batch upsert properties to database using PostgreSQL's ON CONFLICT
    // This is 10-50x faster than individual upserts
    let savedCount = 0;

    if (properties.length > 0) {
      // Process in chunks of 500 to avoid query size limits
      const CHUNK_SIZE = 500;

      for (let i = 0; i < properties.length; i += CHUNK_SIZE) {
        const chunk = properties.slice(i, i + CHUNK_SIZE);

        // Build the VALUES clause dynamically
        const now = new Date();
        const valuesClauses: string[] = [];
        const params: any[] = [];
        let paramIndex = 1;

        for (const property of chunk) {
          valuesClauses.push(
            `($${paramIndex}, $${paramIndex + 1}, $${paramIndex + 2}, $${paramIndex + 3}, $${paramIndex + 4}, ` +
            `$${paramIndex + 5}, $${paramIndex + 6}, $${paramIndex + 7}, $${paramIndex + 8}, ` +
            `$${paramIndex + 9}, $${paramIndex + 10}, $${paramIndex + 11}, $${paramIndex + 12})`
          );

          params.push(
            property.propertyId,
            property.name,
            property.propType,
            property.city,
            property.propertyAddress,
            property.assessedValue,
            property.appraisedValue,
            property.geoId,
            property.description,
            searchTerm,
            now,
            now,
            now
          );

          paramIndex += 13;
        }

        // Execute raw SQL with PostgreSQL's native UPSERT (ON CONFLICT)
        const sql = `
          INSERT INTO properties (
            property_id, name, prop_type, city, property_address,
            assessed_value, appraised_value, geo_id, description,
            search_term, scraped_at, created_at, updated_at
          )
          VALUES ${valuesClauses.join(', ')}
          ON CONFLICT (property_id) DO UPDATE SET
            name = EXCLUDED.name,
            prop_type = EXCLUDED.prop_type,
            city = EXCLUDED.city,
            property_address = EXCLUDED.property_address,
            assessed_value = EXCLUDED.assessed_value,
            appraised_value = EXCLUDED.appraised_value,
            geo_id = EXCLUDED.geo_id,
            description = EXCLUDED.description,
            search_term = EXCLUDED.search_term,
            scraped_at = EXCLUDED.scraped_at,
            updated_at = EXCLUDED.updated_at
        `;

        await prisma.$executeRawUnsafe(sql, ...params);

        savedCount += chunk.length;
        logger.info(`Batch upserted ${chunk.length} properties (${savedCount}/${properties.length} total)`);
      }
    }

    const savedProperties = properties;

    // Update progress: Complete
    await job.progress(100);

    // Update job record
    await prisma.scrapeJob.update({
      where: { id: scrapeJob.id },
      data: {
        status: 'completed',
        resultCount: savedProperties.length,
        completedAt: new Date(),
      },
    });

    // Update search term analytics for optimization
    await searchTermOptimizer.updateAnalytics(
      searchTerm,
      savedProperties.length,
      true // wasSuccessful
    );

    // Invalidate caches since new properties were added
    logger.info('Invalidating caches after successful scrape...');
    await Promise.all([
      cacheService.deletePattern('properties:list:*'),  // Invalidate all list queries
      cacheService.delete('properties:stats:all'),      // Invalidate statistics
    ]);
    logger.info('Caches invalidated successfully');

    const duration = Date.now() - startTime;
    const result: ScrapeJobResult = {
      count: savedProperties.length,
      properties: savedProperties,
      searchTerm,
      duration,
    };

    logger.info(`Job ${job.id} completed successfully. Found ${result.count} properties in ${duration}ms`);

    return result;

  } catch (error) {
    logger.error(`Job ${job.id} failed:`, error);

    // Update job record with error
    await prisma.scrapeJob.update({
      where: { id: scrapeJob.id },
      data: {
        status: 'failed',
        error: error instanceof Error ? error.message : 'Unknown error',
        completedAt: new Date(),
      },
    });

    // Update search term analytics for failed job
    await searchTermOptimizer.updateAnalytics(
      searchTerm,
      0, // resultCount
      false, // wasSuccessful
      error instanceof Error ? error.message : 'Unknown error'
    );

    throw error;

  } finally {
    await scraper.cleanup();
  }
});

// Event listeners for queue monitoring
scraperQueue.on('completed', (job, result: ScrapeJobResult) => {
  logger.info(`Job ${job.id} completed with ${result.count} properties in ${result.duration}ms`);
});

scraperQueue.on('failed', (job, err) => {
  logger.error(`Job ${job.id} failed after ${job.attemptsMade} attempts:`, err);
});

scraperQueue.on('stalled', (job) => {
  logger.warn(`Job ${job.id} stalled and will be retried`);
});

// Clean up old jobs periodically
setInterval(async () => {
  try {
    await scraperQueue.clean(config.queue.cleanupGracePeriod, 'completed');
    await scraperQueue.clean(config.queue.cleanupGracePeriod, 'failed');
    logger.info('Cleaned old jobs from queue');
  } catch (error) {
    logger.error('Failed to clean queue:', error);
  }
}, config.queue.cleanupInterval);

// Rate limiting helper
const activeJobs = new Map<string, number>();

export async function canScheduleJob(searchTerm: string): Promise<boolean> {
  const lastJobTime = activeJobs.get(searchTerm);

  if (lastJobTime && Date.now() - lastJobTime < config.rateLimit.scraper.jobDelay) {
    return false;
  }

  activeJobs.set(searchTerm, Date.now());

  // Clean up old entries
  for (const [term, time] of activeJobs.entries()) {
    if (Date.now() - time > config.rateLimit.scraper.cacheCleanupInterval) {
      activeJobs.delete(term);
    }
  }

  return true;
}
</file>

<file path="routes/__tests__/app.routes.test.ts">
/**
 * App Routes Tests
 */

import { describe, test, expect, beforeAll, afterAll } from '@jest/globals';
import request from 'supertest';
import express from 'express';
import { appRouter } from '../app.routes';
import { nonceMiddleware } from '../../middleware/xcontroller.middleware';

describe('App Routes', () => {
  let app: express.Application;

  beforeAll(() => {
    app = express();
    app.use(nonceMiddleware);
    app.use('/', appRouter);
  });

  describe('GET /', () => {
    test('should return HTML with status 200', async () => {
      const response = await request(app).get('/');
      expect(response.status).toBe(200);
      expect(response.headers['content-type']).toContain('text/html');
    });

    test('should include doctype', async () => {
      const response = await request(app).get('/');
      expect(response.text).toContain('<!DOCTYPE html>');
    });

    test('should include root div', async () => {
      const response = await request(app).get('/');
      expect(response.text).toContain('<div id="root"></div>');
    });

    test('should include initial data script', async () => {
      const response = await request(app).get('/');
      expect(response.text).toContain('type="application/json"');
      expect(response.text).toContain('id="initial-data"');
    });

    test('should include nonce in script tags', async () => {
      const response = await request(app).get('/');
      expect(response.text).toMatch(/nonce="[^"]+"/);
    });

    test('should include app script reference', async () => {
      const response = await request(app).get('/');
      expect(response.text).toContain('/src/main.tsx');
    });

    test('should have proper charset', async () => {
      const response = await request(app).get('/');
      expect(response.headers['content-type']).toContain('charset=utf-8');
    });
  });

  describe('CSP Headers', () => {
    test('should set Content-Security-Policy header', async () => {
      const response = await request(app).get('/');
      expect(response.headers['content-security-policy']).toBeDefined();
    });

    test('should include script-src directive', async () => {
      const response = await request(app).get('/');
      const csp = response.headers['content-security-policy'];
      expect(csp).toContain('script-src');
    });

    test('should include nonce in CSP', async () => {
      const response = await request(app).get('/');
      const csp = response.headers['content-security-policy'];
      expect(csp).toMatch(/'nonce-[^']+'/);
    });

    test('should match nonce in CSP and HTML', async () => {
      const response = await request(app).get('/');

      // Extract nonce from HTML
      const htmlNonceMatch = response.text.match(/nonce="([^"]+)"/);
      expect(htmlNonceMatch).toBeTruthy();
      const htmlNonce = htmlNonceMatch![1];

      // Extract nonce from CSP
      const csp = response.headers['content-security-policy'];
      expect(csp).toContain(`'nonce-${htmlNonce}'`);
    });
  });

  describe('Security Headers', () => {
    test('should set X-Content-Type-Options', async () => {
      const response = await request(app).get('/');
      expect(response.headers['x-content-type-options']).toBe('nosniff');
    });

    test('should set X-Frame-Options', async () => {
      const response = await request(app).get('/');
      expect(response.headers['x-frame-options']).toBe('DENY');
    });

    test('should set X-XSS-Protection', async () => {
      const response = await request(app).get('/');
      expect(response.headers['x-xss-protection']).toBe('1; mode=block');
    });

    test('should set Referrer-Policy', async () => {
      const response = await request(app).get('/');
      expect(response.headers['referrer-policy']).toBe('strict-origin-when-cross-origin');
    });
  });

  describe('Initial Data', () => {
    test('should include version in initial data', async () => {
      const response = await request(app).get('/');
      const dataMatch = response.text.match(
        /<script type="application\/json" id="initial-data"[^>]*>\s*({[\s\S]*?})\s*<\/script>/
      );
      expect(dataMatch).toBeTruthy();

      const data = JSON.parse(dataMatch![1]);
      expect(data).toHaveProperty('version');
    });

    test('should include environment in initial data', async () => {
      const response = await request(app).get('/');
      const dataMatch = response.text.match(
        /<script type="application\/json" id="initial-data"[^>]*>\s*({[\s\S]*?})\s*<\/script>/
      );

      const data = JSON.parse(dataMatch![1]);
      expect(data).toHaveProperty('environment');
    });

    test('should include features in initial data', async () => {
      const response = await request(app).get('/');
      const dataMatch = response.text.match(
        /<script type="application\/json" id="initial-data"[^>]*>\s*({[\s\S]*?})\s*<\/script>/
      );

      const data = JSON.parse(dataMatch![1]);
      expect(data).toHaveProperty('features');
      expect(data.features).toHaveProperty('search');
      expect(data.features).toHaveProperty('analytics');
    });

    test('should properly encode dangerous characters in data', async () => {
      const response = await request(app).get('/');
      const text = response.text;

      // If data contains <, >, & they should be encoded
      const dataSection = text.match(
        /<script type="application\/json" id="initial-data"[^>]*>([\s\S]*?)<\/script>/
      );

      if (dataSection && dataSection[1].includes('"')) {
        // Check that any < > & in the data are encoded
        expect(dataSection[1]).not.toMatch(/<(?!\/script>)/);
        expect(dataSection[1]).not.toMatch(/&(?!amp;|lt;|gt;|quot;|#)/);
      }
    });
  });

  describe('GET /health', () => {
    test('should return health status', async () => {
      const response = await request(app).get('/health');
      expect(response.status).toBe(200);
      expect(response.body).toHaveProperty('status', 'healthy');
      expect(response.body).toHaveProperty('timestamp');
    });
  });

  describe('XSS Prevention', () => {
    test('should not allow script injection in title', async () => {
      const response = await request(app).get('/');
      expect(response.text).not.toContain('<script>alert');
    });

    test('should encode special characters in data', async () => {
      const response = await request(app).get('/');
      const dataSection = response.text.match(
        /<script type="application\/json" id="initial-data"[^>]*>([\s\S]*?)<\/script>/
      );

      if (dataSection) {
        const dataJson = dataSection[1];
        // If there are any encoded characters, they should use unicode escapes
        if (dataJson.includes('\\u003C')) {
          expect(dataJson).not.toContain('<script');
        }
      }
    });
  });
});
</file>

<file path="routes/__tests__/property.routes.claude.test.ts">
/**
 * Property Routes - Claude Search Tests
 */

import { describe, test, expect, beforeAll, afterAll, jest } from '@jest/globals';
import request from 'supertest';
import express from 'express';
import { claudeSearchService } from '../../lib/claude.service';

// Mock the Claude search service
jest.mock('../../lib/claude.service');

// Mock Redis cache service
jest.mock('../../lib/redis-cache.service', () => ({
  cacheService: {
    getOrSet: jest.fn((key, fn) => fn()),
    get: jest.fn().mockResolvedValue(null),
    set: jest.fn().mockResolvedValue(undefined),
  },
}));

// Mock Queue
jest.mock('../../queues/scraper.queue', () => ({
  scraperQueue: {
    add: jest.fn().mockResolvedValue({ id: '123' }),
    getJob: jest.fn().mockResolvedValue(null),
  },
  canScheduleJob: jest.fn().mockResolvedValue(true),
}));

// Mock Prisma
jest.mock('../../lib/prisma', () => ({
  prisma: {
    property: {
      findMany: jest.fn().mockResolvedValue([]),
      count: jest.fn().mockResolvedValue(0),
    },
  },
  prismaReadOnly: {
    property: {
      findMany: jest.fn().mockResolvedValue([]),
      count: jest.fn().mockResolvedValue(0),
    },
  },
}));

// Import after mocks
import { propertyRouter } from '../property.routes';
import { errorHandler } from '../../middleware/error.middleware';

describe('Property Routes - Claude Search', () => {
  let app: express.Application;

  beforeAll(() => {
    app = express();
    app.use(express.json());
    app.use('/api/properties', propertyRouter);
    app.use(errorHandler);
  });

  afterAll(() => {
    jest.restoreAllMocks();
  });

  describe('GET /api/properties/search/test', () => {
    test('should return success when Claude API is working', async () => {
      const mockResult = {
        whereClause: {
          city: { contains: 'Austin', mode: 'insensitive' }
        },
        explanation: 'Searching for properties in Austin'
      };

      (claudeSearchService.parseNaturalLanguageQuery as jest.Mock).mockResolvedValue(mockResult);

      const response = await request(app).get('/api/properties/search/test');

      expect(response.status).toBe(200);
      expect(response.body).toHaveProperty('success', true);
      expect(response.body).toHaveProperty('message', 'Claude API connection successful');
      expect(response.body).toHaveProperty('testQuery', 'properties in Austin');
      expect(response.body.result).toEqual(mockResult);
    });

    test('should return failure when Claude API fails', async () => {
      const mockError = new Error('API Error');
      (claudeSearchService.parseNaturalLanguageQuery as jest.Mock).mockRejectedValue(mockError);

      const response = await request(app).get('/api/properties/search/test');

      expect(response.status).toBe(500);
      expect(response.body).toHaveProperty('error', 'Internal server error');
      expect(response.body).toHaveProperty('message');
    });

    test('should handle authentication errors', async () => {
      const authError = new Error('401 authentication_error: invalid x-api-key');
      authError.name = 'AuthenticationError';
      (claudeSearchService.parseNaturalLanguageQuery as jest.Mock).mockRejectedValue(authError);

      const response = await request(app).get('/api/properties/search/test');

      expect(response.status).toBe(500);
      expect(response.body).toHaveProperty('error', 'Internal server error');
      expect(response.body).toHaveProperty('message');
    });

    test('should handle model not found errors', async () => {
      const modelError = new Error('404 not_found_error: model: claude-3-5-sonnet-20241022');
      modelError.name = 'NotFoundError';
      (claudeSearchService.parseNaturalLanguageQuery as jest.Mock).mockRejectedValue(modelError);

      const response = await request(app).get('/api/properties/search/test');

      expect(response.status).toBe(500);
      expect(response.body).toHaveProperty('error', 'Internal server error');
      expect(response.body).toHaveProperty('message');
    });
  });

  describe('POST /api/properties/search', () => {
    beforeEach(() => {
      // Reset and configure Prisma mocks for each test
      const { prismaReadOnly } = require('../../lib/prisma');
      prismaReadOnly.property.findMany.mockClear();
      prismaReadOnly.property.count.mockClear();

      prismaReadOnly.property.findMany.mockResolvedValue([
        {
          id: '1',
          propertyId: 'PROP001',
          name: 'John Doe',
          propType: 'Residential',
          city: 'Austin',
          propertyAddress: '123 Main St',
          assessedValue: 400000,
          appraisedValue: 500000,
          geoId: 'GEO001',
          description: 'Nice house',
          searchTerm: 'Austin',
          scrapedAt: new Date(),
          createdAt: new Date(),
          updatedAt: new Date(),
        }
      ]);
      prismaReadOnly.property.count.mockResolvedValue(1);
    });

    test('should return 400 when query is missing', async () => {
      const response = await request(app)
        .post('/api/properties/search')
        .send({});

      expect(response.status).toBe(400);
      expect(response.body).toHaveProperty('error', 'Invalid request data');
      expect(response.body.details).toBeDefined();
    });

    test('should return 400 when query is not a string', async () => {
      const response = await request(app)
        .post('/api/properties/search')
        .send({ query: 123 });

      expect(response.status).toBe(400);
      expect(response.body).toHaveProperty('error', 'Invalid request data');
      expect(response.body.details).toBeDefined();
    });

    test('should successfully parse and execute natural language query', async () => {
      const mockResult = {
        whereClause: {
          city: { contains: 'Austin', mode: 'insensitive' }
        },
        orderBy: undefined,
        explanation: 'Searching for properties in Austin'
      };

      (claudeSearchService.parseNaturalLanguageQuery as jest.Mock).mockResolvedValue(mockResult);

      const response = await request(app)
        .post('/api/properties/search')
        .send({ query: 'properties in Austin' });

      expect(response.status).toBe(200);
      expect(response.body).toHaveProperty('data');
      expect(response.body).toHaveProperty('pagination');
      expect(response.body).toHaveProperty('query');
      expect(response.body.query.original).toBe('properties in Austin');
      expect(response.body.query.explanation).toBe('Searching for properties in Austin');
    });

    test('should handle complex queries with value filters', async () => {
      const mockResult = {
        whereClause: {
          city: 'Austin',
          appraisedValue: { gte: 500000 }
        },
        orderBy: { appraisedValue: 'desc' },
        explanation: 'Searching for properties in Austin worth over $500,000'
      };

      (claudeSearchService.parseNaturalLanguageQuery as jest.Mock).mockResolvedValue(mockResult);

      const response = await request(app)
        .post('/api/properties/search')
        .send({ query: 'properties in Austin worth over 500k' });

      expect(response.status).toBe(200);
      expect(response.body.query.explanation).toBe('Searching for properties in Austin worth over $500,000');
    });

    test('should support pagination with limit parameter', async () => {
      const mockResult = {
        whereClause: { city: 'Austin' },
        explanation: 'Test'
      };

      (claudeSearchService.parseNaturalLanguageQuery as jest.Mock).mockResolvedValue(mockResult);

      const response = await request(app)
        .post('/api/properties/search')
        .send({
          query: 'properties in Austin',
          limit: 50
        });

      expect(response.status).toBe(200);
      expect(response.body.pagination.limit).toBe(50);
    });

    test('should support pagination with offset parameter', async () => {
      const mockResult = {
        whereClause: { city: 'Austin' },
        explanation: 'Test'
      };

      (claudeSearchService.parseNaturalLanguageQuery as jest.Mock).mockResolvedValue(mockResult);

      const response = await request(app)
        .post('/api/properties/search')
        .send({
          query: 'properties in Austin',
          offset: 100
        });

      expect(response.status).toBe(200);
      expect(response.body.pagination.offset).toBe(100);
    });

    test('should limit maximum results to 1000', async () => {
      // The validation middleware enforces max limit of 1000, so this test should expect 400
      const response = await request(app)
        .post('/api/properties/search')
        .send({
          query: 'properties in Austin',
          limit: 5000 // Try to request more than max
        });

      expect(response.status).toBe(400);
      expect(response.body).toHaveProperty('error', 'Invalid request data');
    });

    test('should use default limit of 100 when not specified', async () => {
      const mockResult = {
        whereClause: { city: 'Austin' },
        explanation: 'Test'
      };

      (claudeSearchService.parseNaturalLanguageQuery as jest.Mock).mockResolvedValue(mockResult);

      const response = await request(app)
        .post('/api/properties/search')
        .send({ query: 'properties in Austin' });

      expect(response.status).toBe(200);
      expect(response.body.pagination.limit).toBe(100);
    });

    test('should calculate hasMore correctly', async () => {
      const mockResult = {
        whereClause: { city: 'Austin' },
        explanation: 'Test'
      };

      (claudeSearchService.parseNaturalLanguageQuery as jest.Mock).mockResolvedValue(mockResult);

      const { prismaReadOnly } = require('../../lib/prisma');
      prismaReadOnly.property.count.mockResolvedValue(250);

      const response = await request(app)
        .post('/api/properties/search')
        .send({
          query: 'properties in Austin',
          limit: 100,
          offset: 0
        });

      expect(response.status).toBe(200);
      expect(response.body.pagination.hasMore).toBe(true);
    });

    test('should handle errors gracefully', async () => {
      (claudeSearchService.parseNaturalLanguageQuery as jest.Mock).mockRejectedValue(
        new Error('Unexpected error')
      );

      const response = await request(app)
        .post('/api/properties/search')
        .send({ query: 'test query' });

      expect(response.status).toBe(500);
      expect(response.body).toHaveProperty('error', 'Internal server error');
      expect(response.body).toHaveProperty('message');
    });

    test('should work with fallback when Claude fails', async () => {
      // Mock Claude to use fallback
      const fallbackResult = {
        whereClause: {
          OR: [
            { name: { contains: 'test', mode: 'insensitive' } },
            { propertyAddress: { contains: 'test', mode: 'insensitive' } },
            { city: { contains: 'test', mode: 'insensitive' } },
            { description: { contains: 'test', mode: 'insensitive' } },
          ]
        },
        explanation: 'Searching for "test" across property names, addresses, cities, and descriptions'
      };

      (claudeSearchService.parseNaturalLanguageQuery as jest.Mock).mockResolvedValue(fallbackResult);

      const response = await request(app)
        .post('/api/properties/search')
        .send({ query: 'test' });

      expect(response.status).toBe(200);
      expect(response.body.query.explanation).toContain('Searching for "test"');
    });
  });

  describe('Query Types', () => {
    beforeEach(() => {
      const { prismaReadOnly } = require('../../lib/prisma');
      prismaReadOnly.property.findMany.mockClear();
      prismaReadOnly.property.count.mockClear();
      prismaReadOnly.property.findMany.mockResolvedValue([]);
      prismaReadOnly.property.count.mockResolvedValue(0);
    });

    test('should handle city-based queries', async () => {
      const mockResult = {
        whereClause: { city: { contains: 'Round Rock', mode: 'insensitive' } },
        explanation: 'Searching for properties in Round Rock'
      };

      (claudeSearchService.parseNaturalLanguageQuery as jest.Mock).mockResolvedValue(mockResult);

      const response = await request(app)
        .post('/api/properties/search')
        .send({ query: 'homes in Round Rock' });

      expect(response.status).toBe(200);
      expect(claudeSearchService.parseNaturalLanguageQuery).toHaveBeenCalledWith('homes in Round Rock');
    });

    test('should handle owner name queries', async () => {
      const mockResult = {
        whereClause: { name: { contains: 'Smith', mode: 'insensitive' } },
        explanation: 'Searching for properties owned by Smith'
      };

      (claudeSearchService.parseNaturalLanguageQuery as jest.Mock).mockResolvedValue(mockResult);

      const response = await request(app)
        .post('/api/properties/search')
        .send({ query: 'properties owned by Smith' });

      expect(response.status).toBe(200);
    });

    test('should handle property type queries', async () => {
      const mockResult = {
        whereClause: { propType: { contains: 'Commercial', mode: 'insensitive' } },
        explanation: 'Searching for commercial properties'
      };

      (claudeSearchService.parseNaturalLanguageQuery as jest.Mock).mockResolvedValue(mockResult);

      const response = await request(app)
        .post('/api/properties/search')
        .send({ query: 'commercial properties' });

      expect(response.status).toBe(200);
    });

    test('should handle address-based queries', async () => {
      const mockResult = {
        whereClause: { propertyAddress: { contains: 'Congress', mode: 'insensitive' } },
        explanation: "Searching for properties with 'Congress' in the address"
      };

      (claudeSearchService.parseNaturalLanguageQuery as jest.Mock).mockResolvedValue(mockResult);

      const response = await request(app)
        .post('/api/properties/search')
        .send({ query: 'properties on Congress Ave' });

      expect(response.status).toBe(200);
    });

    test('should handle value range queries', async () => {
      const mockResult = {
        whereClause: {
          appraisedValue: { gte: 300000, lte: 600000 }
        },
        orderBy: { appraisedValue: 'asc' },
        explanation: 'Searching for properties with appraised value between $300,000 and $600,000'
      };

      (claudeSearchService.parseNaturalLanguageQuery as jest.Mock).mockResolvedValue(mockResult);

      const response = await request(app)
        .post('/api/properties/search')
        .send({ query: 'find properties appraised between 300k and 600k' });

      expect(response.status).toBe(200);
    });

    test('should handle combined complex queries', async () => {
      const mockResult = {
        whereClause: {
          city: 'Austin',
          propType: { contains: 'Residential', mode: 'insensitive' },
          appraisedValue: { gte: 1000000 }
        },
        orderBy: { appraisedValue: 'desc' },
        explanation: 'Searching for residential properties in Austin worth over $1,000,000'
      };

      (claudeSearchService.parseNaturalLanguageQuery as jest.Mock).mockResolvedValue(mockResult);

      const response = await request(app)
        .post('/api/properties/search')
        .send({ query: 'residential properties in Austin worth over 1 million' });

      expect(response.status).toBe(200);
    });
  });

  describe('Edge Cases', () => {
    beforeEach(() => {
      const { prismaReadOnly } = require('../../lib/prisma');
      prismaReadOnly.property.findMany.mockClear();
      prismaReadOnly.property.count.mockClear();
      prismaReadOnly.property.findMany.mockResolvedValue([]);
      prismaReadOnly.property.count.mockResolvedValue(0);
    });

    test('should handle empty string query', async () => {
      const response = await request(app)
        .post('/api/properties/search')
        .send({ query: '' });

      expect(response.status).toBe(400);
    });

    test('should handle null query', async () => {
      const response = await request(app)
        .post('/api/properties/search')
        .send({ query: null });

      expect(response.status).toBe(400);
    });

    test('should handle undefined query', async () => {
      const response = await request(app)
        .post('/api/properties/search')
        .send({});

      expect(response.status).toBe(400);
    });

    test('should handle very long queries', async () => {
      const longQuery = 'properties '.repeat(100);
      const mockResult = {
        whereClause: { city: 'Austin' },
        explanation: 'Test'
      };

      (claudeSearchService.parseNaturalLanguageQuery as jest.Mock).mockResolvedValue(mockResult);

      const response = await request(app)
        .post('/api/properties/search')
        .send({ query: longQuery });

      expect(response.status).toBe(200);
    });

    test('should handle special characters', async () => {
      const mockResult = {
        whereClause: { propertyAddress: { contains: "O'Connor", mode: 'insensitive' } },
        explanation: 'Test'
      };

      (claudeSearchService.parseNaturalLanguageQuery as jest.Mock).mockResolvedValue(mockResult);

      const response = await request(app)
        .post('/api/properties/search')
        .send({ query: "properties on O'Connor St" });

      expect(response.status).toBe(200);
    });
  });
});
</file>

<file path="routes/__tests__/property.routes.test.ts">
import request from 'supertest';
import express, { Express } from 'express';
import { propertyRouter } from '../property.routes';
import { propertyController } from '../../controllers/property.controller';

// Mock the controller
jest.mock('../../controllers/property.controller', () => ({
  propertyController: {
    scrapeProperties: jest.fn(),
    getJobStatus: jest.fn(),
    getScrapeHistory: jest.fn(),
    getProperties: jest.fn(),
    naturalLanguageSearch: jest.fn(),
    testClaudeConnection: jest.fn(),
    getStats: jest.fn(),
    addMonitoredSearch: jest.fn(),
    getMonitoredSearches: jest.fn(),
  },
}));

describe('Property Routes', () => {
  let app: Express;

  beforeEach(() => {
    // Create a fresh Express app for each test
    app = express();
    app.use(express.json());
    app.use('/api/properties', propertyRouter);

    // Clear all mocks
    jest.clearAllMocks();

    // Setup default successful responses
    (propertyController.scrapeProperties as jest.Mock).mockImplementation(
      (req, res) => res.status(202).json({ jobId: '123', message: 'Scrape job queued successfully' })
    );
    (propertyController.getJobStatus as jest.Mock).mockImplementation(
      (req, res) => res.json({ id: '123', status: 'completed' })
    );
    (propertyController.getScrapeHistory as jest.Mock).mockImplementation(
      (req, res) => res.json({ data: [], pagination: { total: 0, limit: 20, offset: 0, hasMore: false } })
    );
    (propertyController.getProperties as jest.Mock).mockImplementation(
      (req, res) => res.json({ data: [], pagination: { total: 0, limit: 20, offset: 0, hasMore: false } })
    );
    (propertyController.naturalLanguageSearch as jest.Mock).mockImplementation(
      (req, res) => res.json({ data: [], query: req.body.query, parsedFilters: {} })
    );
    (propertyController.testClaudeConnection as jest.Mock).mockImplementation(
      (req, res) => res.json({ status: 'success', message: 'Claude AI connection test successful' })
    );
    (propertyController.getStats as jest.Mock).mockImplementation(
      (req, res) => res.json({ totalProperties: 0, totalJobs: 0 })
    );
    (propertyController.addMonitoredSearch as jest.Mock).mockImplementation(
      (req, res) => res.status(201).json({ id: 'uuid', searchTerm: req.body.searchTerm, enabled: true })
    );
    (propertyController.getMonitoredSearches as jest.Mock).mockImplementation(
      (req, res) => res.json({ data: [] })
    );
  });

  describe('POST /api/properties/scrape', () => {
    it('should accept valid scrape request', async () => {
      const response = await request(app)
        .post('/api/properties/scrape')
        .send({ searchTerm: 'Smith' })
        .expect(202);

      expect(response.body).toHaveProperty('jobId');
      expect(response.body.message).toBe('Scrape job queued successfully');
      expect(propertyController.scrapeProperties).toHaveBeenCalled();
    });

    it('should reject request without searchTerm', async () => {
      const response = await request(app)
        .post('/api/properties/scrape')
        .send({})
        .expect(400);

      expect(response.body).toHaveProperty('error', 'Invalid request data');
      expect(response.body).toHaveProperty('details');
      expect(propertyController.scrapeProperties).not.toHaveBeenCalled();
    });

    it('should reject request with invalid searchTerm type', async () => {
      const response = await request(app)
        .post('/api/properties/scrape')
        .send({ searchTerm: 123 })
        .expect(400);

      expect(response.body).toHaveProperty('error', 'Invalid request data');
      expect(response.body).toHaveProperty('details');
      expect(propertyController.scrapeProperties).not.toHaveBeenCalled();
    });

    it('should accept optional userId and scheduled fields', async () => {
      await request(app)
        .post('/api/properties/scrape')
        .send({ searchTerm: 'Smith', userId: 'user123', scheduled: true })
        .expect(202);

      expect(propertyController.scrapeProperties).toHaveBeenCalled();
    });
  });

  describe('GET /api/properties/jobs/:jobId', () => {
    it('should retrieve job status', async () => {
      const response = await request(app)
        .get('/api/properties/jobs/123')
        .expect(200);

      expect(response.body).toHaveProperty('id');
      expect(response.body).toHaveProperty('status');
      expect(propertyController.getJobStatus).toHaveBeenCalled();
    });

    it('should pass jobId parameter to controller', async () => {
      await request(app)
        .get('/api/properties/jobs/test-job-id')
        .expect(200);

      expect(propertyController.getJobStatus).toHaveBeenCalled();
    });
  });

  describe('GET /api/properties/history', () => {
    it('should retrieve scrape history with default pagination', async () => {
      const response = await request(app)
        .get('/api/properties/history')
        .expect(200);

      expect(response.body).toHaveProperty('data');
      expect(response.body).toHaveProperty('pagination');
      expect(propertyController.getScrapeHistory).toHaveBeenCalled();
    });

    it('should accept valid pagination parameters', async () => {
      await request(app)
        .get('/api/properties/history?limit=10&offset=5')
        .expect(200);

      expect(propertyController.getScrapeHistory).toHaveBeenCalled();
    });

    it('should accept valid status filter', async () => {
      await request(app)
        .get('/api/properties/history?status=completed')
        .expect(200);

      expect(propertyController.getScrapeHistory).toHaveBeenCalled();
    });

    it('should reject invalid limit (too large)', async () => {
      const response = await request(app)
        .get('/api/properties/history?limit=101')
        .expect(400);

      expect(response.body).toHaveProperty('error', 'Invalid request data');
      expect(response.body).toHaveProperty('details');
      expect(propertyController.getScrapeHistory).not.toHaveBeenCalled();
    });

    it('should reject invalid limit (negative)', async () => {
      const response = await request(app)
        .get('/api/properties/history?limit=-1')
        .expect(400);

      expect(response.body).toHaveProperty('error', 'Invalid request data');
      expect(response.body).toHaveProperty('details');
      expect(propertyController.getScrapeHistory).not.toHaveBeenCalled();
    });

    it('should reject invalid offset (negative)', async () => {
      const response = await request(app)
        .get('/api/properties/history?offset=-1')
        .expect(400);

      expect(response.body).toHaveProperty('error', 'Invalid request data');
      expect(response.body).toHaveProperty('details');
      expect(propertyController.getScrapeHistory).not.toHaveBeenCalled();
    });
  });

  describe('GET /api/properties', () => {
    it('should retrieve properties with default filters', async () => {
      const response = await request(app)
        .get('/api/properties')
        .expect(200);

      expect(response.body).toHaveProperty('data');
      expect(response.body).toHaveProperty('pagination');
      expect(propertyController.getProperties).toHaveBeenCalled();
    });

    it('should accept city filter', async () => {
      await request(app)
        .get('/api/properties?city=Austin')
        .expect(200);

      expect(propertyController.getProperties).toHaveBeenCalled();
    });

    it('should accept propType filter', async () => {
      await request(app)
        .get('/api/properties?propType=Residential')
        .expect(200);

      expect(propertyController.getProperties).toHaveBeenCalled();
    });

    it('should accept value range filters', async () => {
      await request(app)
        .get('/api/properties?minValue=100000&maxValue=500000')
        .expect(200);

      expect(propertyController.getProperties).toHaveBeenCalled();
    });

    it('should accept searchTerm filter', async () => {
      await request(app)
        .get('/api/properties?searchTerm=Smith')
        .expect(200);

      expect(propertyController.getProperties).toHaveBeenCalled();
    });

    it('should accept combined filters', async () => {
      await request(app)
        .get('/api/properties?city=Austin&propType=Residential&minValue=100000&limit=50')
        .expect(200);

      expect(propertyController.getProperties).toHaveBeenCalled();
    });

    it('should reject limit exceeding maximum', async () => {
      const response = await request(app)
        .get('/api/properties?limit=1001')
        .expect(400);

      expect(response.body).toHaveProperty('error', 'Invalid request data');
      expect(response.body).toHaveProperty('details');
      expect(propertyController.getProperties).not.toHaveBeenCalled();
    });

    it('should reject invalid minValue type', async () => {
      const response = await request(app)
        .get('/api/properties?minValue=invalid')
        .expect(400);

      expect(response.body).toHaveProperty('error', 'Invalid request data');
      expect(response.body).toHaveProperty('details');
      expect(propertyController.getProperties).not.toHaveBeenCalled();
    });
  });

  describe('POST /api/properties/search', () => {
    it('should accept natural language search query', async () => {
      const response = await request(app)
        .post('/api/properties/search')
        .send({ query: 'Find all residential properties in Austin worth more than $500k' })
        .expect(200);

      expect(response.body).toHaveProperty('data');
      expect(response.body).toHaveProperty('query');
      expect(response.body).toHaveProperty('parsedFilters');
      expect(propertyController.naturalLanguageSearch).toHaveBeenCalled();
    });

    it('should reject request without query', async () => {
      const response = await request(app)
        .post('/api/properties/search')
        .send({})
        .expect(400);

      expect(response.body).toHaveProperty('error', 'Invalid request data');
      expect(response.body).toHaveProperty('details');
      expect(propertyController.naturalLanguageSearch).not.toHaveBeenCalled();
    });

    it('should reject request with non-string query', async () => {
      const response = await request(app)
        .post('/api/properties/search')
        .send({ query: 123 })
        .expect(400);

      expect(response.body).toHaveProperty('error', 'Invalid request data');
      expect(response.body).toHaveProperty('details');
      expect(propertyController.naturalLanguageSearch).not.toHaveBeenCalled();
    });

    it('should accept optional limit parameter', async () => {
      await request(app)
        .post('/api/properties/search')
        .send({ query: 'Find properties', limit: 50 })
        .expect(200);

      expect(propertyController.naturalLanguageSearch).toHaveBeenCalled();
    });

    it('should reject limit exceeding maximum', async () => {
      const response = await request(app)
        .post('/api/properties/search')
        .send({ query: 'Find properties', limit: 1001 })
        .expect(400);

      expect(response.body).toHaveProperty('error', 'Invalid request data');
      expect(response.body).toHaveProperty('details');
      expect(propertyController.naturalLanguageSearch).not.toHaveBeenCalled();
    });
  });

  describe('GET /api/properties/search/test', () => {
    it('should test Claude AI connection', async () => {
      const response = await request(app)
        .get('/api/properties/search/test')
        .expect(200);

      expect(response.body.status).toBe('success');
      expect(response.body.message).toContain('Claude AI');
      expect(propertyController.testClaudeConnection).toHaveBeenCalled();
    });
  });

  describe('GET /api/properties/stats', () => {
    it('should retrieve property statistics', async () => {
      const response = await request(app)
        .get('/api/properties/stats')
        .expect(200);

      expect(response.body).toHaveProperty('totalProperties');
      expect(response.body).toHaveProperty('totalJobs');
      expect(propertyController.getStats).toHaveBeenCalled();
    });
  });

  describe('POST /api/properties/monitor', () => {
    it('should add monitored search term', async () => {
      const response = await request(app)
        .post('/api/properties/monitor')
        .send({ searchTerm: 'Smith' })
        .expect(201);

      expect(response.body).toHaveProperty('id');
      expect(response.body.searchTerm).toBe('Smith');
      expect(propertyController.addMonitoredSearch).toHaveBeenCalled();
    });

    it('should reject request without searchTerm', async () => {
      const response = await request(app)
        .post('/api/properties/monitor')
        .send({})
        .expect(400);

      expect(response.body).toHaveProperty('error', 'Invalid request data');
      expect(response.body).toHaveProperty('details');
      expect(propertyController.addMonitoredSearch).not.toHaveBeenCalled();
    });

    it('should accept optional schedule and enabled fields', async () => {
      await request(app)
        .post('/api/properties/monitor')
        .send({ searchTerm: 'Smith', schedule: '0 0 * * *', enabled: false })
        .expect(201);

      expect(propertyController.addMonitoredSearch).toHaveBeenCalled();
    });
  });

  describe('GET /api/properties/monitor', () => {
    it('should retrieve monitored search terms', async () => {
      const response = await request(app)
        .get('/api/properties/monitor')
        .expect(200);

      expect(response.body).toHaveProperty('data');
      expect(Array.isArray(response.body.data)).toBe(true);
      expect(propertyController.getMonitoredSearches).toHaveBeenCalled();
    });
  });

  describe('Route Registration', () => {
    it('should have all routes registered', () => {
      const routes = propertyRouter.stack
        .filter(layer => layer.route)
        .map(layer => ({
          path: layer.route.path,
          methods: Object.keys(layer.route.methods),
        }));

      expect(routes).toContainEqual({ path: '/scrape', methods: ['post'] });
      expect(routes).toContainEqual({ path: '/jobs/:jobId', methods: ['get'] });
      expect(routes).toContainEqual({ path: '/history', methods: ['get'] });
      expect(routes).toContainEqual({ path: '/', methods: ['get'] });
      expect(routes).toContainEqual({ path: '/search', methods: ['post'] });
      expect(routes).toContainEqual({ path: '/search/test', methods: ['get'] });
      expect(routes).toContainEqual({ path: '/stats', methods: ['get'] });

      // Monitor routes are registered separately for POST and GET
      const monitorRoutes = routes.filter(r => r.path === '/monitor');
      expect(monitorRoutes).toHaveLength(2);
      expect(monitorRoutes.some(r => r.methods.includes('post'))).toBe(true);
      expect(monitorRoutes.some(r => r.methods.includes('get'))).toBe(true);
    });
  });

  describe('404 Handling', () => {
    it('should return 404 for non-existent route', async () => {
      await request(app)
        .get('/api/properties/nonexistent')
        .expect(404);
    });

    it('should return 404 for wrong HTTP method', async () => {
      await request(app)
        .put('/api/properties/scrape')
        .send({ searchTerm: 'Smith' })
        .expect(404);
    });
  });

  describe('Error Handling', () => {
    it('should handle controller errors gracefully', async () => {
      (propertyController.getStats as jest.Mock).mockImplementation(() => {
        throw new Error('Database connection failed');
      });

      await request(app)
        .get('/api/properties/stats')
        .expect(500);
    });

    it('should handle async controller errors', async () => {
      (propertyController.naturalLanguageSearch as jest.Mock).mockImplementation(async () => {
        throw new Error('Claude AI error');
      });

      await request(app)
        .post('/api/properties/search')
        .send({ query: 'test' })
        .expect(500);
    });
  });
});
</file>

<file path="routes/app.routes.ts">
/**
 * App Routes - Serves the frontend application with secure data passing
 */

import { Router, Request, Response } from 'express';
import {
  nonceMiddleware,
  cspMiddleware,
  generateSecureHtml,
  getInitialAppData,
} from '../middleware/xcontroller.middleware';
import logger from '../lib/logger';

const router = Router();

/**
 * Serve the main application with secure initial data
 */
router.get(
  '/',
  nonceMiddleware,
  cspMiddleware,
  (req: Request, res: Response) => {
    try {
      const nonce = res.locals.nonce;
      const initialData = getInitialAppData();

      const html = generateSecureHtml({
        title: 'TCAD Property Analytics',
        nonce,
        initialData,
        scriptSrc: '/src/main.tsx',
        styleSrc: '/src/App.css',
      });

      res.setHeader('Content-Type', 'text/html; charset=utf-8');
      res.send(html);
    } catch (error) {
      logger.error('Error serving app:', error);
      res.status(500).send('Internal Server Error');
    }
  }
);

/**
 * Health check endpoint
 */
router.get('/health', (req: Request, res: Response) => {
  res.json({
    status: 'healthy',
    timestamp: new Date().toISOString(),
  });
});

export { router as appRouter };
</file>

<file path="routes/property.routes.ts">
import { Router } from 'express';
import { propertyController } from '../controllers/property.controller';
import { validateBody, validateQuery } from '../middleware/validation.middleware';
import { asyncHandler } from '../middleware/error.middleware';
import {
  scrapeRequestSchema,
  propertyFilterSchema,
  naturalLanguageSearchSchema,
  historyQuerySchema,
  monitorRequestSchema,
} from '../types/property.types';

const router = Router();

// ============================================================================
// Scraping Routes
// ============================================================================

/**
 * @swagger
 * /api/properties/scrape:
 *   post:
 *     summary: Trigger a new scrape job
 *     description: Queue a new web scraping job to collect property data for the given search term
 *     tags: [Scraping]
 *     security:
 *       - ApiKeyAuth: []
 *       - BearerAuth: []
 *     requestBody:
 *       required: true
 *       content:
 *         application/json:
 *           schema:
 *             type: object
 *             required:
 *               - searchTerm
 *             properties:
 *               searchTerm:
 *                 type: string
 *                 description: Search term to query TCAD website
 *                 example: Smith
 *               userId:
 *                 type: string
 *                 description: Optional user ID for tracking
 *               scheduled:
 *                 type: boolean
 *                 description: Whether this is a scheduled job
 *                 default: false
 *     responses:
 *       202:
 *         description: Job queued successfully
 *         content:
 *           application/json:
 *             schema:
 *               type: object
 *               properties:
 *                 jobId:
 *                   type: string
 *                   description: Job ID for status tracking
 *                   example: "12345"
 *                 message:
 *                   type: string
 *                   example: Scrape job queued successfully
 *       400:
 *         description: Invalid request body
 *         content:
 *           application/json:
 *             schema:
 *               $ref: '#/components/schemas/Error'
 *       429:
 *         description: Rate limit exceeded
 *         content:
 *           application/json:
 *             schema:
 *               $ref: '#/components/schemas/Error'
 */
router.post(
  '/scrape',
  validateBody(scrapeRequestSchema),
  asyncHandler(propertyController.scrapeProperties.bind(propertyController))
);

/**
 * @swagger
 * /api/properties/jobs/{jobId}:
 *   get:
 *     summary: Get scrape job status
 *     description: Retrieve the current status and details of a specific scrape job
 *     tags: [Scraping]
 *     security:
 *       - ApiKeyAuth: []
 *       - BearerAuth: []
 *     parameters:
 *       - in: path
 *         name: jobId
 *         required: true
 *         schema:
 *           type: string
 *         description: The job ID returned when the scrape was queued
 *         example: "12345"
 *     responses:
 *       200:
 *         description: Job status retrieved successfully
 *         content:
 *           application/json:
 *             schema:
 *               $ref: '#/components/schemas/ScrapeJob'
 *       404:
 *         description: Job not found
 *         content:
 *           application/json:
 *             schema:
 *               $ref: '#/components/schemas/Error'
 */
router.get(
  '/jobs/:jobId',
  asyncHandler(propertyController.getJobStatus.bind(propertyController))
);

/**
 * @swagger
 * /api/properties/history:
 *   get:
 *     summary: Get scrape job history
 *     description: Retrieve paginated scrape job history with optional filters
 *     tags: [Scraping]
 *     security:
 *       - ApiKeyAuth: []
 *       - BearerAuth: []
 *     parameters:
 *       - in: query
 *         name: limit
 *         schema:
 *           type: integer
 *           default: 20
 *           minimum: 1
 *           maximum: 100
 *         description: Number of jobs per page
 *       - in: query
 *         name: offset
 *         schema:
 *           type: integer
 *           default: 0
 *           minimum: 0
 *         description: Number of jobs to skip
 *       - in: query
 *         name: status
 *         schema:
 *           type: string
 *           enum: [pending, processing, completed, failed]
 *         description: Filter by job status
 *     responses:
 *       200:
 *         description: Job history retrieved successfully
 *         content:
 *           application/json:
 *             schema:
 *               type: object
 *               properties:
 *                 data:
 *                   type: array
 *                   items:
 *                     $ref: '#/components/schemas/ScrapeJob'
 *                 pagination:
 *                   type: object
 *                   properties:
 *                     total:
 *                       type: integer
 *                     limit:
 *                       type: integer
 *                     offset:
 *                       type: integer
 *                     hasMore:
 *                       type: boolean
 */
router.get(
  '/history',
  validateQuery(historyQuerySchema),
  asyncHandler(propertyController.getScrapeHistory.bind(propertyController))
);

// ============================================================================
// Property Query Routes
// ============================================================================

/**
 * @swagger
 * /api/properties:
 *   get:
 *     summary: Get properties from database
 *     description: Query properties with optional filters (cached for 5 minutes)
 *     tags: [Properties]
 *     security:
 *       - ApiKeyAuth: []
 *       - BearerAuth: []
 *     parameters:
 *       - in: query
 *         name: city
 *         schema:
 *           type: string
 *         description: Filter by city name
 *         example: Austin
 *       - in: query
 *         name: propType
 *         schema:
 *           type: string
 *         description: Filter by property type
 *         example: Residential
 *       - in: query
 *         name: minValue
 *         schema:
 *           type: number
 *         description: Minimum appraised value
 *         example: 100000
 *       - in: query
 *         name: maxValue
 *         schema:
 *           type: number
 *         description: Maximum appraised value
 *         example: 500000
 *       - in: query
 *         name: searchTerm
 *         schema:
 *           type: string
 *         description: Filter by original search term
 *       - in: query
 *         name: limit
 *         schema:
 *           type: integer
 *           default: 20
 *           minimum: 1
 *           maximum: 1000
 *         description: Number of results per page
 *       - in: query
 *         name: offset
 *         schema:
 *           type: integer
 *           default: 0
 *           minimum: 0
 *         description: Number of results to skip
 *     responses:
 *       200:
 *         description: Property list with pagination
 *         content:
 *           application/json:
 *             schema:
 *               type: object
 *               properties:
 *                 data:
 *                   type: array
 *                   items:
 *                     $ref: '#/components/schemas/Property'
 *                 pagination:
 *                   type: object
 *                   properties:
 *                     total:
 *                       type: integer
 *                     limit:
 *                       type: integer
 *                     offset:
 *                       type: integer
 *                     hasMore:
 *                       type: boolean
 */
router.get(
  '/',
  validateQuery(propertyFilterSchema),
  asyncHandler(propertyController.getProperties.bind(propertyController))
);

/**
 * @swagger
 * /api/properties/search:
 *   post:
 *     summary: Natural language property search
 *     description: Search properties using natural language queries powered by Claude AI
 *     tags: [Search]
 *     security:
 *       - ApiKeyAuth: []
 *       - BearerAuth: []
 *     requestBody:
 *       required: true
 *       content:
 *         application/json:
 *           schema:
 *             type: object
 *             required:
 *               - query
 *             properties:
 *               query:
 *                 type: string
 *                 description: Natural language search query
 *                 example: Find all residential properties in Austin worth more than $500k
 *               limit:
 *                 type: integer
 *                 default: 20
 *                 minimum: 1
 *                 maximum: 100
 *                 description: Maximum number of results to return
 *     responses:
 *       200:
 *         description: Search results
 *         content:
 *           application/json:
 *             schema:
 *               type: object
 *               properties:
 *                 data:
 *                   type: array
 *                   items:
 *                     $ref: '#/components/schemas/Property'
 *                 query:
 *                   type: string
 *                   description: The original query
 *                 parsedFilters:
 *                   type: object
 *                   description: AI-interpreted filters
 *       400:
 *         description: Invalid query
 *         content:
 *           application/json:
 *             schema:
 *               $ref: '#/components/schemas/Error'
 */
router.post(
  '/search',
  validateBody(naturalLanguageSearchSchema),
  asyncHandler(propertyController.naturalLanguageSearch.bind(propertyController))
);

/**
 * @swagger
 * /api/properties/search/test:
 *   get:
 *     summary: Test Claude AI connection
 *     description: Test endpoint to verify Claude AI API connectivity and functionality
 *     tags: [Search]
 *     security:
 *       - ApiKeyAuth: []
 *       - BearerAuth: []
 *     responses:
 *       200:
 *         description: Claude AI connection successful
 *         content:
 *           application/json:
 *             schema:
 *               type: object
 *               properties:
 *                 status:
 *                   type: string
 *                   example: success
 *                 message:
 *                   type: string
 *                   example: Claude AI connection test successful
 *       500:
 *         description: Claude AI connection failed
 *         content:
 *           application/json:
 *             schema:
 *               $ref: '#/components/schemas/Error'
 */
router.get(
  '/search/test',
  asyncHandler(propertyController.testClaudeConnection.bind(propertyController))
);

// ============================================================================
// Statistics & Analytics Routes
// ============================================================================

/**
 * @swagger
 * /api/properties/stats:
 *   get:
 *     summary: Get property statistics
 *     description: Retrieve aggregate statistics about properties and scrape jobs (cached for 10 minutes)
 *     tags: [Statistics]
 *     security:
 *       - ApiKeyAuth: []
 *       - BearerAuth: []
 *     responses:
 *       200:
 *         description: Statistics retrieved successfully
 *         content:
 *           application/json:
 *             schema:
 *               type: object
 *               properties:
 *                 totalProperties:
 *                   type: integer
 *                   description: Total number of properties in database
 *                   example: 12345
 *                 totalJobs:
 *                   type: integer
 *                   description: Total number of scrape jobs
 *                   example: 567
 *                 jobsByStatus:
 *                   type: object
 *                   properties:
 *                     pending:
 *                       type: integer
 *                     processing:
 *                       type: integer
 *                     completed:
 *                       type: integer
 *                     failed:
 *                       type: integer
 *                 propertiesByCity:
 *                   type: object
 *                   description: Property count grouped by city
 *                   additionalProperties:
 *                     type: integer
 *                 propertiesByType:
 *                   type: object
 *                   description: Property count grouped by type
 *                   additionalProperties:
 *                     type: integer
 *                 averageValue:
 *                   type: number
 *                   description: Average appraised value
 *                   example: 275000
 */
router.get(
  '/stats',
  asyncHandler(propertyController.getStats.bind(propertyController))
);

// ============================================================================
// Monitoring Routes
// ============================================================================

/**
 * @swagger
 * /api/properties/monitor:
 *   post:
 *     summary: Add monitored search term
 *     description: Add a search term to the monitoring list for scheduled scraping
 *     tags: [Monitoring]
 *     security:
 *       - ApiKeyAuth: []
 *       - BearerAuth: []
 *     requestBody:
 *       required: true
 *       content:
 *         application/json:
 *           schema:
 *             type: object
 *             required:
 *               - searchTerm
 *             properties:
 *               searchTerm:
 *                 type: string
 *                 description: Search term to monitor
 *                 example: Smith
 *               schedule:
 *                 type: string
 *                 description: Cron schedule expression (optional)
 *                 example: "0 0 * * *"
 *               enabled:
 *                 type: boolean
 *                 description: Whether monitoring is active
 *                 default: true
 *     responses:
 *       201:
 *         description: Search term added to monitoring list
 *         content:
 *           application/json:
 *             schema:
 *               type: object
 *               properties:
 *                 id:
 *                   type: string
 *                   format: uuid
 *                 searchTerm:
 *                   type: string
 *                 schedule:
 *                   type: string
 *                 enabled:
 *                   type: boolean
 *       400:
 *         description: Invalid request
 *         content:
 *           application/json:
 *             schema:
 *               $ref: '#/components/schemas/Error'
 */
router.post(
  '/monitor',
  validateBody(monitorRequestSchema),
  asyncHandler(propertyController.addMonitoredSearch.bind(propertyController))
);

/**
 * @swagger
 * /api/properties/monitor:
 *   get:
 *     summary: Get monitored search terms
 *     description: Retrieve all search terms that are actively being monitored
 *     tags: [Monitoring]
 *     security:
 *       - ApiKeyAuth: []
 *       - BearerAuth: []
 *     responses:
 *       200:
 *         description: List of monitored search terms
 *         content:
 *           application/json:
 *             schema:
 *               type: object
 *               properties:
 *                 data:
 *                   type: array
 *                   items:
 *                     type: object
 *                     properties:
 *                       id:
 *                         type: string
 *                         format: uuid
 *                       searchTerm:
 *                         type: string
 *                       schedule:
 *                         type: string
 *                       enabled:
 *                         type: boolean
 *                       lastRun:
 *                         type: string
 *                         format: date-time
 *                       nextRun:
 *                         type: string
 *                         format: date-time
 */
router.get(
  '/monitor',
  asyncHandler(propertyController.getMonitoredSearches.bind(propertyController))
);

export { router as propertyRouter };
</file>

<file path="schedulers/__tests__/scrape-scheduler.test.ts">
/**
 * Scrape Scheduler Tests
 *
 * Tests for the cron-based scheduled job system
 */

// Mock dependencies before imports
jest.mock('node-cron', () => {
  const mockSchedule = jest.fn();
  // Set default implementation
  mockSchedule.mockImplementation(() => ({
    start: jest.fn(),
    stop: jest.fn(),
  }));

  return {
    schedule: mockSchedule,
  };
});

const mockScraperQueue = {
  add: jest.fn().mockResolvedValue(undefined),
  clean: jest.fn().mockResolvedValue(undefined),
};

jest.mock('../../queues/scraper.queue', () => ({
  scraperQueue: mockScraperQueue,
}));

const mockPrisma = {
  monitoredSearch: {
    findMany: jest.fn(),
    update: jest.fn(),
  },
  scrapeJob: {
    deleteMany: jest.fn(),
  },
};

jest.mock('../../lib/prisma', () => ({
  prisma: mockPrisma,
}));

// Mock winston to suppress logs during tests
jest.mock('winston', () => {
  const mockLogger = {
    info: jest.fn(),
    error: jest.fn(),
    warn: jest.fn(),
  };

  return {
    createLogger: jest.fn(() => mockLogger),
    format: {
      json: jest.fn(),
      simple: jest.fn(),
    },
    transports: {
      Console: jest.fn(),
    },
  };
});

import cron from 'node-cron';
import { scheduledJobs } from '../scrape-scheduler';

describe('ScheduledJobs', () => {
  beforeEach(() => {
    jest.clearAllMocks();

    // Configure cron.schedule mock to return task objects
    (cron.schedule as jest.Mock).mockImplementation(() => ({
      start: jest.fn(),
      stop: jest.fn(),
    }));
  });

  describe('initialize', () => {
    it('should create four cron tasks', () => {
      scheduledJobs.initialize();

      // Should create 4 tasks: daily, weekly, monthly, cleanup
      expect(cron.schedule).toHaveBeenCalledTimes(4);
    });

    it('should create daily task with correct schedule', () => {
      scheduledJobs.initialize();

      expect(cron.schedule).toHaveBeenCalledWith(
        '0 2 * * *', // 2 AM daily
        expect.any(Function),
        expect.objectContaining({
          scheduled: false,
          timezone: 'America/Chicago',
        })
      );
    });

    it('should create weekly task with correct schedule', () => {
      scheduledJobs.initialize();

      expect(cron.schedule).toHaveBeenCalledWith(
        '0 3 * * 0', // 3 AM on Sundays
        expect.any(Function),
        expect.objectContaining({
          scheduled: false,
          timezone: 'America/Chicago',
        })
      );
    });

    it('should create monthly task with correct schedule', () => {
      scheduledJobs.initialize();

      expect(cron.schedule).toHaveBeenCalledWith(
        '0 4 1 * *', // 4 AM on the 1st
        expect.any(Function),
        expect.objectContaining({
          scheduled: false,
          timezone: 'America/Chicago',
        })
      );
    });

    it('should create cleanup task with correct schedule', () => {
      scheduledJobs.initialize();

      expect(cron.schedule).toHaveBeenCalledWith(
        '0 * * * *', // Every hour
        expect.any(Function),
        expect.objectContaining({
          scheduled: false,
        })
      );
    });

    it('should start all created tasks', () => {
      scheduledJobs.initialize();

      // Verify that 4 tasks were created and each has start called
      const scheduleMock = cron.schedule as jest.Mock;
      expect(scheduleMock).toHaveBeenCalledTimes(4);

      // Get all returned task mocks and verify start was called
      scheduleMock.mock.results.forEach((result: any) => {
        expect(result.value.start).toHaveBeenCalled();
      });
    });

    it('should handle multiple initializations', () => {
      scheduledJobs.initialize();
      jest.clearAllMocks();

      scheduledJobs.initialize();

      // Should create new tasks on second initialization
      expect(cron.schedule).toHaveBeenCalledTimes(4);
    });
  });

  describe('runScheduledScrapes', () => {
    beforeEach(() => {
      // Setup mock data
      mockPrisma.monitoredSearch.findMany.mockResolvedValue([
        {
          id: '1',
          searchTerm: 'John Smith',
          frequency: 'daily',
          active: true,
        },
        {
          id: '2',
          searchTerm: 'Jane Doe',
          frequency: 'daily',
          active: true,
        },
      ]);

      mockPrisma.monitoredSearch.update.mockResolvedValue({});
    });

    it('should query monitored searches with correct frequency', async () => {
      scheduledJobs.initialize();

      // Get the daily task callback
      const dailyTaskCallback = (cron.schedule as jest.Mock).mock.calls[0][1];

      await dailyTaskCallback();

      expect(mockPrisma.monitoredSearch.findMany).toHaveBeenCalledWith({
        where: {
          active: true,
          frequency: 'daily',
        },
      });
    });

    it('should add jobs to scraper queue for each search', async () => {
      scheduledJobs.initialize();

      const dailyTaskCallback = (cron.schedule as jest.Mock).mock.calls[0][1];

      await dailyTaskCallback();

      expect(mockScraperQueue.add).toHaveBeenCalledTimes(2);
      expect(mockScraperQueue.add).toHaveBeenCalledWith(
        'scrape-properties',
        expect.objectContaining({
          searchTerm: 'John Smith',
          scheduled: true,
        }),
        expect.objectContaining({
          delay: expect.any(Number),
          attempts: 5,
          backoff: {
            type: 'exponential',
            delay: 5000,
          },
        })
      );
    });

    it('should use random delay between 0-60 seconds', async () => {
      scheduledJobs.initialize();

      const dailyTaskCallback = (cron.schedule as jest.Mock).mock.calls[0][1];

      await dailyTaskCallback();

      const addCalls = mockScraperQueue.add.mock.calls;
      addCalls.forEach((call: any) => {
        const delay = call[2].delay;
        expect(delay).toBeGreaterThanOrEqual(0);
        expect(delay).toBeLessThan(60000);
      });
    });

    it('should update last run time for each search', async () => {
      scheduledJobs.initialize();

      const dailyTaskCallback = (cron.schedule as jest.Mock).mock.calls[0][1];

      await dailyTaskCallback();

      expect(mockPrisma.monitoredSearch.update).toHaveBeenCalledTimes(2);
      expect(mockPrisma.monitoredSearch.update).toHaveBeenCalledWith({
        where: { id: '1' },
        data: { lastRun: expect.any(Date) },
      });
    });

    it('should handle weekly frequency', async () => {
      mockPrisma.monitoredSearch.findMany.mockResolvedValue([
        {
          id: '3',
          searchTerm: 'Weekly Search',
          frequency: 'weekly',
          active: true,
        },
      ]);

      scheduledJobs.initialize();

      const weeklyTaskCallback = (cron.schedule as jest.Mock).mock.calls[1][1];

      await weeklyTaskCallback();

      expect(mockPrisma.monitoredSearch.findMany).toHaveBeenCalledWith({
        where: {
          active: true,
          frequency: 'weekly',
        },
      });
    });

    it('should handle monthly frequency', async () => {
      mockPrisma.monitoredSearch.findMany.mockResolvedValue([
        {
          id: '4',
          searchTerm: 'Monthly Search',
          frequency: 'monthly',
          active: true,
        },
      ]);

      scheduledJobs.initialize();

      const monthlyTaskCallback = (cron.schedule as jest.Mock).mock.calls[2][1];

      await monthlyTaskCallback();

      expect(mockPrisma.monitoredSearch.findMany).toHaveBeenCalledWith({
        where: {
          active: true,
          frequency: 'monthly',
        },
      });
    });

    it('should handle empty search results', async () => {
      mockPrisma.monitoredSearch.findMany.mockResolvedValue([]);

      scheduledJobs.initialize();

      const dailyTaskCallback = (cron.schedule as jest.Mock).mock.calls[0][1];

      await dailyTaskCallback();

      expect(mockScraperQueue.add).not.toHaveBeenCalled();
      expect(mockPrisma.monitoredSearch.update).not.toHaveBeenCalled();
    });

    it('should handle errors gracefully', async () => {
      mockPrisma.monitoredSearch.findMany.mockRejectedValue(
        new Error('Database error')
      );

      scheduledJobs.initialize();

      const dailyTaskCallback = (cron.schedule as jest.Mock).mock.calls[0][1];

      // Should not throw
      await expect(dailyTaskCallback()).resolves.not.toThrow();
    });
  });

  describe('cleanupOldJobs', () => {
    beforeEach(() => {
      mockPrisma.scrapeJob.deleteMany.mockResolvedValue({ count: 15 });
      mockScraperQueue.clean.mockResolvedValue(undefined);
    });

    it('should delete scrape jobs older than 30 days', async () => {
      scheduledJobs.initialize();

      const cleanupCallback = (cron.schedule as jest.Mock).mock.calls[3][1];

      await cleanupCallback();

      expect(mockPrisma.scrapeJob.deleteMany).toHaveBeenCalledWith({
        where: {
          completedAt: {
            lt: expect.any(Date),
          },
        },
      });

      // Verify the date is approximately 30 days ago
      const deleteCall = mockPrisma.scrapeJob.deleteMany.mock.calls[0][0];
      const thirtyDaysAgo = deleteCall.where.completedAt.lt;
      const now = new Date();
      const daysDiff = Math.floor(
        (now.getTime() - thirtyDaysAgo.getTime()) / (1000 * 60 * 60 * 24)
      );
      expect(daysDiff).toBe(30);
    });

    it('should clean Bull queue completed jobs older than 7 days', async () => {
      scheduledJobs.initialize();

      const cleanupCallback = (cron.schedule as jest.Mock).mock.calls[3][1];

      await cleanupCallback();

      const sevenDaysInMs = 7 * 24 * 60 * 60 * 1000;
      expect(mockScraperQueue.clean).toHaveBeenCalledWith(
        sevenDaysInMs,
        'completed'
      );
    });

    it('should clean Bull queue failed jobs older than 7 days', async () => {
      scheduledJobs.initialize();

      const cleanupCallback = (cron.schedule as jest.Mock).mock.calls[3][1];

      await cleanupCallback();

      const sevenDaysInMs = 7 * 24 * 60 * 60 * 1000;
      expect(mockScraperQueue.clean).toHaveBeenCalledWith(sevenDaysInMs, 'failed');
    });

    it('should handle cleanup errors gracefully', async () => {
      mockPrisma.scrapeJob.deleteMany.mockRejectedValue(
        new Error('Cleanup error')
      );

      scheduledJobs.initialize();

      const cleanupCallback = (cron.schedule as jest.Mock).mock.calls[3][1];

      // Should not throw
      await expect(cleanupCallback()).resolves.not.toThrow();
    });

    it('should handle queue cleanup errors gracefully', async () => {
      mockScraperQueue.clean.mockRejectedValue(new Error('Queue cleanup error'));

      scheduledJobs.initialize();

      const cleanupCallback = (cron.schedule as jest.Mock).mock.calls[3][1];

      // Should not throw
      await expect(cleanupCallback()).resolves.not.toThrow();
    });
  });

  describe('stop', () => {
    it('should stop all tasks', () => {
      scheduledJobs.initialize();

      const scheduleMock = cron.schedule as jest.Mock;
      const tasks = scheduleMock.mock.results.map((result: any) => result.value);

      // Clear mocks after init
      tasks.forEach((task: any) => {
        task.stop.mockClear();
      });

      scheduledJobs.stop();

      // Should stop all 4 tasks
      tasks.forEach((task: any) => {
        expect(task.stop).toHaveBeenCalled();
      });
    });

    it('should handle stop before initialize', () => {
      // Since we're using a singleton and it may have been initialized in other tests,
      // we can't reliably test this without resetting the module
      // Just verify stop can be called without throwing
      expect(() => scheduledJobs.stop()).not.toThrow();
    });

    it('should handle multiple stop calls', () => {
      scheduledJobs.initialize();

      const scheduleMock = cron.schedule as jest.Mock;
      const tasks = scheduleMock.mock.results.map((result: any) => result.value);

      scheduledJobs.stop();

      // Clear first stop calls
      tasks.forEach((task: any) => {
        task.stop.mockClear();
      });

      // Second stop
      scheduledJobs.stop();

      // Should still attempt to stop tasks
      tasks.forEach((task: any) => {
        expect(task.stop).toHaveBeenCalled();
      });
    });
  });

  describe('triggerDailyScrapes', () => {
    beforeEach(() => {
      mockPrisma.monitoredSearch.findMany.mockResolvedValue([
        {
          id: '1',
          searchTerm: 'Test Search',
          frequency: 'daily',
          active: true,
        },
      ]);

      mockPrisma.monitoredSearch.update.mockResolvedValue({});
    });

    it('should manually trigger daily scrapes', async () => {
      await scheduledJobs.triggerDailyScrapes();

      expect(mockPrisma.monitoredSearch.findMany).toHaveBeenCalledWith({
        where: {
          active: true,
          frequency: 'daily',
        },
      });
    });

    it('should add jobs to queue when manually triggered', async () => {
      await scheduledJobs.triggerDailyScrapes();

      expect(mockScraperQueue.add).toHaveBeenCalledWith(
        'scrape-properties',
        expect.objectContaining({
          searchTerm: 'Test Search',
          scheduled: true,
        }),
        expect.any(Object)
      );
    });

    it('should update last run time when manually triggered', async () => {
      await scheduledJobs.triggerDailyScrapes();

      expect(mockPrisma.monitoredSearch.update).toHaveBeenCalledWith({
        where: { id: '1' },
        data: { lastRun: expect.any(Date) },
      });
    });
  });

  describe('Module Export', () => {
    it('should export scheduledJobs instance', () => {
      expect(scheduledJobs).toBeDefined();
      expect(typeof scheduledJobs.initialize).toBe('function');
      expect(typeof scheduledJobs.stop).toBe('function');
      expect(typeof scheduledJobs.triggerDailyScrapes).toBe('function');
    });
  });
});
</file>

<file path="schedulers/README_ENHANCED.md">
# schedulers

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "SoftwareSourceCode",
  "name": "schedulers",
  "description": "Directory containing 1 code files with 1 classes and 0 functions",
  "programmingLanguage": [
    {
      "@type": "ComputerLanguage",
      "name": "Typescript"
    }
  ],
  "featureList": [
    "1 class definitions"
  ]
}
</script>

## Overview

This directory contains 1 code file(s) with extracted schemas.

## Subdirectories

- `__tests__/`

## Files and Schemas

### `scrape-scheduler.ts` (typescript)

**Classes:**
- `ScheduledJobs` - Line 15

---
*Generated by Enhanced Schema Generator with schema.org markup*
</file>

<file path="schedulers/README.md">
# schedulers

## Overview

This directory contains 1 code file(s) with extracted schemas.

## Files and Schemas

### `scrape-scheduler.ts` (typescript)

**Classes:**
- `ScheduledJobs` - Line 16

**Key Imports:** `../lib/prisma`, `../queues/scraper.queue`, `node-cron`, `winston`

---
*Generated by Schema Generator*
</file>

<file path="schedulers/scrape-scheduler.ts">
import cron from 'node-cron';
import { scraperQueue } from '../queues/scraper.queue';
import { prisma } from '../lib/prisma';
import winston from 'winston';

const logger = winston.createLogger({
  level: 'info',
  format: winston.format.json(),
  transports: [
    new winston.transports.Console({
      format: winston.format.simple(),
    }),
  ],
});

class ScheduledJobs {
  private tasks: cron.ScheduledTask[] = [];

  initialize() {
    logger.info('Initializing scheduled jobs...');

    // Daily scrape at 2 AM for monitored searches
    const dailyTask = cron.schedule('0 2 * * *', async () => {
      await this.runScheduledScrapes('daily');
    }, {
      scheduled: false,
      timezone: 'America/Chicago',
    });

    // Weekly scrape on Sundays at 3 AM
    const weeklyTask = cron.schedule('0 3 * * 0', async () => {
      await this.runScheduledScrapes('weekly');
    }, {
      scheduled: false,
      timezone: 'America/Chicago',
    });

    // Monthly scrape on the 1st at 4 AM
    const monthlyTask = cron.schedule('0 4 1 * *', async () => {
      await this.runScheduledScrapes('monthly');
    }, {
      scheduled: false,
      timezone: 'America/Chicago',
    });

    // Clean up old jobs every hour
    const cleanupTask = cron.schedule('0 * * * *', async () => {
      await this.cleanupOldJobs();
    }, {
      scheduled: false,
    });

    this.tasks = [dailyTask, weeklyTask, monthlyTask, cleanupTask];

    // Start all tasks
    this.tasks.forEach(task => task.start());

    logger.info('Scheduled jobs initialized successfully');
  }

  private async runScheduledScrapes(frequency: string) {
    try {
      logger.info(`Running ${frequency} scheduled scrapes...`);

      const monitoredSearches = await prisma.monitoredSearch.findMany({
        where: {
          active: true,
          frequency,
        },
      });

      logger.info(`Found ${monitoredSearches.length} ${frequency} searches to run`);

      for (const search of monitoredSearches) {
        // Add random delay to avoid overwhelming the target site
        const delay = Math.floor(Math.random() * 60000); // 0-60 seconds

        await scraperQueue.add(
          'scrape-properties',
          {
            searchTerm: search.searchTerm,
            scheduled: true,
          },
          {
            delay,
            attempts: 5,
            backoff: {
              type: 'exponential',
              delay: 5000,
            },
          }
        );

        // Update last run time
        await prisma.monitoredSearch.update({
          where: { id: search.id },
          data: { lastRun: new Date() },
        });

        logger.info(`Scheduled scrape for "${search.searchTerm}" with ${delay}ms delay`);
      }
    } catch (error) {
      logger.error(`Failed to run ${frequency} scheduled scrapes:`, error);
    }
  }

  private async cleanupOldJobs() {
    try {
      logger.info('Cleaning up old jobs...');

      // Delete scrape jobs older than 30 days
      const thirtyDaysAgo = new Date();
      thirtyDaysAgo.setDate(thirtyDaysAgo.getDate() - 30);

      const deletedJobs = await prisma.scrapeJob.deleteMany({
        where: {
          completedAt: {
            lt: thirtyDaysAgo,
          },
        },
      });

      // Clean Bull queue completed/failed jobs older than 7 days
      const sevenDaysInMs = 7 * 24 * 60 * 60 * 1000;
      await scraperQueue.clean(sevenDaysInMs, 'completed');
      await scraperQueue.clean(sevenDaysInMs, 'failed');

      logger.info(`Cleaned up ${deletedJobs.count} old database jobs`);
    } catch (error) {
      logger.error('Failed to clean up old jobs:', error);
    }
  }

  stop() {
    logger.info('Stopping scheduled jobs...');
    this.tasks.forEach(task => task.stop());
    logger.info('Scheduled jobs stopped');
  }

  // Manual trigger for testing
  async triggerDailyScrapes() {
    await this.runScheduledScrapes('daily');
  }
}

export const scheduledJobs = new ScheduledJobs();
</file>

<file path="scripts/batch-scrape-100.ts">
import { scraperQueue } from '../queues/scraper.queue';
import winston from 'winston';

const logger = winston.createLogger({
  level: 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.simple()
  ),
  transports: [
    new winston.transports.Console(),
  ],
});

// 100 diverse search terms for maximum property coverage
const SEARCH_TERMS = [
  // More Austin streets (30)
  'South Lamar', 'East Riverside', 'West Anderson', 'South Congress',
  'East 6th', 'West 6th', 'Manchaca', 'Mopac', 'Red River',
  'Rainey', 'Cesar Chavez', 'MLK', 'Dean Keeton', 'Speedway',
  'Duval', 'Shoal Creek', 'Koenig', 'Far West', 'Research Blvd',
  'South First', 'East 7th', 'West 12th', 'Barton Springs',
  'Westlake', 'Exposition', 'Windsor', 'Enfield', 'Balcones',
  'Spicewood', 'Capital of Texas',

  // Common last names (30)
  'Smith', 'Johnson', 'Williams', 'Jones', 'Brown',
  'Davis', 'Miller', 'Wilson', 'Moore', 'Taylor',
  'Anderson', 'Thomas', 'Jackson', 'White', 'Harris',
  'Martin', 'Thompson', 'Garcia', 'Martinez', 'Robinson',
  'Clark', 'Rodriguez', 'Lewis', 'Lee', 'Walker',
  'Hall', 'Allen', 'Young', 'King', 'Wright',

  // Austin neighborhoods (20)
  'Hyde Park', 'Tarrytown', 'Clarksville', 'Bouldin Creek',
  'South Austin', 'North Austin', 'East Austin', 'West Austin',
  'Rosedale', 'Crestview', 'Mueller', 'Domain', 'Downtown',
  'Zilker', 'Barton Hills', 'Travis Heights', 'Allandale',
  'Brentwood', 'Dawson', 'Cherrywood',

  // Business/building types (10)
  'Plaza', 'Center', 'Tower', 'Building', 'Office',
  'Apartments', 'Condos', 'Ranch', 'Estates', 'Village',

  // Additional streets (10)
  'Cameron', 'Metric', 'Dessau', 'Lamar Blvd', 'IH 35',
  'Loop 360', 'Wells Branch', 'McNeil', 'Howard', 'Jollyville',
];

async function queueBatch() {
  logger.info('');
  logger.info('   QUEUEING 100 NEW SCRAPING JOBS                       ');
  logger.info('\n');

  logger.info(`Total search terms: ${SEARCH_TERMS.length}\n`);

  let queued = 0;
  let failed = 0;

  for (const searchTerm of SEARCH_TERMS) {
    try {
      const job = await scraperQueue.add(
        'scrape-properties',
        {
          searchTerm,
          userId: 'batch-100',
          scheduled: true,
        },
        {
          attempts: 3,
          backoff: {
            type: 'exponential',
            delay: 2000,
          },
          removeOnComplete: 100,
          removeOnFail: 50,
        }
      );

      queued++;
      logger.info(`   [${queued}/${SEARCH_TERMS.length}] ${searchTerm} (Job ${job.id})`);

      // Small delay to avoid overwhelming Redis
      await new Promise(resolve => setTimeout(resolve, 100));

    } catch (error) {
      failed++;
      logger.error({ err: error }, `   ${searchTerm}:`);
    }
  }

  logger.info(`\n Successfully queued ${queued} jobs`);
  if (failed > 0) {
    logger.warn(`  Failed to queue ${failed} jobs`);
  }

  // Get queue stats
  const [waiting, active] = await Promise.all([
    scraperQueue.getWaitingCount(),
    scraperQueue.getActiveCount(),
  ]);

  logger.info(`\nCurrent queue status:`);
  logger.info(`   Waiting: ${waiting}`);
  logger.info(`   Active: ${active}`);
  logger.info(`\nEstimated completion time: ~${Math.ceil((waiting + active) * 30 / 60)} minutes`);

  process.exit(0);
}

queueBatch().catch((error) => {
  logger.error({ err: error }, 'Fatal error:');
  process.exit(1);
});
</file>

<file path="scripts/batch-scrape-comprehensive.ts">
import { scraperQueue } from '../queues/scraper.queue';
import { prisma } from '../lib/prisma';
import winston from 'winston';

const logger = winston.createLogger({
  level: 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.simple()
  ),
  transports: [
    new winston.transports.Console(),
  ],
});

// ALL Travis County ZIP codes
const ALL_ZIP_CODES = [
  '78701', '78702', '78703', '78704', '78705', '78712', '78719',
  '78721', '78722', '78723', '78724', '78725', '78726', '78727',
  '78728', '78729', '78730', '78731', '78732', '78733', '78734',
  '78735', '78736', '78737', '78738', '78739', '78741', '78742',
  '78744', '78745', '78746', '78747', '78748', '78749', '78750',
  '78751', '78752', '78753', '78754', '78756', '78757', '78758',
  '78759', '78760', '78761', '78762', '78763', '78764', '78765',
  '78766', '78767', '78768', '78769', '78772', '78773', '78774',
  '78778', '78779', '78780', '78781', '78783', '78799',
];

// Travis County cities
const CITIES = [
  'Austin',
  'Round Rock',
  'Pflugerville',
  'Cedar Park',
  'Leander',
  'Georgetown',
  'Manor',
  'Lakeway',
  'Bee Cave',
  'West Lake Hills',
  'Rollingwood',
  'Sunset Valley',
  'Jonestown',
  'Creedmoor',
  'Elgin',
  'Hutto',
  'San Marcos',
];

// Common last name patterns for broad coverage
const ALPHABET_PATTERNS = [
  'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',
  'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'
];

// Two-letter combinations for more coverage (common name prefixes)
const COMMON_NAME_PREFIXES = [
  'Mc', 'Mac', 'Van', 'De', 'La', 'Le', 'St', 'San', 'Del',
  'Al', 'El', 'Di', 'Da', 'Du', 'Mc', 'O\'',
];

// Common street names in Austin/Travis County
const COMMON_STREETS = [
  'Main', 'Oak', 'Park', 'Cedar', 'Elm', 'Lake', 'Hill', 'River',
  'Congress', 'Lamar', 'Guadalupe', 'Burnet', 'Airport', 'Oltorf',
  'Anderson', 'Bee Cave', 'Slaughter', 'William Cannon',
  'Research', 'Parmer', 'Braker', 'Rundberg', 'North Loop',
];

// Numeric patterns (property IDs often searchable)
const NUMERIC_PATTERNS = [
  '1', '2', '3', '4', '5', '6', '7', '8', '9', '0',
  '10', '100', '1000', '2000', '3000', '5000',
];

interface ComprehensiveBatchConfig {
  includeZipCodes: boolean;
  includeCities: boolean;
  includeAlphabet: boolean;
  includeNamePrefixes: boolean;
  includeStreets: boolean;
  includeNumeric: boolean;
  batchSize: number;
  delayBetweenBatches: number;
}

class ComprehensiveBatchScraper {
  private config: ComprehensiveBatchConfig;
  private stats = {
    totalQueued: 0,
    totalCompleted: 0,
    totalFailed: 0,
    startTime: Date.now(),
  };

  constructor(config: Partial<ComprehensiveBatchConfig> = {}) {
    this.config = {
      includeZipCodes: false, // ZIP codes don't work on TCAD website
      includeCities: true,
      includeAlphabet: true,
      includeNamePrefixes: true,
      includeStreets: true,
      includeNumeric: true,
      batchSize: 20,
      delayBetweenBatches: 3000,
      ...config,
    };
  }

  private getSearchTerms(): string[] {
    const terms: string[] = [];

    if (this.config.includeZipCodes) {
      terms.push(...ALL_ZIP_CODES);
      logger.info(` Added ${ALL_ZIP_CODES.length} ZIP codes`);
    }

    if (this.config.includeCities) {
      terms.push(...CITIES);
      logger.info(` Added ${CITIES.length} cities`);
    }

    if (this.config.includeAlphabet) {
      terms.push(...ALPHABET_PATTERNS);
      logger.info(` Added ${ALPHABET_PATTERNS.length} alphabet patterns`);
    }

    if (this.config.includeNamePrefixes) {
      terms.push(...COMMON_NAME_PREFIXES);
      logger.info(` Added ${COMMON_NAME_PREFIXES.length} name prefixes`);
    }

    if (this.config.includeStreets) {
      terms.push(...COMMON_STREETS);
      logger.info(` Added ${COMMON_STREETS.length} street names`);
    }

    if (this.config.includeNumeric) {
      terms.push(...NUMERIC_PATTERNS);
      logger.info(` Added ${NUMERIC_PATTERNS.length} numeric patterns`);
    }

    // Filter out search terms with less than 4 characters (TCAD minimum)
    const filteredTerms = terms.filter(term => term.length >= 4);
    const removedCount = terms.length - filteredTerms.length;
    if (removedCount > 0) {
      logger.info(` Filtered out ${removedCount} terms shorter than 4 characters`);
    }

    return filteredTerms;
  }

  private async delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  async queueJobs(): Promise<void> {
    const searchTerms = this.getSearchTerms();

    logger.info('\n');
    logger.info('   COMPREHENSIVE TCAD DATABASE SCRAPING                 ');
    logger.info('\n');

    logger.info(`Total search terms: ${searchTerms.length}`);
    logger.info(`Batch size: ${this.config.batchSize}`);
    logger.info(`Delay between batches: ${this.config.delayBetweenBatches}ms\n`);

    // Process in batches
    for (let i = 0; i < searchTerms.length; i += this.config.batchSize) {
      const batch = searchTerms.slice(i, i + this.config.batchSize);
      const batchNum = Math.floor(i / this.config.batchSize) + 1;
      const totalBatches = Math.ceil(searchTerms.length / this.config.batchSize);

      logger.info(`\n Batch ${batchNum}/${totalBatches} (${batch.length} terms)`);

      for (const searchTerm of batch) {
        try {
          const job = await scraperQueue.add(
            'scrape-properties',
            {
              searchTerm,
              userId: 'comprehensive-batch',
              scheduled: true,
            },
            {
              attempts: 3,
              backoff: {
                type: 'exponential',
                delay: 2000,
              },
              removeOnComplete: 100,
              removeOnFail: 50,
            }
          );

          this.stats.totalQueued++;
          logger.info(`   ${searchTerm} (Job ${job.id})`);
        } catch (error) {
          logger.error({ err: error }, `   ${searchTerm}:`);
        }
      }

      // Delay between batches
      if (i + this.config.batchSize < searchTerms.length) {
        const remaining = searchTerms.length - (i + this.config.batchSize);
        logger.info(`\n Waiting ${this.config.delayBetweenBatches}ms... (${remaining} terms remaining)`);
        await this.delay(this.config.delayBetweenBatches);
      }
    }

    logger.info(`\n All ${this.stats.totalQueued} jobs queued successfully!`);
  }

  async monitorProgress(): Promise<void> {
    logger.info('\n');
    logger.info('          MONITORING PROGRESS                           ');
    logger.info('\n');

    const checkInterval = 30000; // Check every 30 seconds

    while (true) {
      await this.delay(checkInterval);

      // Get queue stats
      const [waiting, active, completed, failed] = await Promise.all([
        scraperQueue.getWaitingCount(),
        scraperQueue.getActiveCount(),
        scraperQueue.getCompletedCount(),
        scraperQueue.getFailedCount(),
      ]);

      const elapsed = Math.floor((Date.now() - this.stats.startTime) / 1000);
      const minutes = Math.floor(elapsed / 60);
      const seconds = elapsed % 60;

      // Get database stats
      const totalProperties = await prisma.property.count();
      const recentProperties = await prisma.property.count({
        where: {
          scrapedAt: {
            gte: new Date(Date.now() - 300000), // Last 5 minutes
          },
        },
      });

      const progress = ((completed + failed) / this.stats.totalQueued) * 100;

      logger.info(`

 Time: ${minutes}m ${seconds}s | Progress: ${progress.toFixed(1)}%

 Queue Status:
    Waiting:   ${waiting.toString().padStart(6)}
    Active:    ${active.toString().padStart(6)}
    Completed: ${completed.toString().padStart(6)}
    Failed:    ${failed.toString().padStart(6)}
    Total:     ${this.stats.totalQueued.toString().padStart(6)}

 Database:
    Total Properties:  ${totalProperties.toString().padStart(8)}
    Last 5 min:        ${recentProperties.toString().padStart(8)}
    Rate: ${(recentProperties / 5).toFixed(1)} properties/min

      `);

      // Check if all jobs are done
      if (waiting === 0 && active === 0 && completed + failed >= this.stats.totalQueued) {
        logger.info('\n All jobs completed!');
        break;
      }
    }

    await this.printFinalReport();
  }

  async printFinalReport(): Promise<void> {
    const [totalProperties, uniqueCount, totalJobs, successfulJobs] = await Promise.all([
      prisma.property.count(),
      prisma.property.findMany({ select: { propertyId: true }, distinct: ['propertyId'] }),
      prisma.scrapeJob.count(),
      prisma.scrapeJob.count({ where: { status: 'completed' } }),
    ]);

    const elapsed = Math.floor((Date.now() - this.stats.startTime) / 1000);
    const hours = Math.floor(elapsed / 3600);
    const minutes = Math.floor((elapsed % 3600) / 60);
    const seconds = elapsed % 60;

    const completed = await scraperQueue.getCompletedCount();
    const failed = await scraperQueue.getFailedCount();

    logger.info(`

         COMPREHENSIVE SCRAPING FINAL REPORT               


  Time Elapsed: ${hours}h ${minutes}m ${seconds}s

 Jobs:
    Total Queued:    ${this.stats.totalQueued}
    Completed:       ${completed}
    Failed:          ${failed}
    Success Rate:    ${((completed / this.stats.totalQueued) * 100).toFixed(2)}%

 Database:
    Total Properties:     ${totalProperties}
    Unique Properties:    ${uniqueCount.length}
    Duplicate Entries:    ${totalProperties - uniqueCount.length}
    Total Scrape Jobs:    ${totalJobs}
    Successful Jobs:      ${successfulJobs}
    Overall Success Rate: ${((successfulJobs / totalJobs) * 100).toFixed(2)}%

 Performance:
    Avg Time per Job:      ${(elapsed / completed).toFixed(2)}s
    Properties per Hour:   ${((totalProperties / elapsed) * 3600).toFixed(0)}
    Jobs per Hour:         ${((completed / elapsed) * 3600).toFixed(0)}

Coverage Strategy:
    All ZIP codes (${ALL_ZIP_CODES.length})
    Cities (${CITIES.length})
    Alphabet patterns (${ALPHABET_PATTERNS.length})
    Name prefixes (${COMMON_NAME_PREFIXES.length})
    Street names (${COMMON_STREETS.length})
    Numeric patterns (${NUMERIC_PATTERNS.length})


   COMPREHENSIVE SCRAPING COMPLETED SUCCESSFULLY!      

    `);
  }

  async run(): Promise<void> {
    try {
      await this.queueJobs();
      await this.monitorProgress();
      process.exit(0);
    } catch (error) {
      logger.error({ err: error }, ' Fatal error:');
      process.exit(1);
    }
  }
}

// Run the scraper
const scraper = new ComprehensiveBatchScraper({
  includeZipCodes: false, // ZIP codes don't work on TCAD website
  includeCities: true,
  includeAlphabet: false, // Single letters likely won't return meaningful results
  includeNamePrefixes: false, // Short name prefixes filtered out by 4-char minimum
  includeStreets: true, // Streets work well!
  includeNumeric: false, // Numbers likely won't return useful results
  batchSize: 10, // Reduce batch size to avoid overwhelming the server
  delayBetweenBatches: 3000, // Increase delay to be more respectful
});

scraper.run();
</file>

<file path="scripts/batch-scrape.ts">
import { scraperQueue } from '../queues/scraper.queue';
import { prisma } from '../lib/prisma';
import winston from 'winston';

const logger = winston.createLogger({
  level: 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.json()
  ),
  transports: [
    new winston.transports.Console({
      format: winston.format.simple(),
    }),
  ],
});

// Travis County cities and major areas
const CITIES = [
  'Austin',
  'Round Rock',
  'Pflugerville',
  'Cedar Park',
  'Leander',
  'Georgetown',
  'Manor',
  'Lakeway',
  'Bee Cave',
  'West Lake Hills',
  'Rollingwood',
  'Sunset Valley',
  'Jonestown',
  'Creedmoor',
  'Elgin',
  'Hutto',
  'San Marcos',
];

// Travis County ZIP codes (major ones)
const ZIP_CODES = [
  '78701', '78702', '78703', '78704', '78705', '78712', '78719',
  '78721', '78722', '78723', '78724', '78725', '78726', '78727',
  '78728', '78729', '78730', '78731', '78732', '78733', '78734',
  '78735', '78736', '78737', '78738', '78739', '78741', '78742',
  '78744', '78745', '78746', '78747', '78748', '78749', '78750',
  '78751', '78752', '78753', '78754', '78756', '78757', '78758',
  '78759', '78760', '78761', '78762', '78763', '78764', '78765',
  '78766', '78767', '78768', '78769', '78772', '78773', '78774',
  '78778', '78779', '78780', '78781', '78783', '78799',
];

// Property types commonly found in TCAD
const PROPERTY_TYPES = [
  'A', // Single Family Residential
  'B', // Multi-Family Residential
  'C', // Vacant Lots/Land
  'D', // Rural Real (Land)
  'E', // Farm & Ranch
  'F', // Commercial Real
  'G', // Oil, Gas, Minerals
  'H', // Industrial Real
  'J', // Water Systems
  'L', // Miscellaneous
  'M', // Mobile Homes
  'N', // Intangible Personal Property
  'O', // Residential Inventory
  'P', // Non-Residential Inventory
  'S', // Special Inventory
  'X', // Totally Exempt Property
];

// Street name prefixes for comprehensive coverage
const STREET_PREFIXES = [
  'North', 'South', 'East', 'West',
  'N', 'S', 'E', 'W',
];

// Common street suffixes
const STREET_SUFFIXES = [
  'Street', 'St', 'Avenue', 'Ave', 'Road', 'Rd', 'Drive', 'Dr',
  'Lane', 'Ln', 'Court', 'Ct', 'Circle', 'Cir', 'Boulevard', 'Blvd',
  'Way', 'Trail', 'Path', 'Place', 'Pl',
];

interface BatchConfig {
  batchSize: number;
  delayBetweenBatches: number; // milliseconds
  maxConcurrentJobs: number;
  searchStrategy: 'cities' | 'zipcodes' | 'types' | 'comprehensive' | 'custom';
  customSearchTerms?: string[];
}

class BatchScraper {
  private config: BatchConfig;
  private jobIds: string[] = [];
  private stats = {
    totalQueued: 0,
    totalCompleted: 0,
    totalFailed: 0,
    startTime: Date.now(),
  };

  constructor(config: Partial<BatchConfig> = {}) {
    this.config = {
      batchSize: 10,
      delayBetweenBatches: 5000,
      maxConcurrentJobs: 3,
      searchStrategy: 'comprehensive',
      ...config,
    };
  }

  private getSearchTerms(): string[] {
    let terms: string[];
    switch (this.config.searchStrategy) {
      case 'cities':
        terms = CITIES;
        break;
      case 'zipcodes':
        terms = ZIP_CODES;
        break;
      case 'types':
        terms = PROPERTY_TYPES;
        break;
      case 'custom':
        terms = this.config.customSearchTerms || [];
        break;
      case 'comprehensive':
      default:
        // Combine multiple strategies for maximum coverage
        terms = [
          ...CITIES,
          ...ZIP_CODES.slice(0, 20), // Use first 20 ZIP codes
          ...PROPERTY_TYPES,
        ];
    }

    // Filter out search terms with less than 4 characters (TCAD minimum)
    return terms.filter(term => term.length >= 4);
  }

  private async delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  async queueJobs(): Promise<void> {
    const searchTerms = this.getSearchTerms();
    logger.info(`Starting batch scrape with ${searchTerms.length} search terms using strategy: ${this.config.searchStrategy}`);
    logger.info(`Batch size: ${this.config.batchSize}, Delay: ${this.config.delayBetweenBatches}ms`);

    // Process in batches
    for (let i = 0; i < searchTerms.length; i += this.config.batchSize) {
      const batch = searchTerms.slice(i, i + this.config.batchSize);
      logger.info(`\nQueuing batch ${Math.floor(i / this.config.batchSize) + 1}/${Math.ceil(searchTerms.length / this.config.batchSize)}`);

      for (const searchTerm of batch) {
        try {
          const job = await scraperQueue.add(
            'scrape-properties',
            {
              searchTerm,
              userId: 'batch-scraper',
              scheduled: true,
            },
            {
              attempts: 3,
              backoff: {
                type: 'exponential',
                delay: 2000,
              },
              removeOnComplete: 100,
              removeOnFail: 50,
            }
          );

          this.jobIds.push(job.id.toString());
          this.stats.totalQueued++;
          logger.info(`   Queued: ${searchTerm} (Job ID: ${job.id})`);
        } catch (error) {
          logger.error({ err: error }, `   Failed to queue: ${searchTerm}`);
        }
      }

      // Delay between batches to avoid overwhelming the system
      if (i + this.config.batchSize < searchTerms.length) {
        logger.info(`Waiting ${this.config.delayBetweenBatches}ms before next batch...`);
        await this.delay(this.config.delayBetweenBatches);
      }
    }

    logger.info(`\n All jobs queued! Total: ${this.stats.totalQueued}`);
  }

  async monitorProgress(): Promise<void> {
    logger.info('\n=== Monitoring Job Progress ===\n');

    const checkInterval = 10000; // Check every 10 seconds
    let lastCheck = Date.now();

    while (this.stats.totalCompleted + this.stats.totalFailed < this.stats.totalQueued) {
      await this.delay(checkInterval);

      // Get job counts from queue
      const [waiting, active, completed, failed] = await Promise.all([
        scraperQueue.getWaitingCount(),
        scraperQueue.getActiveCount(),
        scraperQueue.getCompletedCount(),
        scraperQueue.getFailedCount(),
      ]);

      const elapsed = Math.floor((Date.now() - this.stats.startTime) / 1000);
      const minutes = Math.floor(elapsed / 60);
      const seconds = elapsed % 60;

      logger.info(`
Status Update (${minutes}m ${seconds}s elapsed):
  Waiting: ${waiting}
  Active: ${active}
  Completed: ${completed}
  Failed: ${failed}
  Total: ${this.stats.totalQueued}
      `);

      // Check database stats
      const dbStats = await this.getDatabaseStats();
      logger.info(`
Database Stats:
  Total Properties: ${dbStats.totalProperties}
  Unique Properties: ${dbStats.uniqueProperties}
  Scrape Jobs: ${dbStats.totalJobs}
  Success Rate: ${dbStats.successRate}%
      `);

      // Update our stats
      this.stats.totalCompleted = completed;
      this.stats.totalFailed = failed;

      if (waiting === 0 && active === 0) {
        logger.info('\n All jobs completed!');
        break;
      }
    }

    await this.printFinalReport();
  }

  async getDatabaseStats() {
    const [totalProperties, uniqueCount, totalJobs, successfulJobs] = await Promise.all([
      prisma.property.count(),
      prisma.property.findMany({ select: { propertyId: true }, distinct: ['propertyId'] }),
      prisma.scrapeJob.count(),
      prisma.scrapeJob.count({ where: { status: 'completed' } }),
    ]);

    return {
      totalProperties,
      uniqueProperties: uniqueCount.length,
      totalJobs,
      successfulJobs,
      successRate: totalJobs > 0 ? ((successfulJobs / totalJobs) * 100).toFixed(2) : '0',
    };
  }

  async printFinalReport(): Promise<void> {
    const dbStats = await this.getDatabaseStats();
    const elapsed = Math.floor((Date.now() - this.stats.startTime) / 1000);
    const minutes = Math.floor(elapsed / 60);
    const seconds = elapsed % 60;

    logger.info(`

           BATCH SCRAPING FINAL REPORT                  


Time Elapsed: ${minutes} minutes ${seconds} seconds

Jobs:
   Total Queued: ${this.stats.totalQueued}
   Completed: ${this.stats.totalCompleted}
   Failed: ${this.stats.totalFailed}
   Success Rate: ${((this.stats.totalCompleted / this.stats.totalQueued) * 100).toFixed(2)}%

Database:
   Total Properties: ${dbStats.totalProperties}
   Unique Properties: ${dbStats.uniqueProperties}
   Deduplication Rate: ${(((dbStats.totalProperties - dbStats.uniqueProperties) / dbStats.totalProperties) * 100).toFixed(2)}%
   Total Scrape Jobs: ${dbStats.totalJobs}
   Overall Success Rate: ${dbStats.successRate}%

Performance:
   Avg Time per Job: ${(elapsed / this.stats.totalCompleted).toFixed(2)}s
   Properties per Minute: ${((dbStats.totalProperties / elapsed) * 60).toFixed(2)}

Strategy Used: ${this.config.searchStrategy}
    `);
  }

  async run(): Promise<void> {
    try {
      logger.info('');
      logger.info('        TCAD BATCH SCRAPER - Starting...                ');
      logger.info('\n');

      // Queue all jobs
      await this.queueJobs();

      // Monitor progress
      await this.monitorProgress();

      logger.info('\n Batch scraping completed successfully!');
      process.exit(0);
    } catch (error) {
      logger.error({ err: error }, 'Fatal error during batch scraping:');
      process.exit(1);
    }
  }
}

// CLI interface
const args = process.argv.slice(2);
const strategy = (args[0] as BatchConfig['searchStrategy']) || 'comprehensive';
const batchSize = parseInt(args[1]) || 10;
const delay = parseInt(args[2]) || 5000;

const scraper = new BatchScraper({
  searchStrategy: strategy,
  batchSize,
  delayBetweenBatches: delay,
  maxConcurrentJobs: 3,
});

scraper.run();
</file>

<file path="scripts/check-column-ids.ts">
import { chromium } from 'playwright';
import logger from '../lib/logger';

async function checkColumnIds() {
  logger.info(' Checking actual column IDs...\n');

  const browser = await chromium.launch({
    headless: true,
    args: ['--no-sandbox', '--disable-setuid-sandbox'],
  });

  const context = await browser.newContext({
    userAgent: 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
    viewport: { width: 1920, height: 1080 },
  });

  const page = await context.newPage();

  try {
    await page.goto('https://travis.prodigycad.com/property-search', {
      waitUntil: 'networkidle',
      timeout: 30000,
    });

    await page.waitForFunction(() => {
      const root = document.getElementById('root');
      return root && root.children.length > 0;
    }, { timeout: 15000 });

    await page.waitForSelector('#searchInput', { timeout: 10000 });
    await page.type('#searchInput', 'dede', { delay: 100 });
    await page.waitForTimeout(500);
    await page.press('#searchInput', 'Enter');
    await page.waitForTimeout(7000);

    const columnInfo = await page.evaluate(() => {
      const firstRow = document.querySelector('.ag-row');
      if (!firstRow) return { error: 'No rows found' };

      const cells = firstRow.querySelectorAll('[role="gridcell"]');
      const cellsInfo = Array.from(cells).map(cell => ({
        colId: cell.getAttribute('col-id'),
        text: cell.textContent?.trim(),
        ariaColIndex: cell.getAttribute('aria-colindex'),
      }));

      return { cellsInfo };
    });

    logger.info(' All Column IDs from first row:\n');
    if ('error' in columnInfo) {
      logger.error(columnInfo.error);
    } else {
      columnInfo.cellsInfo.forEach((cell, i) => {
        logger.info(`Column ${i + 1}:`);
        logger.info(`  col-id: ${cell.colId}`);
        logger.info(`  text: ${cell.text || '(empty)'}`);
        logger.info(`  aria-colindex: ${cell.ariaColIndex}\n`);
      });
    }

  } catch (error: any) {
    logger.error(` Error: ${error.message}`);
  } finally {
    await context.close();
    await browser.close();
  }
}

checkColumnIds();
</file>

<file path="scripts/check-grove-job.ts">
import { scraperQueue } from '../queues/scraper.queue';

async function checkGroveJob() {
  const waiting = await scraperQueue.getWaiting();
  const active = await scraperQueue.getActive();
  const completed = await scraperQueue.getCompleted();

  console.log('Queue Status:');
  console.log('- Waiting jobs:', waiting.length);
  console.log('- Active jobs:', active.length);
  console.log('- Completed jobs (recent):', completed.length);

  // Find Grove job
  const groveJobs = [...waiting, ...active, ...completed].filter((job: any) =>
    job.data?.searchTerm === 'Grove'
  );

  console.log('\nGrove job(s):', groveJobs.length);
  if (groveJobs.length > 0) {
    const job = groveJobs[0];
    const state = await job.getState();
    console.log('Grove job details:', JSON.stringify({
      id: job.id,
      state,
      data: job.data,
      finishedOn: job.finishedOn,
      processedOn: job.processedOn,
      returnvalue: job.returnvalue
    }, null, 2));
  } else {
    console.log('No Grove job found in queue');
  }

  process.exit(0);
}

checkGroveJob().catch((err) => {
  console.error('Error:', err);
  process.exit(1);
});
</file>

<file path="scripts/check-queue-status.ts">
#!/usr/bin/env node
/**
 * Check Queue Status
 * Displays current status of all jobs in the scraper queue
 */

import { scraperQueue } from '../queues/scraper.queue';
import logger from '../lib/logger';

async function checkQueueStatus() {
  try {
    logger.info(' Checking Scraper Queue Status...\n');

    // Get job counts by status
    const [
      waiting,
      active,
      completed,
      failed,
      delayed,
      isPaused
    ] = await Promise.all([
      scraperQueue.getWaiting(),
      scraperQueue.getActive(),
      scraperQueue.getCompleted(),
      scraperQueue.getFailed(),
      scraperQueue.getDelayed(),
      scraperQueue.isPaused()
    ]);

    // Get counts
    const counts = {
      waiting: waiting.length,
      active: active.length,
      completed: completed.length,
      failed: failed.length,
      delayed: delayed.length,
      paused: isPaused ? 1 : 0
    };

    logger.info('='.repeat(60));
    logger.info(' QUEUE SUMMARY');
    logger.info('='.repeat(60));
    logger.info(` Waiting:   ${counts.waiting}`);
    logger.info(` Active:    ${counts.active}`);
    logger.info(` Completed: ${counts.completed}`);
    logger.info(` Failed:    ${counts.failed}`);
    logger.info(`  Delayed:   ${counts.delayed}`);
    logger.info(`  Paused:    ${counts.paused}`);
    logger.info('='.repeat(60));
    logger.info(` Total:     ${counts.waiting + counts.active + counts.completed + counts.failed + counts.delayed + counts.paused}`);
    logger.info('='.repeat(60));

    // Show active jobs
    if (active.length > 0) {
      logger.info('\n ACTIVE JOBS:');
      for (const job of active.slice(0, 5)) {
        const data = job.data as any;
        logger.info(`  Job ${job.id}: "${data.searchTerm}" (Progress: ${job.progress}%)`);
      }
      if (active.length > 5) {
        logger.info(`  ... and ${active.length - 5} more`);
      }
    }

    // Show recent completed jobs
    if (completed.length > 0) {
      logger.info('\n RECENT COMPLETED JOBS (last 10):');
      for (const job of completed.slice(-10).reverse()) {
        const data = job.data as any;
        const returnValue = job.returnvalue as any;
        const propertiesCount = returnValue?.propertiesCount || 0;
        logger.info(`  Job ${job.id}: "${data.searchTerm}"  ${propertiesCount} properties`);
      }
    }

    // Show recent failed jobs
    if (failed.length > 0) {
      logger.info('\n RECENT FAILED JOBS (last 5):');
      for (const job of failed.slice(-5).reverse()) {
        const data = job.data as any;
        const failedReason = job.failedReason || 'Unknown error';
        logger.info(`  Job ${job.id}: "${data.searchTerm}" - ${failedReason.substring(0, 80)}`);
      }
    }

    // Show next waiting jobs
    if (waiting.length > 0) {
      logger.info('\n NEXT WAITING JOBS (first 10):');
      for (const job of waiting.slice(0, 10)) {
        const data = job.data as any;
        const priority = job.opts.priority || 3;
        logger.info(`  Job ${job.id}: "${data.searchTerm}" (Priority: ${priority})`);
      }
      if (waiting.length > 10) {
        logger.info(`  ... and ${waiting.length - 10} more`);
      }
    }

    logger.info('');

    // Cleanup
    await scraperQueue.close();
    process.exit(0);
  } catch (error) {
    logger.error({ err: error }, ' Error checking queue status:');
    process.exit(1);
  }
}

checkQueueStatus();
</file>

<file path="scripts/continuous-batch-scraper.ts">
import { scraperQueue } from '../queues/scraper.queue';
import { prisma } from '../lib/prisma';
import winston from 'winston';
import { SearchTermDeduplicator } from '../lib/search-term-deduplicator';
import { searchTermOptimizer, SearchTermOptimizer } from '../services/search-term-optimizer';

const logger = winston.createLogger({
  level: 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.simple()
  ),
  transports: [
    new winston.transports.Console(),
    new winston.transports.File({ filename: 'logs/continuous-scraper.log' }),
  ],
});

const TARGET_PROPERTIES = 451339;
// Using API-based scraping (1000+ results per search). Optimized for high-yield search terms.
// Batch size reduced to enable more frequent optimizations (every 50 jobs = ~2-3 batches)
const BATCH_SIZE = 25; // Reduced from 75 to 25 for faster optimization cycles
const DELAY_BETWEEN_BATCHES = 30000; // 30 seconds
const CHECK_INTERVAL = 60000; // Check every minute

// Generate diverse search patterns
class SearchPatternGenerator {
  private usedTerms = new Set<string>();
  private deduplicator!: SearchTermDeduplicator; // Initialized in loadUsedTerms
  private dbTermsLoaded = false;
  private lastDbRefresh = 0;
  private readonly DB_REFRESH_INTERVAL = 60 * 60 * 1000; // Refresh every hour
  private optimizer: SearchTermOptimizer;
  private jobsProcessedSinceLastOptimization = 0;
  private readonly OPTIMIZATION_INTERVAL = 50; // Optimize after every 50 jobs

  // Common first names (top 200)
  private firstNames = [
    'James', 'Mary', 'John', 'Patricia', 'Robert', 'Jennifer', 'Michael', 'Linda',
    'William', 'Elizabeth', 'David', 'Barbara', 'Richard', 'Susan', 'Joseph', 'Jessica',
    'Thomas', 'Sarah', 'Charles', 'Karen', 'Christopher', 'Nancy', 'Daniel', 'Lisa',
    'Matthew', 'Betty', 'Anthony', 'Margaret', 'Mark', 'Sandra', 'Donald', 'Ashley',
    'Steven', 'Kimberly', 'Paul', 'Emily', 'Andrew', 'Donna', 'Joshua', 'Michelle',
    'Kenneth', 'Dorothy', 'Kevin', 'Carol', 'Brian', 'Amanda', 'George', 'Melissa',
    'Edward', 'Deborah', 'Ronald', 'Stephanie', 'Timothy', 'Rebecca', 'Jason', 'Sharon',
    'Jeffrey', 'Laura', 'Ryan', 'Cynthia', 'Jacob', 'Kathleen', 'Gary', 'Amy',
    'Nicholas', 'Shirley', 'Eric', 'Angela', 'Jonathan', 'Helen', 'Stephen', 'Anna',
    'Larry', 'Brenda', 'Justin', 'Pamela', 'Scott', 'Nicole', 'Brandon', 'Emma',
    'Benjamin', 'Samantha', 'Samuel', 'Katherine', 'Raymond', 'Christine', 'Gregory', 'Debra',
    'Frank', 'Rachel', 'Alexander', 'Catherine', 'Patrick', 'Carolyn', 'Raymond', 'Janet',
    'Jack', 'Ruth', 'Dennis', 'Maria', 'Jerry', 'Heather', 'Tyler', 'Diane',
    'Aaron', 'Virginia', 'Jose', 'Julie', 'Adam', 'Joyce', 'Henry', 'Victoria',
    'Nathan', 'Olivia', 'Douglas', 'Kelly', 'Zachary', 'Christina', 'Peter', 'Lauren',
    'Kyle', 'Joan', 'Walter', 'Evelyn', 'Ethan', 'Judith', 'Jeremy', 'Megan',
    'Harold', 'Cheryl', 'Keith', 'Andrea', 'Christian', 'Hannah', 'Roger', 'Jacqueline',
    'Noah', 'Martha', 'Gerald', 'Gloria', 'Carl', 'Teresa', 'Terry', 'Ann',
    'Sean', 'Sara', 'Austin', 'Madison', 'Arthur', 'Frances', 'Lawrence', 'Kathryn',
    'Jesse', 'Janice', 'Dylan', 'Jean', 'Bryan', 'Abigail', 'Joe', 'Sophia',
    'Jordan', 'Judy', 'Billy', 'Theresa', 'Bruce', 'Rose', 'Albert', 'Beverly',
    'Willie', 'Denise', 'Gabriel', 'Marilyn', 'Logan', 'Amber', 'Alan', 'Danielle',
    'Juan', 'Brittany', 'Wayne', 'Diana', 'Roy', 'Natalie', 'Ralph', 'Sophia',
    'Randy', 'Alexis', 'Eugene', 'Lori', 'Vincent', 'Kayla', 'Russell', 'Jane',
    'Louis', 'Grace', 'Philip', 'Judy', 'Bobby', 'Alice', 'Johnny', 'Julia',
  ];

  // Common last names (expanded to 500+)
  private lastNames = [
    'Smith', 'Johnson', 'Williams', 'Brown', 'Jones', 'Garcia', 'Miller', 'Davis',
    'Rodriguez', 'Martinez', 'Hernandez', 'Lopez', 'Gonzalez', 'Wilson', 'Anderson', 'Thomas',
    'Taylor', 'Moore', 'Jackson', 'Martin', 'Lee', 'Perez', 'Thompson', 'White',
    'Harris', 'Sanchez', 'Clark', 'Ramirez', 'Lewis', 'Robinson', 'Walker', 'Young',
    'Allen', 'King', 'Wright', 'Scott', 'Torres', 'Nguyen', 'Hill', 'Flores',
    'Green', 'Adams', 'Nelson', 'Baker', 'Hall', 'Rivera', 'Campbell', 'Mitchell',
    'Carter', 'Roberts', 'Gomez', 'Phillips', 'Evans', 'Turner', 'Diaz', 'Parker',
    'Cruz', 'Edwards', 'Collins', 'Reyes', 'Stewart', 'Morris', 'Morales', 'Murphy',
    'Cook', 'Rogers', 'Gutierrez', 'Ortiz', 'Morgan', 'Cooper', 'Peterson', 'Bailey',
    'Reed', 'Kelly', 'Howard', 'Ramos', 'Kim', 'Cox', 'Ward', 'Richardson',
    'Watson', 'Brooks', 'Chavez', 'Wood', 'James', 'Bennett', 'Gray', 'Mendoza',
    'Ruiz', 'Hughes', 'Price', 'Alvarez', 'Castillo', 'Sanders', 'Patel', 'Myers',
    'Long', 'Ross', 'Foster', 'Jimenez', 'Powell', 'Jenkins', 'Perry', 'Russell',
    'Sullivan', 'Bell', 'Coleman', 'Butler', 'Henderson', 'Barnes', 'Gonzales', 'Fisher',
    'Vasquez', 'Simmons', 'Romero', 'Jordan', 'Patterson', 'Alexander', 'Hamilton', 'Graham',
    'Reynolds', 'Griffin', 'Wallace', 'Moreno', 'West', 'Cole', 'Hayes', 'Bryant',
    'Herrera', 'Gibson', 'Ellis', 'Tran', 'Medina', 'Aguilar', 'Stevens', 'Murray',
    'Ford', 'Castro', 'Marshall', 'Owens', 'Harrison', 'Fernandez', 'McDonald', 'Woods',
    'Washington', 'Kennedy', 'Wells', 'Vargas', 'Henry', 'Chen', 'Freeman', 'Webb',
    'Tucker', 'Guzman', 'Burns', 'Crawford', 'Olson', 'Simpson', 'Porter', 'Hunter',
    'Gordon', 'Mendez', 'Silva', 'Shaw', 'Snyder', 'Mason', 'Dixon', 'Munoz',
    'Hunt', 'Hicks', 'Holmes', 'Palmer', 'Wagner', 'Black', 'Robertson', 'Boyd',
    'Rose', 'Stone', 'Salazar', 'Fox', 'Warren', 'Mills', 'Meyer', 'Rice',
    'Schmidt', 'Garza', 'Daniels', 'Ferguson', 'Nichols', 'Stephens', 'Soto', 'Weaver',
    'Ryan', 'Gardner', 'Payne', 'Grant', 'Dunn', 'Kelley', 'Spencer', 'Hawkins',
    // Additional 300+ names
    'Lawson', 'Pierce', 'Hart', 'Elliott', 'Cunningham', 'Knight', 'Bradley', 'Carroll',
    'Hudson', 'Duncan', 'Armstrong', 'Berry', 'Andrews', 'Johnston', 'Ray', 'Lane',
    'Riley', 'Carpenter', 'Perkins', 'Williamson', 'Hanson', 'Austin', 'Newman', 'Oliver',
    'Howell', 'Dean', 'Wells', 'Fleming', 'French', 'Cannon', 'Barker', 'Watts',
    'McCoy', 'McLaughlin', 'Caldwell', 'Chandler', 'Lambert', 'Norton', 'Blake', 'Maxwell',
    'Carr', 'Walsh', 'Little', 'Park', 'Hodges', 'Haynes', 'Burgess', 'Benson',
    'Bishop', 'Todd', 'Norris', 'Fuller', 'Barber', 'Lamb', 'Parsons', 'Sutton',
    'Welch', 'Paul', 'Schwartz', 'Newman', 'Manning', 'Goodman', 'Watkins', 'Lyons',
    'Dawson', 'Powers', 'Figueroa', 'Nash', 'McKenzie', 'Booth', 'Shelton', 'Moran',
    'Rojas', 'Frank', 'Conner', 'Brock', 'Hogan', 'Brady', 'McCormick', 'Parks',
    'Floyd', 'Steele', 'Townsend', 'Valdez', 'Dennis', 'Hale', 'Delgado', 'Sutherland',
    'Buchanan', 'Marsh', 'Cummings', 'Patton', 'Rowe', 'Hampton', 'Lang', 'Gross',
    'Garner', 'Vincent', 'Doyle', 'Ramsey', 'Thornton', 'Wolfe', 'Glass', 'McCarthy',
    'Bowman', 'Luna', 'Norman', 'Pearson', 'Floyd', 'Mullins', 'Gregory', 'Schwartz',
    'Singleton', 'Wilkins', 'Schneider', 'Bowen', 'Hoffman', 'Logan', 'Cross', 'Moss',
    'Richards', 'Harmon', 'Brady', 'Rodgers', 'Duran', 'Hubbard', 'Bates', 'Reeves',
    'Klein', 'Frazier', 'Gibbs', 'Craig', 'Cochran', 'Chase', 'Moss', 'McKinney',
    'Bauer', 'Robbins', 'Curry', 'Sawyer', 'Powers', 'Jensen', 'Walters', 'Huff',
    'Aguilar', 'Glover', 'Browning', 'Carson', 'Mack', 'Clayton', 'Fritz', 'Hansen',
    'Schultz', 'Rich', 'Webster', 'Malone', 'Hammond', 'Flowers', 'Cobb', 'Moody',
    'Quinn', 'Randall', 'Brewer', 'Hutchinson', 'Holden', 'Wiley', 'Rowland', 'Mejia',
    'Sweeney', 'Dale', 'Frederick', 'Dalton', 'Logan', 'Sellers', 'Monroe', 'Hickman',
    'Gill', 'Cannon', 'Savage', 'Ballard', 'Joseph', 'Crosby', 'Drake', 'Vaughn',
    'Walls', 'Bolton', 'Chan', 'Stokes', 'Bentley', 'Skinner', 'Woodward', 'Brennan',
    'Hayden', 'Hancock', 'Huang', 'Pearce', 'Ingram', 'Reese', 'Lang', 'Spence',
    'Carey', 'Bird', 'Hess', 'Morse', 'Santiago', 'Leon', 'Krueger', 'Cochran',
    'Pratt', 'Valencia', 'Jarvis', 'Sharp', 'Oconnor', 'Levine', 'Flynn', 'Chang',
    'Yates', 'Nolan', 'Zuniga', 'Maddox', 'Whitehead', 'Gallagher', 'Michael', 'Cooke',
    'Sanford', 'Pitts', 'Haley', 'Hanna', 'Hatfield', 'Hoover', 'Decker', 'Davila',
    'Vega', 'Stafford', 'Cain', 'Dillon', 'Wiggins', 'Mathews', 'Krause', 'McMillan',
    'Kent', 'Holt', 'Shaffer', 'Dyer', 'Koch', 'Blackburn', 'Riddle', 'Shields',
    'Hendrix', 'Mahoney', 'Morrow', 'Collier', 'Stein', 'Best', 'Blanchard', 'Melton',
    'Maynard', 'Mercer', 'Osborne', 'Albert', 'Acosta', 'Petty', 'Winters', 'Trujillo',
    'Jennings', 'Conley', 'Prince', 'McGuire', 'Waller', 'Barr', 'Dickson', 'Stuart',
    'Potts', 'Valentine', 'Frost', 'Gentry', 'Hester', 'Cantrell', 'Ayers', 'Blevins',
    'Holman', 'Donovan', 'Bradshaw', 'English', 'Hahn', 'Aaron', 'Barton', 'Hendricks',
    'Church', 'Rosales', 'Howe', 'Everett', 'Gould', 'Harrington', 'Oneal', 'Bean',
    'Villanueva', 'Schroeder', 'Solomon', 'Summers', 'Dougherty', 'Livingston', 'Pace', 'Avila',
    'Knox', 'Dunlap', 'Saunders', 'Alvarado', 'Hayden', 'Greer', 'Roman', 'Buck',
    'Hines', 'Weeks', 'Witt', 'Navarro', 'Juarez', 'Cervantes', 'Carey', 'Garrett',
    'Lowe', 'Dodd', 'Duke', 'Pena', 'Costa', 'Galloway', 'Tate', 'Mayer',
    'Meyers', 'Schaefer', 'Noel', 'Kruger', 'Giles', 'Crosby', 'Sloan', 'Wyatt',
    'Johns', 'Ramsey', 'Ibarra', 'Escobar', 'Whitaker', 'Joyce', 'Burnett', 'Wall',
    'Barlow', 'Randolph', 'Atkinson', 'Horn', 'Clements', 'Floyd', 'Dodson', 'Lowery',
    'Ashley', 'Moon', 'Buchanan', 'Nava', 'Proctor', 'Pruitt', 'Phelps', 'Hinton',
  ];

  // Austin/Travis County street names (expanded to 150+)
  private streetNames = [
    'Main', 'Oak', 'Lamar', 'Congress', 'Guadalupe', 'Burnet', 'Airport', 'Oltorf',
    'Anderson', 'Cave', 'Slaughter', 'Cannon', 'Research', 'Parmer', 'Braker',
    'Rundberg', 'Loop', 'Lamar', 'Riverside', 'Anderson',
    'Congress', 'Red R', 'Rainey', 'Chavez', 'MLK', 'Dean',
    'Speedway', 'Duval', 'Shoal', 'Koenig', 'Far W', 'Research', 'Blvd',
     'First', 'East 7th', 'West 6th', 'Barton Springs', 'Westlake', 'Exposition',
      'Windsor', 'Enfield', 'Balcones', 'Spicewood', 'Capital of Texas', 'Cameron',
    'Metric', 'Dessau', 'Lamar Blvd', 'IH 35', 'Loop 360', 'Wells Branch',
    'McNeil', 'Howard', 'Jollyville', 'Mopac', 'Manchaca', 'Riverside',
        'Guadalupe', 'Rio Grande', 'Nueces', 'San Antonio', 'Lavaca', 'Colorado',
    'Brazos', 'San Jacinto', 'Trinity', 'Neches', 'Sabine', 'Blanco',
   'Manor', 'Martin Luther King', 'Airport', 'Pleasant Valley', 'Springdale',
    'Loyola', 'Berkman', 'Mueller', 'Cherrywood', 'Hancock',
    // Additional Austin streets
    'Burnet Road', 'South 1st', 'East 6th', 'West 5th', 'East 11th', 'West 12th',
    'Guadalupe', 'Street', 'Avenue', 'Lavaca', 'Street', 'Brazos', 'Boulevard',
   'Red River', 'Trinity', 'Neches', 'Sabine', 'Waller Street',
    'San Marcos', 'Cesar Chavez', 'East Cesar Chavez', 'Drive', 'Town Lake',
    'Manor', 'Airport', 'Koenig Lane', 'North Lamar', 'South Lamar Boulevard',
    'Mopac Expressway', 'Loop 1', 'Highway 183', 'Ben White', 'Highway 290',
    'FM 620', 'FM 2222', 'RM 2244', 'RM 620', 'Lakeline Boulevard',
    'Cedar Park', 'Anderson Lane', 'Steck Avenue', 'Spicewood Springs', 'Mesa Drive',
    'Hill', 'Boulevard', 'Lane', 'Burnet', 'Drive', 'Road', "East", "West", "Avenue", "Ave.",
    'Dittmar', 'Montopolis', 'South', 'North', 'Crossing', 'Fall',
    'Del Valle', 'Webberville', 'Creek', 'Johnny Morris', 'Cameron Road', 'Airport', 'Springdale', 'General',
    '4th S', '5th S', '2nd S', '3rd S', 'Square',
    'West Lynn', 'Park', 'Square', 'Place', 'San G',
  ];

  // Property types and building names (expanded)
  private propertyTypes = [
    'Apartments', 'Condos', 'Townhomes', 'Office', 'Retail', 'Plaza', 'Center',
    'Building', 'Tower', 'Park', 'Ranch', 'Estates', 'Village', 'Square',
    'Commons', 'Crossing', 'Landing', 'Pointe', 'Ridge', 'Creek', 'Hills',
        'Woods', 'Grove', 'Meadows', 'Terrace', 'Court', 'Place',
    'Lofts', 'Flats', 'Studios', 'Villas', 'Gardens', 'Heights', 'Trails',
    'Vista', 'Reserve', 'Springs', 'Oaks', 'Pines', 'Palms', 'Lake',
    'Ranch', 'Farm', 'Pecan', 'Walnut', 'River', 'Lake', 'Mount', 'Ridge',
  ];

  // Business/Company suffixes (optimized for high success rate)
  // ONLY legal entity types and proven real estate terms
  // Removed generic terms that cause zero-results: Ventures, Development, Developers,
  // Real Estate, Management, Equity, Assets, Portfolio (26% zero-result rate)
  private businessSuffixes = [
    'LLC',         // Legal entity - high reliability
    'Inc',         // Legal entity - high reliability
    'Corp',        // Legal entity - high reliability
    'Partner',     // Legal entity
    'Develop',     // Covers 'Developers'/'Development'/etc.
    'LTD',         // Legal entity - high reliability
    'Company',     // Legal entity - high reliability
    'Properties',  // Real estate specific - proven
    'Trust',       // Real estate specific - proven
    'Real',        // Real estate specific - proven
    'Holding',     // Investment specific - proven
    'Assoc',       // Association/Associates, etc.
  ];

  // Austin neighborhoods and subdivisions (expanded to 75+)
  private neighborhoods = [
    'Hyde',  'Park', 'Clark', 'ville', 'Bouldin',  'Creek', 'Travis', 'Heights', 'Zilker',
    'Allandale', 'Crestview', 'Rosedale', 'Loop', 'Mueller',
    'East Austin', 'South Congress', 'Barton', 'Tarrytown', 'West Lake',
    'Circle C', 'Ranch', 'Avery', 'Anderson Mill', 'Brushy Creek',
    'Wells Branch', 'Creek', 'Windsor Park', 'Cherrywood', 'Hancock',
    'Brentwood', 'Walnut', 'Gracywoods', 'Balcones', 'Great Hills',
    // Additional neighborhoods
    'Onion Creek', 'Barton Creek', 'Oak Hill', 'Sunset Valley', 'Rollingwood',
    'West Campus', 'East Cesar Chavez', 'Holly', 'Govalle', 'Riverside',
    'Montopolis', 'Pleasant Valley', 'Del Valle', 'Dove Springs', 'Southpark Meadows',
    'St. Edwards', 'St. Johns', 'North University', 'Wooten', 'Highland',
    'Heritage', 'Pemberton Heights', 'Old West Austin', 'Bryker Woods', 'Old Enfield',
    'Judges', 'Crest', 'Northwest', 'Estates', 'Ridgetop',
    'Spicewood', 'Bull', 'Mesa Park', 'Westover Hills', 'Rollingwood West', 'Lost Creek',
    'Senna', 'Ranch at Cypress Creek', 'Sendero Springs', 'Falconhead', 'Shady Hollow',
    'Eanes', 'Rob Roy', 'Courtyard', 'Sendera',
    'Belterra', 'Canyon', 'Maple Run', 'Common', 'Acres', 'Spring',
  ];

  // Common property descriptors
  private propertyDescriptors = [
    'Home', 'House', 'Property', 'Land', 'Lot', 'Parcel', 'Tract',
    'Residence', 'Unit', 'Suite', 'Space', 'Commercial', 'Residential',
    'Condo', 'Comm', 'Ste.'
  ];

  constructor() {
    this.optimizer = searchTermOptimizer;
  }

  // Load all previously used search terms from database to avoid duplicates
  async loadUsedTermsFromDatabase(forceRefresh = false): Promise<void> {
    const now = Date.now();

    // Check if we need to refresh
    if (!forceRefresh && this.dbTermsLoaded && (now - this.lastDbRefresh) < this.DB_REFRESH_INTERVAL) {
      return; // Already loaded and not time to refresh yet
    }

    const isRefresh = this.dbTermsLoaded;
    logger.info(isRefresh ? ' Refreshing search terms from database...' : ' Loading previously used search terms from database...');

    try {
      const previousCount = this.usedTerms.size;

      // Get all unique search terms from scrape jobs
      const existingTerms = await prisma.scrapeJob.findMany({
        select: {
          searchTerm: true,
        },
        distinct: ['searchTerm'],
      });

      // Add all terms to the set (Set automatically handles duplicates)
      existingTerms.forEach(job => {
        this.usedTerms.add(job.searchTerm);
      });

      // Initialize or update the deduplicator with current terms
      if (!this.deduplicator) {
        this.deduplicator = new SearchTermDeduplicator(this.usedTerms);
      }

      const currentCount = this.usedTerms.size;
      const newTermsFound = currentCount - previousCount;

      if (isRefresh) {
        logger.info(` Refreshed: ${currentCount.toLocaleString()} total terms (${newTermsFound} new since last check)`);
      } else {
        logger.info(` Loaded ${currentCount.toLocaleString()} previously used search terms`);
        logger.info(`   Will avoid duplicates like: "Estate", "Family", "Trust", etc.`);
      }

      this.dbTermsLoaded = true;
      this.lastDbRefresh = now;
    } catch (error) {
      logger.error({ err: error }, ' Failed to load used terms from database:');
      throw error;
    }
  }

  private generateLastNameOnly(): string {
    return this.lastNames[Math.floor(Math.random() * this.lastNames.length)];
  }

  private generateStreetAddress(): string {
    const number = Math.floor(Math.random() * 9999) + 1;
    const street = this.streetNames[Math.floor(Math.random() * this.streetNames.length)];
    return `${number} ${street}`;
  }

  private generatePropertyType(): string {
    return this.propertyTypes[Math.floor(Math.random() * this.propertyTypes.length)];
  }

  private generateBusinessName(): string {
    const name = this.lastNames[Math.floor(Math.random() * this.lastNames.length)];
    const suffix = this.businessSuffixes[Math.floor(Math.random() * this.businessSuffixes.length)];
    return `${name} ${suffix}`;
  }

  private generateStreetNameOnly(): string {
    return this.streetNames[Math.floor(Math.random() * this.streetNames.length)];
  }

  private generateFourLetterWord(): string {
    const words = ['Park', 'Lake', 'Hill', 'Wood', 'Glen', 'Dale', 'View', 'Rock', 'Pine', 'Sage'];
    return words[Math.floor(Math.random() * words.length)];
  }

  // NEW: Generate neighborhood name
  private generateNeighborhood(): string {
    return this.neighborhoods[Math.floor(Math.random() * this.neighborhoods.length)];
  }

  // NEW: Generate property type with descriptor
  private generatePropertyWithDescriptor(): string {
    const type = this.propertyTypes[Math.floor(Math.random() * this.propertyTypes.length)];
    const descriptor = this.propertyDescriptors[Math.floor(Math.random() * this.propertyDescriptors.length)];
    return Math.random() > 0.5 ? `${type} ${descriptor}` : type;
  }

  // NEW: Generate partial street address (just number + street, more common)
  private generatePartialAddress(): string {
    const number = Math.floor(Math.random() * 9999) + 1;
    const street = this.streetNames[Math.floor(Math.random() * this.streetNames.length)];
    const words = street.split(' ');
    // Sometimes use just first word of street name for broader matches
    return Math.random() > 0.3 ? `${number} ${street}` : `${number} ${words[0]}`;
  }

  // OPTIMIZED: Generate first names only (HIGH YIELD - avg 426+ properties)
  private generateFirstNameOnly(): string {
    return this.firstNames[Math.floor(Math.random() * this.firstNames.length)];
  }

  // OPTIMIZED: Generate common street suffixes (VERY HIGH YIELD - avg 637+ properties)
  private generateStreetSuffix(): string {
    const suffixes = ['Avenue', 'Boulevard', 'Court', 'Drive', 'Lane', 'Circle',
                      'Place', 'Way', 'Trail', 'Path', 'Bend', 'Loop', 'Terrace',
                      'Parkway', 'Ridge', 'Hill', 'Manor'];
    return suffixes[Math.floor(Math.random() * suffixes.length)];
  }

  // OPTIMIZED: Generate 4-letter geographic terms (HIGH YIELD - avg 637+ properties)
  private generateGeographicTerm(): string {
    const terms = ['Hill', 'Lake', 'Cave', 'Park', 'Glen', 'Dale', 'Ford',
                   'Cove', 'Rock', 'Wood', 'Farm', 'Mill', 'Pond', 'Peak'];
    return terms[Math.floor(Math.random() * terms.length)];
  }

  // OPTIMIZED: Generate Hispanic/Asian surnames (HIGH YIELD - avg 2000+ properties each)
  private generateHispanicAsianSurname(): string {
    const names = ['Garcia', 'Hernandez', 'Lopez', 'Gonzalez', 'Perez', 'Sanchez',
                   'Rivera', 'Torres', 'Ramirez', 'Flores', 'Gomez', 'Cruz',
                   'Lee', 'Chen', 'Wang', 'Kim', 'Patel', 'Singh', 'Chang', 'Nguyen'];
    return names[Math.floor(Math.random() * names.length)];
  }

  /**
   * Optimize search strategy based on actual performance data every 50 jobs
   * This analyzes completed jobs and suggests high-performing terms
   */
  private async optimizeStrategy(): Promise<string[]> {
    logger.info('\n Optimizing search strategy based on performance data...');

    try {
      // Get performance stats
      const stats = await this.optimizer.getPerformanceStats();
      logger.info(` Analyzed ${stats.totalSearchTerms} unique search terms`);
      logger.info(`   Avg efficiency: ${stats.avgEfficiency.toFixed(2)}`);
      logger.info(`   Avg success rate: ${(stats.avgSuccessRate * 100).toFixed(1)}%`);
      logger.info(`   Avg results per search: ${stats.avgResultsPerSearch.toFixed(1)}`);

      // Get top performers
      if (stats.topPerformers.length > 0) {
        logger.info(`\n Top 5 performing search terms:`);
        stats.topPerformers.slice(0, 5).forEach((term, i) => {
          logger.info(`   ${i + 1}. "${term.searchTerm}" - ${term.avgResultsPerSearch.toFixed(0)} avg results, ${(term.successRate * 100).toFixed(0)}% success`);
        });
      }

      // Get optimized terms for next batch
      const optimizedTerms = await this.optimizer.getOptimizedTerms({
        minEfficiency: 5.0,
        minSuccessRate: 0.5,
        maxTermsToReturn: 30,
        excludeRecentlyUsed: true,
        recentDays: 1, // Only exclude terms used in last 24 hours
      });

      // Get suggested new terms based on successful patterns
      const suggestedTerms = await this.optimizer.suggestNewTerms(20);

      logger.info(` Generated ${optimizedTerms.length} high-efficiency terms to prioritize`);
      logger.info(` Suggested ${suggestedTerms.length} new terms based on successful patterns\n`);

      // Reset the counter
      this.jobsProcessedSinceLastOptimization = 0;

      // Combine optimized and suggested terms
      return [...optimizedTerms, ...suggestedTerms];
    } catch (error) {
      logger.error({ err: error }, ' Failed to optimize strategy:');
      return [];
    }
  }

    async getNextBatch(batchSize: number): Promise<string[]> {
    // Load or refresh database terms (automatic hourly refresh)
    await this.loadUsedTermsFromDatabase();

    // Check if we should optimize strategy every 50 jobs
    this.jobsProcessedSinceLastOptimization++;
    let optimizedTerms: string[] = [];

    if (this.jobsProcessedSinceLastOptimization >= this.OPTIMIZATION_INTERVAL) {
      optimizedTerms = await this.optimizeStrategy();
    }

    const batch: string[] = [];

    // Weighted strategies - OPTIMIZED based on actual performance (286K+ properties analyzed):
    // Real-world results from database analysis:
    //   - Street Suffixes: 637.7 avg properties per term (4-char words) - BEST!
    //   - Common Names: 474.6 avg (6-char), 467.7 avg (5-char) - EXCELLENT
    //   - First Names: 426.4 avg properties - EXCELLENT (James, John, Robert, etc)
    //   - Hispanic/Asian Names: 2000-2700 avg each (Garcia, Rodriguez, Lee, Kim, etc)
    //   - Geographic Terms: 2000-6000 each (Hill, Lake, Cave, etc)
    //   - Business Entities: Only 2.8 avg - VERY POOR
    //
    // Strategy: Focus 85% on 4-6 character single words (proven winners)
    const strategies = [
      { fn: () => this.generateStreetSuffix(), weight: 50 },           // INCREASED! 1000+ avg - Boulevard, Drive, Lane untried
      { fn: () => this.generateFirstNameOnly(), weight: 35 },          // INCREASED! 1132 avg last hour - John: 13,393!
      { fn: () => this.generateLastNameOnly(), weight: 30 },           // REDUCED - Most high-yield names exhausted
      { fn: () => this.generateGeographicTerm(), weight: 25 },         // GREAT! Rock: 4,615, Mill: 3,778
      { fn: () => this.generateNeighborhood(), weight: 20 },           // Good for area coverage
      { fn: () => this.generateHispanicAsianSurname(), weight: 15 },   // 2000+ avg - Garcia, Lee, Kim, etc
      { fn: () => this.generatePropertyType(), weight: 10 },           // REDUCED - Moderate yield
      { fn: () => this.generateStreetNameOnly(), weight: 5 },          // REDUCED - Many covered
      { fn: () => this.generateBusinessName(), weight: 0 },            // ELIMINATED! 13% success, wasted 83% of last hour
      // REMOVED inefficient strategies:
      // - generatePropertyWithDescriptor() - 26% zero-result rate
      // - generateTwoLetterCombo() - 73.9% failure rate
      // - generateThreeLetterCombo() - 73.9% failure rate
      // - generateFourLetterWord() - 73.9% failure rate (now covered by generateGeographicTerm)
      // - generateFullName() - only 4.4 avg props, 26% zero-result rate
      // - generateStreetAddress() - 44.8% zero-result rate
      // - generateCompoundName() - causes JSON parse errors
    ];

    // Create weighted array
    const weightedStrategies: (() => string)[] = [];
    strategies.forEach(s => {
      for (let i = 0; i < s.weight; i++) {
        weightedStrategies.push(s.fn);
      }
    });

    let attempts = 0;
    const maxAttempts = batchSize * 10;

    // Reset deduplicator stats for this batch
    this.deduplicator.resetStats();

    // First, prioritize optimized terms (if available)
    if (optimizedTerms.length > 0) {
      logger.info(` Prioritizing ${optimizedTerms.length} high-performing terms in this batch`);
      for (const term of optimizedTerms) {
        if (batch.length >= batchSize) break;

        // Use the deduplicator to check if we should skip this term
        if (!this.deduplicator.shouldSkipTerm(term)) {
          this.deduplicator.markTermAsUsed(term);
          this.usedTerms.add(term);
          batch.push(term);
        }
      }
    }

    // Fill remaining slots with random strategy-generated terms
    while (batch.length < batchSize && attempts < maxAttempts) {
      attempts++;
      const strategy = weightedStrategies[Math.floor(Math.random() * weightedStrategies.length)];
      const term = strategy();

      // Use the deduplicator to check if we should skip this term
      if (!this.deduplicator.shouldSkipTerm(term)) {
        // Term is unique enough - add it to the batch
        this.deduplicator.markTermAsUsed(term);
        this.usedTerms.add(term); // Also update local set for backwards compatibility
        batch.push(term);
      }
    }

    // Log deduplication statistics
    const stats = this.deduplicator.getStats();
    if (stats.exactDuplicates > 0) {
      logger.info(`     Skipped ${stats.exactDuplicates} exact duplicates`);
    }
    if (stats.tooCommonTerms > 0) {
      logger.info(`     Skipped ${stats.tooCommonTerms} too-common terms (cause API timeouts)`);
    }
    if (stats.businessSupersets > 0) {
      logger.info(`    Skipped ${stats.businessSupersets} business entity supersets`);
    }
    if (stats.twoWordSupersets > 0) {
      logger.info(`    Skipped ${stats.twoWordSupersets} two-word supersets`);
    }
    if (stats.multiWordSupersets > 0) {
      logger.info(`    Skipped ${stats.multiWordSupersets} multi-word supersets`);
    }

    return batch;
  }
}


class ContinuousBatchScraper {
  private generator = new SearchPatternGenerator();
  private stats = {
    totalQueued: 0,
    batchesProcessed: 0,
    startTime: Date.now(),
    startingPropertyCount: 0,
  };
  private running = true;

  async run() {
    logger.info('');
    logger.info('   CONTINUOUS BATCH SCRAPER - VOLUME OPTIMIZED         ');
    logger.info('   Target: 400,000 | Focus: High-Yield Search Terms    ');
    logger.info('\n');

    // Clear pending jobs from queue to start fresh with optimized strategy
    logger.info(' Clearing pending jobs from queue...');
    const pendingCount = await scraperQueue.getWaitingCount();
    if (pendingCount > 0) {
      await scraperQueue.clean(0, 'wait'); // Remove all waiting jobs
      logger.info(` Cleared ${pendingCount} pending jobs\n`);
    } else {
      logger.info(' No pending jobs to clear\n');
    }

    // Get starting property count
    this.stats.startingPropertyCount = await prisma.property.count();
    logger.info(`Starting property count: ${this.stats.startingPropertyCount.toLocaleString()}`);
    logger.info(`Target: ${TARGET_PROPERTIES.toLocaleString()}`);
    logger.info(`Remaining: ${(TARGET_PROPERTIES - this.stats.startingPropertyCount).toLocaleString()}\n`);

    // Handle graceful shutdown
    process.on('SIGINT', () => this.stop());
    process.on('SIGTERM', () => this.stop());

    // Start monitoring in background
    this.startMonitoring();

    // Main loop
    while (this.running) {
      const currentCount = await prisma.property.count();

      if (currentCount >= TARGET_PROPERTIES) {
        logger.info(`\n TARGET REACHED! Current count: ${currentCount.toLocaleString()}`);
        break;
      }

      // Check queue status
      const [waiting, active] = await Promise.all([
        scraperQueue.getWaitingCount(),
        scraperQueue.getActiveCount(),
      ]);

      // Queue threshold reduced from 500 to 100 because API method returns 50x more results
      // With old method: 500 searches * 20 results = 10,000 potential properties
      // With new method: 100 searches * 1000 results = 100,000 potential properties
      if (waiting + active < 100) {
        await this.queueBatch();
      } else {
        logger.info(`Queue full (${waiting} waiting, ${active} active). Waiting...`);
      }

      // Wait before next batch
      await this.delay(DELAY_BETWEEN_BATCHES);
    }

    await this.printFinalReport();
    process.exit(0);
  }

  private async queueBatch() {
    const searchTerms = await this.generator.getNextBatch(BATCH_SIZE);
    this.stats.batchesProcessed++;

    logger.info(`\n Batch #${this.stats.batchesProcessed} (${searchTerms.length} terms)`);

    for (const searchTerm of searchTerms) {
      try {
        await scraperQueue.add(
          'scrape-properties',
          {
            searchTerm,
            userId: 'continuous-batch',
            scheduled: true,
          },
          {
            attempts: 3,
            backoff: {
              type: 'exponential',
              delay: 2000,
            },
            removeOnComplete: 100,
            removeOnFail: 50,
          }
        );

        this.stats.totalQueued++;
      } catch (error) {
        logger.error({ err: error }, `Failed to queue ${searchTerm}:`);
      }
    }

    logger.info(` Queued ${searchTerms.length} jobs (Total: ${this.stats.totalQueued})`);
  }

  private startMonitoring() {
    setInterval(async () => {
      try {
        const [currentCount, waiting, active, completed, failed] = await Promise.all([
          prisma.property.count(),
          scraperQueue.getWaitingCount(),
          scraperQueue.getActiveCount(),
          scraperQueue.getCompletedCount(),
          scraperQueue.getFailedCount(),
        ]);

        const newProperties = currentCount - this.stats.startingPropertyCount;
        const progress = (currentCount / TARGET_PROPERTIES) * 100;
        const elapsed = Math.floor((Date.now() - this.stats.startTime) / 1000);
        const hours = Math.floor(elapsed / 3600);
        const minutes = Math.floor((elapsed % 3600) / 60);
        const rate = newProperties / (elapsed / 60); // properties per minute

        logger.info(`

 Runtime: ${hours}h ${minutes}m | Progress: ${progress.toFixed(2)}%

 Database:
    Current:     ${currentCount.toLocaleString().padStart(10)}
    New:         ${newProperties.toLocaleString().padStart(10)}
    Target:      ${TARGET_PROPERTIES.toLocaleString().padStart(10)}
    Remaining:   ${(TARGET_PROPERTIES - currentCount).toLocaleString().padStart(10)}
    Rate:        ${rate.toFixed(1)} props/min

 Queue:
    Waiting:     ${waiting.toString().padStart(6)}
    Active:      ${active.toString().padStart(6)}
    Completed:   ${completed.toString().padStart(6)}
    Failed:      ${failed.toString().padStart(6)}
    Batches:     ${this.stats.batchesProcessed.toString().padStart(6)}

        `);

        // Estimate time to completion
        if (rate > 0) {
          const remaining = TARGET_PROPERTIES - currentCount;
          const minutesRemaining = remaining / rate;
          const hoursRemaining = minutesRemaining / 60;
          logger.info(`  Estimated time to target: ${hoursRemaining.toFixed(1)} hours`);
        }
      } catch (error) {
        logger.error({ err: error }, 'Monitoring error:');
      }
    }, CHECK_INTERVAL);
  }

  private async printFinalReport() {
    const finalCount = await prisma.property.count();
    const elapsed = Math.floor((Date.now() - this.stats.startTime) / 1000);
    const hours = Math.floor(elapsed / 3600);
    const minutes = Math.floor((elapsed % 3600) / 60);

    logger.info(`

         CONTINUOUS SCRAPER FINAL REPORT                  


  Total Runtime: ${hours}h ${minutes}m

 Properties:
    Starting:     ${this.stats.startingPropertyCount.toLocaleString()}
    Final:        ${finalCount.toLocaleString()}
    Added:        ${(finalCount - this.stats.startingPropertyCount).toLocaleString()}
    Target:       ${TARGET_PROPERTIES.toLocaleString()}

 Jobs:
    Total Queued: ${this.stats.totalQueued.toLocaleString()}
    Batches:      ${this.stats.batchesProcessed}


   SCRAPING SESSION COMPLETED!                        

    `);
  }

  private stop() {
    logger.info('\n Stopping continuous scraper...');
    this.running = false;
  }

  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}

// Run the continuous scraper
const scraper = new ContinuousBatchScraper();
scraper.run().catch((error) => {
  logger.error({ err: error }, 'Fatal error:');
  process.exit(1);
});
</file>

<file path="scripts/debug-token-refresh.ts">
#!/usr/bin/env node
/**
 * Debug Token Refresh
 * Tests the token refresh service and prints detailed diagnostics
 */

import { tokenRefreshService } from '../services/token-refresh.service';
import logger from '../lib/logger';

async function debugTokenRefresh() {
  logger.info('='.repeat(60));
  logger.info('DEBUG: Token Refresh Service');
  logger.info('='.repeat(60));

  // Check initial state
  logger.info('\n1. Initial State:');
  logger.info('   currentToken:', tokenRefreshService.getCurrentToken());

  const initialStats = tokenRefreshService.getStats();
  logger.info('   Stats:', JSON.stringify(initialStats, null, 2));

  // Try to refresh token
  logger.info('\n2. Calling refreshToken()...');
  const startTime = Date.now();

  try {
    const token = await tokenRefreshService.refreshToken();
    const duration = Date.now() - startTime;

    logger.info(`\n3. refreshToken() returned after ${duration}ms:`);
    logger.info('   Type:', typeof token);
    logger.info('   Value:', token);
    logger.info('   Length:', token ? token.length : 'N/A');
    logger.info('   First 50 chars:', token ? token.substring(0, 50) : 'N/A');

  } catch (error) {
    logger.error('\n3. refreshToken() threw error:', error);
  }

  // Check state after refresh
  logger.info('\n4. State After Refresh:');
  logger.info('   currentToken:', tokenRefreshService.getCurrentToken());

  const afterStats = tokenRefreshService.getStats();
  logger.info('   Stats:', JSON.stringify(afterStats, null, 2));

  // Test getCurrentToken multiple times
  logger.info('\n5. Multiple getCurrentToken() calls:');
  for (let i = 0; i < 3; i++) {
    const token = tokenRefreshService.getCurrentToken();
    logger.info(`   Call ${i + 1}:`, token ? token.substring(0, 50) : 'null');
  }

  // Cleanup
  logger.info('\n6. Cleaning up...');
  await tokenRefreshService.cleanup();

  logger.info('\n' + '='.repeat(60));
  logger.info('DEBUG: Complete');
  logger.info('='.repeat(60));
}

debugTokenRefresh()
  .then(() => process.exit(0))
  .catch((error) => {
    logger.error('Script failed:', error);
    process.exit(1);
  });
</file>

<file path="scripts/enqueue-commercial-batch.ts">
#!/usr/bin/env node
/**
 * Enqueue Commercial Property Searches
 * Queues commercial property-related search terms
 */

import { scraperQueue } from '../queues/scraper.queue';
import logger from '../lib/logger';
import { config } from '../config';

const COMMERCIAL_TERMS = [
  'Shopping',
  'Retail',
  'Office',
  'Warehouse',
  'Industrial',
  'Commercial',
  'Business',
  'Store',
  'Mall',
  'Building',
];

async function enqueueCommercialBatch() {
  logger.info(' Starting Commercial Batch Enqueue');
  logger.info(`Auto-refresh token enabled: ${config.scraper.autoRefreshToken}`);
  logger.info(`Using Doppler: ${config.doppler.enabled ? 'Yes' : 'No'}`);

  try {
    let successCount = 0;
    let failCount = 0;

    for (const term of COMMERCIAL_TERMS) {
      try {
        const job = await scraperQueue.add('scrape-properties', {
          searchTerm: term,
          userId: 'commercial-batch-enqueue',
          scheduled: true,
        }, {
          attempts: 3,
          backoff: {
            type: 'exponential',
            delay: 2000,
          },
          priority: 2, // Higher priority for commercial
          removeOnComplete: 100,
          removeOnFail: 50,
        });

        successCount++;
        logger.info(` [${successCount}/${COMMERCIAL_TERMS.length}] Queued: "${term}" (Job ID: ${job.id})`);
      } catch (error) {
        failCount++;
        logger.error({ err: error }, ` Failed to queue "${term}":`);
      }
    }

    logger.info(`\n Summary: ${successCount} queued, ${failCount} failed`);
    logger.info(' Commercial batch enqueue completed!');
  } catch (error) {
    logger.error({ err: error }, ' Fatal error:');
    process.exit(1);
  }
}

enqueueCommercialBatch()
  .then(() => process.exit(0))
  .catch((error) => {
    logger.error({ err: error }, ' Script failed:');
    process.exit(1);
  });
</file>

<file path="scripts/enqueue-construction-batch.ts">
#!/usr/bin/env node
/**
 * Enqueue Construction & Building Searches
 * Queues construction and building-related search terms
 */

import { scraperQueue } from '../queues/scraper.queue';
import logger from '../lib/logger';
import { config } from '../config';

const CONSTRUCTION_TERMS = [
  'Construction',
  'Builders',
  'Builder',
  'Contractor',
  'Contracting',
  'Homes',
  'Home',
  'Custom Homes',
  'Housing',
  'Residential Builders',
];

async function enqueueConstructionBatch() {
  logger.info('  Starting Construction Batch Enqueue');
  logger.info(`Auto-refresh token enabled: ${config.scraper.autoRefreshToken}`);

  try {
    let successCount = 0;
    let failCount = 0;

    for (const term of CONSTRUCTION_TERMS) {
      try {
        const job = await scraperQueue.add('scrape-properties', {
          searchTerm: term,
          userId: 'construction-batch-enqueue',
          scheduled: true,
        }, {
          attempts: 3,
          backoff: {
            type: 'exponential',
            delay: 2000,
          },
          priority: 3,
          removeOnComplete: 100,
          removeOnFail: 50,
        });

        successCount++;
        logger.info(` [${successCount}/${CONSTRUCTION_TERMS.length}] Queued: "${term}" (Job ID: ${job.id})`);
      } catch (error) {
        failCount++;
        logger.error({ err: error }, ` Failed to queue "${term}":`);
      }
    }

    logger.info(`\n Summary: ${successCount} queued, ${failCount} failed`);
    logger.info(' Construction batch enqueue completed!');
  } catch (error) {
    logger.error({ err: error }, ' Fatal error:');
    process.exit(1);
  }
}

enqueueConstructionBatch()
  .then(() => process.exit(0))
  .catch((error) => {
    logger.error({ err: error }, ' Script failed:');
    process.exit(1);
  });
</file>

<file path="scripts/enqueue-corporation-batch.ts">
#!/usr/bin/env node
/**
 * Enqueue Corporation Property Searches
 * Queues corporation-related search terms
 */

import { scraperQueue } from '../queues/scraper.queue';
import logger from '../lib/logger';
import { config } from '../config';

const CORPORATION_TERMS = [
  'Corp',
  'Corp.',
  'Corporation',
  'Incorporated',
  'Inc',
  'Inc.',
  'Company',
  'Co.',
  'Enterprise',
  'Enterprises',
];

async function enqueueCorporationBatch() {
  logger.info('  Starting Corporation Batch Enqueue');
  logger.info(`Auto-refresh token enabled: ${config.scraper.autoRefreshToken}`);

  try {
    let successCount = 0;
    let failCount = 0;

    for (const term of CORPORATION_TERMS) {
      try {
        const job = await scraperQueue.add('scrape-properties', {
          searchTerm: term,
          userId: 'corporation-batch-enqueue',
          scheduled: true,
        }, {
          attempts: 3,
          backoff: {
            type: 'exponential',
            delay: 2000,
          },
          priority: 2,
          removeOnComplete: 100,
          removeOnFail: 50,
        });

        successCount++;
        logger.info(` [${successCount}/${CORPORATION_TERMS.length}] Queued: "${term}" (Job ID: ${job.id})`);
      } catch (error) {
        failCount++;
        logger.error({ err: error }, ` Failed to queue "${term}":`);
      }
    }

    logger.info(`\n Summary: ${successCount} queued, ${failCount} failed`);
    logger.info(' Corporation batch enqueue completed!');
  } catch (error) {
    logger.error({ err: error }, ' Fatal error:');
    process.exit(1);
  }
}

enqueueCorporationBatch()
  .then(() => process.exit(0))
  .catch((error) => {
    logger.error({ err: error }, ' Script failed:');
    process.exit(1);
  });
</file>

<file path="scripts/enqueue-foundation-batch.ts">
#!/usr/bin/env node
/**
 * Enqueue Foundation & Nonprofit Searches
 * Queues foundation, nonprofit, and charitable organization search terms
 */

import { scraperQueue } from '../queues/scraper.queue';
import logger from '../lib/logger';
import { config } from '../config';

const FOUNDATION_TERMS = [
  'Foundation',
  'Charitable',
  'Charity',
  'Nonprofit',
  'Non-Profit',
  'Organization',
  'Institute',
  'Society',
  'Association',
  'Endowment',
];

async function enqueueFoundationBatch() {
  logger.info('  Starting Foundation Batch Enqueue');
  logger.info(`Auto-refresh token enabled: ${config.scraper.autoRefreshToken}`);

  try {
    let successCount = 0;
    let failCount = 0;

    for (const term of FOUNDATION_TERMS) {
      try {
        const job = await scraperQueue.add('scrape-properties', {
          searchTerm: term,
          userId: 'foundation-batch-enqueue',
          scheduled: true,
        }, {
          attempts: 3,
          backoff: {
            type: 'exponential',
            delay: 2000,
          },
          priority: 3,
          removeOnComplete: 100,
          removeOnFail: 50,
        });

        successCount++;
        logger.info(` [${successCount}/${FOUNDATION_TERMS.length}] Queued: "${term}" (Job ID: ${job.id})`);
      } catch (error) {
        failCount++;
        logger.error({ err: error }, ` Failed to queue "${term}":`);
      }
    }

    logger.info(`\n Summary: ${successCount} queued, ${failCount} failed`);
    logger.info(' Foundation batch enqueue completed!');
  } catch (error) {
    logger.error({ err: error }, ' Fatal error:');
    process.exit(1);
  }
}

enqueueFoundationBatch()
  .then(() => process.exit(0))
  .catch((error) => {
    logger.error({ err: error }, ' Script failed:');
    process.exit(1);
  });
</file>

<file path="scripts/enqueue-grove.ts">
import { scraperQueue } from '../queues/scraper.queue';

async function enqueueGrove() {
  console.log('Enqueueing job for search term: Grove');
  await scraperQueue.add('scrape', { searchTerm: 'Grove' });
  console.log('Job enqueued successfully');
  process.exit(0);
}

enqueueGrove().catch((err) => {
  console.error('Error enqueueing job:', err);
  process.exit(1);
});
</file>

<file path="scripts/enqueue-high-priority.ts">
import { scraperQueue } from '../queues/scraper.queue';

// High-value terms identified from last hour analysis
const HIGH_PRIORITY_TERMS = [
  'Boulevard',  // Expected: 7,000+ (Avenue = 25,483)
  'Drive',      // Expected: 5,000+
  'Lane',       // Expected: 5,000+
  'Way',        // Expected: 3,000+
  'Terrace',    // Expected: 2,000+
  'Michelle',   // Expected: 2,000+ (top 30 US name)
];

async function enqueueHighPriority() {
  console.log('Enqueueing high-priority search terms from analysis...\n');

  for (const term of HIGH_PRIORITY_TERMS) {
    try {
      await scraperQueue.add(
        'scrape-properties',
        { searchTerm: term },
        { priority: 1 } // Highest priority
      );
      console.log(` Enqueued: ${term}`);
    } catch (error) {
      console.error(` Failed to enqueue ${term}:`, error);
    }
  }

  console.log(`\n Successfully enqueued ${HIGH_PRIORITY_TERMS.length} high-priority terms`);
  console.log('Expected total: 24,000+ properties from these 6 terms alone!');
  process.exit(0);
}

enqueueHighPriority().catch((err) => {
  console.error('Error:', err);
  process.exit(1);
});
</file>

<file path="scripts/enqueue-high-value-batch.ts">
#!/usr/bin/env node
/**
 * Enqueue High-Value Batch Searches (40 queries)
 *
 * This script:
 * 1. Refreshes the TCAD API token first
 * 2. Enqueues 40 high-value search terms across multiple categories
 *
 * Categories included:
 * - Trust & Estate (highest yield ~70+ properties)
 * - Investment & Holdings (high yield)
 * - Corporate entities (LLC, Corp, etc.)
 * - Commercial properties
 * - Property types
 */

import { scraperQueue } from '../queues/scraper.queue';
import logger from '../lib/logger';
import { config } from '../config';
import { tokenRefreshService } from '../services/token-refresh.service';

// 40 High-Value Search Terms
const HIGH_VALUE_TERMS = [
  // Trust & Estate (10 terms - ~70+ properties each)
  'Trust',
  'Trustee',
  'Estate',
  'Family Trust',
  'Revocable Trust',
  'Irrevocable Trust',
  'Living Trust',
  'Testamentary',
  'Fiduciary',
  'Beneficiary',

  // Investment & Holdings (10 terms - high yield)
  'Investments',
  'Holdings',
  'Capital',
  'Fund',
  'Equity',
  'Ventures',
  'Asset',
  'Portfolio',
  'Management',
  'Partners',

  // Corporate Entities (10 terms - high volume)
  'LLC',
  'Limited',
  'Corporation',
  'Corp',
  'Inc',
  'Partnership',
  'LP',
  'LLP',
  'Company',
  'Group',

  // Commercial & Property Types (10 terms)
  'Commercial',
  'Residential',
  'Industrial',
  'Office',
  'Retail',
  'Warehouse',
  'Shopping',
  'Apartment',
  'Condo',
  'Development',
];

async function enqueueHighValueBatch() {
  logger.info(' Starting High-Value Batch Enqueue (40 queries)');
  logger.info(`Auto-refresh token enabled: ${config.scraper.autoRefreshToken}`);

  try {
    // Step 1: Refresh token first
    logger.info(' Step 1/2: Refreshing TCAD API token...');
    const startRefresh = Date.now();

    const token = await tokenRefreshService.refreshToken();
    const refreshDuration = Date.now() - startRefresh;

    if (token) {
      logger.info(` Token refreshed successfully in ${refreshDuration}ms`);
      logger.info(`   Token preview: ${token.substring(0, 30)}...`);
    } else {
      logger.warn('  Token refresh returned null - continuing with existing token');
    }

    // Step 2: Enqueue all queries
    logger.info('\n Step 2/2: Enqueueing high-value queries...');
    logger.info(`Total queries to enqueue: ${HIGH_VALUE_TERMS.length}`);

    let successCount = 0;
    let failCount = 0;
    const startEnqueue = Date.now();

    for (let i = 0; i < HIGH_VALUE_TERMS.length; i++) {
      const term = HIGH_VALUE_TERMS[i];

      try {
        // Determine priority based on category
        let priority = 3; // Default
        if (i < 10) {
          priority = 1; // Trust & Estate - highest priority
        } else if (i < 20) {
          priority = 1; // Investment - high priority
        } else if (i < 30) {
          priority = 2; // Corporate - medium-high priority
        }

        const job = await scraperQueue.add('scrape-properties', {
          searchTerm: term,
          userId: 'high-value-batch-enqueue',
          scheduled: true,
        }, {
          attempts: 3,
          backoff: {
            type: 'exponential',
            delay: 2000,
          },
          priority,
          removeOnComplete: 100,
          removeOnFail: 50,
        });

        successCount++;

        // Determine category for logging
        let category = '';
        if (i < 10) category = 'Trust/Estate';
        else if (i < 20) category = 'Investment';
        else if (i < 30) category = 'Corporate';
        else category = 'Commercial';

        logger.info(
          ` [${successCount}/${HIGH_VALUE_TERMS.length}] ` +
          `Queued: "${term}" (${category}, Priority: ${priority}, Job ID: ${job.id})`
        );

        // Small delay to avoid overwhelming the queue
        if (i < HIGH_VALUE_TERMS.length - 1) {
          await new Promise(resolve => setTimeout(resolve, 100));
        }
      } catch (error) {
        failCount++;
        logger.error({ err: error }, ` Failed to queue "${term}"`);
      }
    }

    const enqueueDuration = Date.now() - startEnqueue;

    // Summary
    logger.info('\n' + '='.repeat(60));
    logger.info(' BATCH ENQUEUE SUMMARY');
    logger.info('='.repeat(60));
    logger.info(` Successfully queued: ${successCount}/${HIGH_VALUE_TERMS.length}`);
    logger.info(` Failed: ${failCount}`);
    logger.info(`  Enqueue duration: ${enqueueDuration}ms`);
    logger.info(`  Total duration (with token refresh): ${refreshDuration + enqueueDuration}ms`);

    if (successCount > 0) {
      logger.info(`\n Estimated minimum properties: ${successCount * 50}`);
      logger.info(` Estimated maximum properties: ${successCount * 100}`);
      logger.info(`   (Trust/Estate terms typically yield 70-100+ each)`);
    }

    logger.info('\n High-value batch enqueue completed!');
    logger.info('Monitor progress at: http://localhost:3001/admin/queues');
    logger.info('='.repeat(60));

  } catch (error) {
    logger.error({ err: error }, ' Fatal error');
    process.exit(1);
  }
}

// Run the script
enqueueHighValueBatch()
  .then(() => process.exit(0))
  .catch((error) => {
    logger.error({ err: error }, ' Script failed');
    process.exit(1);
  });
</file>

<file path="scripts/enqueue-investment-batch.ts">
#!/usr/bin/env node
/**
 * Enqueue Investment Property Searches
 * Queues investment and management search terms
 */

import { scraperQueue } from '../queues/scraper.queue';
import logger from '../lib/logger';
import { config } from '../config';

const INVESTMENT_TERMS = [
  'Investments',
  'Holdings',
  'Capital',
  'Fund',
  'Equity',
  'Ventures',
  'Asset',
  'Portfolio',
  'Management',
  'Manage',
];

async function enqueueInvestmentBatch() {
  logger.info(' Starting Investment Batch Enqueue');
  logger.info(`Auto-refresh token enabled: ${config.scraper.autoRefreshToken}`);

  try {
    let successCount = 0;
    let failCount = 0;

    for (const term of INVESTMENT_TERMS) {
      try {
        const job = await scraperQueue.add('scrape-properties', {
          searchTerm: term,
          userId: 'investment-batch-enqueue',
          scheduled: true,
        }, {
          attempts: 3,
          backoff: {
            type: 'exponential',
            delay: 2000,
          },
          priority: 1, // High priority - likely high yield
          removeOnComplete: 100,
          removeOnFail: 50,
        });

        successCount++;
        logger.info(` [${successCount}/${INVESTMENT_TERMS.length}] Queued: "${term}" (Job ID: ${job.id})`);
      } catch (error) {
        failCount++;
        logger.error({ err: error }, ` Failed to queue "${term}":`);
      }
    }

    logger.info(`\n Summary: ${successCount} queued, ${failCount} failed`);
    logger.info(' Investment batch enqueue completed!');
  } catch (error) {
    logger.error({ err: error }, ' Fatal error:');
    process.exit(1);
  }
}

enqueueInvestmentBatch()
  .then(() => process.exit(0))
  .catch((error) => {
    logger.error({ err: error }, ' Script failed:');
    process.exit(1);
  });
</file>

<file path="scripts/enqueue-llc-batch.ts">
#!/usr/bin/env node
/**
 * Enqueue LLC Property Searches
 * Queues LLC and limited company search terms
 */

import { scraperQueue } from '../queues/scraper.queue';
import logger from '../lib/logger';
import { config } from '../config';

const LLC_TERMS = [
  'LLC',
  'LLC.',
  'L.L.C.',
  'Limited Liability',
  'Limited',
  'LMTD',
  'Limit',
  'L L C',
  'LTD',
  'Co LLC',
];

async function enqueueLLCBatch() {
  logger.info(' Starting LLC Batch Enqueue');
  logger.info(`Auto-refresh token enabled: ${config.scraper.autoRefreshToken}`);

  try {
    let successCount = 0;
    let failCount = 0;

    for (const term of LLC_TERMS) {
      try {
        const job = await scraperQueue.add('scrape-properties', {
          searchTerm: term,
          userId: 'llc-batch-enqueue',
          scheduled: true,
        }, {
          attempts: 3,
          backoff: {
            type: 'exponential',
            delay: 2000,
          },
          priority: 2,
          removeOnComplete: 100,
          removeOnFail: 50,
        });

        successCount++;
        logger.info(` [${successCount}/${LLC_TERMS.length}] Queued: "${term}" (Job ID: ${job.id})`);
      } catch (error) {
        failCount++;
        logger.error({ err: error }, ` Failed to queue "${term}":`);
      }
    }

    logger.info(`\n Summary: ${successCount} queued, ${failCount} failed`);
    logger.info(' LLC batch enqueue completed!');
  } catch (error) {
    logger.error({ err: error }, ' Fatal error:');
    process.exit(1);
  }
}

enqueueLLCBatch()
  .then(() => process.exit(0))
  .catch((error) => {
    logger.error({ err: error }, ' Script failed:');
    process.exit(1);
  });
</file>

<file path="scripts/enqueue-partnership-batch.ts">
#!/usr/bin/env node
/**
 * Enqueue Partnership Property Searches
 * Queues partnership and association search terms
 */

import { scraperQueue } from '../queues/scraper.queue';
import logger from '../lib/logger';
import { config } from '../config';

const PARTNERSHIP_TERMS = [
  'Partnership',
  'Partners',
  'Part',
  'LP',
  'LLP',
  'Association',
  'Associates',
  'Assoc',
  'Assoc.',
  'Joint Venture',
];

async function enqueuePartnershipBatch() {
  logger.info(' Starting Partnership Batch Enqueue');
  logger.info(`Auto-refresh token enabled: ${config.scraper.autoRefreshToken}`);

  try {
    let successCount = 0;
    let failCount = 0;

    for (const term of PARTNERSHIP_TERMS) {
      try {
        const job = await scraperQueue.add('scrape-properties', {
          searchTerm: term,
          userId: 'partnership-batch-enqueue',
          scheduled: true,
        }, {
          attempts: 3,
          backoff: {
            type: 'exponential',
            delay: 2000,
          },
          priority: 3,
          removeOnComplete: 100,
          removeOnFail: 50,
        });

        successCount++;
        logger.info(` [${successCount}/${PARTNERSHIP_TERMS.length}] Queued: "${term}" (Job ID: ${job.id})`);
      } catch (error) {
        failCount++;
        logger.error({ err: error }, ` Failed to queue "${term}":`);
      }
    }

    logger.info(`\n Summary: ${successCount} queued, ${failCount} failed`);
    logger.info(' Partnership batch enqueue completed!');
  } catch (error) {
    logger.error({ err: error }, ' Fatal error:');
    process.exit(1);
  }
}

enqueuePartnershipBatch()
  .then(() => process.exit(0))
  .catch((error) => {
    logger.error({ err: error }, ' Script failed:');
    process.exit(1);
  });
</file>

<file path="scripts/enqueue-priority-terms.ts">
import { scraperQueue } from '../queues/scraper.queue';

const PRIORITY_TERMS = ['Lake', 'River', 'Pecan', 'Maple', 'Oak', 'Mount', 'Limited'];

async function enqueuePriorityTerms() {
  console.log('Enqueueing priority search terms...');

  for (const term of PRIORITY_TERMS) {
    try {
      await scraperQueue.add(
        'scrape',
        { searchTerm: term },
        { priority: 1 } // Higher priority (lower number = higher priority in Bull)
      );
      console.log(` Enqueued: ${term}`);
    } catch (error) {
      console.error(` Failed to enqueue ${term}:`, error);
    }
  }

  console.log(`\n Successfully enqueued ${PRIORITY_TERMS.length} priority terms`);
  console.log('These jobs will be processed before other waiting jobs');
  process.exit(0);
}

enqueuePriorityTerms().catch((err) => {
  console.error('Error:', err);
  process.exit(1);
});
</file>

<file path="scripts/enqueue-property-type-batch.ts">
#!/usr/bin/env node
/**
 * Enqueue Property Type Searches
 * Queues property type and real estate search terms
 */

import { scraperQueue } from '../queues/scraper.queue';
import logger from '../lib/logger';
import { config } from '../config';

const PROPERTY_TYPE_TERMS = [
  'Properties',
  'Property',
  'Real Estate',
  'Realty',
  'Land',
  'Acres',
  'Development',
  'Developers',
  'Plaza',
  'Center',
];

async function enqueuePropertyTypeBatch() {
  logger.info('  Starting Property Type Batch Enqueue');
  logger.info(`Auto-refresh token enabled: ${config.scraper.autoRefreshToken}`);

  try {
    let successCount = 0;
    let failCount = 0;

    for (const term of PROPERTY_TYPE_TERMS) {
      try {
        const job = await scraperQueue.add('scrape-properties', {
          searchTerm: term,
          userId: 'property-type-batch-enqueue',
          scheduled: true,
        }, {
          attempts: 3,
          backoff: {
            type: 'exponential',
            delay: 2000,
          },
          priority: 2,
          removeOnComplete: 100,
          removeOnFail: 50,
        });

        successCount++;
        logger.info(` [${successCount}/${PROPERTY_TYPE_TERMS.length}] Queued: "${term}" (Job ID: ${job.id})`);
      } catch (error) {
        failCount++;
        logger.error({ err: error }, ` Failed to queue "${term}":`);
      }
    }

    logger.info(`\n Summary: ${successCount} queued, ${failCount} failed`);
    logger.info(' Property type batch enqueue completed!');
  } catch (error) {
    logger.error({ err: error }, ' Fatal error:');
    process.exit(1);
  }
}

enqueuePropertyTypeBatch()
  .then(() => process.exit(0))
  .catch((error) => {
    logger.error({ err: error }, ' Script failed:');
    process.exit(1);
  });
</file>

<file path="scripts/enqueue-residential-batch.ts">
#!/usr/bin/env node
/**
 * Enqueue Residential Property Searches
 * Queues common residential property search terms
 */

import { scraperQueue } from '../queues/scraper.queue';
import logger from '../lib/logger';
import { config } from '../config';

const RESIDENTIAL_TERMS = [
  'Smith',
  'Johnson',
  'Williams',
  'Brown',
  'Jones',
  'Miller',
  'Davis',
  'Garcia',
  'Rodriguez',
  'Wilson',
];

async function enqueueResidentialBatch() {
  logger.info(' Starting Residential Batch Enqueue');
  logger.info(`Auto-refresh token enabled: ${config.scraper.autoRefreshToken}`);
  logger.info(`Token refresh interval: ${config.scraper.tokenRefreshInterval}ms`);

  try {
    let successCount = 0;
    let failCount = 0;

    for (const term of RESIDENTIAL_TERMS) {
      try {
        const job = await scraperQueue.add('scrape-properties', {
          searchTerm: term,
          userId: 'residential-batch-enqueue',
          scheduled: true,
        }, {
          attempts: 3,
          backoff: {
            type: 'exponential',
            delay: 2000,
          },
          removeOnComplete: 100,
          removeOnFail: 50,
        });

        successCount++;
        logger.info(` [${successCount}/${RESIDENTIAL_TERMS.length}] Queued: "${term}" (Job ID: ${job.id})`);
      } catch (error) {
        failCount++;
        logger.error({ err: error }, ` Failed to queue "${term}":`);
      }
    }

    logger.info(`\n Summary: ${successCount} queued, ${failCount} failed`);
    logger.info(' Residential batch enqueue completed!');
  } catch (error) {
    logger.error({ err: error }, ' Fatal error:');
    process.exit(1);
  }
}

enqueueResidentialBatch()
  .then(() => process.exit(0))
  .catch((error) => {
    logger.error({ err: error }, ' Script failed:');
    process.exit(1);
  });
</file>

<file path="scripts/enqueue-test-batch-20.ts">
#!/usr/bin/env node
/**
 * Enqueue Test Batch (20 queries)
 * Tests the fixed token refresh with high-value search terms
 */

import { scraperQueue } from '../queues/scraper.queue';
import logger from '../lib/logger';
import { config } from '../config';

// 20 High-Value Search Terms (including repeats from previous batch)
const TEST_TERMS = [
  // Trust & Estate terms (repeat some from before)
  'Trust',
  'Family Trust',
  'Estate',
  'Living Trust',
  'Trustee',

  // Real estate related
  'Real Estate',
  'Real',
  'Family',
  'Property',
  'Land',

  // Investment terms
  'Investment',
  'Holdings',
  'Capital',
  'Partners',
  'Fund',

  // Entity types
  'LLC',
  'Limited',
  'Partnership',
  'Corporation',
  'Company',
];

async function enqueueTestBatch() {
  logger.info(' Starting Test Batch Enqueue (20 queries with fixed token refresh)');
  logger.info(`Auto-refresh token enabled: ${config.scraper.autoRefreshToken}`);

  try {
    let successCount = 0;
    let failCount = 0;
    const startEnqueue = Date.now();
    const jobIds: number[] = [];

    for (let i = 0; i < TEST_TERMS.length; i++) {
      const term = TEST_TERMS[i];

      try {
        const job = await scraperQueue.add('scrape-properties', {
          searchTerm: term,
          userId: 'test-batch-20',
          scheduled: true,
        }, {
          attempts: 3,
          backoff: {
            type: 'exponential',
            delay: 2000,
          },
          priority: 1, // High priority
          removeOnComplete: 100,
          removeOnFail: 50,
        });

        successCount++;
        jobIds.push(Number(job.id));

        logger.info(
          ` [${successCount}/${TEST_TERMS.length}] ` +
          `Queued: "${term}" (Job ID: ${job.id})`
        );

        // Small delay to avoid overwhelming the queue
        if (i < TEST_TERMS.length - 1) {
          await new Promise(resolve => setTimeout(resolve, 100));
        }
      } catch (error) {
        failCount++;
        logger.error({ err: error }, ` Failed to queue "${term}"`);
      }
    }

    const enqueueDuration = Date.now() - startEnqueue;

    // Summary
    logger.info('\n' + '='.repeat(60));
    logger.info(' TEST BATCH ENQUEUE SUMMARY');
    logger.info('='.repeat(60));
    logger.info(` Successfully queued: ${successCount}/${TEST_TERMS.length}`);
    logger.info(` Failed: ${failCount}`);
    logger.info(`  Enqueue duration: ${enqueueDuration}ms`);
    logger.info(` Job IDs: ${jobIds.join(', ')}`);
    logger.info('\n Test batch enqueue completed!');
    logger.info('Monitor progress at: http://hobbes.taildb60fa.ts.net:3001/admin/queues');
    logger.info('='.repeat(60));

  } catch (error) {
    logger.error({ err: error }, ' Fatal error');
    process.exit(1);
  }
}

// Run the script
enqueueTestBatch()
  .then(() => process.exit(0))
  .catch((error) => {
    logger.error({ err: error }, ' Script failed');
    process.exit(1);
  });
</file>

<file path="scripts/enqueue-trust-batch.ts">
#!/usr/bin/env node
/**
 * Enqueue Trust & Estate Searches
 * Queues trust and estate-related search terms (high-yield searches)
 */

import { scraperQueue } from '../queues/scraper.queue';
import logger from '../lib/logger';
import { config } from '../config';

const TRUST_TERMS = [
  'Trust',
  'Trustee',
  'Estate',
  'Family Trust',
  'Revocable Trust',
  'Irrevocable Trust',
  'Living Trust',
  'Testamentary',
  'Fiduciary',
  'Beneficiary',
];

async function enqueueTrustBatch() {
  logger.info(' Starting Trust & Estate Batch Enqueue');
  logger.info(`Auto-refresh token enabled: ${config.scraper.autoRefreshToken}`);
  logger.info(`Expected high yield: ~70+ properties per term`);

  try {
    let successCount = 0;
    let failCount = 0;

    for (const term of TRUST_TERMS) {
      try {
        const job = await scraperQueue.add('scrape-properties', {
          searchTerm: term,
          userId: 'trust-batch-enqueue',
          scheduled: true,
        }, {
          attempts: 3,
          backoff: {
            type: 'exponential',
            delay: 2000,
          },
          priority: 1, // Highest priority - best yield
          removeOnComplete: 100,
          removeOnFail: 50,
        });

        successCount++;
        logger.info(` [${successCount}/${TRUST_TERMS.length}] Queued: "${term}" (Job ID: ${job.id})`);
      } catch (error) {
        failCount++;
        logger.error({ err: error }, ` Failed to queue "${term}":`);
      }
    }

    logger.info(`\n Summary: ${successCount} queued, ${failCount} failed`);
    logger.info(` Estimated total properties: ${successCount * 70} (if all succeed)`);
    logger.info(' Trust batch enqueue completed!');
  } catch (error) {
    logger.error({ err: error }, ' Fatal error:');
    process.exit(1);
  }
}

enqueueTrustBatch()
  .then(() => process.exit(0))
  .catch((error) => {
    logger.error({ err: error }, ' Script failed:');
    process.exit(1);
  });
</file>

<file path="scripts/enqueue-ultra-high-priority.ts">
import { scraperQueue } from '../queues/scraper.queue';

// Ultra-high-value terms based on complete database analysis
// These are PROVEN patterns that haven't been tried yet
const ULTRA_HIGH_PRIORITY = [
  // Street terms (expected 5,000-10,000 each based on Avenue/Court performance)
  'Street',     // Expected: 10,000+ (like Avenue)
  'Drive',      // Expected: 5,000+
  'Lane',       // Expected: 5,000+
  'Road',       // Expected: 5,000+

  // Female names (expected 1,500-3,000 each)
  'Amy',        // Top 50 US name - Expected: 2,000+
  'Cynthia',    // Top 50 US name - Expected: 1,500+

  // Geographic terms (expected 2,000-4,000 each based on River/Rock)
  'Brook',      // Expected: 3,000+
  'Meadow',     // Expected: 2,500+
  'Valley',     // Expected: 3,000+
  'Point',      // Expected: 2,000+
];

async function enqueueUltraHighPriority() {
  console.log(' Enqueueing ULTRA-high-priority terms...\n');
  console.log('Expected yield: 40,000-60,000 properties from these 10 terms!\n');

  for (const term of ULTRA_HIGH_PRIORITY) {
    try {
      await scraperQueue.add(
        'scrape-properties',
        { searchTerm: term },
        { priority: -100 }  // Ultra-high priority
      );
      console.log(` Enqueued: ${term}`);
    } catch (error) {
      console.error(` Failed to enqueue ${term}:`, error);
    }
  }

  console.log(`\n Successfully enqueued ${ULTRA_HIGH_PRIORITY.length} ultra-high-priority terms`);
  process.exit(0);
}

enqueueUltraHighPriority().catch((err) => {
  console.error('Error:', err);
  process.exit(1);
});
</file>

<file path="scripts/migrate-to-logger.ts">
#!/usr/bin/env tsx
/**
 * Migration Helper: Replace console.log with Pino logger
 *
 * This script helps migrate console.log statements to the Pino logger
 * Usage: tsx migrate-to-logger.ts <file-path>
 */

import * as fs from 'fs';
import * as path from 'path';

function migrateFile(filePath: string): void {
  const content = fs.readFileSync(filePath, 'utf-8');
  const lines = content.split('\n');

  let hasImport = false;
  let importLineIndex = -1;
  let lastImportIndex = -1;

  // Check if logger is already imported
  for (let i = 0; i < lines.length; i++) {
    const line = lines[i];
    if (line.includes("import") && line.includes("logger") && line.includes("../lib/logger")) {
      hasImport = true;
      importLineIndex = i;
      break;
    }
    if (line.startsWith('import ') && !line.includes('type')) {
      lastImportIndex = i;
    }
  }

  // Replace console.log patterns with logger equivalents
  let modified = content;

  // Track different console methods and their logger equivalents
  const replacements: { pattern: RegExp; replacement: string }[] = [
    { pattern: /console\.error\(/g, replacement: 'logger.error(' },
    { pattern: /console\.warn\(/g, replacement: 'logger.warn(' },
    { pattern: /console\.info\(/g, replacement: 'logger.info(' },
    { pattern: /console\.debug\(/g, replacement: 'logger.debug(' },
    { pattern: /console\.log\(/g, replacement: 'logger.info(' },
  ];

  replacements.forEach(({ pattern, replacement }) => {
    modified = modified.replace(pattern, replacement);
  });

  // Add import if not present
  if (!hasImport && modified !== content) {
    const lines = modified.split('\n');
    const insertIndex = lastImportIndex >= 0 ? lastImportIndex + 1 : 0;

    // Calculate relative path
    const fileDir = path.dirname(filePath);
    const loggerPath = path.join(__dirname, '../lib/logger');
    const relativePath = path.relative(fileDir, loggerPath).replace(/\\/g, '/');
    const importPath = relativePath.startsWith('.') ? relativePath : `./${relativePath}`;

    lines.splice(insertIndex, 0, `import logger from '${importPath}';`);
    modified = lines.join('\n');
  }

  // Write back if changed
  if (modified !== content) {
    fs.writeFileSync(filePath, modified, 'utf-8');
    console.log(` Migrated: ${filePath}`);
  } else {
    console.log(`  No changes: ${filePath}`);
  }
}

// Get file path from command line
const filePath = process.argv[2];

if (!filePath) {
  console.error('Usage: tsx migrate-to-logger.ts <file-path>');
  process.exit(1);
}

if (!fs.existsSync(filePath)) {
  console.error(`File not found: ${filePath}`);
  process.exit(1);
}

try {
  migrateFile(filePath);
} catch (error) {
  console.error('Migration failed:', error);
  process.exit(1);
}
</file>

<file path="scripts/queue-entity-searches-fresh.ts">
import { scraperQueue } from '../queues/scraper.queue';
import logger from '../lib/logger';

/**
 * Queue 50 high-yield entity term searches with fresh TCAD token
 * First clears failed jobs, then queues new searches
 */

const ENTITY_TERMS = [
  // Trust/Estate terms (highest yield)
  'Trust',
  'Estate',
  'Family',
  'Revocable',
  'Irrevocable',

  // Business entities - LLC variations
  'LLC.',
  'LLC',
  'L.L.C',
  'L.L.C.',
  'Limited',
  'Limit',
  'LMTD',

  // Business entities - Corporation
  'Corp',
  'Corp.',
  'Corporation',
  'Inc.',
  'Inc',
  'Incorporated',

  // Partnership terms
  'Part',
  'Partnership',
  'Partners',
  'Assoc',
  'Association',
  'Associates',

  // Property/Real Estate terms
  'Real',
  'Realty',
  'Properties',
  'Property',
  'Park',
  'Parc',
  'Plaza',
  'Center',

  // Management/Investment terms
  'Manage',
  'Management',
  'Investments',
  'Holdings',
  'Group',
  'Ventures',

  // Other entity terms
  'Home',
  'Homes',
  'Company',
  'Foundation',
  'Fund',
  'Capital',
  'Development',
  'Builders',
  'Construction',
];

async function clearAndQueueSearches() {
  logger.info(' Clearing Failed Jobs and Queuing Fresh Entity Searches\n');
  logger.info('=' .repeat(80) + '\n');

  try {
    // Clean up failed jobs
    logger.info(' Cleaning up failed jobs...');
    const failedJobs = await scraperQueue.getFailed(0, 100);
    logger.info(`Found ${failedJobs.length} failed jobs`);

    let removedCount = 0;
    for (const job of failedJobs) {
      try {
        await job.remove();
        removedCount++;
      } catch (error) {
        logger.error(`Failed to remove job ${job.id}:`, error instanceof Error ? error.message : 'Unknown error');
      }
    }
    logger.info(` Removed ${removedCount} failed jobs\n`);

    // Take first 50 entity terms
    const searchTerms = ENTITY_TERMS.slice(0, 50);

    logger.info(`Queuing ${searchTerms.length} high-yield entity term searches...\n`);

    const jobs = [];
    let queuedCount = 0;
    let failedCount = 0;

    for (const searchTerm of searchTerms) {
      try {
        const job = await scraperQueue.add('scrape-properties', {
          searchTerm,
          userId: 'entity-batch-scraper-fresh',
          scheduled: true,
        }, {
          attempts: 3,
          backoff: {
            type: 'exponential',
            delay: 2000,
          },
          removeOnComplete: 100,
          removeOnFail: 50,
        });

        jobs.push(job);
        queuedCount++;
        logger.info(` [${queuedCount}/${searchTerms.length}] Queued: "${searchTerm}" (Job ID: ${job.id})`);

      } catch (error) {
        failedCount++;
        logger.error(` Failed to queue "${searchTerm}":`, error instanceof Error ? error.message : 'Unknown error');
      }
    }

    logger.info('\n' + ''.repeat(80));
    logger.info('QUEUE SUMMARY');
    logger.info(''.repeat(80) + '\n');
    logger.info(` Successfully queued: ${queuedCount} jobs`);
    logger.info(` Failed to queue: ${failedCount} jobs`);
    logger.info(` Total jobs added: ${queuedCount}`);

    if (queuedCount > 0) {
      logger.info('\n' + '='.repeat(80));
      logger.info('MONITORING');
      logger.info('='.repeat(80) + '\n');
      logger.info(' Bull Board Dashboard: http://localhost:3001/admin/queues');
      logger.info('   Monitor job progress, view completed/failed jobs, and queue stats\n');

      logger.info(' Expected Results:');
      logger.info(`   - Entity terms average: ~70 properties/search`);
      logger.info(`   - Estimated total properties: ${queuedCount * 70} (if all succeed)`);
      logger.info(`   - Processing time: ~${Math.ceil(queuedCount / 2 * 15 / 60)} hours (2 concurrent workers)\n`);

      logger.info('  Note: Token expires in 5 minutes!');
      logger.info('   Run refresh-tcad-token.sh every 4 minutes to keep scraping active\n');
    }

    logger.info(' Entity term searches queued successfully!\n');

  } catch (error) {
    logger.error(' Fatal error:', error);
    process.exit(1);
  }
}

// Run the script
clearAndQueueSearches()
  .then(() => {
    logger.info(' Script completed. Jobs are now processing...');
    process.exit(0);
  })
  .catch((error) => {
    logger.error(' Script failed:', error);
    process.exit(1);
  });
</file>

<file path="scripts/queue-entity-searches.ts">
import { scraperQueue } from '../queues/scraper.queue';
import logger from '../lib/logger';

/**
 * Queue 50 high-yield entity term searches based on optimal search strategy
 *
 * Priority: Entity terms perform best (~70+ properties/search)
 * These terms target trusts, LLCs, partnerships, and corporations
 */

const ENTITY_TERMS = [
  // Trust/Estate terms (highest yield)
  'Trust',
  'Estate',
  'Family',
  'Revocable',
  'Irrevocable',

  // Business entities - LLC variations
  'LLC.',
  'LLC',
  'L.L.C',
  'L.L.C.',
  'Limited',
  'Limit',
  'LMTD',

  // Business entities - Corporation
  'Corp',
  'Corp.',
  'Corporation',
  'Inc.',
  'Inc',
  'Incorporated',

  // Partnership terms
  'Part',
  'Partnership',
  'Partners',
  'Assoc',
  'Association',
  'Associates',

  // Property/Real Estate terms
  'Real',
  'Realty',
  'Properties',
  'Property',
  'Park',
  'Parc',
  'Plaza',
  'Center',

  // Management/Investment terms
  'Manage',
  'Management',
  'Investments',
  'Holdings',
  'Group',
  'Ventures',

  // Other entity terms
  'Home',
  'Homes',
  'Company',
  'Foundation',
  'Fund',
  'Capital',
  'Development',
  'Builders',
  'Construction',
];

async function queueEntitySearches() {
  logger.info(' Queuing Entity Term Searches for TCAD Scraper\n');
  logger.info('=' .repeat(80) + '\n');

  try {
    // Take first 50 entity terms
    const searchTerms = ENTITY_TERMS.slice(0, 50);

    logger.info(`Queuing ${searchTerms.length} high-yield entity term searches...\n`);

    const jobs = [];
    let queuedCount = 0;
    let failedCount = 0;

    for (const searchTerm of searchTerms) {
      try {
        const job = await scraperQueue.add('scrape-properties', {
          searchTerm,
          userId: 'entity-batch-scraper',
          scheduled: true,
        }, {
          attempts: 3,
          backoff: {
            type: 'exponential',
            delay: 2000,
          },
          removeOnComplete: 100,
          removeOnFail: 50,
        });

        jobs.push(job);
        queuedCount++;
        logger.info(` [${queuedCount}/${searchTerms.length}] Queued: "${searchTerm}" (Job ID: ${job.id})`);

      } catch (error) {
        failedCount++;
        logger.error(` Failed to queue "${searchTerm}":`, error instanceof Error ? error.message : 'Unknown error');
      }
    }

    logger.info('\n' + ''.repeat(80));
    logger.info('QUEUE SUMMARY');
    logger.info(''.repeat(80) + '\n');
    logger.info(` Successfully queued: ${queuedCount} jobs`);
    logger.info(` Failed to queue: ${failedCount} jobs`);
    logger.info(` Total jobs added: ${queuedCount}`);

    if (queuedCount > 0) {
      logger.info('\n' + '='.repeat(80));
      logger.info('MONITORING');
      logger.info('='.repeat(80) + '\n');
      logger.info(' Bull Board Dashboard: http://localhost:3001/admin/queues');
      logger.info('   Monitor job progress, view completed/failed jobs, and queue stats\n');

      logger.info(' Expected Results:');
      logger.info(`   - Entity terms average: ~70 properties/search`);
      logger.info(`   - Estimated total properties: ${queuedCount * 70} (if all succeed)`);
      logger.info(`   - Processing time: ~${Math.ceil(queuedCount / 2 * 15 / 60)} hours (2 concurrent workers)\n`);
    }

    logger.info(' Entity term searches queued successfully!\n');

  } catch (error) {
    logger.error(' Fatal error:', error);
    process.exit(1);
  }
}

// Run the script
queueEntitySearches()
  .then(() => {
    logger.info(' Script completed. Jobs are now processing...');
    process.exit(0);
  })
  .catch((error) => {
    logger.error(' Script failed:', error);
    process.exit(1);
  });
</file>

<file path="scripts/README_ENHANCED.md">
# scripts

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "SoftwareSourceCode",
  "name": "scripts",
  "description": "Directory containing 30 code files with 6 classes and 29 functions",
  "programmingLanguage": [
    {
      "@type": "ComputerLanguage",
      "name": "Typescript"
    }
  ],
  "featureList": [
    "6 class definitions",
    "29 function definitions"
  ]
}
</script>

## Overview

This directory contains 30 code file(s) with extracted schemas.

## Files and Schemas

### `batch-scrape-100.ts` (typescript)

**Functions:**
- `async queueBatch()` - Line 49

### `batch-scrape-comprehensive.ts` (typescript)

**Classes:**
- `ComprehensiveBatchScraper` - Line 86
- `ComprehensiveBatchConfig` - Line 75

### `batch-scrape.ts` (typescript)

**Classes:**
- `BatchScraper` - Line 92
- `BatchConfig` - Line 84

### `check-column-ids.ts` (typescript)

**Functions:**
- `async checkColumnIds()` - Line 3

### `check-grove-job.ts` (typescript)

**Functions:**
- `async checkGroveJob()` - Line 2

### `check-queue-status.ts` (typescript)

**Functions:**
- `async checkQueueStatus()` - Line 9

### `continuous-batch-scraper.ts` (typescript)

**Classes:**
- `SearchPatternGenerator` - Line 26
- `ContinuousBatchScraper` - Line 522

### `debug-token-refresh.ts` (typescript)

**Functions:**
- `async debugTokenRefresh()` - Line 9

### `enqueue-commercial-batch.ts` (typescript)

**Functions:**
- `async enqueueCommercialBatch()` - Line 23

### `enqueue-construction-batch.ts` (typescript)

**Functions:**
- `async enqueueConstructionBatch()` - Line 23

### `enqueue-corporation-batch.ts` (typescript)

**Functions:**
- `async enqueueCorporationBatch()` - Line 23

### `enqueue-foundation-batch.ts` (typescript)

**Functions:**
- `async enqueueFoundationBatch()` - Line 23

### `enqueue-grove.ts` (typescript)

**Functions:**
- `async enqueueGrove()` - Line 2

### `enqueue-high-priority.ts` (typescript)

**Functions:**
- `async enqueueHighPriority()` - Line 12

### `enqueue-high-value-batch.ts` (typescript)

**Functions:**
- `async enqueueHighValueBatch()` - Line 72

### `enqueue-investment-batch.ts` (typescript)

**Functions:**
- `async enqueueInvestmentBatch()` - Line 23

### `enqueue-llc-batch.ts` (typescript)

**Functions:**
- `async enqueueLLCBatch()` - Line 23

### `enqueue-partnership-batch.ts` (typescript)

**Functions:**
- `async enqueuePartnershipBatch()` - Line 23

### `enqueue-priority-terms.ts` (typescript)

**Functions:**
- `async enqueuePriorityTerms()` - Line 4

### `enqueue-property-type-batch.ts` (typescript)

**Functions:**
- `async enqueuePropertyTypeBatch()` - Line 23

### `enqueue-residential-batch.ts` (typescript)

**Functions:**
- `async enqueueResidentialBatch()` - Line 23

### `enqueue-test-batch-20.ts` (typescript)

**Functions:**
- `async enqueueTestBatch()` - Line 41

### `enqueue-trust-batch.ts` (typescript)

**Functions:**
- `async enqueueTrustBatch()` - Line 23

### `enqueue-ultra-high-priority.ts` (typescript)

**Functions:**
- `async enqueueUltraHighPriority()` - Line 22

### `queue-entity-searches-fresh.ts` (typescript)

**Functions:**
- `async clearAndQueueSearches()` - Line 71

### `queue-entity-searches.ts` (typescript)

**Functions:**
- `async queueEntitySearches()` - Line 73

### `test-api-token-config.ts` (typescript)

**Functions:**
- `async testTokenUsage()` - Line 47
- `simulateQueueJob()` - Line 85
- `async runAllTests()` - Line 110

### `test-queue-job-flow.ts` (typescript)

**Functions:**
- `async simulateQueueJobProcessing()` - Line 15

### `test-single-job.ts` (typescript)

**Functions:**
- `async testSingleJob()` - Line 9

### `test-token-refresh.ts` (typescript)

**Functions:**
- `async testTokenRefresh()` - Line 18

---
*Generated by Enhanced Schema Generator with schema.org markup*
</file>

<file path="scripts/test-api-token-config.ts">
#!/usr/bin/env ts-node

/**
 * Test script to verify TCAD_API_KEY configuration
 *
 * This script tests:
 * 1. Config loading for TCAD_API_KEY
 * 2. Scraper initialization with token
 * 3. Token usage in API calls (without actually making requests)
 */

import { config } from '../config';
import { TCADScraper } from '../lib/tcad-scraper';
import logger from '../lib/logger';

logger.info('=== TCAD API Token Configuration Test ===\n');

// Test 1: Check if TCAD_API_KEY is loaded in config
logger.info('Test 1: Config Loading');
logger.info('----------------------');
if (config.scraper.tcadApiKey) {
  logger.info(' TCAD_API_KEY is configured');
  logger.info(`   Token preview: ${config.scraper.tcadApiKey.substring(0, 20)}...`);
} else {
  logger.info(' TCAD_API_KEY is NOT configured');
  logger.info('   Scraper will fall back to browser-based token capture');
}
logger.info('');

// Test 2: Check full configuration
logger.info('Test 2: Full Scraper Configuration');
logger.info('-----------------------------------');
logger.info(`Headless: ${config.scraper.headless}`);
logger.info(`Timeout: ${config.scraper.timeout}ms`);
logger.info(`Retry Attempts: ${config.scraper.retryAttempts}`);
logger.info(`Retry Delay: ${config.scraper.retryDelay}ms`);
logger.info(`TCAD API Token: ${config.scraper.tcadApiKey ? ' Set' : ' Not Set'}`);
logger.info('');

// Test 3: Initialize scraper and check token usage
logger.info('Test 3: Scraper Initialization');
logger.info('-------------------------------');

const scraper = new TCADScraper();

// We can't directly access private fields, but we can test the flow
// by checking if the scraper would use the token
async function testTokenUsage() {
  try {
    logger.info('Initializing browser...');
    await scraper.initialize();
    logger.info(' Browser initialized successfully');

    // Note: We won't actually run a scrape to avoid hitting the API
    // But we can verify the configuration is correct
    logger.info('');
    logger.info('Configuration Status:');
    logger.info('--------------------');

    if (config.scraper.tcadApiKey) {
      logger.info(' When scraping runs, it will:');
      logger.info('   1. Use pre-fetched TCAD_API_KEY from environment');
      logger.info('   2. Skip browser-based token capture');
      logger.info('   3. Make direct API calls');
      logger.info('   4. Faster and more efficient');
    } else {
      logger.info('  When scraping runs, it will:');
      logger.info('   1. Load the TCAD search page');
      logger.info('   2. Perform a test search');
      logger.info('   3. Capture auth token from network requests');
      logger.info('   4. Then make API calls (slower)');
    }

  } catch (error) {
    logger.error(' Error during test:', error);
  } finally {
    await scraper.cleanup();
    logger.info('\n Cleanup complete');
  }
}

// Test 4: Simulate what would happen in a queue job
logger.info('Test 4: Queue Job Simulation');
logger.info('-----------------------------');

function simulateQueueJob() {
  logger.info('When a scrape job is added to the queue:');
  logger.info('');
  logger.info('1. Queue worker creates new TCADScraper instance');
  logger.info('2. Calls scraper.initialize()');
  logger.info('3. Calls scraper.scrapePropertiesViaAPI(searchTerm)');
  logger.info('');
  logger.info('Inside scrapePropertiesViaAPI:');
  logger.info('   - Line 128: let authToken = appConfig.scraper.tcadApiKey || null;');

  if (config.scraper.tcadApiKey) {
    logger.info('   -  authToken is set from config');
    logger.info('   -  Logs: "Using pre-fetched TCAD_API_KEY from environment"');
    logger.info('   -  Skips browser token capture (lines 133-166)');
    logger.info('   -  Proceeds directly to API calls (line 170+)');
  } else {
    logger.info('   -   authToken is null');
    logger.info('   -   Logs: "No TCAD_API_KEY found, capturing token from browser..."');
    logger.info('   -   Loads page and captures token (lines 133-166)');
    logger.info('   -   Then proceeds to API calls (slower)');
  }
  logger.info('');
}

// Run all tests
async function runAllTests() {
  simulateQueueJob();

  logger.info('=== Running Browser Initialization Test ===\n');
  await testTokenUsage();

  logger.info('\n=== Test Complete ===\n');

  // Summary
  logger.info('Summary:');
  logger.info('--------');
  if (config.scraper.tcadApiKey) {
    logger.info(' PASS: API token is configured');
    logger.info(' PASS: Scraper will use fast API mode');
    logger.info('');
    logger.info('Next steps:');
    logger.info('  1. Run a test scrape: npm run test:scrape');
    logger.info('  2. Check logs for "Using pre-fetched TCAD_API_KEY from environment"');
  } else {
    logger.info('  WARNING: API token is NOT configured');
    logger.info('  WARNING: Scraper will use fallback browser mode');
    logger.info('');
    logger.info('To enable fast API mode:');
    logger.info('  1. Get token from https://travis.prodigycad.com (see docs/TCAD_API_TOKEN_SETUP.md)');
    logger.info('  2. Add to .env: TCAD_API_KEY=your_token_here');
    logger.info('  3. Restart server: pm2 restart ecosystem.config.js');
    logger.info('  4. Re-run this test: npm run test:token-config');
  }

  process.exit(0);
}

runAllTests().catch((error) => {
  logger.error('Test failed:', error);
  process.exit(1);
});
</file>

<file path="scripts/test-queue-job-flow.ts">
#!/usr/bin/env ts-node

/**
 * Comprehensive test that simulates the full queue job flow
 * Shows exactly what happens when a scrape job is created
 */

import { config } from '../config';
import { TCADScraper } from '../lib/tcad-scraper';
import logger from '../lib/logger';

logger.info('=== Queue Job Flow Simulation ===\n');
logger.info('This simulates what happens when you add a scrape job to the queue.\n');

// Simulate the queue worker processing a job
async function simulateQueueJobProcessing() {
  const searchTerm = 'TEST_SEARCH_TERM';
  const jobId = 'test-job-123';

  logger.info('Step 1: Queue worker receives job');
  logger.info('----------------------------------');
  logger.info(`Job ID: ${jobId}`);
  logger.info(`Search Term: ${searchTerm}`);
  logger.info(`Status: pending  processing\n`);

  logger.info('Step 2: Create TCADScraper instance');
  logger.info('------------------------------------');
  logger.info('Code: const scraper = new TCADScraper({ headless: true });');

  const scraper = new TCADScraper({
    headless: config.env.isProduction ? true : config.scraper.headless,
  });

  logger.info(' Scraper instance created\n');

  logger.info('Step 3: Initialize browser');
  logger.info('--------------------------');
  logger.info('Code: await scraper.initialize();');

  try {
    await scraper.initialize();
    logger.info(' Browser initialized\n');

    logger.info('Step 4: Call scrapePropertiesViaAPI');
    logger.info('------------------------------------');
    logger.info(`Code: await scraper.scrapePropertiesViaAPI('${searchTerm}');`);
    logger.info('');

    logger.info('Inside scrapePropertiesViaAPI (src/lib/tcad-scraper.ts:106):');
    logger.info('  Line 128: let authToken = appConfig.scraper.tcadApiKey || null;');
    logger.info('');

    if (config.scraper.tcadApiKey) {
      logger.info('   authToken = appConfig.scraper.tcadApiKey');
      logger.info(`   Token value: ${config.scraper.tcadApiKey.substring(0, 20)}...`);
      logger.info('   Condition: if (authToken)  TRUE');
      logger.info('');
      logger.info('  Line 131: logger.info("Using pre-fetched TCAD_API_KEY from environment");');
      logger.info('   Skips lines 133-166 (browser token capture)');
      logger.info('   Jumps to line 170 (API calls)');
      logger.info('');
      logger.info('  Flow:');
      logger.info('    1. Inject __tcad_search function into page (lines 170-291)');
      logger.info('    2. Call function with pre-fetched token (line 294)');
      logger.info('    3. Function makes API calls to prod-container.trueprodigyapi.com');
      logger.info('    4. Returns property data');
      logger.info('    5. Transform to PropertyData format (lines 299-309)');
      logger.info('');
      logger.info('   Performance: FAST (no page load, direct API)');
    } else {
      logger.info('    authToken = null');
      logger.info('    Condition: if (authToken)  FALSE');
      logger.info('');
      logger.info('  Line 133: logger.info("No TCAD_API_KEY found, capturing token from browser...");');
      logger.info('    Executes lines 135-166 (browser token capture):');
      logger.info('');
      logger.info('    Lines 142-145: Navigate to https://travis.prodigycad.com/property-search');
      logger.info('    Lines 149-152: Wait for React app to load');
      logger.info('    Lines 155-159: Perform test search to trigger API request');
      logger.info('    Lines 136-140: Capture Authorization header from request');
      logger.info('');
      logger.info('  Then continues to line 170 (API calls) with captured token');
      logger.info('');
      logger.info('   Performance: SLOW (full page load + test search + token capture)');
    }

    logger.info('');
    logger.info('Step 5: Save to database');
    logger.info('------------------------');
    logger.info('Code: await prisma.property.upsert(...)');
    logger.info(' Properties saved to database');
    logger.info('');

    logger.info('Step 6: Update job status');
    logger.info('-------------------------');
    logger.info('Code: await prisma.scrapeJob.update({ status: "completed" })');
    logger.info(' Job marked as completed\n');

  } catch (error) {
    logger.error(' Error during simulation:', error);
  } finally {
    logger.info('Step 7: Cleanup');
    logger.info('---------------');
    logger.info('Code: await scraper.cleanup();');
    await scraper.cleanup();
    logger.info(' Browser closed\n');
  }

  // Summary
  logger.info('=== Summary ===\n');

  if (config.scraper.tcadApiKey) {
    logger.info(' Current Configuration: OPTIMAL');
    logger.info('');
    logger.info('Your scrape jobs will:');
    logger.info('   Use pre-fetched API token');
    logger.info('   Skip browser-based token capture');
    logger.info('   Complete faster');
    logger.info('   Use fewer resources');
    logger.info('');
    logger.info('Execution Path:');
    logger.info('  Line 128: Get token from config ');
    logger.info('  Line 131: Log "Using pre-fetched..." ');
    logger.info('  Lines 133-166: SKIPPED ');
    logger.info('  Line 170+: Direct API calls ');
    logger.info('');
    logger.info('Next Steps:');
    logger.info('  1. Replace test token with real token from https://travis.prodigycad.com');
    logger.info('  2. Restart server: pm2 restart ecosystem.config.js');
    logger.info('  3. Run actual scrape job and monitor logs');
  } else {
    logger.info('  Current Configuration: FALLBACK MODE');
    logger.info('');
    logger.info('Your scrape jobs will:');
    logger.info('   Load full webpage');
    logger.info('   Perform test search');
    logger.info('   Capture token from browser');
    logger.info('   Then make API calls');
    logger.info('   Take longer to complete');
    logger.info('');
    logger.info('Execution Path:');
    logger.info('  Line 128: authToken = null ');
    logger.info('  Line 133: Log "No TCAD_API_KEY found..." ');
    logger.info('  Lines 133-166: EXECUTED (browser capture) ');
    logger.info('  Line 170+: API calls with captured token ');
    logger.info('');
    logger.info('To Enable Fast Mode:');
    logger.info('  1. Get token from https://travis.prodigycad.com (see docs/TCAD_API_TOKEN_SETUP.md)');
    logger.info('  2. Add to .env: TCAD_API_KEY=your_token_here');
    logger.info('  3. Restart server: pm2 restart ecosystem.config.js');
    logger.info('  4. Re-run this test: npm run test:queue-flow');
  }
}

// Run simulation
simulateQueueJobProcessing().catch((error) => {
  logger.error('Simulation failed:', error);
  process.exit(1);
});
</file>

<file path="scripts/test-single-job.ts">
#!/usr/bin/env node
/**
 * Test Single Job
 * Enqueues a single test job and monitors its progress
 */

import { scraperQueue } from '../queues/scraper.queue';
import logger from '../lib/logger';

async function testSingleJob() {
  const searchTerm = 'Development';

  logger.info(` Enqueueing test job for: "${searchTerm}"`);

  try {
    const job = await scraperQueue.add('scrape-properties', {
      searchTerm,
      userId: 'test-single-job',
      scheduled: false,
    }, {
      attempts: 3,
      backoff: {
        type: 'exponential',
        delay: 2000,
      },
      priority: 1,
    });

    logger.info(` Job enqueued: ID ${job.id}`);
    logger.info(` Waiting for job to complete...`);

    // Wait for job to finish
    const result = await job.finished();

    logger.info(` Job completed successfully!`);
    logger.info(`   Properties found: ${result.count}`);
    logger.info(`   Duration: ${result.duration}ms`);

    if (result.properties && result.properties.length > 0) {
      logger.info(`   Sample property: ${JSON.stringify(result.properties[0], null, 2)}`);
    }

    process.exit(0);
  } catch (error) {
    logger.error({ err: error }, ` Job failed:`);
    process.exit(1);
  }
}

testSingleJob();
</file>

<file path="scripts/test-token-refresh.ts">
#!/usr/bin/env ts-node

/**
 * Test script for TCAD Token Auto-Refresh Service
 *
 * This script tests:
 * 1. Manual token refresh
 * 2. Token retrieval
 * 3. Service statistics
 * 4. Auto-refresh scheduling
 */

import { tokenRefreshService } from '../services/token-refresh.service';
import { config } from '../config';
import logger from '../lib/logger';

logger.info('=== TCAD Token Auto-Refresh Service Test ===\n');

async function testTokenRefresh() {
  logger.info('Configuration:');
  logger.info('--------------');
  logger.info(`Auto-Refresh Enabled: ${config.scraper.autoRefreshToken}`);
  logger.info(`Refresh Interval: ${config.scraper.tokenRefreshInterval}ms (${config.scraper.tokenRefreshInterval / 60000} minutes)`);
  logger.info(`Cron Schedule: ${config.scraper.tokenRefreshCron || 'Not set (using interval)'}`);
  logger.info('');

  // Test 1: Check initial state
  logger.info('Test 1: Initial State');
  logger.info('---------------------');
  const initialStats = tokenRefreshService.getStats();
  logger.info(`Current Token: ${initialStats.currentToken || 'None'}`);
  logger.info(`Last Refresh: ${initialStats.lastRefreshTime || 'Never'}`);
  logger.info(`Refresh Count: ${initialStats.refreshCount}`);
  logger.info(`Failure Count: ${initialStats.failureCount}`);
  logger.info(`Is Running: ${initialStats.isRunning}`);
  logger.info('');

  // Test 2: Manual token refresh
  logger.info('Test 2: Manual Token Refresh');
  logger.info('-----------------------------');
  logger.info(' Refreshing token (this may take 5-10 seconds)...');
  logger.info('');

  const startTime = Date.now();
  const token = await tokenRefreshService.refreshToken();
  const duration = Date.now() - startTime;

  logger.info('');
  if (token) {
    logger.info(` Token refreshed successfully in ${duration}ms`);
    logger.info(`Token preview: ${token.substring(0, 50)}...`);
  } else {
    logger.info(` Token refresh failed`);
  }
  logger.info('');

  // Test 3: Check stats after refresh
  logger.info('Test 3: Statistics After Refresh');
  logger.info('---------------------------------');
  const statsAfterRefresh = tokenRefreshService.getStats();
  logger.info(`Current Token: ${statsAfterRefresh.currentToken || 'None'}`);
  logger.info(`Last Refresh: ${statsAfterRefresh.lastRefreshTime}`);
  logger.info(`Refresh Count: ${statsAfterRefresh.refreshCount}`);
  logger.info(`Failure Count: ${statsAfterRefresh.failureCount}`);
  logger.info('');

  // Test 4: Health check
  logger.info('Test 4: Health Check');
  logger.info('--------------------');
  const health = tokenRefreshService.getHealth();
  logger.info(`Healthy: ${health.healthy ? '' : ''}`);
  logger.info(`Has Token: ${health.hasToken ? '' : ''}`);
  logger.info(`Time Since Last Refresh: ${health.timeSinceLastRefresh ? `${health.timeSinceLastRefresh}ms` : 'N/A'}`);
  logger.info(`Failure Rate: ${health.failureRate}`);
  logger.info(`Auto-Refresh Running: ${health.isAutoRefreshRunning ? '' : ''}`);
  logger.info('');

  // Test 5: Demo auto-refresh (run for 30 seconds)
  if (config.scraper.autoRefreshToken) {
    logger.info('Test 5: Auto-Refresh Demo');
    logger.info('-------------------------');
    logger.info(' Starting auto-refresh service for 30 seconds...');
    logger.info('   (In production, this runs continuously)');
    logger.info('');

    // Start auto-refresh with a short interval for demo (30 seconds)
    tokenRefreshService.startAutoRefreshInterval(30000); // 30 seconds for demo

    logger.info('Service started. Waiting for first scheduled refresh...');
    logger.info('(Press Ctrl+C to stop early)');
    logger.info('');

    // Wait 35 seconds to see at least one refresh
    await new Promise(resolve => setTimeout(resolve, 35000));

    // Stop auto-refresh
    tokenRefreshService.stopAutoRefresh();
    logger.info('');
    logger.info('Auto-refresh stopped.');
    logger.info('');

    // Show final stats
    const finalStats = tokenRefreshService.getStats();
    logger.info('Final Statistics:');
    logger.info(`  Total Refreshes: ${finalStats.refreshCount}`);
    logger.info(`  Total Failures: ${finalStats.failureCount}`);
    logger.info(`  Last Refresh: ${finalStats.lastRefreshTime}`);
    logger.info('');
  } else {
    logger.info('Test 5: Auto-Refresh Demo');
    logger.info('-------------------------');
    logger.info('  Auto-refresh is disabled in configuration');
    logger.info('   Set TCAD_AUTO_REFRESH_TOKEN=true to enable');
    logger.info('');
  }

  // Cleanup
  logger.info('Cleaning up...');
  await tokenRefreshService.cleanup();
  logger.info(' Cleanup complete');
  logger.info('');

  // Summary
  logger.info('=== Summary ===');
  logger.info('');

  const finalHealth = tokenRefreshService.getHealth();
  if (finalHealth.healthy) {
    logger.info(' Token refresh service is working correctly');
    logger.info('');
    logger.info('Production Usage:');
    logger.info('  1. Service starts automatically with server');
    logger.info(`  2. Refreshes token every ${config.scraper.tokenRefreshInterval / 60000} minutes`);
    logger.info('  3. Scraper uses refreshed token automatically');
    logger.info('  4. Check health: GET /health/token');
    logger.info('');
    logger.info('Next Steps:');
    logger.info('   Start server: npm run dev');
    logger.info('   Monitor logs for "Token refreshed successfully"');
    logger.info('   Check health endpoint: curl http://localhost:3001/health/token');
  } else {
    logger.info('  Token refresh encountered issues');
    logger.info('');
    logger.info('Troubleshooting:');
    logger.info('   Check browser executable path');
    logger.info('   Verify TCAD website is accessible');
    logger.info('   Review error logs above');
  }
}

// Run the test
testTokenRefresh()
  .then(() => {
    logger.info('');
    logger.info('Test complete!');
    process.exit(0);
  })
  .catch((error) => {
    logger.error('');
    logger.error('Test failed:', error);
    process.exit(1);
  });
</file>

<file path="scripts/worker.ts">
import { scraperQueue } from '../queues/scraper.queue';
import winston from 'winston';

const logger = winston.createLogger({
  level: 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.simple()
  ),
  transports: [
    new winston.transports.Console(),
  ],
});

logger.info(' TCAD Scraper Worker started');
logger.info(`   Redis: ${process.env.REDIS_HOST || 'localhost'}:${process.env.REDIS_PORT || '6379'}`);
logger.info(`   Database: ${process.env.DATABASE_URL}`);
logger.info('\n Listening for jobs...\n');

// Graceful shutdown
process.on('SIGTERM', async () => {
  logger.info('\n Shutting down worker...');
  await scraperQueue.close();
  process.exit(0);
});

process.on('SIGINT', async () => {
  logger.info('\n Shutting down worker...');
  await scraperQueue.close();
  process.exit(0);
});
</file>

<file path="services/__tests__/search-term-optimizer.test.ts">
/**
 * Search Term Optimizer Tests
 *
 * Tests for the search term performance analysis and optimization service
 */

import {
  OPTIMIZED_4_CHAR_STARTER_TERMS,
  SearchTermOptimizer,
} from '../search-term-optimizer';

// Mock Prisma
const mockPrisma = {
  searchTermAnalytics: {
    count: jest.fn(),
    findMany: jest.fn(),
    findUnique: jest.fn(),
    create: jest.fn(),
    upsert: jest.fn(),
    groupBy: jest.fn(),
    update: jest.fn(),
  },
  scrapeJob: {
    count: jest.fn(),
  },
};

// Mock logger
jest.mock('../../lib/logger', () => ({
  info: jest.fn(),
  error: jest.fn(),
  warn: jest.fn(),
}));

describe('Search Term Optimizer', () => {
  let optimizer: SearchTermOptimizer;

  beforeEach(() => {
    jest.clearAllMocks();
    optimizer = new SearchTermOptimizer(mockPrisma as any);
  });

  describe('OPTIMIZED_4_CHAR_STARTER_TERMS', () => {
    it('should export an array of search terms', () => {
      expect(Array.isArray(OPTIMIZED_4_CHAR_STARTER_TERMS)).toBe(true);
      expect(OPTIMIZED_4_CHAR_STARTER_TERMS.length).toBeGreaterThan(0);
    });

    it('should contain only string values', () => {
      OPTIMIZED_4_CHAR_STARTER_TERMS.forEach((term) => {
        expect(typeof term).toBe('string');
      });
    });

    it('should contain terms with length of at least 4 characters', () => {
      OPTIMIZED_4_CHAR_STARTER_TERMS.forEach((term) => {
        expect(term.length).toBeGreaterThanOrEqual(4);
      });
    });

    it('should not contain empty strings', () => {
      OPTIMIZED_4_CHAR_STARTER_TERMS.forEach((term) => {
        expect(term.trim()).not.toBe('');
      });
    });

    it('should contain common entity terms', () => {
      const entityTerms = ['Trus', 'LLC.', 'Corp', 'Part'];
      entityTerms.forEach((term) => {
        expect(OPTIMIZED_4_CHAR_STARTER_TERMS).toContain(term);
      });
    });

    it('should contain real estate related terms', () => {
      const realEstateTerms = ['Real', 'Prop', 'Home'];
      realEstateTerms.forEach((term) => {
        expect(OPTIMIZED_4_CHAR_STARTER_TERMS).toContain(term);
      });
    });
  });

  describe('SearchTermOptimizer class', () => {
    describe('constructor', () => {
      it('should accept custom Prisma client', () => {
        const customPrisma = { custom: 'client' };
        const customOptimizer = new SearchTermOptimizer(customPrisma as any);
        expect(customOptimizer).toBeDefined();
      });

      it('should use default Prisma client if not provided', () => {
        const defaultOptimizer = new SearchTermOptimizer();
        expect(defaultOptimizer).toBeDefined();
      });
    });

    describe('getStarterTerms', () => {
      it('should return optimized 4-char terms for cold start (empty database)', async () => {
        mockPrisma.searchTermAnalytics.count.mockResolvedValue(0);

        const terms = await optimizer.getStarterTerms();

        expect(terms).toEqual(OPTIMIZED_4_CHAR_STARTER_TERMS);
        expect(mockPrisma.searchTermAnalytics.count).toHaveBeenCalled();
      });

      it('should use analytics to optimize when database has data', async () => {
        mockPrisma.searchTermAnalytics.count.mockResolvedValue(100);
        mockPrisma.searchTermAnalytics.findMany.mockResolvedValue([
          {
            id: '1',
            searchTerm: 'Test',
            termLength: 4,
            totalSearches: 10,
            successfulSearches: 9,
            failedSearches: 1,
            totalResults: 50,
            maxResults: 10,
            minResults: 2,
            lastSearched: new Date(),
          },
        ]);

        const terms = await optimizer.getStarterTerms();

        expect(mockPrisma.searchTermAnalytics.count).toHaveBeenCalled();
        expect(mockPrisma.searchTermAnalytics.findMany).toHaveBeenCalled();
        expect(Array.isArray(terms)).toBe(true);
      });
    });

    describe('updateAnalytics', () => {
      it('should create analytics for successful scrape when term does not exist', async () => {
        mockPrisma.searchTermAnalytics.findUnique.mockResolvedValue(null);
        mockPrisma.searchTermAnalytics.create.mockResolvedValue({});

        await optimizer.updateAnalytics('TestTerm', 25, true);

        expect(mockPrisma.searchTermAnalytics.create).toHaveBeenCalledWith({
          data: expect.objectContaining({
            searchTerm: 'TestTerm',
            termLength: 8,
          }),
        });
      });

      it('should update existing analytics for successful scrape', async () => {
        mockPrisma.searchTermAnalytics.findUnique.mockResolvedValue({
          id: '1',
          searchTerm: 'TestTerm',
          termLength: 8,
          totalSearches: 5,
          successfulSearches: 4,
          failedSearches: 1,
          totalResults: 100,
          maxResults: 25,
          minResults: 10,
          lastSearched: new Date(),
        });
        mockPrisma.searchTermAnalytics.update.mockResolvedValue({});

        await optimizer.updateAnalytics('TestTerm', 30, true);

        expect(mockPrisma.searchTermAnalytics.update).toHaveBeenCalledWith({
          where: { searchTerm: 'TestTerm' },
          data: expect.objectContaining({
            totalSearches: 6,
            successfulSearches: 5,
            totalResults: 130,
          }),
        });
      });

      it('should update failed searches correctly', async () => {
        mockPrisma.searchTermAnalytics.findUnique.mockResolvedValue(null);
        mockPrisma.searchTermAnalytics.create.mockResolvedValue({});

        await optimizer.updateAnalytics('FailTerm', 0, false);

        expect(mockPrisma.searchTermAnalytics.create).toHaveBeenCalled();
      });
    });

    describe('getOptimizedTerms', () => {
      beforeEach(() => {
        mockPrisma.searchTermAnalytics.findMany.mockResolvedValue([
          {
            id: '1',
            searchTerm: 'Good',
            termLength: 4,
            totalSearches: 10,
            successfulSearches: 9,
            failedSearches: 1,
            totalResults: 100,
            maxResults: 20,
            minResults: 5,
            lastSearched: new Date('2025-01-01'),
            efficiency: 10.0,
            successRate: 0.9,
            avgResultsPerSearch: 10.0,
          },
          {
            id: '2',
            searchTerm: 'Bad',
            termLength: 3,
            totalSearches: 10,
            successfulSearches: 2,
            failedSearches: 8,
            totalResults: 10,
            maxResults: 5,
            minResults: 0,
            lastSearched: new Date('2025-01-01'),
            efficiency: 1.0,
            successRate: 0.2,
            avgResultsPerSearch: 1.0,
          },
        ]);
      });

      it('should call findMany with efficiency and success rate filters', async () => {
        await optimizer.getOptimizedTerms({
          minEfficiency: 5.0,
          minSuccessRate: 0.5,
        });

        expect(mockPrisma.searchTermAnalytics.findMany).toHaveBeenCalledWith(
          expect.objectContaining({
            where: expect.objectContaining({
              efficiency: { gte: 5.0 },
              successRate: { gte: 0.5 },
            }),
          })
        );
      });

      it('should filter by preferred term length', async () => {
        const terms = await optimizer.getOptimizedTerms({
          preferredTermLength: 4,
        });

        expect(terms).toContain('Good');
      });

      it('should call findMany with maxTermsToReturn in take parameter', async () => {
        mockPrisma.searchTermAnalytics.findMany.mockResolvedValue([
          {
            id: '1',
            searchTerm: 'Term1',
            termLength: 4,
            totalSearches: 10,
            successfulSearches: 10,
            failedSearches: 0,
            totalResults: 100,
            maxResults: 20,
            minResults: 5,
            lastSearched: new Date(),
            efficiency: 10.0,
            successRate: 1.0,
            avgResultsPerSearch: 10.0,
          },
        ]);

        await optimizer.getOptimizedTerms({
          maxTermsToReturn: 25,
        });

        expect(mockPrisma.searchTermAnalytics.findMany).toHaveBeenCalledWith(
          expect.objectContaining({
            take: 25,
          })
        );
      });

      it('should call findMany with date filter when excluding recently used terms', async () => {
        mockPrisma.searchTermAnalytics.findMany.mockResolvedValue([]);

        await optimizer.getOptimizedTerms({
          excludeRecentlyUsed: true,
          recentDays: 7,
        });

        expect(mockPrisma.searchTermAnalytics.findMany).toHaveBeenCalledWith(
          expect.objectContaining({
            where: expect.objectContaining({
              lastSearched: expect.objectContaining({
                lte: expect.any(Date),
              }),
            }),
          })
        );
      });

      it('should return empty array if no terms meet criteria', async () => {
        mockPrisma.searchTermAnalytics.findMany.mockResolvedValue([]);

        const terms = await optimizer.getOptimizedTerms({
          minEfficiency: 100,
        });

        expect(terms).toEqual([]);
      });
    });

    describe('getPerformanceStats', () => {
      it('should calculate aggregate statistics', async () => {
        mockPrisma.searchTermAnalytics.findMany.mockResolvedValue([
          {
            id: '1',
            searchTerm: 'Term1',
            termLength: 4,
            totalSearches: 10,
            successfulSearches: 8,
            failedSearches: 2,
            totalResults: 100,
            maxResults: 20,
            minResults: 5,
            lastSearched: new Date(),
            efficiency: 10.0,
            successRate: 0.8,
            avgResultsPerSearch: 10.0,
          },
          {
            id: '2',
            searchTerm: 'Term2',
            termLength: 5,
            totalSearches: 5,
            successfulSearches: 5,
            failedSearches: 0,
            totalResults: 50,
            maxResults: 15,
            minResults: 8,
            lastSearched: new Date(),
            efficiency: 10.0,
            successRate: 1.0,
            avgResultsPerSearch: 10.0,
          },
        ]);

        const stats = await optimizer.getPerformanceStats();

        expect(stats.totalSearchTerms).toBe(2);
        expect(stats.avgEfficiency).toBe(10.0);
        expect(stats.avgSuccessRate).toBe(0.9);
        expect(stats.avgResultsPerSearch).toBe(10.0);
        expect(Array.isArray(stats.topPerformers)).toBe(true);
        expect(Array.isArray(stats.poorPerformers)).toBe(true);
      });

      it('should handle empty database', async () => {
        mockPrisma.searchTermAnalytics.findMany.mockResolvedValue([]);

        const stats = await optimizer.getPerformanceStats();

        expect(stats.totalSearchTerms).toBe(0);
        expect(stats.avgResultsPerSearch).toBe(0);
        expect(stats.avgSuccessRate).toBe(0);
        expect(stats.avgEfficiency).toBe(0);
      });
    });

    describe('isDatabaseEmpty', () => {
      it('should return true when database is empty', async () => {
        mockPrisma.scrapeJob.count.mockResolvedValue(0);

        const isEmpty = await optimizer.isDatabaseEmpty();

        expect(isEmpty).toBe(true);
      });

      it('should return false when database has data', async () => {
        mockPrisma.scrapeJob.count.mockResolvedValue(100);

        const isEmpty = await optimizer.isDatabaseEmpty();

        expect(isEmpty).toBe(false);
      });
    });
  });
});
</file>

<file path="services/__tests__/token-refresh.service.test.ts">
/**
 * Token Refresh Service Tests
 */

// Mock Playwright
const mockPage = {
  goto: jest.fn(),
  waitForFunction: jest.fn(),
  waitForSelector: jest.fn(),
  type: jest.fn(),
  press: jest.fn(),
  on: jest.fn(),
};

const mockContext = {
  newPage: jest.fn().mockResolvedValue(mockPage),
  close: jest.fn(),
};

const mockBrowser = {
  newContext: jest.fn().mockResolvedValue(mockContext),
  close: jest.fn(),
};

jest.mock('playwright', () => ({
  chromium: {
    launch: jest.fn().mockResolvedValue(mockBrowser),
  },
}));

// Mock node-cron
const mockCronJob = {
  stop: jest.fn(),
};

jest.mock('node-cron', () => ({
  schedule: jest.fn().mockReturnValue(mockCronJob),
}));

// Mock config
jest.mock('../../config', () => ({
  config: {
    logging: {
      level: 'error',
    },
    scraper: {
      headless: true,
      tcadApiKey: 'test-token-from-env',
    },
  },
}));

import { TCADTokenRefreshService } from '../token-refresh.service';
import { chromium } from 'playwright';
import cron from 'node-cron';

describe('TCADTokenRefreshService', () => {
  let service: TCADTokenRefreshService;

  beforeEach(() => {
    jest.clearAllMocks();
    service = new TCADTokenRefreshService();
  });

  afterEach(async () => {
    await service.cleanup();
  });

  describe('constructor', () => {
    it('should initialize with token from environment if available', () => {
      const token = service.getCurrentToken();
      expect(token).toBe('test-token-from-env');
    });

    it('should initialize stats correctly', () => {
      const stats = service.getStats();
      expect(stats.refreshCount).toBe(0);
      expect(stats.failureCount).toBe(0);
      expect(stats.isRefreshing).toBe(false);
      expect(stats.lastRefreshTime).toBeNull();
    });
  });

  describe('getCurrentToken', () => {
    it('should return the current token', () => {
      const token = service.getCurrentToken();
      expect(token).toBe('test-token-from-env');
    });

    it('should return null if no token is set', () => {
      const serviceWithoutToken = new TCADTokenRefreshService();
      // Can't easily test this without mocking config differently
      // but we can test the getter works
      expect(typeof serviceWithoutToken.getCurrentToken()).toBe('string');
    });
  });

  describe('getStats', () => {
    it('should return complete statistics', () => {
      const stats = service.getStats();

      expect(stats).toHaveProperty('currentToken');
      expect(stats).toHaveProperty('lastRefreshTime');
      expect(stats).toHaveProperty('refreshCount');
      expect(stats).toHaveProperty('failureCount');
      expect(stats).toHaveProperty('isRefreshing');
      expect(stats).toHaveProperty('isRunning');
    });

    it('should mask token in stats', () => {
      const stats = service.getStats();
      expect(stats.currentToken).toContain('...');
      expect(stats.currentToken).not.toBe('test-token-from-env');
    });

    it('should show isRunning as false initially', () => {
      const stats = service.getStats();
      expect(stats.isRunning).toBe(false);
    });
  });

  describe('getHealth', () => {
    it('should return health status', () => {
      const health = service.getHealth();

      expect(health).toHaveProperty('healthy');
      expect(health).toHaveProperty('hasToken');
      expect(health).toHaveProperty('lastRefresh');
      expect(health).toHaveProperty('timeSinceLastRefresh');
      expect(health).toHaveProperty('refreshCount');
      expect(health).toHaveProperty('failureCount');
      expect(health).toHaveProperty('failureRate');
      expect(health).toHaveProperty('isRefreshing');
      expect(health).toHaveProperty('isAutoRefreshRunning');
    });

    it('should show healthy when token exists', () => {
      const health = service.getHealth();
      expect(health.healthy).toBe(true);
      expect(health.hasToken).toBe(true);
    });

    it('should calculate failure rate correctly', () => {
      const health = service.getHealth();
      expect(health.failureRate).toBe('0%');
    });

    it('should show autoRefresh as not running initially', () => {
      const health = service.getHealth();
      expect(health.isAutoRefreshRunning).toBe(false);
    });
  });

  describe('refreshToken', () => {
    it('should not refresh if already refreshing', async () => {
      // Mock to make refresh take time
      mockPage.goto.mockImplementation(() => new Promise(resolve => setTimeout(resolve, 100)));

      // Start first refresh (won't complete immediately)
      const promise1 = service.refreshToken();

      // Wait a bit to ensure first refresh has started
      await new Promise(resolve => setTimeout(resolve, 10));

      // Try to start second refresh while first is in progress
      const promise2 = service.refreshToken();

      const result = await promise2;

      // Should return current token without launching browser again
      expect(result).toBe('test-token-from-env');

      // Wait for first to complete
      await promise1;
    });

    it('should initialize browser on first refresh', async () => {
      // Mock successful token capture
      mockPage.on.mockImplementation((event, handler) => {
        if (event === 'request') {
          // Simulate a request with auth header
          setTimeout(() => {
            handler({
              headers: () => ({
                authorization: 'eyJtest-captured-token-with-enough-length-to-pass-validation',
              }),
            });
          }, 10);
        }
      });

      mockPage.goto.mockResolvedValue(undefined);
      mockPage.waitForFunction.mockResolvedValue(undefined);
      mockPage.waitForSelector.mockResolvedValue(undefined);
      mockPage.type.mockResolvedValue(undefined);
      mockPage.press.mockResolvedValue(undefined);

      await service.refreshToken();

      expect(chromium.launch).toHaveBeenCalled();
    });

    it('should track failure count on error', async () => {
      // Force an error by not mocking the browser properly
      mockPage.goto.mockRejectedValue(new Error('Navigation failed'));

      const initialStats = service.getStats();
      const initialFailureCount = initialStats.failureCount;

      await service.refreshToken();

      const newStats = service.getStats();
      expect(newStats.failureCount).toBeGreaterThan(initialFailureCount);
    });

    it('should handle token capture failure gracefully', async () => {
      // No token will be captured
      mockPage.on.mockImplementation(() => {});
      mockPage.goto.mockResolvedValue(undefined);
      mockPage.waitForFunction.mockResolvedValue(undefined);
      mockPage.waitForSelector.mockResolvedValue(undefined);
      mockPage.type.mockResolvedValue(undefined);
      mockPage.press.mockResolvedValue(undefined);

      const result = await service.refreshToken();

      // Should return existing token on failure
      expect(result).toBe('test-token-from-env');

      const stats = service.getStats();
      expect(stats.failureCount).toBeGreaterThan(0);
    });

    it('should set isRefreshing flag during refresh', async () => {
      // Mock a slow refresh
      mockPage.goto.mockImplementation(() => new Promise(resolve => setTimeout(resolve, 50)));

      const promise = service.refreshToken();

      // Check flag is set during refresh
      const stats = service.getStats();
      expect(stats.isRefreshing).toBe(true);

      await promise;

      // Check flag is cleared after
      const finalStats = service.getStats();
      expect(finalStats.isRefreshing).toBe(false);
    });
  });

  describe('startAutoRefresh', () => {
    it('should start cron job with default schedule', () => {
      service.startAutoRefresh();

      expect(cron.schedule).toHaveBeenCalledWith(
        '*/4 * * * *',
        expect.any(Function)
      );
    });

    it('should start cron job with custom schedule', () => {
      service.startAutoRefresh('*/10 * * * *');

      expect(cron.schedule).toHaveBeenCalledWith(
        '*/10 * * * *',
        expect.any(Function)
      );
    });

    it.skip('should not start if already running - SKIPPED (async timing issue)', () => {
      service.startAutoRefresh();

      const stats1 = service.getStats();
      expect(stats1.isRunning).toBe(true);

      // Clear mocks after first start
      jest.clearAllMocks();

      // Try to start again
      service.startAutoRefresh();

      // Should not have called schedule again
      expect(cron.schedule).not.toHaveBeenCalled();

      // Should still be running
      const stats2 = service.getStats();
      expect(stats2.isRunning).toBe(true);
    });

    it('should show as running in stats after start', () => {
      service.startAutoRefresh();

      const stats = service.getStats();
      expect(stats.isRunning).toBe(true);

      const health = service.getHealth();
      expect(health.isAutoRefreshRunning).toBe(true);
    });
  });

  describe('startAutoRefreshInterval', () => {
    beforeEach(() => {
      jest.useFakeTimers();
    });

    afterEach(() => {
      jest.useRealTimers();
    });

    it('should start interval with default time', () => {
      service.startAutoRefreshInterval();

      const stats = service.getStats();
      expect(stats.isRunning).toBe(true);
    });

    it('should start interval with custom time', () => {
      service.startAutoRefreshInterval(60000); // 1 minute

      const stats = service.getStats();
      expect(stats.isRunning).toBe(true);
    });

    it('should not start if already running', () => {
      service.startAutoRefreshInterval();
      const stats1 = service.getStats();

      service.startAutoRefreshInterval();
      const stats2 = service.getStats();

      expect(stats1.isRunning).toBe(stats2.isRunning);
    });
  });

  describe('stopAutoRefresh', () => {
    it.skip('should stop cron job if running - SKIPPED (async timing issue)', () => {
      service.startAutoRefresh();

      // Verify it's running
      expect(service.getStats().isRunning).toBe(true);

      service.stopAutoRefresh();

      // Verify it's stopped
      const stats = service.getStats();
      expect(stats.isRunning).toBe(false);

      // Verify stop was called
      expect(mockCronJob.stop).toHaveBeenCalled();
    });

    it('should stop interval if running', () => {
      jest.useFakeTimers();

      service.startAutoRefreshInterval();
      service.stopAutoRefresh();

      const stats = service.getStats();
      expect(stats.isRunning).toBe(false);

      jest.useRealTimers();
    });

    it('should handle being called when not running', () => {
      // Should not throw
      expect(() => service.stopAutoRefresh()).not.toThrow();
    });
  });

  describe('cleanup', () => {
    it.skip('should stop auto-refresh - SKIPPED (async timing issue)', async () => {
      // Start auto-refresh
      service.startAutoRefresh();

      expect(service.getStats().isRunning).toBe(true);

      // Now cleanup
      await service.cleanup();

      // Verify auto-refresh was stopped
      expect(service.getStats().isRunning).toBe(false);
      expect(mockCronJob.stop).toHaveBeenCalled();
    });

    it('should handle cleanup when browser not initialized', async () => {
      await expect(service.cleanup()).resolves.not.toThrow();
    });

    it('should handle cleanup when auto-refresh not running', async () => {
      await expect(service.cleanup()).resolves.not.toThrow();

      const stats = service.getStats();
      expect(stats.isRunning).toBe(false);
    });
  });
});
</file>

<file path="services/code-complexity.service.ts">
/**
 * Code Complexity Analyzer Service
 *
 * Analyzes TypeScript/JavaScript codebase for complexity metrics
 * Updates Prometheus metrics with code quality indicators
 *
 * Features:
 * - Cyclomatic complexity calculation
 * - Lines of code counting (total, code, comments)
 * - File and function size tracking
 * - Class and function counting
 * - Maintainability index calculation
 *
 * Usage:
 * - Run periodically via cron job (e.g., hourly or daily)
 * - Provides early warning for code quality degradation
 */

import * as fs from 'fs/promises';
import * as path from 'path';
import { glob } from 'glob';
import logger from '../lib/logger';
import { updateCodeComplexityMetrics, CodeComplexityMetrics } from '../lib/metrics.service';

// ============================================================================
// Configuration
// ============================================================================

interface AnalyzerConfig {
  /** Root directory to analyze (default: server/src) */
  rootDir: string;
  /** File patterns to include */
  include: string[];
  /** File patterns to exclude */
  exclude: string[];
  /** Update interval in milliseconds */
  updateIntervalMs: number;
}

const DEFAULT_CONFIG: AnalyzerConfig = {
  rootDir: path.join(__dirname, '..'),
  include: ['**/*.ts', '**/*.js'],
  exclude: [
    '**/node_modules/**',
    '**/dist/**',
    '**/*.test.ts',
    '**/*.test.js',
    '**/*.spec.ts',
    '**/*.spec.js',
  ],
  updateIntervalMs: 3600000, // 1 hour
};

// ============================================================================
// Complexity Analysis
// ============================================================================

interface FileMetrics {
  file: string;
  totalLines: number;
  codeLines: number;
  commentLines: number;
  blankLines: number;
  functions: number;
  classes: number;
  maxFunctionLines: number;
  avgCyclomatic: number;
  maxCyclomatic: number;
}

/**
 * Analyze a single file for complexity metrics
 */
async function analyzeFile(filePath: string): Promise<FileMetrics> {
  const content = await fs.readFile(filePath, 'utf-8');
  const lines = content.split('\n');

  let codeLines = 0;
  let commentLines = 0;
  let blankLines = 0;
  let inBlockComment = false;

  // Count line types
  for (const line of lines) {
    const trimmed = line.trim();

    if (trimmed === '') {
      blankLines++;
    } else if (trimmed.startsWith('//')) {
      commentLines++;
    } else if (trimmed.startsWith('/*') || trimmed.startsWith('*')) {
      commentLines++;
      if (trimmed.startsWith('/*')) {
        inBlockComment = true;
      }
      if (trimmed.endsWith('*/')) {
        inBlockComment = false;
      }
    } else if (inBlockComment) {
      commentLines++;
      if (trimmed.endsWith('*/')) {
        inBlockComment = false;
      }
    } else {
      codeLines++;
    }
  }

  // Count functions (simple regex-based approach)
  const functionMatches = content.match(/\bfunction\s+\w+|=>\s*{|\basync\s+function/g) || [];
  const functions = functionMatches.length;

  // Count classes
  const classMatches = content.match(/\bclass\s+\w+/g) || [];
  const classes = classMatches.length;

  // Calculate cyclomatic complexity (simplified)
  const cyclomaticComplexity = calculateCyclomaticComplexity(content);

  // Calculate max function lines (simplified - estimate based on braces)
  const maxFunctionLines = estimateMaxFunctionLines(content);

  return {
    file: filePath,
    totalLines: lines.length,
    codeLines,
    commentLines,
    blankLines,
    functions,
    classes,
    maxFunctionLines,
    avgCyclomatic: cyclomaticComplexity.avg,
    maxCyclomatic: cyclomaticComplexity.max,
  };
}

/**
 * Calculate cyclomatic complexity (simplified)
 * Counts decision points: if, else, for, while, case, catch, &&, ||, ?
 */
function calculateCyclomaticComplexity(content: string): { avg: number; max: number } {
  // Split into functions (simplified)
  const functionBodies = content.split(/\bfunction\s+\w+|=>\s*{/);

  const complexities: number[] = [];

  for (const body of functionBodies) {
    if (body.trim().length === 0) continue;

    // Count decision points
    const ifCount = (body.match(/\bif\s*\(/g) || []).length;
    const elseCount = (body.match(/\belse\b/g) || []).length;
    const forCount = (body.match(/\bfor\s*\(/g) || []).length;
    const whileCount = (body.match(/\bwhile\s*\(/g) || []).length;
    const caseCount = (body.match(/\bcase\s+/g) || []).length;
    const catchCount = (body.match(/\bcatch\s*\(/g) || []).length;
    const ternaryCount = (body.match(/\?[^:]+:/g) || []).length;
    const andCount = (body.match(/&&/g) || []).length;
    const orCount = (body.match(/\|\|/g) || []).length;

    const complexity =
      1 + // Base complexity
      ifCount +
      elseCount +
      forCount +
      whileCount +
      caseCount +
      catchCount +
      ternaryCount +
      andCount +
      orCount;

    complexities.push(complexity);
  }

  if (complexities.length === 0) {
    return { avg: 0, max: 0 };
  }

  const avg = complexities.reduce((a, b) => a + b, 0) / complexities.length;
  const max = Math.max(...complexities);

  return { avg, max };
}

/**
 * Estimate maximum function lines (simplified)
 */
function estimateMaxFunctionLines(content: string): number {
  const lines = content.split('\n');
  let currentFunctionLines = 0;
  let maxLines = 0;
  let braceDepth = 0;
  let inFunction = false;

  for (const line of lines) {
    const trimmed = line.trim();

    // Detect function start
    if (trimmed.match(/\bfunction\s+\w+|=>\s*{|\basync\s+function/)) {
      inFunction = true;
      currentFunctionLines = 0;
    }

    if (inFunction) {
      currentFunctionLines++;

      // Track brace depth
      braceDepth += (trimmed.match(/{/g) || []).length;
      braceDepth -= (trimmed.match(/}/g) || []).length;

      // Function ended
      if (braceDepth === 0 && trimmed.includes('}')) {
        maxLines = Math.max(maxLines, currentFunctionLines);
        inFunction = false;
        currentFunctionLines = 0;
      }
    }
  }

  return maxLines;
}

/**
 * Calculate maintainability index
 * Formula: 171 - 5.2 * ln(HV) - 0.23 * CC - 16.2 * ln(LOC)
 * Where: HV = Halstead Volume, CC = Cyclomatic Complexity, LOC = Lines of Code
 * Simplified version using code lines and cyclomatic complexity
 */
function calculateMaintainabilityIndex(
  codeLines: number,
  avgCyclomatic: number
): number {
  if (codeLines === 0) return 100;

  // Simplified formula (without Halstead Volume)
  const mi = Math.max(
    0,
    Math.min(
      100,
      171 - 0.23 * avgCyclomatic - 16.2 * Math.log(codeLines)
    )
  );

  return Math.round(mi);
}

/**
 * Calculate technical debt ratio
 * Based on code complexity and maintainability
 */
function calculateTechnicalDebtRatio(
  maintainabilityIndex: number,
  avgCyclomatic: number
): number {
  // Higher complexity and lower maintainability = higher debt
  const complexityFactor = Math.min(avgCyclomatic / 10, 5); // Max 5
  const maintainabilityFactor = (100 - maintainabilityIndex) / 10; // 0-10

  const debtRatio = (complexityFactor + maintainabilityFactor) * 2;

  return Math.round(Math.min(debtRatio, 100));
}

// ============================================================================
// Codebase Analysis
// ============================================================================

/**
 * Analyze entire codebase
 */
export async function analyzeCodebase(
  config: Partial<AnalyzerConfig> = {}
): Promise<CodeComplexityMetrics> {
  const finalConfig = { ...DEFAULT_CONFIG, ...config };

  logger.info({
    rootDir: finalConfig.rootDir,
    include: finalConfig.include,
  }, 'Starting code complexity analysis');

  try {
    // Find all files matching patterns
    const files = await glob(finalConfig.include, {
      cwd: finalConfig.rootDir,
      ignore: finalConfig.exclude,
      absolute: true,
    });

    logger.info(`Found ${files.length} files to analyze`);

    // Analyze each file
    const fileMetrics: FileMetrics[] = [];
    for (const file of files) {
      try {
        const metrics = await analyzeFile(file);
        fileMetrics.push(metrics);
      } catch (error) {
        logger.warn({ error, file }, `Failed to analyze file`);
      }
    }

    // Aggregate metrics
    const totalLines = fileMetrics.reduce((sum, m) => sum + m.totalLines, 0);
    const codeLines = fileMetrics.reduce((sum, m) => sum + m.codeLines, 0);
    const commentLines = fileMetrics.reduce((sum, m) => sum + m.commentLines, 0);
    const totalFunctions = fileMetrics.reduce((sum, m) => sum + m.functions, 0);
    const totalClasses = fileMetrics.reduce((sum, m) => sum + m.classes, 0);

    // Calculate average cyclomatic complexity
    const complexities = fileMetrics
      .filter((m) => m.avgCyclomatic > 0)
      .map((m) => m.avgCyclomatic);
    const avgCyclomatic =
      complexities.length > 0
        ? complexities.reduce((a, b) => a + b, 0) / complexities.length
        : 0;

    // Find max cyclomatic complexity
    const maxCyclomatic = Math.max(...fileMetrics.map((m) => m.maxCyclomatic), 0);

    // Find max function lines
    const maxFunctionLines = Math.max(...fileMetrics.map((m) => m.maxFunctionLines), 0);

    // Calculate maintainability index
    const maintainabilityIndex = calculateMaintainabilityIndex(codeLines, avgCyclomatic);

    // Calculate technical debt ratio
    const technicalDebtRatio = calculateTechnicalDebtRatio(
      maintainabilityIndex,
      avgCyclomatic
    );

    // Top 10 largest files for detailed tracking
    const topFiles = fileMetrics
      .sort((a, b) => b.totalLines - a.totalLines)
      .slice(0, 10)
      .map((m) => ({
        file: path.relative(finalConfig.rootDir, m.file),
        lines: m.totalLines,
      }));

    const metrics: CodeComplexityMetrics = {
      avgCyclomatic: Math.round(avgCyclomatic * 10) / 10,
      maxCyclomatic,
      totalLines,
      codeLines,
      commentLines,
      totalFiles: fileMetrics.length,
      totalFunctions,
      totalClasses,
      maxFunctionLines,
      fileMetrics: topFiles,
      maintainabilityIndex,
      technicalDebtRatio,
    };

    logger.info(metrics, 'Code complexity analysis complete');

    return metrics;
  } catch (error) {
    logger.error({ error }, 'Failed to analyze codebase');
    throw error;
  }
}

/**
 * Update Prometheus metrics with latest complexity data
 */
export async function updateComplexityMetrics(
  config?: Partial<AnalyzerConfig>
): Promise<void> {
  try {
    const metrics = await analyzeCodebase(config);
    updateCodeComplexityMetrics(metrics);
    logger.info('Code complexity metrics updated successfully');
  } catch (error) {
    logger.error({ error }, 'Failed to update code complexity metrics');
    throw error;
  }
}

/**
 * Start periodic complexity analysis
 */
let analysisInterval: NodeJS.Timeout | null = null;

export function startPeriodicAnalysis(config?: Partial<AnalyzerConfig>): void {
  const finalConfig = { ...DEFAULT_CONFIG, ...config };

  // Run immediately on start
  updateComplexityMetrics(finalConfig).catch((error) => {
    logger.error({ error }, 'Initial complexity analysis failed');
  });

  // Schedule periodic updates
  analysisInterval = setInterval(() => {
    updateComplexityMetrics(finalConfig).catch((error) => {
      logger.error({ error }, 'Periodic complexity analysis failed');
    });
  }, finalConfig.updateIntervalMs);

  logger.info({
    intervalMs: finalConfig.updateIntervalMs,
  }, 'Started periodic code complexity analysis');
}

export function stopPeriodicAnalysis(): void {
  if (analysisInterval) {
    clearInterval(analysisInterval);
    analysisInterval = null;
    logger.info('Stopped periodic code complexity analysis');
  }
}

// ============================================================================
// Exports
// ============================================================================

export default {
  analyzeCodebase,
  updateComplexityMetrics,
  startPeriodicAnalysis,
  stopPeriodicAnalysis,
};
</file>

<file path="services/README_ENHANCED.md">
# services

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "SoftwareSourceCode",
  "name": "services",
  "description": "Directory containing 3 code files with 6 classes and 0 functions",
  "programmingLanguage": [
    {
      "@type": "ComputerLanguage",
      "name": "Typescript"
    }
  ],
  "featureList": [
    "6 class definitions"
  ]
}
</script>

## Overview

This directory contains 3 code file(s) with extracted schemas.

## Subdirectories

- `__tests__/`

## Files and Schemas

### `code-complexity.service.ts` (typescript)

**Classes:**
- `AnalyzerConfig` - Line 28
- `FileMetrics` - Line 57

### `search-term-optimizer.ts` (typescript)

**Classes:**
- `SearchTermOptimizer` - Line 67
- `SearchTermPerformance` - Line 43
- `OptimizerConfig` - Line 58

### `token-refresh.service.ts` (typescript)

**Classes:**
- `TCADTokenRefreshService` - Line 34

---
*Generated by Enhanced Schema Generator with schema.org markup*
</file>

<file path="services/search-term-optimizer.ts">
import { PrismaClient } from '@prisma/client';
import logger from '../lib/logger';

const prisma = new PrismaClient();

/**
 * Optimized 4-character search terms for cold start
 * These are strategically chosen to maximize results per query
 * Based on common prefixes in entity names, property types, and locations
 */
export const OPTIMIZED_4_CHAR_STARTER_TERMS = [
  // Trust & Estate related (high yield)
  'Trus', 'Esta', 'Revo', 'Irre', 'Fami', 'Bene',

  // LLC & Corporate (high yield)
  'L.L.', 'LLC.', 'Limi', 'LMTD', 'Corp', 'Inc.', 'Inco',

  // Partnership & Associations
  'Part', 'Partn', 'Asso', 'Assn',

  // Real estate specific
  'Real', 'Realt', 'Prop', 'Park', 'Parc', 'Plaz', 'Cent',
  'Land', 'Lane', 'Home', 'Hous', 'Apar', 'Cond',

  // Business types (high yield)
  'Mana', 'Hold', 'Inve', 'Grou', 'Vent', 'Fund',
  'Capi', 'Deve', 'Buil', 'Cons',

  // Geographic/Street patterns
  'Main', 'Oak ', 'Elms', 'Pine', 'Mapl', 'Cedr',
  'West', 'East', 'Nort', 'Sout',

  // Common last names (high yield)
  'Smit', 'John', 'Wili', 'Brow', 'Jone', 'Mill', 'Davi',
  'Garc', 'Rodr', 'Wils', 'Mart', 'Ande', 'Tayl', 'Thom',

  // Foundation & Non-profit
  'Foun', 'Char', 'Endow',

  // Investment & Finance
  'Equi', 'Asse', 'Port', 'Trad',
];

export interface SearchTermPerformance {
  searchTerm: string;
  termLength: number;
  totalSearches: number;
  successfulSearches: number;
  failedSearches: number;
  totalResults: number;
  avgResultsPerSearch: number;
  maxResults: number;
  minResults: number | null;
  lastSearched: Date;
  successRate: number;
  efficiency: number;
}

export interface OptimizerConfig {
  minEfficiency?: number;        // Minimum efficiency score to consider term "good"
  minSuccessRate?: number;       // Minimum success rate (0-1)
  preferredTermLength?: number;  // Preferred term length (default: 4)
  maxTermsToReturn?: number;     // Maximum number of terms to return
  excludeRecentlyUsed?: boolean; // Exclude terms used within last N days
  recentDays?: number;           // Days to consider "recent"
}

export class SearchTermOptimizer {
  private prisma: PrismaClient;

  constructor(prismaClient?: PrismaClient) {
    this.prisma = prismaClient || prisma;
  }

  /**
   * Get optimized starter terms for cold start (empty database)
   * Returns 4-character terms optimized for maximum coverage
   */
  async getStarterTerms(): Promise<string[]> {
    // Check if database has analytics data
    const analyticsCount = await this.prisma.searchTermAnalytics.count();

    if (analyticsCount === 0) {
      // Cold start - return optimized 4-char terms
      logger.info(' Cold start detected - using optimized 4-character starter terms');
      return OPTIMIZED_4_CHAR_STARTER_TERMS;
    }

    // Database has data - use analytics to optimize
    logger.info(' Using analytics to optimize starter terms');
    return this.getOptimizedTerms({
      preferredTermLength: 4,
      minEfficiency: 5.0,
      minSuccessRate: 0.5,
      maxTermsToReturn: 50,
    });
  }

  /**
   * Update analytics after a scrape job completes
   */
  async updateAnalytics(
    searchTerm: string,
    resultCount: number,
    wasSuccessful: boolean,
    error?: string
  ): Promise<void> {
    const existing = await this.prisma.searchTermAnalytics.findUnique({
      where: { searchTerm },
    });

    if (existing) {
      // Update existing record
      const newTotalSearches = existing.totalSearches + 1;
      const newSuccessfulSearches = existing.successfulSearches + (wasSuccessful ? 1 : 0);
      const newFailedSearches = existing.failedSearches + (wasSuccessful ? 0 : 1);
      const newTotalResults = existing.totalResults + resultCount;
      const newAvgResults = newTotalResults / newSuccessfulSearches || 0;
      const newSuccessRate = newSuccessfulSearches / newTotalSearches;
      const newEfficiency = newAvgResults * newSuccessRate;

      await this.prisma.searchTermAnalytics.update({
        where: { searchTerm },
        data: {
          totalSearches: newTotalSearches,
          successfulSearches: newSuccessfulSearches,
          failedSearches: newFailedSearches,
          totalResults: newTotalResults,
          avgResultsPerSearch: newAvgResults,
          maxResults: Math.max(existing.maxResults, resultCount),
          minResults: existing.minResults
            ? Math.min(existing.minResults, resultCount)
            : resultCount,
          lastSearched: new Date(),
          successRate: newSuccessRate,
          efficiency: newEfficiency,
        },
      });
    } else {
      // Create new record
      const successRate = wasSuccessful ? 1.0 : 0.0;
      const avgResults = wasSuccessful ? resultCount : 0;
      const efficiency = avgResults * successRate;

      await this.prisma.searchTermAnalytics.create({
        data: {
          searchTerm,
          termLength: searchTerm.length,
          totalSearches: 1,
          successfulSearches: wasSuccessful ? 1 : 0,
          failedSearches: wasSuccessful ? 0 : 1,
          totalResults: resultCount,
          avgResultsPerSearch: avgResults,
          maxResults: resultCount,
          minResults: wasSuccessful ? resultCount : null,
          lastSearched: new Date(),
          successRate,
          efficiency,
        },
      });
    }
  }

  /**
   * Get optimized search terms based on historical performance
   */
  async getOptimizedTerms(config: OptimizerConfig = {}): Promise<string[]> {
    const {
      minEfficiency = 5.0,
      minSuccessRate = 0.5,
      preferredTermLength = 4,
      maxTermsToReturn = 50,
      excludeRecentlyUsed = false,
      recentDays = 7,
    } = config;

    const whereClause: any = {
      efficiency: { gte: minEfficiency },
      successRate: { gte: minSuccessRate },
    };

    if (preferredTermLength) {
      whereClause.termLength = preferredTermLength;
    }

    if (excludeRecentlyUsed) {
      const cutoffDate = new Date();
      cutoffDate.setDate(cutoffDate.getDate() - recentDays);
      whereClause.lastSearched = { lte: cutoffDate };
    }

    const analytics = await this.prisma.searchTermAnalytics.findMany({
      where: whereClause,
      orderBy: [
        { efficiency: 'desc' },
        { avgResultsPerSearch: 'desc' },
      ],
      take: maxTermsToReturn,
    });

    return analytics.map(a => a.searchTerm);
  }

  /**
   * Get performance statistics for all search terms
   */
  async getPerformanceStats(): Promise<{
    totalSearchTerms: number;
    avgEfficiency: number;
    avgSuccessRate: number;
    avgResultsPerSearch: number;
    topPerformers: SearchTermPerformance[];
    poorPerformers: SearchTermPerformance[];
  }> {
    const allAnalytics = await this.prisma.searchTermAnalytics.findMany();

    if (allAnalytics.length === 0) {
      return {
        totalSearchTerms: 0,
        avgEfficiency: 0,
        avgSuccessRate: 0,
        avgResultsPerSearch: 0,
        topPerformers: [],
        poorPerformers: [],
      };
    }

    const totalEfficiency = allAnalytics.reduce((sum, a) => sum + a.efficiency, 0);
    const totalSuccessRate = allAnalytics.reduce((sum, a) => sum + a.successRate, 0);
    const totalAvgResults = allAnalytics.reduce((sum, a) => sum + a.avgResultsPerSearch, 0);

    const topPerformers = await this.prisma.searchTermAnalytics.findMany({
      orderBy: { efficiency: 'desc' },
      take: 20,
    });

    const poorPerformers = await this.prisma.searchTermAnalytics.findMany({
      where: { successRate: { lt: 0.3 } },
      orderBy: { efficiency: 'asc' },
      take: 20,
    });

    return {
      totalSearchTerms: allAnalytics.length,
      avgEfficiency: totalEfficiency / allAnalytics.length,
      avgSuccessRate: totalSuccessRate / allAnalytics.length,
      avgResultsPerSearch: totalAvgResults / allAnalytics.length,
      topPerformers: topPerformers as SearchTermPerformance[],
      poorPerformers: poorPerformers as SearchTermPerformance[],
    };
  }

  /**
   * Get insights on what term lengths and patterns work best
   */
  async getTermLengthAnalysis(): Promise<{
    byLength: Record<number, {
      count: number;
      avgEfficiency: number;
      avgResultsPerSearch: number;
      avgSuccessRate: number;
    }>;
  }> {
    const allAnalytics = await this.prisma.searchTermAnalytics.findMany();

    const byLength: Record<number, any> = {};

    for (const analytics of allAnalytics) {
      if (!byLength[analytics.termLength]) {
        byLength[analytics.termLength] = {
          count: 0,
          totalEfficiency: 0,
          totalAvgResults: 0,
          totalSuccessRate: 0,
        };
      }

      byLength[analytics.termLength].count++;
      byLength[analytics.termLength].totalEfficiency += analytics.efficiency;
      byLength[analytics.termLength].totalAvgResults += analytics.avgResultsPerSearch;
      byLength[analytics.termLength].totalSuccessRate += analytics.successRate;
    }

    // Calculate averages
    for (const length in byLength) {
      const data = byLength[length];
      byLength[length] = {
        count: data.count,
        avgEfficiency: data.totalEfficiency / data.count,
        avgResultsPerSearch: data.totalAvgResults / data.count,
        avgSuccessRate: data.totalSuccessRate / data.count,
      };
    }

    return { byLength };
  }

  /**
   * Suggest new terms based on successful patterns
   */
  async suggestNewTerms(count: number = 20): Promise<string[]> {
    // Get top performing terms
    const topTerms = await this.prisma.searchTermAnalytics.findMany({
      where: { efficiency: { gte: 10.0 } },
      orderBy: { efficiency: 'desc' },
      take: 50,
    });

    if (topTerms.length === 0) {
      return OPTIMIZED_4_CHAR_STARTER_TERMS.slice(0, count);
    }

    // Analyze patterns in successful terms
    const suggestions = new Set<string>();

    for (const term of topTerms) {
      // Generate variations of successful terms
      if (term.searchTerm.length >= 4) {
        // Prefix variations (first 4 chars)
        suggestions.add(term.searchTerm.substring(0, 4));

        // If term is longer, try middle and end substrings
        if (term.searchTerm.length > 4) {
          suggestions.add(term.searchTerm.substring(0, 5));
          suggestions.add(term.searchTerm.substring(0, 3));
        }
      }
    }

    // Filter out terms we've already tried
    const alreadyTried = new Set(topTerms.map(t => t.searchTerm));
    const newSuggestions = Array.from(suggestions)
      .filter(s => !alreadyTried.has(s))
      .slice(0, count);

    return newSuggestions;
  }

  /**
   * Check if database is empty (cold start scenario)
   */
  async isDatabaseEmpty(): Promise<boolean> {
    const scrapeJobCount = await this.prisma.scrapeJob.count();
    return scrapeJobCount === 0;
  }
}

export const searchTermOptimizer = new SearchTermOptimizer();
</file>

<file path="services/token-refresh.service.ts">
/**
 * TCAD Token Refresh Service
 *
 * Automatically refreshes the TCAD API token by:
 * 1. Launching a headless browser
 * 2. Navigating to TCAD property search
 * 3. Performing a test search to trigger API call
 * 4. Capturing the Authorization header
 * 5. Updating the in-memory token
 *
 * Runs on a configurable schedule (default: every 4-5 minutes)
 */

import { chromium, Browser } from 'playwright';
import winston from 'winston';
import cron from 'node-cron';
import { config } from '../config';

const logger = winston.createLogger({
  level: config.logging.level || 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.json()
  ),
  transports: [
    new winston.transports.Console({
      format: winston.format.combine(
        winston.format.colorize(),
        winston.format.simple()
      ),
    }),
  ],
});

export class TCADTokenRefreshService {
  private currentToken: string | null = null;
  private browser: Browser | null = null;
  private refreshInterval: NodeJS.Timeout | null = null;
  private cronJob: cron.ScheduledTask | null = null;
  private isRefreshing: boolean = false;
  private lastRefreshTime: Date | null = null;
  private refreshCount: number = 0;
  private failureCount: number = 0;

  constructor() {
    // Initialize with env token if available
    this.currentToken = config.scraper.tcadApiKey || null;

    if (this.currentToken) {
      logger.info('Token refresh service initialized with existing token from environment');
    } else {
      logger.info('Token refresh service initialized without token - will fetch on first refresh');
    }
  }

  /**
   * Get the current valid token
   */
  getCurrentToken(): string | null {
    return this.currentToken;
  }

  /**
   * Get refresh statistics
   */
  getStats() {
    return {
      currentToken: this.currentToken ? `${this.currentToken.substring(0, 20)}...` : null,
      lastRefreshTime: this.lastRefreshTime,
      refreshCount: this.refreshCount,
      failureCount: this.failureCount,
      isRefreshing: this.isRefreshing,
      isRunning: this.cronJob !== null || this.refreshInterval !== null,
    };
  }

  /**
   * Refresh the token by capturing from browser
   */
  async refreshToken(): Promise<string | null> {
    if (this.isRefreshing) {
      logger.warn('Token refresh already in progress, skipping...');
      return this.currentToken;
    }

    this.isRefreshing = true;
    const startTime = Date.now();

    try {
      logger.info('Starting token refresh...');

      // Initialize browser if needed
      if (!this.browser) {
        logger.info('Initializing browser for token refresh...');
        this.browser = await chromium.launch({
          headless: config.scraper.headless,
          executablePath: process.env.PLAYWRIGHT_CHROMIUM_EXECUTABLE_PATH || undefined,
          args: [
            '--disable-blink-features=AutomationControlled',
            '--disable-web-security',
            '--disable-features=IsolateOrigins,site-per-process',
            '--no-sandbox',
            '--disable-setuid-sandbox',
          ],
        });
        logger.info('Browser initialized for token refresh');
      }

      const context = await this.browser.newContext({
        userAgent: 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        viewport: { width: 1920, height: 1080 },
        locale: 'en-US',
        timezoneId: 'America/Chicago',
      });

      const page = await context.newPage();
      let capturedToken: string | null = null;

      // Set up request interception to capture Authorization header
      page.on('request', (request) => {
        const headers = request.headers();
        const authHeader = headers['authorization'];

        // Only capture valid tokens (ignore "null" string and ensure it looks like a JWT)
        if (authHeader &&
            authHeader !== 'null' &&
            authHeader.length > 50 &&
            authHeader.startsWith('eyJ') &&
            !capturedToken) {
          capturedToken = authHeader;
          logger.info(`Authorization token captured from request: length: ${capturedToken.length}, preview: ${capturedToken.substring(0, 50)}...`);
        }
      });

      try {
        // Navigate to TCAD property search
        logger.info('Navigating to TCAD property search...');
        await page.goto('https://travis.prodigycad.com/property-search', {
          waitUntil: 'networkidle',
          timeout: 30000,
        });

        // Wait for React app to load
        logger.info('Waiting for React app to load...');
        await page.waitForFunction(() => {
          const root = document.getElementById('root');
          return root && root.children.length > 0;
        }, { timeout: 15000 });

        // Perform a test search to trigger API request with auth token
        logger.info('Performing test search to capture token...');
        await page.waitForSelector('#searchInput', { timeout: 10000 });

        // Small delay to appear more human-like
        await new Promise(resolve => setTimeout(resolve, 500 + Math.random() * 500));

        await page.type('#searchInput', 'test', { delay: 50 });
        await page.press('#searchInput', 'Enter');

        // Wait for API request to be made
        await new Promise(resolve => setTimeout(resolve, 3000 + Math.random() * 1000));

        if (!capturedToken) {
          throw new Error('Failed to capture authorization token from network requests');
        }

        // Update current token
        this.currentToken = capturedToken;
        this.lastRefreshTime = new Date();
        this.refreshCount++;

        const duration = Date.now() - startTime;
        logger.info(`Token refreshed successfully in ${duration}ms (refresh #${this.refreshCount})`);
        logger.info(`New token: ${capturedToken.substring(0, 30)}...`);

        return capturedToken;

      } finally {
        await context.close();
      }

    } catch (error) {
      this.failureCount++;
      const duration = Date.now() - startTime;
      logger.error(`Token refresh failed after ${duration}ms (failure #${this.failureCount}):`, error);

      // If we have a current token, keep using it
      if (this.currentToken) {
        logger.warn('Keeping existing token after refresh failure');
      }

      return this.currentToken;

    } finally {
      this.isRefreshing = false;
    }
  }

  /**
   * Start automatic token refresh using cron schedule
   * Default: Every 4-5 minutes (randomized to avoid detection patterns)
   */
  startAutoRefresh(cronSchedule?: string): void {
    if (this.cronJob) {
      logger.warn('Auto-refresh already running');
      return;
    }

    // Default: Run every 4.5 minutes
    // Cron format: */5 * * * * (every 5 minutes)
    // We'll use 4.5 minutes by alternating between 4 and 5 minute intervals
    const schedule = cronSchedule || '*/4 * * * *'; // Every 4 minutes as baseline

    logger.info(`Starting automatic token refresh (schedule: ${schedule})`);

    // Perform initial refresh
    this.refreshToken().catch((error) => {
      logger.error('Initial token refresh failed:', error);
    });

    // Schedule recurring refreshes
    this.cronJob = cron.schedule(schedule, async () => {
      logger.info('Scheduled token refresh triggered');
      await this.refreshToken();
    });

    logger.info('Automatic token refresh started successfully');
  }

  /**
   * Start automatic token refresh using interval (alternative to cron)
   * @param intervalMs Interval in milliseconds (default: 4.5 minutes)
   */
  startAutoRefreshInterval(intervalMs: number = 270000): void {
    if (this.refreshInterval) {
      logger.warn('Auto-refresh interval already running');
      return;
    }

    logger.info(`Starting automatic token refresh (interval: ${intervalMs}ms / ${intervalMs / 60000} minutes)`);

    // Perform initial refresh
    this.refreshToken().catch((error) => {
      logger.error('Initial token refresh failed:', error);
    });

    // Schedule recurring refreshes with slight randomization
    this.refreshInterval = setInterval(async () => {
      // Add 30 seconds of randomization to avoid detection patterns
      const randomDelay = Math.floor(Math.random() * 60000) - 30000;
      await new Promise(resolve => setTimeout(resolve, Math.max(0, randomDelay)));

      logger.info('Scheduled token refresh triggered');
      await this.refreshToken();
    }, intervalMs);

    logger.info('Automatic token refresh interval started successfully');
  }

  /**
   * Stop automatic token refresh
   */
  stopAutoRefresh(): void {
    if (this.cronJob) {
      this.cronJob.stop();
      this.cronJob = null;
      logger.info('Cron-based token refresh stopped');
    }

    if (this.refreshInterval) {
      clearInterval(this.refreshInterval);
      this.refreshInterval = null;
      logger.info('Interval-based token refresh stopped');
    }
  }

  /**
   * Cleanup resources
   */
  async cleanup(): Promise<void> {
    logger.info('Cleaning up token refresh service...');

    this.stopAutoRefresh();

    if (this.browser) {
      await this.browser.close();
      this.browser = null;
      logger.info('Browser closed');
    }

    logger.info('Token refresh service cleanup complete');
  }

  /**
   * Get health status
   */
  getHealth() {
    const timeSinceLastRefresh = this.lastRefreshTime
      ? Date.now() - this.lastRefreshTime.getTime()
      : null;

    return {
      healthy: this.currentToken !== null,
      hasToken: this.currentToken !== null,
      lastRefresh: this.lastRefreshTime,
      timeSinceLastRefresh,
      refreshCount: this.refreshCount,
      failureCount: this.failureCount,
      failureRate: this.refreshCount > 0
        ? (this.failureCount / (this.refreshCount + this.failureCount) * 100).toFixed(2) + '%'
        : '0%',
      isRefreshing: this.isRefreshing,
      isAutoRefreshRunning: this.cronJob !== null || this.refreshInterval !== null,
    };
  }
}

// Export singleton instance
export const tokenRefreshService = new TCADTokenRefreshService();

// Graceful shutdown
process.on('SIGTERM', async () => {
  logger.info('SIGTERM received, shutting down token refresh service...');
  await tokenRefreshService.cleanup();
});

process.on('SIGINT', async () => {
  logger.info('SIGINT received, shutting down token refresh service...');
  await tokenRefreshService.cleanup();
});
</file>

<file path="types/index.ts">
// Scraper configuration types
export interface ScraperConfig {
  headless: boolean;
  timeout: number;
  retryAttempts: number;
  retryDelay: number;
  userAgents: string[];
  viewports: Array<{ width: number; height: number }>;
  proxyServer?: string;
  proxyUsername?: string;
  proxyPassword?: string;
}

// Property data structure matching database schema
export interface PropertyData {
  propertyId: string;
  name: string;
  propType: string;
  city: string | null;
  propertyAddress: string;
  assessedValue: number;
  appraisedValue: number;
  geoId: string | null;
  description: string | null;
}

// API request/response types
export interface ScrapeRequest {
  searchTerm: string;
  userId?: string;
}

export interface ScrapeResponse {
  jobId: string;
  message: string;
}

export interface JobStatus {
  id: string;
  status: 'pending' | 'processing' | 'completed' | 'failed';
  progress?: number;
  resultCount?: number;
  error?: string;
  data?: PropertyData[];
  createdAt: Date;
  completedAt?: Date;
}

// Queue job data types
export interface ScrapeJobData {
  searchTerm: string;
  userId?: string;
  scheduled?: boolean;
}

export interface ScrapeJobResult {
  count: number;
  properties: PropertyData[];
  searchTerm: string;
  duration: number;
}
</file>

<file path="types/property.types.ts">
/**
 * TCAD Property Type Definitions with Schema.org Alignment
 *
 * This file provides TypeScript interfaces that align with Schema.org vocabulary
 * for maximum SEO value and semantic clarity. The types are designed to work
 * across frontend, backend, and provide excellent structured data for search engines.
 *
 * Schema.org Types Used:
 * - Place (https://schema.org/Place)
 * - RealEstateListing (https://schema.org/RealEstateListing)
 * - PropertyValue (https://schema.org/PropertyValue)
 * - PostalAddress (https://schema.org/PostalAddress)
 * - MonetaryAmount (https://schema.org/MonetaryAmount)
 * - GeoCoordinates (https://schema.org/GeoCoordinates)
 * - Organization (https://schema.org/Organization)
 * - Person (https://schema.org/Person)
 */

import { z } from 'zod';

// ============================================================================
// Database Level Types (Prisma/Backend)
// ============================================================================

/**
 * Database representation of a property matching Prisma schema
 * Maps to Schema.org: Place + RealEstateListing hybrid
 */
export interface PropertyDatabase {
  id: string;
  propertyId: string;           // TCAD unique identifier
  name: string;                 // Owner/taxpayer name
  propType: string;             // Property classification
  city: string | null;
  propertyAddress: string;
  assessedValue: number | null;  // Tax assessed value
  appraisedValue: number;        // Market appraised value
  geoId: string | null;          // Geographic identifier
  description: string | null;    // Legal description
  searchTerm: string | null;
  scrapedAt: Date;
  createdAt: Date;
  updatedAt: Date;
}

/**
 * Property type enumeration based on common TCAD classifications
 * Maps to Schema.org: @type values for subtypes of Place/Residence
 */
export enum PropertyType {
  SINGLE_FAMILY = 'Single Family',
  CONDO = 'Condo',
  TOWNHOUSE = 'Townhouse',
  MULTI_FAMILY = 'Multi Family',
  COMMERCIAL = 'Commercial',
  INDUSTRIAL = 'Industrial',
  LAND = 'Land',
  AGRICULTURAL = 'Agricultural',
  MIXED_USE = 'Mixed Use'
}

// ============================================================================
// API Level Types (Frontend/API Response)
// ============================================================================

/**
 * API representation with Schema.org alignment
 * Enhanced with semantic annotations for structured data
 * Maps to Schema.org: RealEstateListing
 */
export interface PropertyAPI {
  // Core identification
  '@context'?: 'https://schema.org';
  '@type'?: 'RealEstateListing' | 'Place' | 'Residence';
  '@id'?: string;               // Unique URI for this property

  id: string;
  propertyId: string;           // Schema.org: identifier

  // Ownership (Schema.org: seller/owner)
  owner: PropertyOwner;

  // Property details (Schema.org: name, description)
  propertyType: string;         // Schema.org: additionalType
  legalDescription?: string;    // Schema.org: description

  // Location (Schema.org: address, geo)
  address: PropertyAddress;
  geography?: PropertyGeography;

  // Valuation (Schema.org: offers/priceSpecification)
  valuation: PropertyValuation;

  // Metadata
  metadata: PropertyMetadata;
}

/**
 * Property owner information
 * Maps to Schema.org: Person or Organization
 */
export interface PropertyOwner {
  '@type'?: 'Person' | 'Organization';
  name: string;                 // Schema.org: name
  type?: 'individual' | 'entity'; // Determines Person vs Organization
}

/**
 * Property address with full Schema.org PostalAddress alignment
 */
export interface PropertyAddress {
  '@type'?: 'PostalAddress';
  streetAddress: string;        // Schema.org: streetAddress
  addressLocality?: string;     // Schema.org: addressLocality (city)
  addressRegion: string;        // Schema.org: addressRegion (state)
  addressCountry: string;       // Schema.org: addressCountry
  postalCode?: string;          // Schema.org: postalCode

  // Formatted versions
  formatted: string;            // Full formatted address
  shortFormat?: string;         // Abbreviated format for display
}

/**
 * Geographic information for the property
 * Maps to Schema.org: GeoCoordinates + geo properties
 */
export interface PropertyGeography {
  '@type'?: 'GeoCoordinates';
  geoId?: string;               // TCAD geographic identifier
  latitude?: number;            // Schema.org: latitude
  longitude?: number;           // Schema.org: longitude
  elevation?: number;           // Schema.org: elevation

  // Additional geographic context
  neighborhood?: string;        // Schema.org: containedInPlace
  schoolDistrict?: string;
  taxDistrict?: string;
  censusTract?: string;
}

/**
 * Property valuation information
 * Maps to Schema.org: PriceSpecification / PropertyValue
 */
export interface PropertyValuation {
  '@type'?: 'PropertyValue';

  // Assessed value for tax purposes
  assessedValue?: MonetaryAmount;

  // Market appraisal value
  appraisedValue: MonetaryAmount;

  // Additional valuation details
  landValue?: MonetaryAmount;
  improvementValue?: MonetaryAmount;

  // Tax information
  taxableValue?: MonetaryAmount;
  exemptions?: TaxExemption[];

  // Valuation metadata
  valuationDate?: string;       // ISO 8601 date
  valuationMethod?: string;
}

/**
 * Monetary amount with currency
 * Maps to Schema.org: MonetaryAmount
 */
export interface MonetaryAmount {
  '@type'?: 'MonetaryAmount';
  value: number;                // Schema.org: value
  currency: string;             // Schema.org: currency (e.g., "USD")

  // Display helpers
  formatted?: string;           // e.g., "$450,000"
  abbreviated?: string;         // e.g., "$450K"
}

/**
 * Tax exemption information
 */
export interface TaxExemption {
  type: string;                 // e.g., "Homestead", "Senior", "Veteran"
  amount: MonetaryAmount;
  percentage?: number;          // If percentage-based exemption
}

/**
 * Property metadata for tracking and management
 */
export interface PropertyMetadata {
  searchTerm?: string;          // Search term that found this property
  dataSource: string;           // e.g., "TCAD"
  scrapedAt: string;           // ISO 8601 datetime
  createdAt: string;           // ISO 8601 datetime
  updatedAt: string;           // ISO 8601 datetime
  dataFreshness?: 'current' | 'stale' | 'historical';
  lastVerified?: string;        // ISO 8601 datetime
}

// ============================================================================
// Legacy Validation Schemas (Preserved for backward compatibility)
// ============================================================================

export const scrapeRequestSchema = z.object({
  searchTerm: z.string().min(4, 'Search term must be at least 4 characters').max(100),
  userId: z.string().optional(),
});

export const propertyFilterSchema = z.object({
  searchTerm: z.string().optional(),
  city: z.string().optional(),
  propType: z.string().optional(),
  minValue: z.coerce.number().optional(),
  maxValue: z.coerce.number().optional(),
  limit: z.coerce.number().min(1).max(1000).default(100),
  offset: z.coerce.number().min(0).default(0),
});

export const naturalLanguageSearchSchema = z.object({
  query: z.string().min(1),
  limit: z.number().min(1).max(1000).optional(),
  offset: z.number().min(0).optional(),
});

export const historyQuerySchema = z.object({
  limit: z.coerce.number().min(1).max(100).default(20),
  offset: z.coerce.number().min(0).default(0),
});

export const monitorRequestSchema = z.object({
  searchTerm: z.string().min(1),
  frequency: z.enum(['hourly', 'daily', 'weekly']).default('daily'),
});

// Legacy type exports
export type ScrapeRequestBody = z.infer<typeof scrapeRequestSchema>;
export type PropertyFilters = z.infer<typeof propertyFilterSchema>;
export type NaturalLanguageSearchBody = z.infer<typeof naturalLanguageSearchSchema>;
export type HistoryQueryParams = z.infer<typeof historyQuerySchema>;
export type MonitorRequestBody = z.infer<typeof monitorRequestSchema>;

// ============================================================================
// Enhanced Search and Filter Types
// ============================================================================

/**
 * Search parameters for querying properties
 */
export interface PropertySearchParams {
  query?: string;               // Full text search
  propertyTypes?: PropertyType[];
  cities?: string[];
  priceRange?: {
    min?: number;
    max?: number;
  };
  owner?: string;
  propertyId?: string;
  geoId?: string;

  // Pagination
  limit?: number;
  offset?: number;

  // Sorting
  sortBy?: 'appraisedValue' | 'assessedValue' | 'address' | 'updatedAt';
  sortOrder?: 'asc' | 'desc';
}

// ============================================================================
// Response Types
// ============================================================================

export interface PaginationMeta {
  total: number;
  limit: number;
  offset: number;
  hasMore: boolean;
}

export interface PaginatedResponse<T> {
  data: T[];
  pagination: PaginationMeta;
}

/**
 * Paginated property response with Schema.org alignment
 */
export interface PaginatedPropertyResponse {
  '@context'?: 'https://schema.org';
  '@type'?: 'SearchResultsPage';

  results: PropertyAPI[];
  pagination: PaginationMeta;

  // Aggregations for filtering
  aggregations?: {
    propertyTypes: Array<{ type: string; count: number }>;
    cities: Array<{ city: string; count: number }>;
    priceRanges: Array<{ range: string; count: number }>;
  };
}

export interface JobStatusResponse {
  id: string;
  status: string;
  progress: number;
  resultCount?: number;
  error?: string | null;
  createdAt: Date;
  completedAt: Date | null;
}

export interface StatsResponse {
  totalProperties: number;
  totalJobs: number;
  recentJobs: number;
  cityDistribution: Array<{
    city: string;
    _count: number;
  }>;
  propertyTypeDistribution: Array<{
    propType: string;
    _count: number;
    _avg: {
      appraisedValue: number | null;
    };
  }>;
}

// ============================================================================
// Transformation Utilities
// ============================================================================

/**
 * Transform database property to API format with Schema.org alignment
 */
export function transformPropertyToAPI(
  dbProperty: PropertyDatabase,
  includeSchemaContext = true
): PropertyAPI {
  const [streetAddress, ...addressParts] = dbProperty.propertyAddress.split(',').map(s => s.trim());

  return {
    ...(includeSchemaContext && {
      '@context': 'https://schema.org',
      '@type': getSchemaType(dbProperty.propType),
      '@id': `/properties/${dbProperty.propertyId}`
    }),

    id: dbProperty.id,
    propertyId: dbProperty.propertyId,

    owner: {
      '@type': dbProperty.name.includes('LLC') || dbProperty.name.includes('INC')
        ? 'Organization'
        : 'Person',
      name: dbProperty.name,
      type: dbProperty.name.includes('LLC') || dbProperty.name.includes('INC')
        ? 'entity'
        : 'individual'
    },

    propertyType: dbProperty.propType,
    legalDescription: dbProperty.description || undefined,

    address: {
      '@type': 'PostalAddress',
      streetAddress,
      addressLocality: dbProperty.city || 'Austin',
      addressRegion: 'TX',
      addressCountry: 'US',
      formatted: dbProperty.propertyAddress,
      shortFormat: `${streetAddress}, ${dbProperty.city || 'Austin'}`
    },

    geography: dbProperty.geoId ? {
      '@type': 'GeoCoordinates',
      geoId: dbProperty.geoId
    } : undefined,

    valuation: {
      '@type': 'PropertyValue',
      assessedValue: dbProperty.assessedValue ? {
        '@type': 'MonetaryAmount',
        value: dbProperty.assessedValue,
        currency: 'USD',
        formatted: formatCurrency(dbProperty.assessedValue)
      } : undefined,
      appraisedValue: {
        '@type': 'MonetaryAmount',
        value: dbProperty.appraisedValue,
        currency: 'USD',
        formatted: formatCurrency(dbProperty.appraisedValue)
      }
    },

    metadata: {
      searchTerm: dbProperty.searchTerm || undefined,
      dataSource: 'TCAD',
      scrapedAt: dbProperty.scrapedAt.toISOString(),
      createdAt: dbProperty.createdAt.toISOString(),
      updatedAt: dbProperty.updatedAt.toISOString(),
      dataFreshness: getDataFreshness(dbProperty.scrapedAt)
    }
  };
}

/**
 * Get appropriate Schema.org type based on property type
 */
function getSchemaType(propType: string): 'RealEstateListing' | 'Place' | 'Residence' {
  const commercialTypes = ['Commercial', 'Industrial', 'Mixed Use'];
  const residentialTypes = ['Single Family', 'Condo', 'Townhouse', 'Multi Family'];

  if (commercialTypes.includes(propType)) {
    return 'Place';
  } else if (residentialTypes.includes(propType)) {
    return 'Residence';
  }
  return 'RealEstateListing';
}

/**
 * Format currency for display
 */
function formatCurrency(value: number): string {
  return new Intl.NumberFormat('en-US', {
    style: 'currency',
    currency: 'USD',
    minimumFractionDigits: 0,
    maximumFractionDigits: 0
  }).format(value);
}

/**
 * Determine data freshness based on scrape date
 */
function getDataFreshness(scrapedAt: Date): 'current' | 'stale' | 'historical' {
  const daysSinceUpdate = (Date.now() - scrapedAt.getTime()) / (1000 * 60 * 60 * 24);

  if (daysSinceUpdate < 7) return 'current';
  if (daysSinceUpdate < 30) return 'stale';
  return 'historical';
}

// ============================================================================
// Type Guards
// ============================================================================

export function isPropertyDatabase(obj: any): obj is PropertyDatabase {
  return obj &&
    typeof obj.propertyId === 'string' &&
    typeof obj.name === 'string' &&
    typeof obj.propType === 'string' &&
    typeof obj.propertyAddress === 'string' &&
    typeof obj.appraisedValue === 'number';
}

export function isPropertyAPI(obj: any): obj is PropertyAPI {
  return obj &&
    typeof obj.propertyId === 'string' &&
    obj.owner &&
    obj.address &&
    obj.valuation;
}
</file>

<file path="types/README_ENHANCED.md">
# types

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "SoftwareSourceCode",
  "name": "types",
  "description": "Directory containing 2 code files with 21 classes and 0 functions",
  "programmingLanguage": [
    {
      "@type": "ComputerLanguage",
      "name": "Typescript"
    }
  ],
  "featureList": [
    "21 class definitions"
  ]
}
</script>

## Overview

This directory contains 2 code file(s) with extracted schemas.

## Files and Schemas

### `index.ts` (typescript)

**Classes:**
- `ScraperConfig` - Line 1
- `PropertyData` - Line 14
- `ScrapeRequest` - Line 27
- `ScrapeResponse` - Line 32
- `JobStatus` - Line 37
- `ScrapeJobData` - Line 49
- `ScrapeJobResult` - Line 55

### `property.types.ts` (typescript)

**Classes:**
- `PropertyDatabase` - Line 28
- `PropertyAPI` - Line 70
- `PropertyOwner` - Line 101
- `PropertyAddress` - Line 110
- `PropertyGeography` - Line 127
- `PropertyValuation` - Line 145
- `MonetaryAmount` - Line 171
- `TaxExemption` - Line 184
- `PropertyMetadata` - Line 193
- `PropertySearchParams` - Line 252
- `PaginationMeta` - Line 277
- `PaginatedPropertyResponse` - Line 292
- `JobStatusResponse` - Line 307
- `StatsResponse` - Line 317

---
*Generated by Enhanced Schema Generator with schema.org markup*
</file>

<file path="types/README.md">
# types

## Overview

This directory contains 1 code file(s) with extracted schemas.

## Files and Schemas

### `index.ts` (typescript)

**Classes:**
- `ScraperConfig` - Line 2
- `PropertyData` - Line 12
- `ScrapeRequest` - Line 25
- `ScrapeResponse` - Line 30
- `JobStatus` - Line 35
- `ScrapeJobData` - Line 47
- `ScrapeJobResult` - Line 53

---
*Generated by Schema Generator*
</file>

<file path="types/SCHEMA-DOCUMENTATION.md">
# TCAD Property Schema.org Type System Documentation

## Overview

This document describes the comprehensive TypeScript type system designed for the Travis County Appraisal District (TCAD) property scraper application. The type system aligns with Schema.org vocabulary to provide maximum SEO value and semantic clarity.

## Architecture

### Three-Layer Type System

1. **Database Layer** (`PropertyDatabase`) - Matches Prisma schema exactly
2. **API Layer** (`PropertyAPI`) - Enhanced with Schema.org properties
3. **Presentation Layer** (JSON-LD) - Full Schema.org structured data

## Schema.org Type Mapping

### Primary Schema.org Types Used

| TCAD Property Type | Schema.org Type | Use Case |
|-------------------|-----------------|----------|
| Single Family | `Residence` | Residential homes |
| Condo | `Residence` | Condominiums |
| Townhouse | `Residence` | Townhomes |
| Multi Family | `Residence` | Apartments/Duplexes |
| Commercial | `Place` | Business properties |
| Industrial | `Place` | Industrial facilities |
| Land | `RealEstateListing` | Vacant land |
| Agricultural | `Place` | Farms/Ranches |
| Mixed Use | `Place` | Mixed-use buildings |

### Property Components Schema Mapping

| Component | Schema.org Type | Properties |
|-----------|-----------------|------------|
| Address | `PostalAddress` | streetAddress, addressLocality, addressRegion, postalCode |
| Location | `GeoCoordinates` | latitude, longitude, elevation |
| Owner | `Person` / `Organization` | name, type |
| Valuation | `PropertyValue` / `MonetaryAmount` | value, currency |
| Tax Info | `PriceSpecification` | price, name, description |

## Type Definitions

### Core Types

```typescript
// Database representation (Prisma)
PropertyDatabase

// API representation (Frontend/Backend)
PropertyAPI

// Search/Filter types
PropertySearchParams
PaginatedPropertyResponse

// Supporting types
PropertyOwner
PropertyAddress
PropertyGeography
PropertyValuation
MonetaryAmount
TaxExemption
```

## Implementation Examples

### 1. Transform Database to API Format

```typescript
import { transformPropertyToAPI } from './types/property.types';

const dbProperty = await prisma.property.findUnique({
  where: { propertyId: 'TCAD-123456' }
});

const apiProperty = transformPropertyToAPI(dbProperty);
```

### 2. Generate JSON-LD for SEO

```typescript
import { generatePropertyJsonLd } from './utils/json-ld.utils';

const jsonLd = generatePropertyJsonLd(
  apiProperty,
  'Travis County Appraisal District',
  'https://example.com'
);

// Inject into HTML
const script = `<script type="application/ld+json">
${JSON.stringify(jsonLd, null, 2)}
</script>`;
```

### 3. API Response with Schema.org

```typescript
app.get('/api/properties/:id', async (req, res) => {
  const property = await getProperty(req.params.id);
  const apiProperty = transformPropertyToAPI(property);

  res.json({
    '@context': 'https://schema.org',
    ...apiProperty
  });
});
```

### 4. Property Listing Page

```typescript
app.get('/api/properties', async (req, res) => {
  const properties = await searchProperties(req.query);

  const response: PaginatedPropertyResponse = {
    '@context': 'https://schema.org',
    '@type': 'SearchResultsPage',
    results: properties.map(p => transformPropertyToAPI(p)),
    pagination: {
      total: totalCount,
      limit: 20,
      offset: 0,
      hasMore: true
    }
  };

  res.json(response);
});
```

## SEO Benefits

### Rich Results Eligibility

The Schema.org implementation enables:

1. **Property Rich Cards** - Enhanced search results with images, prices, and details
2. **Breadcrumb Navigation** - Clear site hierarchy in search results
3. **Site Search Box** - Direct search from Google results
4. **Knowledge Graph** - Entity recognition for properties and locations
5. **Local Search** - Enhanced local business/property listings

### Structured Data Features

- **Price Range Display** - Shows min/max prices in search results
- **Location Mapping** - Geographic coordinates for map integration
- **Owner Information** - Clear entity attribution
- **Tax Information** - Detailed financial breakdowns
- **Property Classifications** - Clear categorization for filtering

## JSON-LD Examples

### Individual Property

```json
{
  "@context": "https://schema.org",
  "@type": "RealEstateListing",
  "@id": "https://example.com/properties/TCAD-123456",
  "identifier": "TCAD-123456",
  "name": "123 Main St, Austin TX",
  "address": {
    "@type": "PostalAddress",
    "streetAddress": "123 Main St",
    "addressLocality": "Austin",
    "addressRegion": "TX",
    "addressCountry": "US",
    "postalCode": "78701"
  },
  "offers": {
    "@type": "Offer",
    "price": 450000,
    "priceCurrency": "USD"
  }
}
```

### Property Collection

```json
{
  "@context": "https://schema.org",
  "@type": "ItemList",
  "name": "Austin Properties",
  "numberOfItems": 100,
  "itemListElement": [
    {
      "@type": "ListItem",
      "position": 1,
      "item": {
        "@type": "RealEstateListing",
        "identifier": "TCAD-123456",
        "name": "123 Main St"
      }
    }
  ]
}
```

## Validation

### Schema.org Validation Tools

1. **Google Rich Results Test**: https://search.google.com/test/rich-results
2. **Schema.org Validator**: https://validator.schema.org/
3. **Google Search Console**: Monitor rich results performance

### TypeScript Type Validation

```typescript
import { isPropertyAPI, isPropertyDatabase } from './types/property.types';

// Runtime type guards
if (isPropertyAPI(data)) {
  // Safe to use as PropertyAPI
}

// Compile-time validation with Zod
import { propertyFilterSchema } from './types/property.types';

const filters = propertyFilterSchema.parse(req.query);
```

## Best Practices

### 1. Always Include Context

```typescript
// Good
const property: PropertyAPI = {
  '@context': 'https://schema.org',
  '@type': 'RealEstateListing',
  // ...
};

// Bad - missing context
const property = {
  propertyId: '123',
  // ...
};
```

### 2. Use Specific Schema Types

```typescript
// Good - specific type
'@type': 'Residence'  // for residential properties

// Bad - generic type
'@type': 'Thing'
```

### 3. Include All Recommended Properties

Essential properties for rich results:
- `name` - Property title
- `address` - Full postal address
- `offers.price` - Current value
- `geo` - Coordinates when available
- `image` - Property photos (when available)

### 4. Maintain Data Consistency

```typescript
// Ensure consistency between visible content and structured data
<h1>{property.address.formatted}</h1>  // Visible
"name": "123 Main St, Austin TX"       // Structured data matches
```

### 5. Update Timestamps

```typescript
metadata: {
  scrapedAt: new Date().toISOString(),
  dataFreshness: getDataFreshness(scrapedAt),
  lastVerified: new Date().toISOString()
}
```

## Migration Guide

### From Legacy Types to Schema.org Types

```typescript
// Legacy
interface OldProperty {
  property_id: string;
  owner_name: string;
  value: number;
}

// New Schema.org aligned
interface PropertyAPI {
  propertyId: string;
  owner: {
    '@type': 'Person',
    name: string;
  };
  valuation: {
    appraisedValue: {
      '@type': 'MonetaryAmount',
      value: number;
      currency: 'USD';
    };
  };
}
```

## Testing

### Unit Tests

```typescript
describe('Property Type Transformations', () => {
  it('should transform database property to API format', () => {
    const dbProperty: PropertyDatabase = mockDbProperty();
    const apiProperty = transformPropertyToAPI(dbProperty);

    expect(apiProperty['@context']).toBe('https://schema.org');
    expect(apiProperty['@type']).toMatch(/RealEstateListing|Residence|Place/);
    expect(apiProperty.address['@type']).toBe('PostalAddress');
  });
});
```

### Validation Tests

```typescript
describe('JSON-LD Validation', () => {
  it('should generate valid structured data', () => {
    const jsonLd = generatePropertyJsonLd(mockProperty);
    const errors = validateJsonLd(jsonLd);

    expect(errors).toHaveLength(0);
  });
});
```

## Performance Considerations

1. **Lazy Loading** - Include full Schema.org context only when needed
2. **Caching** - Cache transformed API responses
3. **Selective Fields** - Use `includeSchemaContext` parameter
4. **Batch Processing** - Transform multiple properties efficiently

## Future Enhancements

1. **Additional Schema Types**
   - `ApartmentComplex` for multi-family
   - `Office` for commercial properties
   - `Store` for retail properties

2. **Enhanced Geographic Data**
   - School district boundaries
   - Neighborhood polygons
   - Transit accessibility

3. **Historical Data**
   - `PriceSpecification` with date ranges
   - Value trend graphs
   - Tax history

4. **Images and Media**
   - `ImageObject` for property photos
   - `VideoObject` for virtual tours
   - `3DModel` for interactive views

## Resources

- [Schema.org Documentation](https://schema.org/)
- [Google Structured Data Guide](https://developers.google.com/search/docs/appearance/structured-data)
- [JSON-LD Specification](https://json-ld.org/)
- [TypeScript Handbook](https://www.typescriptlang.org/docs/)
</file>

<file path="utils/__tests__/deduplication.test.ts">
import { removeDuplicatesFromQueue } from '../deduplication';

// Mock dependencies
jest.mock('../../queues/scraper.queue', () => ({
  scraperQueue: {
    getWaiting: jest.fn(),
    getDelayed: jest.fn(),
  },
}));

jest.mock('../../lib/prisma', () => ({
  prisma: {
    scrapeJob: {
      findMany: jest.fn(),
    },
  },
}));

jest.mock('../../lib/logger', () => ({
  info: jest.fn(),
  error: jest.fn(),
  warn: jest.fn(),
  debug: jest.fn(),
}));

describe('removeDuplicatesFromQueue', () => {
  let scraperQueue: any;
  let prisma: any;
  let logger: any;

  beforeEach(() => {
    jest.clearAllMocks();

    const scraperQueueModule = require('../../queues/scraper.queue');
    scraperQueue = scraperQueueModule.scraperQueue;

    const prismaModule = require('../../lib/prisma');
    prisma = prismaModule.prisma;

    logger = require('../../lib/logger');
  });

  describe('with no duplicates', () => {
    it('should return zero removed when queue is empty', async () => {
      scraperQueue.getWaiting.mockResolvedValue([]);
      scraperQueue.getDelayed.mockResolvedValue([]);
      prisma.scrapeJob.findMany.mockResolvedValue([]);

      const result = await removeDuplicatesFromQueue({ verbose: false });

      expect(result).toEqual({ removed: 0, failed: 0 });
      expect(scraperQueue.getWaiting).toHaveBeenCalled();
      expect(scraperQueue.getDelayed).toHaveBeenCalled();
    });

    it('should return zero removed when no duplicates exist', async () => {
      const mockJobs = [
        {
          id: 'job-1',
          data: { searchTerm: 'Smith' },
          opts: { priority: 10 },
          remove: jest.fn(),
        },
        {
          id: 'job-2',
          data: { searchTerm: 'Johnson' },
          opts: { priority: 10 },
          remove: jest.fn(),
        },
      ];

      scraperQueue.getWaiting.mockResolvedValue(mockJobs);
      scraperQueue.getDelayed.mockResolvedValue([]);
      prisma.scrapeJob.findMany.mockResolvedValue([]);

      const result = await removeDuplicatesFromQueue({ verbose: false });

      expect(result).toEqual({ removed: 0, failed: 0 });
      expect(mockJobs[0].remove).not.toHaveBeenCalled();
      expect(mockJobs[1].remove).not.toHaveBeenCalled();
    });
  });

  describe('with duplicate pending jobs', () => {
    it('should remove duplicate pending jobs and keep highest priority', async () => {
      const mockJobs = [
        {
          id: 'job-1',
          data: { searchTerm: 'Smith' },
          opts: { priority: 5 }, // Higher priority (lower number)
          remove: jest.fn().mockResolvedValue(true),
        },
        {
          id: 'job-2',
          data: { searchTerm: 'Smith' },
          opts: { priority: 10 }, // Lower priority (higher number)
          remove: jest.fn().mockResolvedValue(true),
        },
        {
          id: 'job-3',
          data: { searchTerm: 'Smith' },
          opts: { priority: 15 }, // Lowest priority
          remove: jest.fn().mockResolvedValue(true),
        },
      ];

      scraperQueue.getWaiting.mockResolvedValue(mockJobs);
      scraperQueue.getDelayed.mockResolvedValue([]);
      prisma.scrapeJob.findMany.mockResolvedValue([]);

      const result = await removeDuplicatesFromQueue({ verbose: false });

      expect(result.removed).toBe(2); // Remove 2 out of 3
      expect(mockJobs[0].remove).not.toHaveBeenCalled(); // Keep highest priority
      expect(mockJobs[1].remove).toHaveBeenCalled(); // Remove
      expect(mockJobs[2].remove).toHaveBeenCalled(); // Remove
    });

    it('should handle jobs with no priority (default to 10)', async () => {
      const mockJobs = [
        {
          id: 'job-1',
          data: { searchTerm: 'Smith' },
          opts: {}, // No priority
          remove: jest.fn().mockResolvedValue(true),
        },
        {
          id: 'job-2',
          data: { searchTerm: 'Smith' },
          opts: { priority: 15 },
          remove: jest.fn().mockResolvedValue(true),
        },
      ];

      scraperQueue.getWaiting.mockResolvedValue(mockJobs);
      scraperQueue.getDelayed.mockResolvedValue([]);
      prisma.scrapeJob.findMany.mockResolvedValue([]);

      const result = await removeDuplicatesFromQueue({ verbose: false });

      expect(result.removed).toBe(1);
      expect(mockJobs[0].remove).not.toHaveBeenCalled(); // Default priority 10 < 15
      expect(mockJobs[1].remove).toHaveBeenCalled();
    });

    it('should handle multiple duplicate groups', async () => {
      const mockJobs = [
        {
          id: 'job-1',
          data: { searchTerm: 'Smith' },
          opts: { priority: 10 },
          remove: jest.fn().mockResolvedValue(true),
        },
        {
          id: 'job-2',
          data: { searchTerm: 'Smith' },
          opts: { priority: 10 },
          remove: jest.fn().mockResolvedValue(true),
        },
        {
          id: 'job-3',
          data: { searchTerm: 'Johnson' },
          opts: { priority: 10 },
          remove: jest.fn().mockResolvedValue(true),
        },
        {
          id: 'job-4',
          data: { searchTerm: 'Johnson' },
          opts: { priority: 10 },
          remove: jest.fn().mockResolvedValue(true),
        },
      ];

      scraperQueue.getWaiting.mockResolvedValue(mockJobs);
      scraperQueue.getDelayed.mockResolvedValue([]);
      prisma.scrapeJob.findMany.mockResolvedValue([]);

      const result = await removeDuplicatesFromQueue({ verbose: false });

      expect(result.removed).toBe(2); // Remove 1 from each group
    });
  });

  describe('with already completed terms', () => {
    it('should remove all pending jobs for completed terms', async () => {
      const mockJobs = [
        {
          id: 'job-1',
          data: { searchTerm: 'Smith' },
          opts: { priority: 10 },
          remove: jest.fn().mockResolvedValue(true),
        },
        {
          id: 'job-2',
          data: { searchTerm: 'Smith' },
          opts: { priority: 10 },
          remove: jest.fn().mockResolvedValue(true),
        },
      ];

      scraperQueue.getWaiting.mockResolvedValue(mockJobs);
      scraperQueue.getDelayed.mockResolvedValue([]);
      prisma.scrapeJob.findMany.mockResolvedValue([
        { searchTerm: 'Smith' }, // Already completed
      ]);

      const result = await removeDuplicatesFromQueue({ verbose: false });

      // Note: These 2 jobs are both duplicates AND completed, so they get removed
      // by both the duplicate removal logic and the completed term logic
      // This results in 3 removals (1 from duplicate handling + 2 from completed handling)
      expect(result.removed).toBe(3);
      expect(mockJobs[0].remove).toHaveBeenCalled();
      expect(mockJobs[1].remove).toHaveBeenCalled();
    });

    it('should handle mix of completed and unique terms', async () => {
      const mockJobs = [
        {
          id: 'job-1',
          data: { searchTerm: 'Smith' }, // Already completed
          opts: { priority: 10 },
          remove: jest.fn().mockResolvedValue(true),
        },
        {
          id: 'job-2',
          data: { searchTerm: 'Johnson' }, // Not completed
          opts: { priority: 10 },
          remove: jest.fn().mockResolvedValue(true),
        },
      ];

      scraperQueue.getWaiting.mockResolvedValue(mockJobs);
      scraperQueue.getDelayed.mockResolvedValue([]);
      prisma.scrapeJob.findMany.mockResolvedValue([
        { searchTerm: 'Smith' },
      ]);

      const result = await removeDuplicatesFromQueue({ verbose: false });

      expect(result.removed).toBe(1);
      expect(mockJobs[0].remove).toHaveBeenCalled();
      expect(mockJobs[1].remove).not.toHaveBeenCalled();
    });
  });

  describe('with both waiting and delayed jobs', () => {
    it('should process jobs from both queues', async () => {
      const waitingJobs = [
        {
          id: 'job-1',
          data: { searchTerm: 'Smith' },
          opts: { priority: 10 },
          remove: jest.fn().mockResolvedValue(true),
        },
      ];

      const delayedJobs = [
        {
          id: 'job-2',
          data: { searchTerm: 'Smith' },
          opts: { priority: 10 },
          remove: jest.fn().mockResolvedValue(true),
        },
      ];

      scraperQueue.getWaiting.mockResolvedValue(waitingJobs);
      scraperQueue.getDelayed.mockResolvedValue(delayedJobs);
      prisma.scrapeJob.findMany.mockResolvedValue([]);

      const result = await removeDuplicatesFromQueue({ verbose: false });

      expect(result.removed).toBe(1);
    });
  });

  describe('error handling', () => {
    it('should continue removing jobs even if some fail', async () => {
      const mockJobs = [
        {
          id: 'job-1',
          data: { searchTerm: 'Smith' },
          opts: { priority: 10 },
          remove: jest.fn().mockResolvedValue(true),
        },
        {
          id: 'job-2',
          data: { searchTerm: 'Smith' },
          opts: { priority: 10 },
          remove: jest.fn().mockRejectedValue(new Error('Remove failed')),
        },
        {
          id: 'job-3',
          data: { searchTerm: 'Smith' },
          opts: { priority: 10 },
          remove: jest.fn().mockResolvedValue(true),
        },
      ];

      scraperQueue.getWaiting.mockResolvedValue(mockJobs);
      scraperQueue.getDelayed.mockResolvedValue([]);
      prisma.scrapeJob.findMany.mockResolvedValue([]);

      const result = await removeDuplicatesFromQueue({ verbose: false });

      expect(result.removed).toBe(1); // 2 attempts, 1 success, 1 failure
      expect(result.failed).toBe(1);
    });

    it('should track multiple failures correctly', async () => {
      const mockJobs = [
        {
          id: 'job-1',
          data: { searchTerm: 'Smith' },
          opts: { priority: 10 },
          remove: jest.fn().mockResolvedValue(true),
        },
        {
          id: 'job-2',
          data: { searchTerm: 'Smith' },
          opts: { priority: 10 },
          remove: jest.fn().mockRejectedValue(new Error('Failed 1')),
        },
        {
          id: 'job-3',
          data: { searchTerm: 'Smith' },
          opts: { priority: 10 },
          remove: jest.fn().mockRejectedValue(new Error('Failed 2')),
        },
      ];

      scraperQueue.getWaiting.mockResolvedValue(mockJobs);
      scraperQueue.getDelayed.mockResolvedValue([]);
      prisma.scrapeJob.findMany.mockResolvedValue([]);

      const result = await removeDuplicatesFromQueue({ verbose: false });

      expect(result.failed).toBe(2);
      expect(result.removed).toBe(0);
    });

    it('should handle failures when removing completed terms', async () => {
      // Use only one job to avoid duplicate removal logic
      const mockJobs = [
        {
          id: 'job-1',
          data: { searchTerm: 'CompletedTerm' },
          opts: { priority: 10 },
          remove: jest.fn().mockRejectedValue(new Error('Remove failed for completed term')),
        },
      ];

      scraperQueue.getWaiting.mockResolvedValue(mockJobs);
      scraperQueue.getDelayed.mockResolvedValue([]);
      prisma.scrapeJob.findMany.mockResolvedValue([
        { searchTerm: 'CompletedTerm' },
      ]);

      const result = await removeDuplicatesFromQueue({ verbose: true, showProgress: false });

      expect(result.failed).toBe(1);
      expect(result.removed).toBe(0);
      expect(logger.error).toHaveBeenCalled();
    });
  });

  describe('verbose logging', () => {
    it('should log information when verbose is true', async () => {
      const mockJobs = [
        {
          id: 'job-1',
          data: { searchTerm: 'Smith' },
          opts: { priority: 10 },
          remove: jest.fn().mockResolvedValue(true),
        },
        {
          id: 'job-2',
          data: { searchTerm: 'Smith' },
          opts: { priority: 10 },
          remove: jest.fn().mockResolvedValue(true),
        },
      ];

      scraperQueue.getWaiting.mockResolvedValue(mockJobs);
      scraperQueue.getDelayed.mockResolvedValue([]);
      prisma.scrapeJob.findMany.mockResolvedValue([]);

      await removeDuplicatesFromQueue({ verbose: true, showProgress: false });

      expect(logger.info).toHaveBeenCalled();
      expect(logger.info).toHaveBeenCalledWith(
        expect.stringContaining('checking for duplicates')
      );
    });

    it('should not log when verbose is false', async () => {
      scraperQueue.getWaiting.mockResolvedValue([]);
      scraperQueue.getDelayed.mockResolvedValue([]);
      prisma.scrapeJob.findMany.mockResolvedValue([]);

      await removeDuplicatesFromQueue({ verbose: false });

      expect(logger.info).not.toHaveBeenCalled();
    });

    it('should log "No duplicates found" when verbose and queue is clean', async () => {
      scraperQueue.getWaiting.mockResolvedValue([]);
      scraperQueue.getDelayed.mockResolvedValue([]);
      prisma.scrapeJob.findMany.mockResolvedValue([]);

      await removeDuplicatesFromQueue({ verbose: true });

      expect(logger.info).toHaveBeenCalledWith(
        expect.stringContaining('No duplicates or completed terms found')
      );
    });

    it('should log errors for failed removals when verbose', async () => {
      const mockJobs = [
        {
          id: 'job-1',
          data: { searchTerm: 'Smith' },
          opts: { priority: 10 },
          remove: jest.fn().mockResolvedValue(true),
        },
        {
          id: 'job-2',
          data: { searchTerm: 'Smith' },
          opts: { priority: 10 },
          remove: jest.fn().mockRejectedValue(new Error('Remove failed')),
        },
      ];

      scraperQueue.getWaiting.mockResolvedValue(mockJobs);
      scraperQueue.getDelayed.mockResolvedValue([]);
      prisma.scrapeJob.findMany.mockResolvedValue([]);

      await removeDuplicatesFromQueue({ verbose: true, showProgress: false });

      expect(logger.error).toHaveBeenCalled();
    });

    it('should show "... and X more" when more than 10 duplicate terms', async () => {
      // Create 15 different search terms, each with 2 duplicate jobs
      const mockJobs = [];
      for (let i = 0; i < 15; i++) {
        mockJobs.push(
          {
            id: `job-${i}-1`,
            data: { searchTerm: `Term${i}` },
            opts: { priority: 10 },
            remove: jest.fn().mockResolvedValue(true),
          },
          {
            id: `job-${i}-2`,
            data: { searchTerm: `Term${i}` },
            opts: { priority: 15 },
            remove: jest.fn().mockResolvedValue(true),
          }
        );
      }

      scraperQueue.getWaiting.mockResolvedValue(mockJobs);
      scraperQueue.getDelayed.mockResolvedValue([]);
      prisma.scrapeJob.findMany.mockResolvedValue([]);

      await removeDuplicatesFromQueue({ verbose: true, showProgress: true });

      expect(logger.info).toHaveBeenCalledWith(
        expect.stringContaining('... and 5 more')
      );
    });

    it('should show "... and X more" when more than 20 completed terms', async () => {
      // Create 25 different completed terms, each with 1 pending job
      const mockJobs = [];
      const completedTerms = [];
      for (let i = 0; i < 25; i++) {
        mockJobs.push({
          id: `job-${i}`,
          data: { searchTerm: `CompletedTerm${i}` },
          opts: { priority: 10 },
          remove: jest.fn().mockResolvedValue(true),
        });
        completedTerms.push({ searchTerm: `CompletedTerm${i}` });
      }

      scraperQueue.getWaiting.mockResolvedValue(mockJobs);
      scraperQueue.getDelayed.mockResolvedValue([]);
      prisma.scrapeJob.findMany.mockResolvedValue(completedTerms);

      await removeDuplicatesFromQueue({ verbose: true, showProgress: true });

      expect(logger.info).toHaveBeenCalledWith(
        expect.stringContaining('... and 5 more')
      );
    });
  });

  describe('progress reporting', () => {
    it('should show progress when showProgress is true and removing many jobs', async () => {
      // Create enough duplicate jobs to trigger progress reporting (10+ removals)
      const mockJobs = [];
      for (let i = 0; i < 12; i++) {
        mockJobs.push(
          {
            id: `job-${i}-1`,
            data: { searchTerm: 'DuplicateTerm' },
            opts: { priority: 10 },
            remove: jest.fn().mockResolvedValue(true),
          }
        );
      }

      // Mock process.stdout.write to verify progress output
      const stdoutWriteSpy = jest.spyOn(process.stdout, 'write').mockImplementation();

      scraperQueue.getWaiting.mockResolvedValue(mockJobs);
      scraperQueue.getDelayed.mockResolvedValue([]);
      prisma.scrapeJob.findMany.mockResolvedValue([]);

      await removeDuplicatesFromQueue({ verbose: true, showProgress: true });

      // Should have written progress at 10 removals
      expect(stdoutWriteSpy).toHaveBeenCalledWith(
        expect.stringContaining('Progress: 10/')
      );

      stdoutWriteSpy.mockRestore();
    });

    it('should not show progress when showProgress is false', async () => {
      const mockJobs = [];
      for (let i = 0; i < 12; i++) {
        mockJobs.push(
          {
            id: `job-${i}-1`,
            data: { searchTerm: 'DuplicateTerm' },
            opts: { priority: 10 },
            remove: jest.fn().mockResolvedValue(true),
          }
        );
      }

      const stdoutWriteSpy = jest.spyOn(process.stdout, 'write').mockImplementation();

      scraperQueue.getWaiting.mockResolvedValue(mockJobs);
      scraperQueue.getDelayed.mockResolvedValue([]);
      prisma.scrapeJob.findMany.mockResolvedValue([]);

      await removeDuplicatesFromQueue({ verbose: true, showProgress: false });

      // Should not have written any progress
      expect(stdoutWriteSpy).not.toHaveBeenCalled();

      stdoutWriteSpy.mockRestore();
    });

    it('should log new line after progress when verbose and showProgress', async () => {
      const mockJobs = [];
      for (let i = 0; i < 12; i++) {
        mockJobs.push({
          id: `job-${i}`,
          data: { searchTerm: 'CompletedTerm' },
          opts: { priority: 10 },
          remove: jest.fn().mockResolvedValue(true),
        });
      }

      scraperQueue.getWaiting.mockResolvedValue(mockJobs);
      scraperQueue.getDelayed.mockResolvedValue([]);
      prisma.scrapeJob.findMany.mockResolvedValue([
        { searchTerm: 'CompletedTerm' },
      ]);

      await removeDuplicatesFromQueue({ verbose: true, showProgress: true });

      // Should log empty string for new line after progress (line 172)
      expect(logger.info).toHaveBeenCalledWith('');
    });
  });

  describe('complex scenarios', () => {
    it('should handle combination of duplicates and completed terms', async () => {
      const mockJobs = [
        // Duplicates for 'Smith' (2 jobs)
        {
          id: 'job-1',
          data: { searchTerm: 'Smith' },
          opts: { priority: 5 },
          remove: jest.fn().mockResolvedValue(true),
        },
        {
          id: 'job-2',
          data: { searchTerm: 'Smith' },
          opts: { priority: 10 },
          remove: jest.fn().mockResolvedValue(true),
        },
        // Already completed 'Johnson' (should remove all)
        {
          id: 'job-3',
          data: { searchTerm: 'Johnson' },
          opts: { priority: 10 },
          remove: jest.fn().mockResolvedValue(true),
        },
        // Unique 'Williams' (should keep)
        {
          id: 'job-4',
          data: { searchTerm: 'Williams' },
          opts: { priority: 10 },
          remove: jest.fn().mockResolvedValue(true),
        },
      ];

      scraperQueue.getWaiting.mockResolvedValue(mockJobs);
      scraperQueue.getDelayed.mockResolvedValue([]);
      prisma.scrapeJob.findMany.mockResolvedValue([
        { searchTerm: 'Johnson' },
      ]);

      const result = await removeDuplicatesFromQueue({ verbose: false });

      // Should remove: 1 duplicate Smith + 1 completed Johnson = 2 total
      expect(result.removed).toBe(2);
      expect(mockJobs[0].remove).not.toHaveBeenCalled(); // Keep high priority Smith
      expect(mockJobs[1].remove).toHaveBeenCalled(); // Remove duplicate Smith
      expect(mockJobs[2].remove).toHaveBeenCalled(); // Remove completed Johnson
      expect(mockJobs[3].remove).not.toHaveBeenCalled(); // Keep unique Williams
    });

    it('should handle empty searchTerm gracefully', async () => {
      const mockJobs = [
        {
          id: 'job-1',
          data: { searchTerm: '' },
          opts: { priority: 10 },
          remove: jest.fn().mockResolvedValue(true),
        },
        {
          id: 'job-2',
          data: { searchTerm: '' },
          opts: { priority: 10 },
          remove: jest.fn().mockResolvedValue(true),
        },
      ];

      scraperQueue.getWaiting.mockResolvedValue(mockJobs);
      scraperQueue.getDelayed.mockResolvedValue([]);
      prisma.scrapeJob.findMany.mockResolvedValue([]);

      const result = await removeDuplicatesFromQueue({ verbose: false });

      expect(result.removed).toBe(1); // Treat empty strings as duplicates
    });
  });
});
</file>

<file path="utils/__tests__/json-ld.utils.test.ts">
import {
  generatePropertyJsonLd,
  generatePropertyListJsonLd,
  generateOrganizationJsonLd,
  generateBreadcrumbJsonLd,
  generatePropertyCollectionJsonLd,
  injectJsonLdScript,
  generatePageJsonLd,
  validateJsonLd,
} from '../json-ld.utils';
import { PropertyAPI, PaginatedPropertyResponse } from '../../types/property.types';

describe('JSON-LD Utils', () => {
  const mockProperty: PropertyAPI = {
    '@type': 'RealEstateListing',
    propertyId: 'TEST-123',
    address: {
      formatted: '123 Main St, Austin, TX 78701',
      shortFormat: '123 Main St',
      streetAddress: '123 Main St',
      addressLocality: 'Austin',
      addressRegion: 'TX',
      addressCountry: 'US',
      postalCode: '78701',
    },
    propertyType: 'Residential',
    owner: {
      '@type': 'Person',
      name: 'John Doe',
    },
    valuation: {
      appraisedValue: {
        value: 500000,
        currency: 'USD',
        formatted: '$500,000',
      },
      assessedValue: {
        value: 450000,
        currency: 'USD',
        formatted: '$450,000',
      },
    },
    geography: {
      latitude: 30.2672,
      longitude: -97.7431,
      neighborhood: 'Downtown',
    },
    legalDescription: 'Lot 5, Block 3, Downtown Addition',
    metadata: {
      createdAt: '2024-01-01T00:00:00Z',
      updatedAt: '2024-01-02T00:00:00Z',
      scrapedAt: '2024-01-01T00:00:00Z',
      dataFreshness: 'fresh' as const,
    },
  };

  describe('generatePropertyJsonLd', () => {
    it('should generate valid property JSON-LD with all fields', () => {
      const result = generatePropertyJsonLd(mockProperty, 'TCAD', 'https://example.com');

      expect(result).toMatchObject({
        '@context': 'https://schema.org',
        '@type': 'RealEstateListing',
        '@id': 'https://example.com/properties/TEST-123',
        identifier: 'TEST-123',
        name: '123 Main St, Austin, TX 78701 - TCAD Property',
      });
    });

    it('should include address information', () => {
      const result = generatePropertyJsonLd(mockProperty) as any;

      expect(result.address).toEqual({
        '@type': 'PostalAddress',
        streetAddress: '123 Main St',
        addressLocality: 'Austin',
        addressRegion: 'TX',
        addressCountry: 'US',
        postalCode: '78701',
      });
    });

    it('should include geographic coordinates when available', () => {
      const result = generatePropertyJsonLd(mockProperty) as any;

      expect(result.geo).toEqual({
        '@type': 'GeoCoordinates',
        latitude: 30.2672,
        longitude: -97.7431,
      });
    });

    it('should include owner/seller information', () => {
      const result = generatePropertyJsonLd(mockProperty) as any;

      expect(result.seller).toEqual({
        '@type': 'Person',
        name: 'John Doe',
      });
    });

    it('should include pricing offers', () => {
      const result = generatePropertyJsonLd(mockProperty) as any;

      expect(result.offers).toMatchObject({
        '@type': 'Offer',
        price: 500000,
        priceCurrency: 'USD',
      });
    });

    it('should include both appraised and assessed values in price specifications', () => {
      const result = generatePropertyJsonLd(mockProperty) as any;

      expect(result.offers.priceSpecification).toHaveLength(2);
      expect(result.offers.priceSpecification[0]).toMatchObject({
        '@type': 'PriceSpecification',
        price: 500000,
        name: 'Appraised Value',
      });
      expect(result.offers.priceSpecification[1]).toMatchObject({
        '@type': 'PriceSpecification',
        price: 450000,
        name: 'Assessed Value',
      });
    });

    it('should work without optional fields', () => {
      const minimalProperty: PropertyAPI = {
        propertyId: 'MIN-123',
        address: {
          formatted: '456 Oak Ave',
          streetAddress: '456 Oak Ave',
          addressLocality: 'Austin',
          addressRegion: 'TX',
          addressCountry: 'US',
        },
        propertyType: 'Commercial',
        valuation: {
          appraisedValue: {
            value: 1000000,
            currency: 'USD',
            formatted: '$1,000,000',
          },
        },
        metadata: {
          createdAt: '2024-01-01T00:00:00Z',
          updatedAt: '2024-01-01T00:00:00Z',
          scrapedAt: '2024-01-01T00:00:00Z',
          dataFreshness: 'fresh' as const,
        },
      };

      const result = generatePropertyJsonLd(minimalProperty) as any;

      expect(result['@type']).toBe('RealEstateListing');
      expect(result.identifier).toBe('MIN-123');
      expect(result.geo).toBeUndefined();
      expect(result.seller).toBeUndefined();
    });
  });

  describe('generatePropertyListJsonLd', () => {
    const mockResponse: PaginatedPropertyResponse = {
      results: [mockProperty],
      pagination: {
        total: 1,
        offset: 0,
        limit: 20,
        hasMore: false,
      },
    };

    it('should generate valid ItemList JSON-LD', () => {
      const result = generatePropertyListJsonLd(mockResponse);

      expect(result).toMatchObject({
        '@context': 'https://schema.org',
        '@type': 'ItemList',
        numberOfItems: 1,
      });
    });

    it('should include search query in name when provided', () => {
      const result = generatePropertyListJsonLd(mockResponse, 'Austin homes') as any;

      expect(result.name).toBe('Property Search Results for "Austin homes"');
    });

    it('should use default name when no search query', () => {
      const result = generatePropertyListJsonLd(mockResponse) as any;

      expect(result.name).toBe('Travis County Properties');
    });

    it('should include list items with correct positions', () => {
      const result = generatePropertyListJsonLd(mockResponse) as any;

      expect(result.itemListElement).toHaveLength(1);
      expect(result.itemListElement[0]).toMatchObject({
        '@type': 'ListItem',
        position: 1,
      });
    });

    it('should include item details for each property', () => {
      const result = generatePropertyListJsonLd(mockResponse) as any;

      expect(result.itemListElement[0].item).toMatchObject({
        '@type': 'RealEstateListing',
        '@id': 'https://example.com/properties/TEST-123',
        identifier: 'TEST-123',
        name: '123 Main St, Austin, TX 78701',
      });
    });

    it('should include nextItem when hasMore is true', () => {
      const responseWithMore: PaginatedPropertyResponse = {
        ...mockResponse,
        pagination: {
          ...mockResponse.pagination,
          hasMore: true,
        },
      };

      const result = generatePropertyListJsonLd(responseWithMore) as any;

      expect(result.nextItem).toBeDefined();
      expect(result.nextItem).toContain('offset=20');
    });

    it('should not include nextItem when hasMore is false', () => {
      const result = generatePropertyListJsonLd(mockResponse) as any;

      expect(result.nextItem).toBeUndefined();
    });

    it('should include search action', () => {
      const result = generatePropertyListJsonLd(mockResponse) as any;

      expect(result.potentialAction).toMatchObject({
        '@type': 'SearchAction',
        'query-input': 'required name=search_term_string',
      });
    });
  });

  describe('generateOrganizationJsonLd', () => {
    it('should generate valid WebSite JSON-LD with defaults', () => {
      const result = generateOrganizationJsonLd() as any;

      expect(result['@context']).toBe('https://schema.org');
      expect(result['@type']).toBe('WebSite');
      expect(result.name).toBeDefined();
      expect(result.url).toBeDefined();
    });

    it('should use custom website URL', () => {
      const result = generateOrganizationJsonLd('https://custom.com') as any;

      expect(result.url).toBe('https://custom.com');
    });

    it('should use custom organization name', () => {
      const result = generateOrganizationJsonLd('https://example.com', 'Custom TCAD') as any;

      expect(result.name).toBe('Custom TCAD');
    });

    it('should include description', () => {
      const result = generateOrganizationJsonLd() as any;

      expect(result.description).toBeDefined();
      expect(typeof result.description).toBe('string');
    });
  });

  describe('generateBreadcrumbJsonLd', () => {
    it('should generate valid BreadcrumbList JSON-LD', () => {
      const items = [
        { name: 'Home', url: '/' },
        { name: 'Properties', url: '/properties' },
        { name: 'Details' }
      ];

      const result = generateBreadcrumbJsonLd(items) as any;

      expect(result['@context']).toBe('https://schema.org');
      expect(result['@type']).toBe('BreadcrumbList');
      expect(result.itemListElement).toHaveLength(3);
    });

    it('should set correct position for each item', () => {
      const items = [
        { name: 'Home', url: '/' },
        { name: 'Properties', url: '/properties' }
      ];

      const result = generateBreadcrumbJsonLd(items) as any;

      expect(result.itemListElement[0].position).toBe(1);
      expect(result.itemListElement[1].position).toBe(2);
    });

    it('should include URLs when provided', () => {
      const items = [
        { name: 'Home', url: '/' },
        { name: 'Properties', url: '/properties' }
      ];

      const result = generateBreadcrumbJsonLd(items, 'https://example.com') as any;

      expect(result.itemListElement[0].item).toBe('https://example.com/');
      expect(result.itemListElement[1].item).toBe('https://example.com/properties');
    });

    it('should omit item field when URL not provided', () => {
      const items = [
        { name: 'Home', url: '/' },
        { name: 'Current Page' }
      ];

      const result = generateBreadcrumbJsonLd(items) as any;

      expect(result.itemListElement[0].item).toBeDefined();
      expect(result.itemListElement[1].item).toBeUndefined();
    });

    it('should handle empty items array', () => {
      const result = generateBreadcrumbJsonLd([]) as any;

      expect(result.itemListElement).toHaveLength(0);
    });
  });

  describe('generatePropertyCollectionJsonLd', () => {
    const mockProperties: PropertyAPI[] = [
      mockProperty,
      {
        ...mockProperty,
        propertyId: 'TEST-456',
        valuation: {
          appraisedValue: {
            value: 750000,
            currency: 'USD',
            formatted: '$750,000',
          },
        },
      },
    ];

    it('should generate valid CollectionPage JSON-LD', () => {
      const result = generatePropertyCollectionJsonLd(
        mockProperties,
        'Austin Properties',
        'city'
      ) as any;

      expect(result['@context']).toBe('https://schema.org');
      expect(result['@type']).toBe('CollectionPage');
      expect(result.name).toBe('Austin Properties');
    });

    it('should include correct number of items', () => {
      const result = generatePropertyCollectionJsonLd(
        mockProperties,
        'Austin Properties',
        'city'
      ) as any;

      expect(result.description).toBe('Collection of 2 properties');
      expect(result.mainEntity.numberOfItems).toBe(2);
    });

    it('should limit list items to 10', () => {
      const manyProperties = Array(15).fill(mockProperty).map((p, i) => ({
        ...p,
        propertyId: `TEST-${i}`,
      }));

      const result = generatePropertyCollectionJsonLd(
        manyProperties,
        'Large Collection',
        'custom'
      ) as any;

      expect(result.mainEntity.itemListElement).toHaveLength(10);
    });

    it('should calculate aggregate statistics correctly', () => {
      const result = generatePropertyCollectionJsonLd(
        mockProperties,
        'Austin Properties',
        'city'
      ) as any;

      expect(result.aggregateRating).toMatchObject({
        '@type': 'AggregateOffer',
        lowPrice: 500000,
        highPrice: 750000,
        priceCurrency: 'USD',
        offerCount: 2,
        averagePrice: 625000,
      });
    });

    it('should include city metadata for city collections', () => {
      const result = generatePropertyCollectionJsonLd(
        mockProperties,
        'Austin',
        'city'
      ) as any;

      expect(result.about).toEqual({
        '@type': 'City',
        name: 'Austin',
      });
    });

    it('should omit city metadata for non-city collections', () => {
      const result = generatePropertyCollectionJsonLd(
        mockProperties,
        'Residential',
        'type'
      ) as any;

      expect(result.about).toBeUndefined();
    });

    it('should include modification date', () => {
      const result = generatePropertyCollectionJsonLd(
        mockProperties,
        'Test Collection',
        'custom'
      ) as any;

      expect(result.dateModified).toBeDefined();
      expect(new Date(result.dateModified)).toBeInstanceOf(Date);
    });

    it('should include item URLs', () => {
      const result = generatePropertyCollectionJsonLd(
        mockProperties,
        'Austin Properties',
        'city',
        'https://example.com'
      ) as any;

      expect(result.mainEntity.itemListElement[0].item.url).toBe(
        'https://example.com/properties/TEST-123'
      );
    });
  });

  describe('injectJsonLdScript', () => {
    it('should generate valid script tag', () => {
      const jsonLd = {
        '@context': 'https://schema.org',
        '@type': 'WebSite',
        name: 'Test',
      };

      const result = injectJsonLdScript(jsonLd);

      expect(result).toContain('<script type="application/ld+json">');
      expect(result).toContain('</script>');
    });

    it('should include properly formatted JSON', () => {
      const jsonLd = {
        '@context': 'https://schema.org',
        '@type': 'WebSite',
        name: 'Test',
      };

      const result = injectJsonLdScript(jsonLd);

      expect(result).toContain('"@context": "https://schema.org"');
      expect(result).toContain('"@type": "WebSite"');
      expect(result).toContain('"name": "Test"');
    });

    it('should handle complex nested objects', () => {
      const jsonLd = {
        '@context': 'https://schema.org',
        '@type': 'RealEstateListing',
        address: {
          '@type': 'PostalAddress',
          streetAddress: '123 Main St',
        },
      };

      const result = injectJsonLdScript(jsonLd);

      expect(result).toContain('PostalAddress');
      expect(result).toContain('123 Main St');
    });
  });

  describe('generatePageJsonLd', () => {
    it('should generate property page scripts', () => {
      const result = generatePageJsonLd('property', mockProperty);

      expect(result).toHaveLength(2);
      expect(result[0]).toContain('RealEstateListing');
      expect(result[1]).toContain('BreadcrumbList');
    });

    it('should generate listing page scripts', () => {
      const data: PaginatedPropertyResponse = {
        results: [mockProperty],
        pagination: {
          total: 1,
          offset: 0,
          limit: 20,
          hasMore: false,
        },
      };

      const result = generatePageJsonLd('listing', data);

      expect(result).toHaveLength(2);
      expect(result[0]).toContain('ItemList');
      expect(result[1]).toContain('BreadcrumbList');
    });

    it('should generate home page scripts', () => {
      const result = generatePageJsonLd('home', null);

      expect(result).toHaveLength(1);
      expect(result[0]).toContain('WebSite');
    });

    it('should include proper breadcrumbs for property page', () => {
      const result = generatePageJsonLd('property', mockProperty);

      expect(result[1]).toContain('Home');
      expect(result[1]).toContain('Properties');
      expect(result[1]).toContain('123 Main St');
    });

    it('should include proper breadcrumbs for listing page', () => {
      const data: PaginatedPropertyResponse = {
        results: [mockProperty],
        pagination: {
          total: 1,
          offset: 0,
          limit: 20,
          hasMore: false,
        },
      };

      const result = generatePageJsonLd('listing', data);

      expect(result[1]).toContain('Search Results');
    });

    it('should use custom website URL', () => {
      const result = generatePageJsonLd('home', null, 'https://custom.com');

      expect(result[0]).toContain('https://custom.com');
    });
  });

  describe('validateJsonLd', () => {
    it('should return no errors for valid JSON-LD', () => {
      const validJsonLd = {
        '@context': 'https://schema.org',
        '@type': 'WebSite',
        name: 'Test',
      };

      const errors = validateJsonLd(validJsonLd);

      expect(errors).toHaveLength(0);
    });

    it('should detect missing @context', () => {
      const invalidJsonLd = {
        '@type': 'WebSite',
        name: 'Test',
      };

      const errors = validateJsonLd(invalidJsonLd);

      expect(errors).toContain('Missing @context field');
    });

    it('should detect missing @type', () => {
      const invalidJsonLd = {
        '@context': 'https://schema.org',
        name: 'Test',
      };

      const errors = validateJsonLd(invalidJsonLd);

      expect(errors).toContain('Missing @type field');
    });

    it('should validate RealEstateListing requires address', () => {
      const invalidJsonLd = {
        '@context': 'https://schema.org',
        '@type': 'RealEstateListing',
        name: 'Test Property',
      };

      const errors = validateJsonLd(invalidJsonLd);

      expect(errors).toContain('RealEstateListing requires address field');
    });

    it('should validate RealEstateListing requires offers or price', () => {
      const invalidJsonLd = {
        '@context': 'https://schema.org',
        '@type': 'RealEstateListing',
        address: {
          '@type': 'PostalAddress',
          streetAddress: '123 Main St',
        },
      };

      const errors = validateJsonLd(invalidJsonLd);

      expect(errors).toContain('RealEstateListing requires offers or price field');
    });

    it('should validate PostalAddress requires streetAddress', () => {
      const invalidJsonLd = {
        '@context': 'https://schema.org',
        '@type': 'Thing',
        address: {
          '@type': 'PostalAddress',
          addressLocality: 'Austin',
        },
      };

      const errors = validateJsonLd(invalidJsonLd);

      expect(errors).toContain('PostalAddress requires streetAddress');
    });

    it('should validate PostalAddress requires locality or region', () => {
      const invalidJsonLd = {
        '@context': 'https://schema.org',
        '@type': 'Thing',
        address: {
          '@type': 'PostalAddress',
          streetAddress: '123 Main St',
        },
      };

      const errors = validateJsonLd(invalidJsonLd);

      expect(errors).toContain('PostalAddress requires addressLocality or addressRegion');
    });

    it('should accept valid RealEstateListing with price instead of offers', () => {
      const validJsonLd = {
        '@context': 'https://schema.org',
        '@type': 'RealEstateListing',
        address: {
          '@type': 'PostalAddress',
          streetAddress: '123 Main St',
          addressLocality: 'Austin',
        },
        price: 500000,
      };

      const errors = validateJsonLd(validJsonLd);

      expect(errors).not.toContain('RealEstateListing requires offers or price field');
    });

    it('should handle array @type with RealEstateListing', () => {
      const jsonLd = {
        '@context': 'https://schema.org',
        '@type': ['Place', 'RealEstateListing'],
        name: 'Test',
      };

      const errors = validateJsonLd(jsonLd);

      expect(errors).toContain('RealEstateListing requires address field');
    });

    it('should accumulate multiple errors', () => {
      const invalidJsonLd = {
        name: 'Test',
      };

      const errors = validateJsonLd(invalidJsonLd);

      expect(errors.length).toBeGreaterThanOrEqual(2);
      expect(errors).toContain('Missing @context field');
      expect(errors).toContain('Missing @type field');
    });
  });
});
</file>

<file path="utils/deduplication.ts">
import { scraperQueue } from '../queues/scraper.queue';
import { prisma } from '../lib/prisma';
import logger from '../lib/logger';

interface DeduplicationOptions {
  verbose?: boolean;
  showProgress?: boolean;
}

export async function removeDuplicatesFromQueue(options: DeduplicationOptions = {}) {
  const { verbose = true, showProgress = true } = options;

  if (verbose) {
    logger.info(' Now checking for duplicates...\n');
  }

  // Get all pending jobs (waiting + delayed)
  const [waitingJobs, delayedJobs] = await Promise.all([
    scraperQueue.getWaiting(),
    scraperQueue.getDelayed(),
  ]);

  const allPendingJobs = [...waitingJobs, ...delayedJobs];

  if (verbose) {
    logger.info(` Queue State:`);
    logger.info(`   Waiting: ${waitingJobs.length}`);
    logger.info(`   Delayed: ${delayedJobs.length}`);
    logger.info(`   Total Pending: ${allPendingJobs.length}\n`);
  }

  // Get completed search terms from database
  const completedTerms = await prisma.scrapeJob.findMany({
    where: { status: 'completed' },
    select: { searchTerm: true },
    distinct: ['searchTerm'],
  });

  const completedTermSet = new Set(completedTerms.map(j => j.searchTerm));

  // Track search terms and their job IDs
  const termMap = new Map<string, Array<{ job: any; priority: number; state: string }>>();

  // Build map of search terms to jobs
  for (const job of allPendingJobs) {
    const term = job.data.searchTerm;
    let state = 'waiting';
    if (delayedJobs.includes(job)) state = 'delayed';

    if (!termMap.has(term)) {
      termMap.set(term, []);
    }
    termMap.get(term)!.push({
      job,
      priority: job.opts.priority || 10,
      state
    });
  }

  // Find duplicates within pending jobs
  const duplicateTerms = Array.from(termMap.entries())
    .filter(([_, jobs]) => jobs.length > 1);

  // Find jobs that were already completed
  const alreadyCompletedTerms = Array.from(termMap.entries())
    .filter(([term, _]) => completedTermSet.has(term));

  if (verbose) {
    logger.info(` Analysis:`);
    logger.info(`   Unique pending terms: ${termMap.size}`);
    logger.info(`    Terms with duplicate pending jobs: ${duplicateTerms.length}`);
    logger.info(`    Terms already completed: ${alreadyCompletedTerms.length}`);
  }

  let totalToRemove = 0;

  // Count duplicates
  for (const [_, jobs] of duplicateTerms) {
    totalToRemove += jobs.length - 1; // Keep one
  }

  // Count already completed
  for (const [_, jobs] of alreadyCompletedTerms) {
    totalToRemove += jobs.length; // Remove all
  }

  if (verbose) {
    logger.info(`     Total jobs to remove: ${totalToRemove}\n`);
  }

  if (totalToRemove === 0) {
    if (verbose) {
      logger.info(' No duplicates or completed terms found!');
    }
    return { removed: 0, failed: 0 };
  }

  // Show what we're removing
  if (verbose) {
    if (duplicateTerms.length > 0) {
      logger.info(' Duplicate pending jobs:');
      const displayCount = showProgress ? 10 : duplicateTerms.length;
      duplicateTerms.slice(0, displayCount).forEach(([term, jobs]) => {
        logger.info(`   "${term}": ${jobs.length} copies (keeping 1, removing ${jobs.length - 1})`);
      });
      if (duplicateTerms.length > displayCount) {
        logger.info(`   ... and ${duplicateTerms.length - displayCount} more`);
      }
      logger.info('');
    }

    if (alreadyCompletedTerms.length > 0) {
      logger.info(' Already completed terms in queue:');
      const displayCount = showProgress ? 20 : alreadyCompletedTerms.length;
      alreadyCompletedTerms.slice(0, displayCount).forEach(([term, jobs]) => {
        logger.info(`   "${term}": ${jobs.length} pending (removing all)`);
      });
      if (alreadyCompletedTerms.length > displayCount) {
        logger.info(`   ... and ${alreadyCompletedTerms.length - displayCount} more`);
      }
      logger.info('');
    }

    logger.info(` Removing ${totalToRemove} duplicate/completed jobs...`);
  }

  let removed = 0;
  let failed = 0;

  // Remove duplicates (keep highest priority)
  for (const [term, jobs] of duplicateTerms) {
    // Sort by priority (lower number = higher priority)
    jobs.sort((a, b) => a.priority - b.priority);

    // Remove all but the first (highest priority) job
    for (let i = 1; i < jobs.length; i++) {
      try {
        await jobs[i].job.remove();
        removed++;
        if (showProgress && removed % 10 === 0) {
          process.stdout.write(`\r   Progress: ${removed}/${totalToRemove} (${((removed/totalToRemove)*100).toFixed(1)}%)`);
        }
      } catch (error: any) {
        failed++;
        if (verbose && failed <= 3) {
          logger.error(`${showProgress ? '\n' : ''}    Failed to remove job ${jobs[i].job.id}:`, error.message);
        }
      }
    }
  }

  // Remove already completed terms
  for (const [term, jobs] of alreadyCompletedTerms) {
    for (const jobInfo of jobs) {
      try {
        await jobInfo.job.remove();
        removed++;
        if (showProgress && removed % 10 === 0) {
          process.stdout.write(`\r   Progress: ${removed}/${totalToRemove} (${((removed/totalToRemove)*100).toFixed(1)}%)`);
        }
      } catch (error: any) {
        failed++;
        if (verbose && failed <= 3) {
          logger.error(`${showProgress ? '\n' : ''}    Failed to remove job ${jobInfo.job.id}:`, error.message);
        }
      }
    }
  }

  if (verbose) {
    if (showProgress) {
      logger.info(''); // New line after progress
    }
    logger.info(`\n Cleanup complete!`);
    logger.info(`   - Successfully removed: ${removed}`);
    logger.info(`   - Failed to remove: ${failed}`);
  }

  return { removed, failed };
}
</file>

<file path="utils/json-ld.utils.ts">
/**
 * JSON-LD Structured Data Utilities for TCAD Properties
 *
 * This module provides utilities to generate Schema.org compliant JSON-LD
 * structured data for maximum SEO value. It supports various contexts including
 * individual property pages, property listings, and search results.
 *
 * @see https://schema.org/RealEstateListing
 * @see https://developers.google.com/search/docs/appearance/structured-data
 */

import { PropertyAPI, PropertyDatabase, PaginatedPropertyResponse } from '../types/property.types';

// ============================================================================
// Type Definitions for JSON-LD
// ============================================================================

interface JsonLdBase {
  '@context': 'https://schema.org';
  '@type': string | string[];
  '@id'?: string;
}

interface BreadcrumbItem {
  '@type': 'ListItem';
  position: number;
  name: string;
  item?: string;
}

interface SearchAction {
  '@type': 'SearchAction';
  target: {
    '@type': 'EntryPoint';
    urlTemplate: string;
  };
  'query-input': string;
}

// ============================================================================
// Individual Property JSON-LD
// ============================================================================

/**
 * Generate JSON-LD for a single property detail page
 * This provides the most comprehensive structured data for SEO
 */
export function generatePropertyJsonLd(
  property: PropertyAPI,
  organizationName = 'Travis County Appraisal District',
  websiteUrl = 'https://example.com'
): object {
  const jsonLd: any = {
    '@context': 'https://schema.org',
    '@type': property['@type'] || 'RealEstateListing',
    '@id': `${websiteUrl}/properties/${property.propertyId}`,

    // Core property information
    identifier: property.propertyId,
    name: `${property.address.formatted} - TCAD Property`,
    description: property.legalDescription ||
      `${property.propertyType} property located at ${property.address.formatted}`,

    // Address with full PostalAddress structure
    address: {
      '@type': 'PostalAddress',
      streetAddress: property.address.streetAddress,
      addressLocality: property.address.addressLocality,
      addressRegion: property.address.addressRegion,
      addressCountry: property.address.addressCountry,
      postalCode: property.address.postalCode
    },

    // Geographic coordinates if available
    ...(property.geography?.latitude && property.geography?.longitude && {
      geo: {
        '@type': 'GeoCoordinates',
        latitude: property.geography.latitude,
        longitude: property.geography.longitude
      }
    }),

    // Property type categorization
    additionalType: property.propertyType,

    // Owner/Seller information
    ...(property.owner && {
      seller: {
        '@type': property.owner['@type'] || 'Person',
        name: property.owner.name
      }
    }),

    // Pricing and valuation
    offers: {
      '@type': 'Offer',
      price: property.valuation.appraisedValue.value,
      priceCurrency: property.valuation.appraisedValue.currency,

      // Additional price specifications
      priceSpecification: [
        {
          '@type': 'PriceSpecification',
          price: property.valuation.appraisedValue.value,
          priceCurrency: property.valuation.appraisedValue.currency,
          name: 'Appraised Value',
          description: 'Market value as determined by TCAD'
        },
        ...(property.valuation.assessedValue ? [{
          '@type': 'PriceSpecification',
          price: property.valuation.assessedValue.value,
          priceCurrency: property.valuation.assessedValue.currency,
          name: 'Assessed Value',
          description: 'Tax assessed value for property tax calculations'
        }] : [])
      ],

      // Seller/offerer information
      seller: {
        '@type': 'Organization',
        name: organizationName,
        url: websiteUrl
      },

      // Validity dates based on data freshness
      validFrom: property.metadata.scrapedAt,
      ...(property.metadata.dataFreshness === 'stale' && {
        validThrough: new Date(Date.now() + 30 * 24 * 60 * 60 * 1000).toISOString()
      })
    },

    // Additional property details
    ...(property.geography?.neighborhood && {
      containedInPlace: {
        '@type': 'Place',
        name: property.geography.neighborhood
      }
    }),

    // Data provider information
    provider: {
      '@type': 'Organization',
      name: organizationName,
      url: websiteUrl,
      sameAs: [
        'https://www.traviscad.org'
      ]
    },

    // Metadata
    datePosted: property.metadata.createdAt,
    dateModified: property.metadata.updatedAt,

    // Potential actions
    potentialAction: [
      {
        '@type': 'ViewAction',
        target: `${websiteUrl}/properties/${property.propertyId}`,
        name: 'View Property Details'
      }
    ]
  };

  return jsonLd;
}

// ============================================================================
// Property Listing/Search Results JSON-LD
// ============================================================================

/**
 * Generate JSON-LD for a property listing or search results page
 * Implements ItemList for better search result presentation
 */
export function generatePropertyListJsonLd(
  response: PaginatedPropertyResponse,
  searchQuery?: string,
  websiteUrl = 'https://example.com'
): object {
  const jsonLd = {
    '@context': 'https://schema.org',
    '@type': 'ItemList',
    name: searchQuery
      ? `Property Search Results for "${searchQuery}"`
      : 'Travis County Properties',
    description: `Browse ${response.pagination.total} properties in Travis County`,
    numberOfItems: response.pagination.total,

    // Individual property items
    itemListElement: response.results.map((property, index) => ({
      '@type': 'ListItem',
      position: response.pagination.offset + index + 1,
      item: {
        '@type': property['@type'] || 'RealEstateListing',
        '@id': `${websiteUrl}/properties/${property.propertyId}`,
        identifier: property.propertyId,
        name: property.address.formatted,
        description: `${property.propertyType} - ${property.valuation.appraisedValue.formatted}`,

        address: {
          '@type': 'PostalAddress',
          streetAddress: property.address.streetAddress,
          addressLocality: property.address.addressLocality,
          addressRegion: property.address.addressRegion,
          addressCountry: property.address.addressCountry
        },

        offers: {
          '@type': 'Offer',
          price: property.valuation.appraisedValue.value,
          priceCurrency: property.valuation.appraisedValue.currency
        },

        url: `${websiteUrl}/properties/${property.propertyId}`
      }
    })),

    // Pagination information
    ...(response.pagination.hasMore && {
      nextItem: `${websiteUrl}/search?offset=${response.pagination.offset + response.pagination.limit}`
    }),

    // Search action for the listing
    potentialAction: {
      '@type': 'SearchAction',
      target: {
        '@type': 'EntryPoint',
        urlTemplate: `${websiteUrl}/search?q={search_term_string}`
      },
      'query-input': 'required name=search_term_string'
    }
  };

  return jsonLd;
}

// ============================================================================
// Website/Organization JSON-LD
// ============================================================================

/**
 * Generate JSON-LD for the website/organization
 * Should be included on the homepage
 */
export function generateOrganizationJsonLd(
  websiteUrl = 'https://example.com',
  organizationName = 'TCAD Property Search'
): object {
  return {
    '@context': 'https://schema.org',
    '@type': 'WebSite',
    '@id': websiteUrl,
    name: organizationName,
    description: 'Search and browse Travis County Appraisal District property records',
    url: websiteUrl,

    // Publisher/operator
    publisher: {
      '@type': 'Organization',
      name: organizationName,
      url: websiteUrl,
      logo: {
        '@type': 'ImageObject',
        url: `${websiteUrl}/logo.png`,
        width: 600,
        height: 60
      }
    },

    // Site search box
    potentialAction: {
      '@type': 'SearchAction',
      target: {
        '@type': 'EntryPoint',
        urlTemplate: `${websiteUrl}/search?q={search_term_string}`
      },
      'query-input': 'required name=search_term_string'
    },

    // Related entities
    about: {
      '@type': 'Thing',
      name: 'Travis County Property Records',
      description: 'Official property appraisal and tax assessment records for Travis County, Texas'
    },

    // Geographic service area
    areaServed: {
      '@type': 'AdministrativeArea',
      name: 'Travis County',
      containedInPlace: {
        '@type': 'State',
        name: 'Texas',
        containedInPlace: {
          '@type': 'Country',
          name: 'United States'
        }
      }
    }
  };
}

// ============================================================================
// Breadcrumb JSON-LD
// ============================================================================

/**
 * Generate breadcrumb JSON-LD for navigation
 */
export function generateBreadcrumbJsonLd(
  items: Array<{ name: string; url?: string }>,
  websiteUrl = 'https://example.com'
): object {
  return {
    '@context': 'https://schema.org',
    '@type': 'BreadcrumbList',
    itemListElement: items.map((item, index) => ({
      '@type': 'ListItem',
      position: index + 1,
      name: item.name,
      ...(item.url && {
        item: `${websiteUrl}${item.url}`
      })
    }))
  };
}

// ============================================================================
// Property Collection JSON-LD
// ============================================================================

/**
 * Generate JSON-LD for a collection of properties (e.g., by city or type)
 */
export function generatePropertyCollectionJsonLd(
  properties: PropertyAPI[],
  collectionName: string,
  collectionType: 'city' | 'type' | 'custom',
  websiteUrl = 'https://example.com'
): object {
  const totalValue = properties.reduce(
    (sum, p) => sum + p.valuation.appraisedValue.value,
    0
  );

  const avgValue = totalValue / properties.length;

  return {
    '@context': 'https://schema.org',
    '@type': 'CollectionPage',
    name: collectionName,
    description: `Collection of ${properties.length} properties`,

    // Main entity of the page
    mainEntity: {
      '@type': 'ItemList',
      numberOfItems: properties.length,
      itemListElement: properties.slice(0, 10).map((property, index) => ({
        '@type': 'ListItem',
        position: index + 1,
        item: {
          '@type': property['@type'] || 'RealEstateListing',
          identifier: property.propertyId,
          name: property.address.formatted,
          offers: {
            '@type': 'Offer',
            price: property.valuation.appraisedValue.value,
            priceCurrency: property.valuation.appraisedValue.currency
          },
          url: `${websiteUrl}/properties/${property.propertyId}`
        }
      }))
    },

    // Aggregate statistics
    aggregateRating: {
      '@type': 'AggregateOffer',
      lowPrice: Math.min(...properties.map(p => p.valuation.appraisedValue.value)),
      highPrice: Math.max(...properties.map(p => p.valuation.appraisedValue.value)),
      priceCurrency: 'USD',
      offerCount: properties.length,
      averagePrice: avgValue
    },

    // Collection metadata
    ...(collectionType === 'city' && {
      about: {
        '@type': 'City',
        name: collectionName
      }
    }),

    dateModified: new Date().toISOString()
  };
}

// ============================================================================
// Helper Functions
// ============================================================================

/**
 * Inject JSON-LD script into HTML head
 */
export function injectJsonLdScript(jsonLd: object): string {
  return `<script type="application/ld+json">
${JSON.stringify(jsonLd, null, 2)}
</script>`;
}

/**
 * Generate multiple JSON-LD scripts for a page
 */
export function generatePageJsonLd(
  type: 'property' | 'listing' | 'home',
  data: any,
  websiteUrl = 'https://example.com'
): string[] {
  const scripts: string[] = [];

  switch (type) {
    case 'property':
      // Individual property page
      scripts.push(injectJsonLdScript(generatePropertyJsonLd(data, undefined, websiteUrl)));
      scripts.push(injectJsonLdScript(generateBreadcrumbJsonLd([
        { name: 'Home', url: '/' },
        { name: 'Properties', url: '/properties' },
        { name: data.address.shortFormat }
      ], websiteUrl)));
      break;

    case 'listing':
      // Property listing/search results
      scripts.push(injectJsonLdScript(generatePropertyListJsonLd(data, undefined, websiteUrl)));
      scripts.push(injectJsonLdScript(generateBreadcrumbJsonLd([
        { name: 'Home', url: '/' },
        { name: 'Search Results' }
      ], websiteUrl)));
      break;

    case 'home':
      // Homepage
      scripts.push(injectJsonLdScript(generateOrganizationJsonLd(websiteUrl)));
      break;
  }

  return scripts;
}

/**
 * Validate JSON-LD structure
 * Returns validation errors if any
 */
export function validateJsonLd(jsonLd: any): string[] {
  const errors: string[] = [];

  // Check for required @context
  if (!jsonLd['@context']) {
    errors.push('Missing @context field');
  }

  // Check for required @type
  if (!jsonLd['@type']) {
    errors.push('Missing @type field');
  }

  // Validate RealEstateListing specific fields
  if (jsonLd['@type'] === 'RealEstateListing' ||
      (Array.isArray(jsonLd['@type']) && jsonLd['@type'].includes('RealEstateListing'))) {
    if (!jsonLd.address) {
      errors.push('RealEstateListing requires address field');
    }
    if (!jsonLd.offers && !jsonLd.price) {
      errors.push('RealEstateListing requires offers or price field');
    }
  }

  // Validate PostalAddress
  if (jsonLd.address && jsonLd.address['@type'] === 'PostalAddress') {
    if (!jsonLd.address.streetAddress) {
      errors.push('PostalAddress requires streetAddress');
    }
    if (!jsonLd.address.addressLocality && !jsonLd.address.addressRegion) {
      errors.push('PostalAddress requires addressLocality or addressRegion');
    }
  }

  return errors;
}

export default {
  generatePropertyJsonLd,
  generatePropertyListJsonLd,
  generateOrganizationJsonLd,
  generateBreadcrumbJsonLd,
  generatePropertyCollectionJsonLd,
  generatePageJsonLd,
  validateJsonLd,
  injectJsonLdScript
};
</file>

<file path="utils/README_ENHANCED.md">
# utils

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "SoftwareSourceCode",
  "name": "utils",
  "description": "Directory containing 2 code files with 4 classes and 1 functions",
  "programmingLanguage": [
    {
      "@type": "ComputerLanguage",
      "name": "Typescript"
    }
  ],
  "featureList": [
    "4 class definitions",
    "1 function definitions"
  ]
}
</script>

## Overview

This directory contains 2 code file(s) with extracted schemas.

## Subdirectories

- `__tests__/`

## Files and Schemas

### `deduplication.ts` (typescript)

**Classes:**
- `DeduplicationOptions` - Line 4

**Functions:**
- `async removeDuplicatesFromQueue()` - Line 9

### `json-ld.utils.ts` (typescript)

**Classes:**
- `JsonLdBase` - Line 17
- `BreadcrumbItem` - Line 23
- `SearchAction` - Line 30

---
*Generated by Enhanced Schema Generator with schema.org markup*
</file>

<file path="index.ts">
import express from 'express';
import cors from 'cors';
import helmet from 'helmet';
import rateLimit from 'express-rate-limit';
import { createBullBoard } from '@bull-board/api';
import { BullAdapter } from '@bull-board/api/bullAdapter';
import { ExpressAdapter } from '@bull-board/express';
import swaggerUi from 'swagger-ui-express';
import { swaggerSpec } from './config/swagger';

import { config, validateConfig, logConfigSummary } from './config';
import { scraperQueue } from './queues/scraper.queue';
import { propertyRouter } from './routes/property.routes';
import { scheduledJobs } from './schedulers/scrape-scheduler';
import { optionalAuth } from './middleware/auth';
import { nonceMiddleware } from './middleware/xcontroller.middleware';
import { appRouter } from './routes/app.routes';
import { tokenRefreshService } from './services/token-refresh.service';
import { cacheService } from './lib/redis-cache.service';
import logger from './lib/logger';
import {
  initializeSentry,
  sentryRequestHandler,
  sentryTracingHandler,
  sentryErrorHandler,
  flush as sentryFlush,
  getHealth as getSentryHealth,
} from './lib/sentry.service';
import { metricsMiddleware } from './middleware/metrics.middleware';
import { getMetrics, updateQueueMetrics } from './lib/metrics.service';
import { startPeriodicAnalysis, stopPeriodicAnalysis } from './services/code-complexity.service';

// Initialize Sentry (must be first)
initializeSentry();

// Validate configuration
validateConfig();

// Log configuration summary
logConfigSummary();

// Create Express app
const app = express();

// Sentry request handler MUST be the first middleware
app.use(sentryRequestHandler());

// Sentry tracing handler (for performance monitoring)
app.use(sentryTracingHandler());

// Add nonce generation for all requests (used by CSP in frontend routes)
app.use(nonceMiddleware);

// Security middleware - exclude Bull Board dashboard from CSP
app.use((req, res, next) => {
  // Skip CSP for Bull Board dashboard
  if (req.path.startsWith(config.queue.dashboard.basePath)) {
    return next();
  }

  helmet({
    crossOriginResourcePolicy: { policy: config.security.helmet.crossOriginResourcePolicy as any },
    hsts: config.security.helmet.enableHsts,
    crossOriginOpenerPolicy: config.security.helmet.enableCoop,
    contentSecurityPolicy: config.security.helmet.enableCsp,
    originAgentCluster: config.security.helmet.enableOriginAgentCluster,
  })(req, res, next);
});

// CORS configuration
const allowedOrigins = config.frontend.url
  ? [...config.cors.allowedOrigins, config.frontend.url]
  : config.cors.allowedOrigins;

app.use(cors({
  origin: (origin, callback) => {
    // Allow requests with no origin (like mobile apps or curl requests)
    if (!origin && config.cors.allowNoOrigin) return callback(null, true);

    if (allowedOrigins.includes(origin as string)) {
      callback(null, true);
    } else {
      callback(new Error('Not allowed by CORS'));
    }
  },
  credentials: config.cors.credentials,
}));

// Body parsing middleware
app.use(express.json());
app.use(express.urlencoded({ extended: true }));

// Prometheus metrics middleware
app.use(metricsMiddleware);

// Rate limiting for API endpoints
const apiLimiter = rateLimit({
  windowMs: config.rateLimit.api.windowMs,
  max: config.rateLimit.api.max,
  message: config.rateLimit.api.message,
});

app.use('/api/', apiLimiter);

// Rate limiting specifically for scraping endpoints
const scrapeLimiter = rateLimit({
  windowMs: config.rateLimit.scraper.windowMs,
  max: config.rateLimit.scraper.max,
  message: config.rateLimit.scraper.message,
});

app.use('/api/properties/scrape', scrapeLimiter);

// Bull Dashboard setup
if (config.queue.dashboard.enabled) {
  const serverAdapter = new ExpressAdapter();
  serverAdapter.setBasePath(config.queue.dashboard.basePath);

  createBullBoard({
    queues: [new BullAdapter(scraperQueue)],
    serverAdapter,
  });

  app.use(config.queue.dashboard.basePath, serverAdapter.getRouter());
  logger.info(`Bull Dashboard enabled at ${config.queue.dashboard.basePath}`);
}

// Swagger API Documentation
app.use('/api-docs', swaggerUi.serve, swaggerUi.setup(swaggerSpec, {
  customSiteTitle: 'TCAD Scraper API Docs',
  customCss: '.swagger-ui .topbar { display: none }',
  swaggerOptions: {
    persistAuthorization: true,
    displayRequestDuration: true,
    filter: true,
    syntaxHighlight: {
      activate: true,
      theme: 'monokai',
    },
  },
}));
logger.info('Swagger API documentation available at /api-docs');

// Health check endpoints (before other routes)

/**
 * @swagger
 * /health:
 *   get:
 *     summary: Basic health check
 *     description: Returns basic server health status and uptime
 *     tags: [Health]
 *     responses:
 *       200:
 *         description: Server is healthy
 *         content:
 *           application/json:
 *             schema:
 *               type: object
 *               properties:
 *                 status:
 *                   type: string
 *                   example: healthy
 *                 timestamp:
 *                   type: string
 *                   format: date-time
 *                 uptime:
 *                   type: number
 *                   description: Server uptime in seconds
 *                 environment:
 *                   type: string
 *                   example: production
 */
app.get('/health', (_req, res) => {
  res.json({
    status: 'healthy',
    timestamp: new Date().toISOString(),
    uptime: process.uptime(),
    environment: config.env.nodeEnv,
  });
});

/**
 * @swagger
 * /health/queue:
 *   get:
 *     summary: Queue health check
 *     description: Returns BullMQ queue health status and job counts
 *     tags: [Health]
 *     responses:
 *       200:
 *         description: Queue is healthy
 *         content:
 *           application/json:
 *             schema:
 *               type: object
 *               properties:
 *                 status:
 *                   type: string
 *                   example: healthy
 *                 queue:
 *                   type: object
 *                   properties:
 *                     name:
 *                       type: string
 *                       example: scraper-queue
 *                     waiting:
 *                       type: integer
 *                       description: Number of jobs waiting
 *                     active:
 *                       type: integer
 *                       description: Number of jobs currently processing
 *                     completed:
 *                       type: integer
 *                       description: Number of completed jobs
 *                     failed:
 *                       type: integer
 *                       description: Number of failed jobs
 *       500:
 *         description: Queue is unhealthy
 */
app.get('/health/queue', async (_req, res) => {
  try {
    const [waiting, active, completed, failed] = await Promise.all([
      scraperQueue.getWaitingCount(),
      scraperQueue.getActiveCount(),
      scraperQueue.getCompletedCount(),
      scraperQueue.getFailedCount(),
    ]);

    res.json({
      status: 'healthy',
      queue: {
        name: 'scraper-queue',
        waiting,
        active,
        completed,
        failed,
      },
    });
  } catch (error) {
    logger.error({ error }, 'Queue health check failed');
    res.status(500).json({
      status: 'unhealthy',
      error: 'Failed to get queue status',
    });
  }
});

/**
 * @swagger
 * /health/token:
 *   get:
 *     summary: Token refresh service health check
 *     description: Returns TCAD token refresh service health status and statistics
 *     tags: [Health]
 *     responses:
 *       200:
 *         description: Token service status
 *         content:
 *           application/json:
 *             schema:
 *               type: object
 *               properties:
 *                 status:
 *                   type: string
 *                   enum: [healthy, unhealthy]
 *                 tokenRefresh:
 *                   type: object
 *                   properties:
 *                     healthy:
 *                       type: boolean
 *                     lastRefresh:
 *                       type: string
 *                       format: date-time
 *                     nextRefresh:
 *                       type: string
 *                       format: date-time
 *                     successCount:
 *                       type: integer
 *                     failureCount:
 *                       type: integer
 *       500:
 *         description: Failed to get token status
 */
app.get('/health/token', async (_req, res) => {
  try {
    const health = tokenRefreshService.getHealth();
    const stats = tokenRefreshService.getStats();

    res.json({
      status: health.healthy ? 'healthy' : 'unhealthy',
      tokenRefresh: {
        ...health,
        ...stats,
      },
    });
  } catch (error) {
    logger.error({ error }, 'Token health check failed');
    res.status(500).json({
      status: 'unhealthy',
      error: 'Failed to get token status',
    });
  }
});

/**
 * @swagger
 * /health/cache:
 *   get:
 *     summary: Redis cache health check
 *     description: Returns Redis cache connection status and statistics
 *     tags: [Health]
 *     responses:
 *       200:
 *         description: Cache service status
 *         content:
 *           application/json:
 *             schema:
 *               type: object
 *               properties:
 *                 status:
 *                   type: string
 *                   enum: [healthy, unhealthy]
 *                 cache:
 *                   type: object
 *                   properties:
 *                     connected:
 *                       type: boolean
 *                     isConnected:
 *                       type: boolean
 *                     hits:
 *                       type: integer
 *                       description: Number of cache hits
 *                     misses:
 *                       type: integer
 *                       description: Number of cache misses
 *                     hitRate:
 *                       type: number
 *                       description: Cache hit rate percentage
 *       500:
 *         description: Failed to get cache status
 */
app.get('/health/cache', async (_req, res) => {
  try {
    const healthy = await cacheService.healthCheck();
    const stats = cacheService.getStats();

    res.json({
      status: healthy ? 'healthy' : 'unhealthy',
      cache: {
        connected: stats.isConnected,
        ...stats,
      },
    });
  } catch (error) {
    logger.error({ error }, 'Cache health check failed');
    res.status(500).json({
      status: 'unhealthy',
      error: 'Failed to get cache status',
    });
  }
});

/**
 * @swagger
 * /health/sentry:
 *   get:
 *     summary: Sentry error tracking health check
 *     description: Returns Sentry error tracking service health status
 *     tags: [Health]
 *     responses:
 *       200:
 *         description: Sentry service status
 *         content:
 *           application/json:
 *             schema:
 *               type: object
 *               properties:
 *                 status:
 *                   type: string
 *                   example: healthy
 *                 sentry:
 *                   type: object
 *                   properties:
 *                     enabled:
 *                       type: boolean
 *                     environment:
 *                       type: string
 *                     release:
 *                       type: string
 *       500:
 *         description: Failed to get Sentry status
 */
app.get('/health/sentry', (_req, res) => {
  try {
    const health = getSentryHealth();

    res.json({
      status: 'healthy',
      sentry: health,
    });
  } catch (error) {
    logger.error({ error }, 'Sentry health check failed');
    res.status(500).json({
      status: 'unhealthy',
      error: 'Failed to get Sentry status',
    });
  }
});

/**
 * @swagger
 * /metrics:
 *   get:
 *     summary: Prometheus metrics endpoint
 *     description: Returns application metrics in Prometheus format for scraping
 *     tags: [Monitoring]
 *     responses:
 *       200:
 *         description: Prometheus metrics
 *         content:
 *           text/plain:
 *             schema:
 *               type: string
 *               example: |
 *                 # HELP tcad_scraper_http_requests_total Total number of HTTP requests
 *                 # TYPE tcad_scraper_http_requests_total counter
 *                 tcad_scraper_http_requests_total{method="GET",route="/api/properties",status_code="200"} 42
 */
app.get('/metrics', async (_req, res) => {
  try {
    // Update queue metrics before returning
    const [waiting, active, completed, failed] = await Promise.all([
      scraperQueue.getWaitingCount(),
      scraperQueue.getActiveCount(),
      scraperQueue.getCompletedCount(),
      scraperQueue.getFailedCount(),
    ]);

    await updateQueueMetrics(waiting, active, completed, failed);

    // Get cache stats and update metrics
    const cacheStats = cacheService.getStats();
    const { updateCacheMetrics } = await import('./lib/metrics.service');
    updateCacheMetrics(cacheStats.hits, cacheStats.misses, 0); // Size not tracked yet

    // Return metrics in Prometheus format
    const metrics = await getMetrics();
    res.set('Content-Type', 'text/plain; version=0.0.4');
    res.send(metrics);
  } catch (error) {
    logger.error({ error }, 'Failed to generate metrics');
    res.status(500).send('Failed to generate metrics');
  }
});

// API Routes (with optional authentication)
app.use('/api/properties', optionalAuth, propertyRouter);

// Frontend app routes (with xcontroller security)
// This must come last to serve the SPA for all unmatched routes
app.use('/', appRouter);

// Sentry error handler MUST be before other error handlers
app.use(sentryErrorHandler());

// Error handling middleware
app.use((err: Error, _req: express.Request, res: express.Response, _next: express.NextFunction) => {
  logger.error({ err }, 'Unhandled error');

  res.status(500).json({
    error: 'Internal server error',
    message: config.env.isDevelopment ? err.message : undefined,
  });
});

// 404 handler
app.use((_req, res) => {
  res.status(404).json({ error: 'Route not found' });
});

// Start server
const server = app.listen(config.server.port, config.server.host, () => {
  logger.info(`Server running on http://${config.server.host}:${config.server.port}`);
  if (config.queue.dashboard.enabled) {
    logger.info(`Bull Dashboard available at http://${config.server.host}:${config.server.port}${config.queue.dashboard.basePath}`);
  }
  logger.info(`Environment: ${config.env.nodeEnv}`);

  // Initialize scheduled jobs
  scheduledJobs.initialize();

  // Start automatic token refresh if enabled
  if (config.scraper.autoRefreshToken) {
    logger.info('Starting TCAD token auto-refresh service...');

    if (config.scraper.tokenRefreshCron) {
      // Use cron schedule if provided
      tokenRefreshService.startAutoRefresh(config.scraper.tokenRefreshCron);
      logger.info(`Token refresh scheduled with cron: ${config.scraper.tokenRefreshCron}`);
    } else {
      // Use interval-based refresh
      tokenRefreshService.startAutoRefreshInterval(config.scraper.tokenRefreshInterval);
      logger.info(`Token refresh scheduled every ${config.scraper.tokenRefreshInterval / 60000} minutes`);
    }
  } else {
    logger.info('TCAD token auto-refresh is disabled');
  }

  // Start periodic code complexity analysis
  logger.info('Starting periodic code complexity analysis...');
  startPeriodicAnalysis({
    updateIntervalMs: 3600000, // 1 hour (configurable)
  });
  logger.info('Code complexity analysis will run every 1 hour');
});

// Graceful shutdown
process.on('SIGTERM', async () => {
  logger.info('SIGTERM signal received: closing HTTP server');

  server.close(() => {
    logger.info('HTTP server closed');
  });

  // Flush Sentry events before shutdown
  logger.info('Flushing Sentry events...');
  await sentryFlush(2000);

  // Close queue connections
  await scraperQueue.close();

  // Close scheduled jobs
  scheduledJobs.stop();

  // Cleanup token refresh service
  await tokenRefreshService.cleanup();

  // Stop code complexity analysis
  stopPeriodicAnalysis();

  process.exit(0);
});

process.on('SIGINT', async () => {
  logger.info('SIGINT signal received: closing HTTP server');

  server.close(() => {
    logger.info('HTTP server closed');
  });

  // Flush Sentry events before shutdown
  await sentryFlush(2000);

  await scraperQueue.close();
  scheduledJobs.stop();
  await tokenRefreshService.cleanup();
  stopPeriodicAnalysis();

  process.exit(0);
});

export default app;
</file>

<file path="README_ENHANCED.md">
# src

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "SoftwareSourceCode",
  "name": "src",
  "description": "Directory containing 3 code files with 0 classes and 3 functions",
  "programmingLanguage": [
    {
      "@type": "ComputerLanguage",
      "name": "Typescript"
    }
  ],
  "featureList": [
    "3 function definitions"
  ]
}
</script>

## Overview

This directory contains 3 code file(s) with extracted schemas.

## Subdirectories

- `__tests__/`
- `cli/`
- `config/`
- `controllers/`
- `examples/`
- `lib/`
- `middleware/`
- `queues/`
- `routes/`
- `schedulers/`
- `scripts/`
- `services/`
- `types/`
- `utils/`

## Files and Schemas

### `test-api-direct.ts` (typescript)

**Functions:**
- `async testApi()` - Line 1

### `test-api-discovery.ts` (typescript)

**Functions:**
- `async testApiDiscovery()` - Line 3

### `test-api-scraper.ts` (typescript)

**Functions:**
- `async testApiScraper()` - Line 3

---
*Generated by Enhanced Schema Generator with schema.org markup*
</file>

<file path="README.md">
# src

## Overview

This directory contains 3 code file(s) with extracted schemas.

## Subdirectories

- `lib/`
- `queues/`
- `routes/`
- `schedulers/`
- `types/`

## Files and Schemas

### `test-api-direct.ts` (typescript)

**Functions:**
- `testApi()` - Line 1

### `test-api-discovery.ts` (typescript)

**Functions:**
- `testApiDiscovery()` - Line 3

**Key Imports:** `./lib/tcad-scraper`

### `test-api-scraper.ts` (typescript)

**Functions:**
- `testApiScraper()` - Line 3

**Key Imports:** `./lib/tcad-scraper`

---
*Generated by Schema Generator*
</file>

<file path="test-api-direct.ts">
import logger from '../lib/logger';
async function testApi() {
  logger.info('Testing TCAD API directly...\n');

  // Step 1: Look up the office first (as the browser does)
  logger.info('1. Looking up office...');
  const officeLookupResponse = await fetch('https://prod-container.trueprodigyapi.com/trueprodigy/officelookup/travis.prodigycad.com');
  const officeLookup = await officeLookupResponse.json();
  logger.info(` Office: ${officeLookup.results.office}\n`);

  // Step 2: Get auth token
  logger.info('2. Getting auth token...');
  const authResponse = await fetch('https://prod-container.trueprodigyapi.com/trueprodigy/cadpublic/auth/token', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ office: officeLookup.results.office }),
  });

  const authData = await authResponse.json();
  const token = authData.user.token;
  logger.info(` Got token: ${token.substring(0, 50)}...\n`);

  // Step 3: Search for properties (exact format from API discovery with browser headers)
  logger.info('3. Searching for properties...');
  const searchResponse = await fetch('https://prod-container.trueprodigyapi.com/public/property/searchfulltext?page=1&pageSize=5', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Accept': 'application/json, text/plain, */*',
      'Accept-Language': 'en-US,en;q=0.9',
      'Authorization': `Bearer ${token}`,
      'Origin': 'https://travis.prodigycad.com',
      'Referer': 'https://travis.prodigycad.com/property-search',
      'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',
    },
    body: JSON.stringify({
      pYear: { operator: '=', value: '2025' },
      fullTextSearch: { operator: 'match', value: 'Willow' },
    }),
  });

  logger.info(`   Status: ${searchResponse.status}`);
  const searchData = await searchResponse.json();
  logger.info(` Total properties found: ${searchData.totalProperty?.propertyCount || 0}\n`);

  // Step 4: Show first property with all fields
  if (searchData.results && searchData.results.length > 0) {
    const firstProperty = searchData.results[0];
    logger.info('4. First property data:');
    logger.info(JSON.stringify(firstProperty, null, 2));

    logger.info('\n5. Key fields check:');
    logger.info(`   - Property ID: ${firstProperty.pid}`);
    logger.info(`   - Owner Name: ${firstProperty.displayName || firstProperty.ownerName || 'N/A'}`);
    logger.info(`   - City: ${firstProperty.situsCity || firstProperty.city || 'NOT FOUND'}`);
    logger.info(`   - Address: ${firstProperty.streetPrimary || firstProperty.situsAddress || firstProperty.situs || 'N/A'}`);
    logger.info(`   - Appraised Value: ${firstProperty.appraisedValue || firstProperty.marketValue || firstProperty.mktValue || firstProperty.totalAppraised || 'NOT FOUND'}`);
    logger.info(`   - Property Type: ${firstProperty.propType || 'N/A'}`);

    logger.info('\n6. All available keys in response:');
    logger.info(Object.keys(firstProperty).join(', '));
  } else {
    logger.info(' No results returned');
  }
}

testApi().catch(logger.error);
</file>

<file path="test-api-discovery.ts">
import { TCADScraper } from './lib/tcad-scraper';
import logger from '../lib/logger';

async function testApiDiscovery() {
  logger.info('Starting API discovery...');

  const scraper = new TCADScraper({
    headless: false, // Run with visible browser to see what's happening
  });

  try {
    await scraper.initialize();

    // Use the discoverApiEndpoint method via type assertion
    // @ts-ignore - accessing private method for testing
    await scraper.discoverApiEndpoint('Willow');

    logger.info('\n API discovery complete!');
  } catch (error) {
    logger.error(' API discovery failed:', error);
  } finally {
    await scraper.cleanup();
  }
}

testApiDiscovery();
</file>

<file path="test-api-scraper.ts">
import { TCADScraper } from './lib/tcad-scraper';
import logger from '../lib/logger';

async function testApiScraper() {
  logger.info('Testing API-based scraper...\n');

  const scraper = new TCADScraper({
    headless: true, // Run headless for speed
  });

  try {
    await scraper.initialize();

    logger.info('Scraping properties for "Willow"...');
    const properties = await scraper.scrapePropertiesViaAPI('Willow');

    logger.info(`\n Successfully scraped ${properties.length} properties\n`);

    if (properties.length > 0) {
      logger.info('First 3 properties:\n');
      properties.slice(0, 3).forEach((prop, index) => {
        logger.info(`Property ${index + 1}:`);
        logger.info(`  Property ID: ${prop.propertyId}`);
        logger.info(`  Owner: ${prop.name}`);
        logger.info(`  City: ${prop.city || 'NOT FOUND'}`);
        logger.info(`  Address: ${prop.propertyAddress}`);
        logger.info(`  Appraised Value: $${prop.appraisedValue.toLocaleString()}`);
        logger.info(`  Property Type: ${prop.propType}`);
        logger.info('');
      });

      // Check for city and appraised value coverage
      const withCity = properties.filter(p => p.city).length;
      const withValue = properties.filter(p => p.appraisedValue > 0).length;

      logger.info('\n Data Quality:');
      logger.info(`  Properties with city: ${withCity}/${properties.length} (${Math.round(withCity/properties.length*100)}%)`);
      logger.info(`  Properties with appraised value: ${withValue}/${properties.length} (${Math.round(withValue/properties.length*100)}%)`);
    }

  } catch (error) {
    logger.error('\n Test failed:', error);
  } finally {
    await scraper.cleanup();
  }
}

testApiScraper();
</file>

</files>
